{
  "per_prompt": [
    {
      "prompt_index": 0,
      "prompt": "Dwayne the Rock Johnson wrestles Jesus Christ in a WWE match in a hell in a cell.",
      "image_filenames": [
        "test_0_0.jpg",
        "test_0_1.jpg",
        "test_0_2.jpg",
        "test_0_3.jpg",
        "test_0_4.jpg",
        "test_0_5.jpg",
        "test_0_6.jpg",
        "test_0_7.jpg",
        "test_0_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          6,
          5,
          4,
          1,
          3,
          8,
          0,
          7
        ],
        "order_filenames": [
          "test_0_2.jpg",
          "test_0_6.jpg",
          "test_0_5.jpg",
          "test_0_4.jpg",
          "test_0_1.jpg",
          "test_0_3.jpg",
          "test_0_8.jpg",
          "test_0_0.jpg",
          "test_0_7.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_0_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_0_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_0_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1363525390625,
            0.205810546875,
            0.2415771484375,
            0.1578369140625,
            0.1463623046875,
            0.052886962890625,
            0.251708984375,
            0.18359375,
            0.2061767578125
          ],
          "order_indices": [
            6,
            2,
            8,
            1,
            7,
            3,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_0_6.jpg",
            "test_0_2.jpg",
            "test_0_8.jpg",
            "test_0_1.jpg",
            "test_0_7.jpg",
            "test_0_3.jpg",
            "test_0_4.jpg",
            "test_0_0.jpg",
            "test_0_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.33333333333333337,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.25,
            28.640625,
            38.25,
            27.671875,
            26.78125,
            9.078125,
            31.109375,
            41.5625,
            30.234375
          ],
          "order_indices": [
            7,
            2,
            0,
            6,
            8,
            1,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_0_7.jpg",
            "test_0_2.jpg",
            "test_0_0.jpg",
            "test_0_6.jpg",
            "test_0_8.jpg",
            "test_0_1.jpg",
            "test_0_3.jpg",
            "test_0_4.jpg",
            "test_0_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.2666666666666666,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.9942981004714966,
            -0.720634937286377,
            -0.3852250874042511,
            -1.7349274158477783,
            -2.138939619064331,
            -2.2789225578308105,
            -0.20074251294136047,
            0.10617314279079437,
            -1.4618257284164429
          ],
          "order_indices": [
            7,
            6,
            2,
            1,
            8,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_0_7.jpg",
            "test_0_6.jpg",
            "test_0_2.jpg",
            "test_0_1.jpg",
            "test_0_8.jpg",
            "test_0_3.jpg",
            "test_0_0.jpg",
            "test_0_4.jpg",
            "test_0_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.050000000000000044,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 1,
      "prompt": "An anime man in flight uniform with hyper detailed digital artwork and an art style inspired by Klimt, Nixeu, Ian Sprigger, Wlop, and Krenz Cushart.",
      "image_filenames": [
        "test_1_0.jpg",
        "test_1_1.jpg",
        "test_1_2.jpg",
        "test_1_3.jpg",
        "test_1_4.jpg",
        "test_1_5.jpg",
        "test_1_6.jpg",
        "test_1_7.jpg",
        "test_1_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          2,
          5,
          4,
          7,
          8,
          0,
          1,
          6
        ],
        "order_filenames": [
          "test_1_3.jpg",
          "test_1_2.jpg",
          "test_1_5.jpg",
          "test_1_4.jpg",
          "test_1_7.jpg",
          "test_1_8.jpg",
          "test_1_0.jpg",
          "test_1_1.jpg",
          "test_1_6.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_1_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_1_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2,
            4
          ],
          "winner_filenames": [
            "test_1_2.jpg",
            "test_1_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.191162109375,
            0.296142578125,
            0.2235107421875,
            0.244384765625,
            0.169189453125,
            0.107666015625,
            0.216552734375,
            0.214111328125,
            0.259033203125
          ],
          "order_indices": [
            1,
            8,
            3,
            2,
            6,
            7,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_1_1.jpg",
            "test_1_8.jpg",
            "test_1_3.jpg",
            "test_1_2.jpg",
            "test_1_6.jpg",
            "test_1_7.jpg",
            "test_1_0.jpg",
            "test_1_4.jpg",
            "test_1_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.3125,
            36.65625,
            39.1875,
            35.375,
            20.59375,
            19.8125,
            28.796875,
            43.28125,
            32.03125
          ],
          "order_indices": [
            7,
            0,
            2,
            1,
            3,
            8,
            6,
            4,
            5
          ],
          "order_filenames": [
            "test_1_7.jpg",
            "test_1_0.jpg",
            "test_1_2.jpg",
            "test_1_1.jpg",
            "test_1_3.jpg",
            "test_1_8.jpg",
            "test_1_6.jpg",
            "test_1_4.jpg",
            "test_1_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.08333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.9077937006950378,
            0.5251500606536865,
            0.44919073581695557,
            -0.8844466209411621,
            -0.386181503534317,
            -1.7542412281036377,
            -0.473177433013916,
            -0.7811758518218994,
            1.5016785860061646
          ],
          "order_indices": [
            8,
            0,
            1,
            2,
            4,
            6,
            7,
            3,
            5
          ],
          "order_filenames": [
            "test_1_8.jpg",
            "test_1_0.jpg",
            "test_1_1.jpg",
            "test_1_2.jpg",
            "test_1_4.jpg",
            "test_1_6.jpg",
            "test_1_7.jpg",
            "test_1_3.jpg",
            "test_1_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.4833333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 2,
      "prompt": "A Wojak looking over a sea of memes from a cliff on 4chan.",
      "image_filenames": [
        "test_2_0.jpg",
        "test_2_1.jpg",
        "test_2_2.jpg",
        "test_2_3.jpg",
        "test_2_4.jpg",
        "test_2_5.jpg",
        "test_2_6.jpg",
        "test_2_7.jpg",
        "test_2_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          3,
          4,
          2,
          5,
          6,
          8,
          1,
          7
        ],
        "order_filenames": [
          "test_2_0.jpg",
          "test_2_3.jpg",
          "test_2_4.jpg",
          "test_2_2.jpg",
          "test_2_5.jpg",
          "test_2_6.jpg",
          "test_2_8.jpg",
          "test_2_1.jpg",
          "test_2_7.jpg"
        ],
        "condorcet_winner": 0,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_2_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3,
            5
          ],
          "winner_filenames": [
            "test_2_3.jpg",
            "test_2_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_2_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.16845703125,
            0.213134765625,
            0.228271484375,
            0.19482421875,
            0.1937255859375,
            0.111572265625,
            0.201416015625,
            0.2344970703125,
            0.2108154296875
          ],
          "order_indices": [
            7,
            2,
            1,
            8,
            6,
            3,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_2_7.jpg",
            "test_2_2.jpg",
            "test_2_1.jpg",
            "test_2_8.jpg",
            "test_2_6.jpg",
            "test_2_3.jpg",
            "test_2_4.jpg",
            "test_2_0.jpg",
            "test_2_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5555555555555556,
            "spearman_rho": -0.6666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.25,
            36.0625,
            41.78125,
            33.6875,
            37.25,
            12.9609375,
            33.3125,
            42.1875,
            42.71875
          ],
          "order_indices": [
            8,
            7,
            2,
            0,
            4,
            1,
            3,
            6,
            5
          ],
          "order_filenames": [
            "test_2_8.jpg",
            "test_2_7.jpg",
            "test_2_2.jpg",
            "test_2_0.jpg",
            "test_2_4.jpg",
            "test_2_1.jpg",
            "test_2_3.jpg",
            "test_2_6.jpg",
            "test_2_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.2333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.14316917955875397,
            -0.775210440158844,
            -0.6211410760879517,
            -0.8286418914794922,
            -0.566189706325531,
            -2.275303363800049,
            0.7715835571289062,
            0.37062302231788635,
            0.5417124629020691
          ],
          "order_indices": [
            6,
            8,
            7,
            0,
            4,
            2,
            1,
            3,
            5
          ],
          "order_filenames": [
            "test_2_6.jpg",
            "test_2_8.jpg",
            "test_2_7.jpg",
            "test_2_0.jpg",
            "test_2_4.jpg",
            "test_2_2.jpg",
            "test_2_1.jpg",
            "test_2_3.jpg",
            "test_2_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.30000000000000004,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 3,
      "prompt": "Ralsei and Asriel from Deltarune eating pizza.",
      "image_filenames": [
        "test_3_0.jpg",
        "test_3_1.jpg",
        "test_3_2.jpg",
        "test_3_3.jpg",
        "test_3_4.jpg",
        "test_3_5.jpg",
        "test_3_6.jpg",
        "test_3_7.jpg",
        "test_3_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          4,
          5,
          2,
          8,
          6,
          3,
          7,
          0
        ],
        "order_filenames": [
          "test_3_1.jpg",
          "test_3_4.jpg",
          "test_3_5.jpg",
          "test_3_2.jpg",
          "test_3_8.jpg",
          "test_3_6.jpg",
          "test_3_3.jpg",
          "test_3_7.jpg",
          "test_3_0.jpg"
        ],
        "condorcet_winner": 1,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_3_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_3_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_3_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1768798828125,
            0.2196044921875,
            0.25732421875,
            0.1844482421875,
            0.1898193359375,
            0.136474609375,
            0.2171630859375,
            0.21142578125,
            0.2496337890625
          ],
          "order_indices": [
            2,
            8,
            1,
            6,
            7,
            4,
            3,
            0,
            5
          ],
          "order_filenames": [
            "test_3_2.jpg",
            "test_3_8.jpg",
            "test_3_1.jpg",
            "test_3_6.jpg",
            "test_3_7.jpg",
            "test_3_4.jpg",
            "test_3_3.jpg",
            "test_3_0.jpg",
            "test_3_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2777777777777778,
            "spearman_rho": 0.2666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.625,
            45.28125,
            45.375,
            42.9375,
            28.140625,
            26.46875,
            43.6875,
            44.46875,
            41.65625
          ],
          "order_indices": [
            2,
            1,
            7,
            6,
            3,
            8,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_3_2.jpg",
            "test_3_1.jpg",
            "test_3_7.jpg",
            "test_3_6.jpg",
            "test_3_3.jpg",
            "test_3_8.jpg",
            "test_3_0.jpg",
            "test_3_4.jpg",
            "test_3_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.0,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -2.1545071601867676,
            -0.7867547273635864,
            0.14102429151535034,
            -0.7544886469841003,
            0.024745048955082893,
            -2.2773077487945557,
            -0.08520936965942383,
            0.23460450768470764,
            0.4578918218612671
          ],
          "order_indices": [
            8,
            7,
            2,
            4,
            6,
            3,
            1,
            0,
            5
          ],
          "order_filenames": [
            "test_3_8.jpg",
            "test_3_7.jpg",
            "test_3_2.jpg",
            "test_3_4.jpg",
            "test_3_6.jpg",
            "test_3_3.jpg",
            "test_3_1.jpg",
            "test_3_0.jpg",
            "test_3_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.10000000000000009,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 4,
      "prompt": "A portrait of an anime mecha robot with a Japanese town background and a starred night sky.",
      "image_filenames": [
        "test_4_0.jpg",
        "test_4_1.jpg",
        "test_4_2.jpg",
        "test_4_3.jpg",
        "test_4_4.jpg",
        "test_4_5.jpg",
        "test_4_6.jpg",
        "test_4_7.jpg",
        "test_4_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          2,
          4,
          5,
          6,
          7,
          8,
          1,
          0
        ],
        "order_filenames": [
          "test_4_3.jpg",
          "test_4_2.jpg",
          "test_4_4.jpg",
          "test_4_5.jpg",
          "test_4_6.jpg",
          "test_4_7.jpg",
          "test_4_8.jpg",
          "test_4_1.jpg",
          "test_4_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_4_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            0,
            4,
            5,
            6
          ],
          "winner_filenames": [
            "test_4_0.jpg",
            "test_4_4.jpg",
            "test_4_5.jpg",
            "test_4_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_4_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.162841796875,
            0.1944580078125,
            0.26318359375,
            0.20166015625,
            0.1495361328125,
            0.1334228515625,
            0.218994140625,
            0.2115478515625,
            0.293212890625
          ],
          "order_indices": [
            8,
            2,
            6,
            7,
            3,
            1,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_4_8.jpg",
            "test_4_2.jpg",
            "test_4_6.jpg",
            "test_4_7.jpg",
            "test_4_3.jpg",
            "test_4_1.jpg",
            "test_4_0.jpg",
            "test_4_4.jpg",
            "test_4_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.01666666666666672,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.75,
            34.28125,
            34.375,
            29.5625,
            26.359375,
            18.984375,
            36.6875,
            45.75,
            35.59375
          ],
          "order_indices": [
            7,
            0,
            6,
            8,
            2,
            1,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_4_7.jpg",
            "test_4_0.jpg",
            "test_4_6.jpg",
            "test_4_8.jpg",
            "test_4_2.jpg",
            "test_4_1.jpg",
            "test_4_3.jpg",
            "test_4_4.jpg",
            "test_4_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.55,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.5274692177772522,
            -0.47229069471359253,
            -0.028311269357800484,
            0.02398073859512806,
            -0.09341942518949509,
            -1.976927638053894,
            0.5238813161849976,
            1.2513052225112915,
            1.0344735383987427
          ],
          "order_indices": [
            7,
            8,
            0,
            6,
            3,
            2,
            4,
            1,
            5
          ],
          "order_filenames": [
            "test_4_7.jpg",
            "test_4_8.jpg",
            "test_4_0.jpg",
            "test_4_6.jpg",
            "test_4_3.jpg",
            "test_4_2.jpg",
            "test_4_4.jpg",
            "test_4_1.jpg",
            "test_4_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.33333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 5,
      "prompt": "A minimalist portrait of Chloe Grace by Jean Giraud in a comic style.",
      "image_filenames": [
        "test_5_0.jpg",
        "test_5_1.jpg",
        "test_5_2.jpg",
        "test_5_3.jpg",
        "test_5_4.jpg",
        "test_5_5.jpg",
        "test_5_6.jpg",
        "test_5_7.jpg",
        "test_5_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          5,
          1,
          6,
          4,
          7,
          8,
          0,
          2
        ],
        "order_filenames": [
          "test_5_3.jpg",
          "test_5_5.jpg",
          "test_5_1.jpg",
          "test_5_6.jpg",
          "test_5_4.jpg",
          "test_5_7.jpg",
          "test_5_8.jpg",
          "test_5_0.jpg",
          "test_5_2.jpg"
        ],
        "condorcet_winner": 3,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_5_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4,
            5
          ],
          "winner_filenames": [
            "test_5_4.jpg",
            "test_5_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_5_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1544189453125,
            0.22509765625,
            0.1925048828125,
            0.144775390625,
            0.146728515625,
            0.0606689453125,
            0.229248046875,
            0.2188720703125,
            0.198974609375
          ],
          "order_indices": [
            6,
            1,
            7,
            8,
            2,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_5_6.jpg",
            "test_5_1.jpg",
            "test_5_7.jpg",
            "test_5_8.jpg",
            "test_5_2.jpg",
            "test_5_0.jpg",
            "test_5_4.jpg",
            "test_5_3.jpg",
            "test_5_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.25,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            31.875,
            36.53125,
            42.78125,
            25.234375,
            18.078125,
            14.7109375,
            37.0625,
            38.875,
            36.71875
          ],
          "order_indices": [
            2,
            7,
            6,
            8,
            1,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_5_2.jpg",
            "test_5_7.jpg",
            "test_5_6.jpg",
            "test_5_8.jpg",
            "test_5_1.jpg",
            "test_5_0.jpg",
            "test_5_3.jpg",
            "test_5_4.jpg",
            "test_5_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.6000000000000001,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.7740235328674316,
            0.5228641629219055,
            0.028786882758140564,
            -1.57417631149292,
            -0.6367365121841431,
            -2.2814559936523438,
            1.5706965923309326,
            -1.3840155601501465,
            0.601148784160614
          ],
          "order_indices": [
            6,
            8,
            1,
            2,
            4,
            0,
            7,
            3,
            5
          ],
          "order_filenames": [
            "test_5_6.jpg",
            "test_5_8.jpg",
            "test_5_1.jpg",
            "test_5_2.jpg",
            "test_5_4.jpg",
            "test_5_0.jpg",
            "test_5_7.jpg",
            "test_5_3.jpg",
            "test_5_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.3500000000000001,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 6,
      "prompt": "A raccoon riding an oversized fox through a forest in a furry art anime still.",
      "image_filenames": [
        "test_6_0.jpg",
        "test_6_1.jpg",
        "test_6_2.jpg",
        "test_6_3.jpg",
        "test_6_4.jpg",
        "test_6_5.jpg",
        "test_6_6.jpg",
        "test_6_7.jpg",
        "test_6_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          6,
          3,
          1,
          7,
          5,
          4,
          8,
          0
        ],
        "order_filenames": [
          "test_6_2.jpg",
          "test_6_6.jpg",
          "test_6_3.jpg",
          "test_6_1.jpg",
          "test_6_7.jpg",
          "test_6_5.jpg",
          "test_6_4.jpg",
          "test_6_8.jpg",
          "test_6_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_6_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_6_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_6_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1435546875,
            0.23828125,
            0.273681640625,
            0.178955078125,
            0.1719970703125,
            0.11041259765625,
            0.2109375,
            0.19677734375,
            0.275146484375
          ],
          "order_indices": [
            8,
            2,
            1,
            6,
            7,
            3,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_6_8.jpg",
            "test_6_2.jpg",
            "test_6_1.jpg",
            "test_6_6.jpg",
            "test_6_7.jpg",
            "test_6_3.jpg",
            "test_6_4.jpg",
            "test_6_0.jpg",
            "test_6_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.3833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.09375,
            33.59375,
            38.1875,
            30.734375,
            28.8125,
            25.03125,
            33.4375,
            36.46875,
            38.8125
          ],
          "order_indices": [
            0,
            8,
            2,
            7,
            1,
            6,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_6_0.jpg",
            "test_6_8.jpg",
            "test_6_2.jpg",
            "test_6_7.jpg",
            "test_6_1.jpg",
            "test_6_6.jpg",
            "test_6_3.jpg",
            "test_6_4.jpg",
            "test_6_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.2333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.2608237862586975,
            -0.8008089065551758,
            0.42118600010871887,
            -0.7708163857460022,
            -1.3446753025054932,
            -1.8918323516845703,
            -0.4537622332572937,
            -0.22177524864673615,
            0.5297203063964844
          ],
          "order_indices": [
            8,
            2,
            0,
            7,
            6,
            3,
            1,
            4,
            5
          ],
          "order_filenames": [
            "test_6_8.jpg",
            "test_6_2.jpg",
            "test_6_0.jpg",
            "test_6_7.jpg",
            "test_6_6.jpg",
            "test_6_3.jpg",
            "test_6_1.jpg",
            "test_6_4.jpg",
            "test_6_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": -0.03333333333333344,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 7,
      "prompt": "Chucky doll dressed as Beetlejuice.",
      "image_filenames": [
        "test_7_0.jpg",
        "test_7_1.jpg",
        "test_7_2.jpg",
        "test_7_3.jpg",
        "test_7_4.jpg",
        "test_7_5.jpg",
        "test_7_6.jpg",
        "test_7_7.jpg",
        "test_7_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          7,
          2,
          1,
          8,
          4,
          6,
          3,
          5
        ],
        "order_filenames": [
          "test_7_0.jpg",
          "test_7_7.jpg",
          "test_7_2.jpg",
          "test_7_1.jpg",
          "test_7_8.jpg",
          "test_7_4.jpg",
          "test_7_6.jpg",
          "test_7_3.jpg",
          "test_7_5.jpg"
        ],
        "condorcet_winner": 7,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_7_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_7_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_7_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.164794921875,
            0.2420654296875,
            0.3037109375,
            0.2181396484375,
            0.1820068359375,
            0.141845703125,
            0.287353515625,
            0.19189453125,
            0.2724609375
          ],
          "order_indices": [
            2,
            6,
            8,
            1,
            3,
            7,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_7_2.jpg",
            "test_7_6.jpg",
            "test_7_8.jpg",
            "test_7_1.jpg",
            "test_7_3.jpg",
            "test_7_7.jpg",
            "test_7_4.jpg",
            "test_7_0.jpg",
            "test_7_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.09999999999999998,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            45.4375,
            32.9375,
            38.03125,
            33.1875,
            35.28125,
            15.4921875,
            37.0625,
            44.78125,
            38.71875
          ],
          "order_indices": [
            0,
            7,
            8,
            2,
            6,
            4,
            3,
            1,
            5
          ],
          "order_filenames": [
            "test_7_0.jpg",
            "test_7_7.jpg",
            "test_7_8.jpg",
            "test_7_2.jpg",
            "test_7_6.jpg",
            "test_7_4.jpg",
            "test_7_3.jpg",
            "test_7_1.jpg",
            "test_7_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.6666666666666666,
            "spearman_rho": 0.7833333333333333,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.4444444444444444,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.7963691353797913,
            0.7349994778633118,
            0.6589768528938293,
            0.33009225130081177,
            -1.6477909088134766,
            -2.0080819129943848,
            1.0544204711914062,
            0.1535499542951584,
            0.6573151350021362
          ],
          "order_indices": [
            6,
            1,
            2,
            8,
            3,
            7,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_7_6.jpg",
            "test_7_1.jpg",
            "test_7_2.jpg",
            "test_7_8.jpg",
            "test_7_3.jpg",
            "test_7_7.jpg",
            "test_7_0.jpg",
            "test_7_4.jpg",
            "test_7_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.1166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 8,
      "prompt": "2B from NieR Automata eating a bagel.",
      "image_filenames": [
        "test_8_0.jpg",
        "test_8_1.jpg",
        "test_8_2.jpg",
        "test_8_3.jpg",
        "test_8_4.jpg",
        "test_8_5.jpg",
        "test_8_6.jpg",
        "test_8_7.jpg",
        "test_8_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          2,
          0,
          6,
          4,
          5,
          1,
          8,
          3
        ],
        "order_filenames": [
          "test_8_7.jpg",
          "test_8_2.jpg",
          "test_8_0.jpg",
          "test_8_6.jpg",
          "test_8_4.jpg",
          "test_8_5.jpg",
          "test_8_1.jpg",
          "test_8_8.jpg",
          "test_8_3.jpg"
        ],
        "condorcet_winner": 7,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_8_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_8_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_8_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.15087890625,
            0.244873046875,
            0.28369140625,
            0.157470703125,
            0.1612548828125,
            0.1357421875,
            0.21142578125,
            0.1871337890625,
            0.1986083984375
          ],
          "order_indices": [
            2,
            1,
            6,
            8,
            7,
            4,
            3,
            0,
            5
          ],
          "order_filenames": [
            "test_8_2.jpg",
            "test_8_1.jpg",
            "test_8_6.jpg",
            "test_8_8.jpg",
            "test_8_7.jpg",
            "test_8_4.jpg",
            "test_8_3.jpg",
            "test_8_0.jpg",
            "test_8_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.5625,
            43.46875,
            43.1875,
            33.5,
            30.890625,
            24.78125,
            36.5,
            43.09375,
            40.5625
          ],
          "order_indices": [
            1,
            2,
            7,
            8,
            0,
            6,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_8_1.jpg",
            "test_8_2.jpg",
            "test_8_7.jpg",
            "test_8_8.jpg",
            "test_8_0.jpg",
            "test_8_6.jpg",
            "test_8_3.jpg",
            "test_8_4.jpg",
            "test_8_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2777777777777778,
            "spearman_rho": 0.2833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.3151713609695435,
            1.6022074222564697,
            1.7597707509994507,
            -0.7236126661300659,
            0.9622475504875183,
            -1.9460073709487915,
            1.2057746648788452,
            0.8903623819351196,
            1.7479838132858276
          ],
          "order_indices": [
            2,
            8,
            1,
            6,
            4,
            7,
            3,
            0,
            5
          ],
          "order_filenames": [
            "test_8_2.jpg",
            "test_8_8.jpg",
            "test_8_1.jpg",
            "test_8_6.jpg",
            "test_8_4.jpg",
            "test_8_7.jpg",
            "test_8_3.jpg",
            "test_8_0.jpg",
            "test_8_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.033333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 9,
      "prompt": "Groot depicted as a flower.",
      "image_filenames": [
        "test_9_0.jpg",
        "test_9_1.jpg",
        "test_9_2.jpg",
        "test_9_3.jpg",
        "test_9_4.jpg",
        "test_9_5.jpg",
        "test_9_6.jpg",
        "test_9_7.jpg",
        "test_9_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          1,
          0,
          5,
          4,
          8,
          2,
          6,
          3
        ],
        "order_filenames": [
          "test_9_7.jpg",
          "test_9_1.jpg",
          "test_9_0.jpg",
          "test_9_5.jpg",
          "test_9_4.jpg",
          "test_9_8.jpg",
          "test_9_2.jpg",
          "test_9_6.jpg",
          "test_9_3.jpg"
        ],
        "condorcet_winner": 7,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_9_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_9_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_9_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.228271484375,
            0.29443359375,
            0.313232421875,
            0.2186279296875,
            0.2254638671875,
            0.1558837890625,
            0.296630859375,
            0.276611328125,
            0.2064208984375
          ],
          "order_indices": [
            2,
            6,
            1,
            7,
            0,
            4,
            3,
            8,
            5
          ],
          "order_filenames": [
            "test_9_2.jpg",
            "test_9_6.jpg",
            "test_9_1.jpg",
            "test_9_7.jpg",
            "test_9_0.jpg",
            "test_9_4.jpg",
            "test_9_3.jpg",
            "test_9_8.jpg",
            "test_9_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.0,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            42.0,
            42.9375,
            39.78125,
            16.828125,
            32.90625,
            32.46875,
            29.890625,
            41.6875,
            30.625
          ],
          "order_indices": [
            1,
            0,
            7,
            2,
            4,
            5,
            8,
            6,
            3
          ],
          "order_filenames": [
            "test_9_1.jpg",
            "test_9_0.jpg",
            "test_9_7.jpg",
            "test_9_2.jpg",
            "test_9_4.jpg",
            "test_9_5.jpg",
            "test_9_8.jpg",
            "test_9_6.jpg",
            "test_9_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.6666666666666666,
            "spearman_rho": 0.8333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.3078113794326782,
            1.6390023231506348,
            1.5236893892288208,
            -1.8945304155349731,
            -0.5870803594589233,
            -2.281874895095825,
            0.3334963917732239,
            1.309468150138855,
            -0.5819576978683472
          ],
          "order_indices": [
            1,
            2,
            7,
            0,
            6,
            8,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_9_1.jpg",
            "test_9_2.jpg",
            "test_9_7.jpg",
            "test_9_0.jpg",
            "test_9_6.jpg",
            "test_9_8.jpg",
            "test_9_4.jpg",
            "test_9_3.jpg",
            "test_9_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2777777777777778,
            "spearman_rho": 0.41666666666666663,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 10,
      "prompt": "A portrait of two women with purple hair flying in different directions against a dark background.",
      "image_filenames": [
        "test_10_0.jpg",
        "test_10_1.jpg",
        "test_10_2.jpg",
        "test_10_3.jpg",
        "test_10_4.jpg",
        "test_10_5.jpg",
        "test_10_6.jpg",
        "test_10_7.jpg",
        "test_10_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          5,
          1,
          7,
          2,
          6,
          3,
          8,
          0
        ],
        "order_filenames": [
          "test_10_4.jpg",
          "test_10_5.jpg",
          "test_10_1.jpg",
          "test_10_7.jpg",
          "test_10_2.jpg",
          "test_10_6.jpg",
          "test_10_3.jpg",
          "test_10_8.jpg",
          "test_10_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_10_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_10_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_10_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2130126953125,
            0.2486572265625,
            0.232177734375,
            0.2236328125,
            0.2093505859375,
            0.1507568359375,
            0.25927734375,
            0.2239990234375,
            0.2861328125
          ],
          "order_indices": [
            8,
            6,
            1,
            2,
            7,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_10_8.jpg",
            "test_10_6.jpg",
            "test_10_1.jpg",
            "test_10_2.jpg",
            "test_10_7.jpg",
            "test_10_3.jpg",
            "test_10_0.jpg",
            "test_10_4.jpg",
            "test_10_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.41666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            42.71875,
            45.09375,
            36.96875,
            35.46875,
            36.03125,
            24.09375,
            41.21875,
            42.1875,
            45.1875
          ],
          "order_indices": [
            8,
            1,
            0,
            7,
            6,
            2,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_10_8.jpg",
            "test_10_1.jpg",
            "test_10_0.jpg",
            "test_10_7.jpg",
            "test_10_6.jpg",
            "test_10_2.jpg",
            "test_10_4.jpg",
            "test_10_3.jpg",
            "test_10_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.44999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.7299594879150391,
            -0.06253854185342789,
            -0.7002347111701965,
            -0.7105483412742615,
            -1.1269696950912476,
            -2.284430980682373,
            0.5046687126159668,
            -0.31405678391456604,
            1.2151515483856201
          ],
          "order_indices": [
            8,
            6,
            1,
            7,
            2,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_10_8.jpg",
            "test_10_6.jpg",
            "test_10_1.jpg",
            "test_10_7.jpg",
            "test_10_2.jpg",
            "test_10_3.jpg",
            "test_10_0.jpg",
            "test_10_4.jpg",
            "test_10_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.3999999999999999,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 11,
      "prompt": "A girl with pink pigtails and face tattoos.",
      "image_filenames": [
        "test_11_0.jpg",
        "test_11_1.jpg",
        "test_11_2.jpg",
        "test_11_3.jpg",
        "test_11_4.jpg",
        "test_11_5.jpg",
        "test_11_6.jpg",
        "test_11_7.jpg",
        "test_11_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          2,
          4,
          0,
          5,
          1,
          3,
          7,
          8
        ],
        "order_filenames": [
          "test_11_6.jpg",
          "test_11_2.jpg",
          "test_11_4.jpg",
          "test_11_0.jpg",
          "test_11_5.jpg",
          "test_11_1.jpg",
          "test_11_3.jpg",
          "test_11_7.jpg",
          "test_11_8.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_11_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_11_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_11_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.211669921875,
            0.268310546875,
            0.292724609375,
            0.2108154296875,
            0.185302734375,
            0.11407470703125,
            0.23291015625,
            0.222412109375,
            0.244873046875
          ],
          "order_indices": [
            2,
            1,
            8,
            6,
            7,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_11_2.jpg",
            "test_11_1.jpg",
            "test_11_8.jpg",
            "test_11_6.jpg",
            "test_11_7.jpg",
            "test_11_0.jpg",
            "test_11_3.jpg",
            "test_11_4.jpg",
            "test_11_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.033333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.78125,
            34.6875,
            36.0625,
            29.609375,
            27.78125,
            16.203125,
            35.46875,
            37.03125,
            36.90625
          ],
          "order_indices": [
            0,
            7,
            8,
            2,
            6,
            1,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_11_0.jpg",
            "test_11_7.jpg",
            "test_11_8.jpg",
            "test_11_2.jpg",
            "test_11_6.jpg",
            "test_11_1.jpg",
            "test_11_3.jpg",
            "test_11_4.jpg",
            "test_11_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.7266282439231873,
            1.9237706661224365,
            1.9322733879089355,
            0.7431692481040955,
            -1.5968791246414185,
            -2.2827212810516357,
            1.3986390829086304,
            0.18288332223892212,
            0.8732209801673889
          ],
          "order_indices": [
            2,
            1,
            6,
            8,
            3,
            0,
            7,
            4,
            5
          ],
          "order_filenames": [
            "test_11_2.jpg",
            "test_11_1.jpg",
            "test_11_6.jpg",
            "test_11_8.jpg",
            "test_11_3.jpg",
            "test_11_0.jpg",
            "test_11_7.jpg",
            "test_11_4.jpg",
            "test_11_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.19999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 12,
      "prompt": "A cat in a tutu dancing to Swan Lake.",
      "image_filenames": [
        "test_12_0.jpg",
        "test_12_1.jpg",
        "test_12_2.jpg",
        "test_12_3.jpg",
        "test_12_4.jpg",
        "test_12_5.jpg",
        "test_12_6.jpg",
        "test_12_7.jpg",
        "test_12_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          2,
          3,
          1,
          8,
          5,
          6,
          7,
          4
        ],
        "order_filenames": [
          "test_12_0.jpg",
          "test_12_2.jpg",
          "test_12_3.jpg",
          "test_12_1.jpg",
          "test_12_8.jpg",
          "test_12_5.jpg",
          "test_12_6.jpg",
          "test_12_7.jpg",
          "test_12_4.jpg"
        ],
        "condorcet_winner": 0,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_12_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_12_3.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_12_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.256591796875,
            0.2484130859375,
            0.270263671875,
            0.285888671875,
            0.1939697265625,
            0.2183837890625,
            0.18115234375,
            0.2177734375,
            0.2210693359375
          ],
          "order_indices": [
            3,
            2,
            0,
            1,
            8,
            5,
            7,
            4,
            6
          ],
          "order_filenames": [
            "test_12_3.jpg",
            "test_12_2.jpg",
            "test_12_0.jpg",
            "test_12_1.jpg",
            "test_12_8.jpg",
            "test_12_5.jpg",
            "test_12_7.jpg",
            "test_12_4.jpg",
            "test_12_6.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.7222222222222222,
            "spearman_rho": 0.8833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.4444444444444444,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            45.28125,
            36.625,
            41.34375,
            40.4375,
            29.3125,
            22.078125,
            31.59375,
            40.9375,
            35.5
          ],
          "order_indices": [
            0,
            2,
            7,
            3,
            1,
            8,
            6,
            4,
            5
          ],
          "order_filenames": [
            "test_12_0.jpg",
            "test_12_2.jpg",
            "test_12_7.jpg",
            "test_12_3.jpg",
            "test_12_1.jpg",
            "test_12_8.jpg",
            "test_12_6.jpg",
            "test_12_4.jpg",
            "test_12_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.6111111111111112,
            "spearman_rho": 0.6833333333333333,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 1.0,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.296067714691162,
            1.357383131980896,
            1.8911148309707642,
            1.9247972965240479,
            0.7922662496566772,
            -1.4034368991851807,
            -0.015557426027953625,
            -0.5438095331192017,
            0.9387365579605103
          ],
          "order_indices": [
            3,
            2,
            1,
            0,
            8,
            4,
            6,
            7,
            5
          ],
          "order_filenames": [
            "test_12_3.jpg",
            "test_12_2.jpg",
            "test_12_1.jpg",
            "test_12_0.jpg",
            "test_12_8.jpg",
            "test_12_4.jpg",
            "test_12_6.jpg",
            "test_12_7.jpg",
            "test_12_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.5,
            "spearman_rho": 0.7333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.4444444444444444,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 13,
      "prompt": "Wicked witch casting fireball dressed in green with screaming expression.",
      "image_filenames": [
        "test_13_0.jpg",
        "test_13_1.jpg",
        "test_13_2.jpg",
        "test_13_3.jpg",
        "test_13_4.jpg",
        "test_13_5.jpg",
        "test_13_6.jpg",
        "test_13_7.jpg",
        "test_13_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          6,
          2,
          5,
          7,
          4,
          8,
          3,
          0
        ],
        "order_filenames": [
          "test_13_1.jpg",
          "test_13_6.jpg",
          "test_13_2.jpg",
          "test_13_5.jpg",
          "test_13_7.jpg",
          "test_13_4.jpg",
          "test_13_8.jpg",
          "test_13_3.jpg",
          "test_13_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_13_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_13_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2,
            6
          ],
          "winner_filenames": [
            "test_13_2.jpg",
            "test_13_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.192626953125,
            0.2406005859375,
            0.2919921875,
            0.1947021484375,
            0.1741943359375,
            0.15283203125,
            0.177490234375,
            0.26806640625,
            0.30810546875
          ],
          "order_indices": [
            8,
            2,
            7,
            1,
            3,
            0,
            6,
            4,
            5
          ],
          "order_filenames": [
            "test_13_8.jpg",
            "test_13_2.jpg",
            "test_13_7.jpg",
            "test_13_1.jpg",
            "test_13_3.jpg",
            "test_13_0.jpg",
            "test_13_6.jpg",
            "test_13_4.jpg",
            "test_13_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.016666666666666607,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.75,
            29.4375,
            40.59375,
            22.96875,
            26.671875,
            21.078125,
            28.078125,
            41.5625,
            43.3125
          ],
          "order_indices": [
            8,
            7,
            2,
            0,
            1,
            6,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_13_8.jpg",
            "test_13_7.jpg",
            "test_13_2.jpg",
            "test_13_0.jpg",
            "test_13_1.jpg",
            "test_13_6.jpg",
            "test_13_4.jpg",
            "test_13_3.jpg",
            "test_13_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.6350640654563904,
            -0.7207154035568237,
            1.868981957435608,
            -1.3388996124267578,
            -2.1147472858428955,
            -2.225351572036743,
            -1.3741799592971802,
            1.4508241415023804,
            1.8872729539871216
          ],
          "order_indices": [
            8,
            2,
            7,
            0,
            1,
            3,
            6,
            4,
            5
          ],
          "order_filenames": [
            "test_13_8.jpg",
            "test_13_2.jpg",
            "test_13_7.jpg",
            "test_13_0.jpg",
            "test_13_1.jpg",
            "test_13_3.jpg",
            "test_13_6.jpg",
            "test_13_4.jpg",
            "test_13_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.16666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 14,
      "prompt": "Link fights an octorok in a cave in a Don Bluth-style from The Legend of Zelda, Breath of the Wild.",
      "image_filenames": [
        "test_14_0.jpg",
        "test_14_1.jpg",
        "test_14_2.jpg",
        "test_14_3.jpg",
        "test_14_4.jpg",
        "test_14_5.jpg",
        "test_14_6.jpg",
        "test_14_7.jpg",
        "test_14_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          1,
          2,
          7,
          0,
          4,
          8,
          5,
          3
        ],
        "order_filenames": [
          "test_14_6.jpg",
          "test_14_1.jpg",
          "test_14_2.jpg",
          "test_14_7.jpg",
          "test_14_0.jpg",
          "test_14_4.jpg",
          "test_14_8.jpg",
          "test_14_5.jpg",
          "test_14_3.jpg"
        ],
        "condorcet_winner": 6,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_14_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_14_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_14_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1683349609375,
            0.27783203125,
            0.285400390625,
            0.1929931640625,
            0.13818359375,
            0.1026611328125,
            0.2529296875,
            0.2230224609375,
            0.2415771484375
          ],
          "order_indices": [
            2,
            1,
            6,
            8,
            7,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_14_2.jpg",
            "test_14_1.jpg",
            "test_14_6.jpg",
            "test_14_8.jpg",
            "test_14_7.jpg",
            "test_14_3.jpg",
            "test_14_0.jpg",
            "test_14_4.jpg",
            "test_14_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.5,
            "spearman_rho": 0.7,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.96875,
            33.21875,
            31.296875,
            33.125,
            23.5625,
            16.359375,
            29.71875,
            42.125,
            32.71875
          ],
          "order_indices": [
            7,
            0,
            1,
            3,
            8,
            2,
            6,
            4,
            5
          ],
          "order_filenames": [
            "test_14_7.jpg",
            "test_14_0.jpg",
            "test_14_1.jpg",
            "test_14_3.jpg",
            "test_14_8.jpg",
            "test_14_2.jpg",
            "test_14_6.jpg",
            "test_14_4.jpg",
            "test_14_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.18626117706298828,
            0.41885125637054443,
            0.7320283055305481,
            -0.3961756229400635,
            -1.5515284538269043,
            -2.146790027618408,
            0.655318021774292,
            0.622184693813324,
            -0.09086571633815765
          ],
          "order_indices": [
            2,
            6,
            7,
            1,
            0,
            8,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_14_2.jpg",
            "test_14_6.jpg",
            "test_14_7.jpg",
            "test_14_1.jpg",
            "test_14_0.jpg",
            "test_14_8.jpg",
            "test_14_3.jpg",
            "test_14_4.jpg",
            "test_14_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.6666666666666666,
            "spearman_rho": 0.8333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 15,
      "prompt": "A cat with two horns on its head.",
      "image_filenames": [
        "test_15_0.jpg",
        "test_15_1.jpg",
        "test_15_2.jpg",
        "test_15_3.jpg",
        "test_15_4.jpg",
        "test_15_5.jpg",
        "test_15_6.jpg",
        "test_15_7.jpg",
        "test_15_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          0,
          2,
          3,
          4,
          8,
          5,
          1,
          7
        ],
        "order_filenames": [
          "test_15_6.jpg",
          "test_15_0.jpg",
          "test_15_2.jpg",
          "test_15_3.jpg",
          "test_15_4.jpg",
          "test_15_8.jpg",
          "test_15_5.jpg",
          "test_15_1.jpg",
          "test_15_7.jpg"
        ],
        "condorcet_winner": 6,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_15_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_15_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_15_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2410888671875,
            0.276611328125,
            0.29296875,
            0.2353515625,
            0.1964111328125,
            0.201904296875,
            0.2276611328125,
            0.205322265625,
            0.2216796875
          ],
          "order_indices": [
            2,
            1,
            0,
            3,
            6,
            8,
            7,
            5,
            4
          ],
          "order_filenames": [
            "test_15_2.jpg",
            "test_15_1.jpg",
            "test_15_0.jpg",
            "test_15_3.jpg",
            "test_15_6.jpg",
            "test_15_8.jpg",
            "test_15_7.jpg",
            "test_15_5.jpg",
            "test_15_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.35,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            41.375,
            33.1875,
            40.5,
            25.578125,
            37.34375,
            28.0,
            34.4375,
            37.125,
            28.015625
          ],
          "order_indices": [
            0,
            2,
            4,
            7,
            6,
            1,
            8,
            5,
            3
          ],
          "order_filenames": [
            "test_15_0.jpg",
            "test_15_2.jpg",
            "test_15_4.jpg",
            "test_15_7.jpg",
            "test_15_6.jpg",
            "test_15_1.jpg",
            "test_15_8.jpg",
            "test_15_5.jpg",
            "test_15_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.35,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.8265029191970825,
            1.2595256567001343,
            1.7911046743392944,
            -0.1470666229724884,
            -0.3157584071159363,
            0.2900078296661377,
            1.6112089157104492,
            0.41500356793403625,
            0.778810441493988
          ],
          "order_indices": [
            0,
            2,
            6,
            1,
            8,
            7,
            5,
            3,
            4
          ],
          "order_filenames": [
            "test_15_0.jpg",
            "test_15_2.jpg",
            "test_15_6.jpg",
            "test_15_1.jpg",
            "test_15_8.jpg",
            "test_15_7.jpg",
            "test_15_5.jpg",
            "test_15_3.jpg",
            "test_15_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2777777777777778,
            "spearman_rho": 0.4666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 16,
      "prompt": "A cute anime schoolgirl with a sad face submerged in dark pink and blue water, portrayed in an oil painting style.",
      "image_filenames": [
        "test_16_0.jpg",
        "test_16_1.jpg",
        "test_16_2.jpg",
        "test_16_3.jpg",
        "test_16_4.jpg",
        "test_16_5.jpg",
        "test_16_6.jpg",
        "test_16_7.jpg",
        "test_16_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          5,
          7,
          1,
          4,
          2,
          6,
          8,
          3
        ],
        "order_filenames": [
          "test_16_0.jpg",
          "test_16_5.jpg",
          "test_16_7.jpg",
          "test_16_1.jpg",
          "test_16_4.jpg",
          "test_16_2.jpg",
          "test_16_6.jpg",
          "test_16_8.jpg",
          "test_16_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_16_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_16_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_16_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1728515625,
            0.27734375,
            0.300048828125,
            0.2135009765625,
            0.2095947265625,
            0.1356201171875,
            0.2822265625,
            0.23388671875,
            0.270263671875
          ],
          "order_indices": [
            2,
            6,
            1,
            8,
            7,
            3,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_16_2.jpg",
            "test_16_6.jpg",
            "test_16_1.jpg",
            "test_16_8.jpg",
            "test_16_7.jpg",
            "test_16_3.jpg",
            "test_16_4.jpg",
            "test_16_0.jpg",
            "test_16_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.5166666666666666,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.09375,
            38.15625,
            37.96875,
            40.84375,
            31.703125,
            30.828125,
            41.9375,
            43.59375,
            43.6875
          ],
          "order_indices": [
            8,
            7,
            6,
            3,
            1,
            0,
            2,
            4,
            5
          ],
          "order_filenames": [
            "test_16_8.jpg",
            "test_16_7.jpg",
            "test_16_6.jpg",
            "test_16_3.jpg",
            "test_16_1.jpg",
            "test_16_0.jpg",
            "test_16_2.jpg",
            "test_16_4.jpg",
            "test_16_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.46666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.0916763544082642,
            -0.08395037055015564,
            0.8811427354812622,
            -0.9528182744979858,
            -1.0318183898925781,
            -2.187941551208496,
            0.9488504528999329,
            -0.3162643015384674,
            0.7145918607711792
          ],
          "order_indices": [
            6,
            2,
            8,
            1,
            7,
            3,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_16_6.jpg",
            "test_16_2.jpg",
            "test_16_8.jpg",
            "test_16_1.jpg",
            "test_16_7.jpg",
            "test_16_3.jpg",
            "test_16_4.jpg",
            "test_16_0.jpg",
            "test_16_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.6000000000000001,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 17,
      "prompt": "The image is a portrait of Homer Simpson as a Na'vi from Avatar, created with vibrant colors and highly detailed in a cinematic style reminiscent of romanticism by Eugene de Blaas and Ross Tran, available on Artstation with credits to Greg Rutkowski.",
      "image_filenames": [
        "test_17_0.jpg",
        "test_17_1.jpg",
        "test_17_2.jpg",
        "test_17_3.jpg",
        "test_17_4.jpg",
        "test_17_5.jpg",
        "test_17_6.jpg",
        "test_17_7.jpg",
        "test_17_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          3,
          5,
          1,
          8,
          4,
          6,
          2,
          0
        ],
        "order_filenames": [
          "test_17_7.jpg",
          "test_17_3.jpg",
          "test_17_5.jpg",
          "test_17_1.jpg",
          "test_17_8.jpg",
          "test_17_4.jpg",
          "test_17_6.jpg",
          "test_17_2.jpg",
          "test_17_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_17_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_17_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5,
            7
          ],
          "winner_filenames": [
            "test_17_5.jpg",
            "test_17_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.14404296875,
            0.1971435546875,
            0.2225341796875,
            0.1336669921875,
            0.136474609375,
            0.14794921875,
            0.2044677734375,
            0.2042236328125,
            0.24755859375
          ],
          "order_indices": [
            8,
            2,
            6,
            7,
            1,
            5,
            0,
            4,
            3
          ],
          "order_filenames": [
            "test_17_8.jpg",
            "test_17_2.jpg",
            "test_17_6.jpg",
            "test_17_7.jpg",
            "test_17_1.jpg",
            "test_17_5.jpg",
            "test_17_0.jpg",
            "test_17_4.jpg",
            "test_17_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.19999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            31.359375,
            31.734375,
            36.84375,
            25.8125,
            22.1875,
            17.953125,
            29.8125,
            41.9375,
            24.390625
          ],
          "order_indices": [
            7,
            2,
            1,
            0,
            6,
            3,
            8,
            4,
            5
          ],
          "order_filenames": [
            "test_17_7.jpg",
            "test_17_2.jpg",
            "test_17_1.jpg",
            "test_17_0.jpg",
            "test_17_6.jpg",
            "test_17_3.jpg",
            "test_17_8.jpg",
            "test_17_4.jpg",
            "test_17_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.050000000000000044,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.5290638208389282,
            -0.18496021628379822,
            0.45247015357017517,
            -0.9972615242004395,
            -0.41352781653404236,
            -1.935144305229187,
            0.6458566188812256,
            0.4003886580467224,
            0.7961013913154602
          ],
          "order_indices": [
            8,
            6,
            2,
            7,
            1,
            4,
            0,
            3,
            5
          ],
          "order_filenames": [
            "test_17_8.jpg",
            "test_17_6.jpg",
            "test_17_2.jpg",
            "test_17_7.jpg",
            "test_17_1.jpg",
            "test_17_4.jpg",
            "test_17_0.jpg",
            "test_17_3.jpg",
            "test_17_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.2666666666666666,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 18,
      "prompt": "A depiction of Chucky, the killer doll in anime style.",
      "image_filenames": [
        "test_18_0.jpg",
        "test_18_1.jpg",
        "test_18_2.jpg",
        "test_18_3.jpg",
        "test_18_4.jpg",
        "test_18_5.jpg",
        "test_18_6.jpg",
        "test_18_7.jpg",
        "test_18_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          4,
          0,
          5,
          1,
          7,
          6,
          8,
          3
        ],
        "order_filenames": [
          "test_18_2.jpg",
          "test_18_4.jpg",
          "test_18_0.jpg",
          "test_18_5.jpg",
          "test_18_1.jpg",
          "test_18_7.jpg",
          "test_18_6.jpg",
          "test_18_8.jpg",
          "test_18_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_18_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_18_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_18_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2042236328125,
            0.298583984375,
            0.28759765625,
            0.22607421875,
            0.1934814453125,
            0.134033203125,
            0.2305908203125,
            0.240234375,
            0.2166748046875
          ],
          "order_indices": [
            1,
            2,
            7,
            6,
            3,
            8,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_18_1.jpg",
            "test_18_2.jpg",
            "test_18_7.jpg",
            "test_18_6.jpg",
            "test_18_3.jpg",
            "test_18_8.jpg",
            "test_18_0.jpg",
            "test_18_4.jpg",
            "test_18_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.10000000000000009,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.0,
            38.71875,
            39.8125,
            34.875,
            28.625,
            14.921875,
            35.28125,
            45.875,
            35.28125
          ],
          "order_indices": [
            7,
            2,
            1,
            0,
            6,
            8,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_18_7.jpg",
            "test_18_2.jpg",
            "test_18_1.jpg",
            "test_18_0.jpg",
            "test_18_6.jpg",
            "test_18_8.jpg",
            "test_18_3.jpg",
            "test_18_4.jpg",
            "test_18_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.1333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.478365957736969,
            1.5193803310394287,
            1.3302793502807617,
            -0.05788232386112213,
            -1.7933558225631714,
            -1.5466907024383545,
            1.3130247592926025,
            0.9513031840324402,
            0.09038881212472916
          ],
          "order_indices": [
            1,
            2,
            6,
            7,
            0,
            8,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_18_1.jpg",
            "test_18_2.jpg",
            "test_18_6.jpg",
            "test_18_7.jpg",
            "test_18_0.jpg",
            "test_18_8.jpg",
            "test_18_3.jpg",
            "test_18_5.jpg",
            "test_18_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.050000000000000044,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 19,
      "prompt": "A hand-drawn cute gnome holding a pumpkin in an autumn disguise, portrayed in a detailed close-up of the face with warm lighting and high detail.",
      "image_filenames": [
        "test_19_0.jpg",
        "test_19_1.jpg",
        "test_19_2.jpg",
        "test_19_3.jpg",
        "test_19_4.jpg",
        "test_19_5.jpg",
        "test_19_6.jpg",
        "test_19_7.jpg",
        "test_19_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          6,
          5,
          1,
          7,
          4,
          8,
          2,
          0
        ],
        "order_filenames": [
          "test_19_3.jpg",
          "test_19_6.jpg",
          "test_19_5.jpg",
          "test_19_1.jpg",
          "test_19_7.jpg",
          "test_19_4.jpg",
          "test_19_8.jpg",
          "test_19_2.jpg",
          "test_19_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_19_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5,
            6
          ],
          "winner_filenames": [
            "test_19_5.jpg",
            "test_19_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3,
            5
          ],
          "winner_filenames": [
            "test_19_3.jpg",
            "test_19_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.175048828125,
            0.260986328125,
            0.2413330078125,
            0.1925048828125,
            0.1773681640625,
            0.1390380859375,
            0.2344970703125,
            0.25048828125,
            0.278564453125
          ],
          "order_indices": [
            8,
            1,
            7,
            2,
            6,
            3,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_19_8.jpg",
            "test_19_1.jpg",
            "test_19_7.jpg",
            "test_19_2.jpg",
            "test_19_6.jpg",
            "test_19_3.jpg",
            "test_19_4.jpg",
            "test_19_0.jpg",
            "test_19_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.10000000000000009,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.40625,
            33.625,
            36.65625,
            34.6875,
            30.96875,
            29.171875,
            28.90625,
            41.03125,
            40.75
          ],
          "order_indices": [
            7,
            8,
            2,
            0,
            3,
            1,
            4,
            5,
            6
          ],
          "order_filenames": [
            "test_19_7.jpg",
            "test_19_8.jpg",
            "test_19_2.jpg",
            "test_19_0.jpg",
            "test_19_3.jpg",
            "test_19_1.jpg",
            "test_19_4.jpg",
            "test_19_5.jpg",
            "test_19_6.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.55,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.5626237988471985,
            0.1765442043542862,
            1.2267268896102905,
            -0.44559916853904724,
            -0.903873860836029,
            -1.8489012718200684,
            -0.4216527044773102,
            0.08220777660608292,
            1.625863790512085
          ],
          "order_indices": [
            8,
            2,
            0,
            1,
            7,
            6,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_19_8.jpg",
            "test_19_2.jpg",
            "test_19_0.jpg",
            "test_19_1.jpg",
            "test_19_7.jpg",
            "test_19_6.jpg",
            "test_19_3.jpg",
            "test_19_4.jpg",
            "test_19_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.6666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 20,
      "prompt": "The image is of an anthropomorphic orange walking on a sidewalk.",
      "image_filenames": [
        "test_20_0.jpg",
        "test_20_1.jpg",
        "test_20_2.jpg",
        "test_20_3.jpg",
        "test_20_4.jpg",
        "test_20_5.jpg",
        "test_20_6.jpg",
        "test_20_7.jpg",
        "test_20_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          3,
          2,
          5,
          6,
          0,
          4,
          8,
          7
        ],
        "order_filenames": [
          "test_20_1.jpg",
          "test_20_3.jpg",
          "test_20_2.jpg",
          "test_20_5.jpg",
          "test_20_6.jpg",
          "test_20_0.jpg",
          "test_20_4.jpg",
          "test_20_8.jpg",
          "test_20_7.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_20_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_20_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1,
            5
          ],
          "winner_filenames": [
            "test_20_1.jpg",
            "test_20_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.187744140625,
            0.2529296875,
            0.2418212890625,
            0.2232666015625,
            0.2298583984375,
            0.137451171875,
            0.199462890625,
            0.205810546875,
            0.2392578125
          ],
          "order_indices": [
            1,
            2,
            8,
            4,
            3,
            7,
            6,
            0,
            5
          ],
          "order_filenames": [
            "test_20_1.jpg",
            "test_20_2.jpg",
            "test_20_8.jpg",
            "test_20_4.jpg",
            "test_20_3.jpg",
            "test_20_7.jpg",
            "test_20_6.jpg",
            "test_20_0.jpg",
            "test_20_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.2833333333333333,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            45.40625,
            40.65625,
            45.21875,
            43.9375,
            42.34375,
            18.90625,
            42.40625,
            43.40625,
            38.53125
          ],
          "order_indices": [
            0,
            2,
            3,
            7,
            6,
            4,
            1,
            8,
            5
          ],
          "order_filenames": [
            "test_20_0.jpg",
            "test_20_2.jpg",
            "test_20_3.jpg",
            "test_20_7.jpg",
            "test_20_6.jpg",
            "test_20_4.jpg",
            "test_20_1.jpg",
            "test_20_8.jpg",
            "test_20_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.050000000000000044,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.10226708650588989,
            1.8058005571365356,
            0.8677737712860107,
            0.7070537805557251,
            1.6152421236038208,
            -2.2560718059539795,
            -0.2915191948413849,
            0.63458251953125,
            1.469805121421814
          ],
          "order_indices": [
            1,
            4,
            8,
            2,
            3,
            7,
            0,
            6,
            5
          ],
          "order_filenames": [
            "test_20_1.jpg",
            "test_20_4.jpg",
            "test_20_8.jpg",
            "test_20_2.jpg",
            "test_20_3.jpg",
            "test_20_7.jpg",
            "test_20_0.jpg",
            "test_20_6.jpg",
            "test_20_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.1333333333333333,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 21,
      "prompt": "16-year-old teenager wearing a white bear-ear hat with a smirk on their face.",
      "image_filenames": [
        "test_21_0.jpg",
        "test_21_1.jpg",
        "test_21_2.jpg",
        "test_21_3.jpg",
        "test_21_4.jpg",
        "test_21_5.jpg",
        "test_21_6.jpg",
        "test_21_7.jpg",
        "test_21_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          0,
          5,
          4,
          1,
          7,
          2,
          8,
          3
        ],
        "order_filenames": [
          "test_21_6.jpg",
          "test_21_0.jpg",
          "test_21_5.jpg",
          "test_21_4.jpg",
          "test_21_1.jpg",
          "test_21_7.jpg",
          "test_21_2.jpg",
          "test_21_8.jpg",
          "test_21_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_21_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_21_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_21_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1566162109375,
            0.2498779296875,
            0.3154296875,
            0.2003173828125,
            0.1746826171875,
            0.0992431640625,
            0.3037109375,
            0.2403564453125,
            0.27001953125
          ],
          "order_indices": [
            2,
            6,
            8,
            1,
            7,
            3,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_21_2.jpg",
            "test_21_6.jpg",
            "test_21_8.jpg",
            "test_21_1.jpg",
            "test_21_7.jpg",
            "test_21_3.jpg",
            "test_21_4.jpg",
            "test_21_0.jpg",
            "test_21_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.28333333333333344,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            28.96875,
            38.59375,
            45.71875,
            25.484375,
            29.765625,
            22.671875,
            34.28125,
            40.5625,
            46.15625
          ],
          "order_indices": [
            8,
            2,
            7,
            1,
            6,
            4,
            0,
            3,
            5
          ],
          "order_filenames": [
            "test_21_8.jpg",
            "test_21_2.jpg",
            "test_21_7.jpg",
            "test_21_1.jpg",
            "test_21_6.jpg",
            "test_21_4.jpg",
            "test_21_0.jpg",
            "test_21_3.jpg",
            "test_21_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.3833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.8874552249908447,
            1.6020227670669556,
            1.9567891359329224,
            0.3275401294231415,
            -0.5472787618637085,
            -2.2815780639648438,
            0.7791933417320251,
            0.6952812075614929,
            1.7963789701461792
          ],
          "order_indices": [
            2,
            8,
            1,
            6,
            7,
            3,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_21_2.jpg",
            "test_21_8.jpg",
            "test_21_1.jpg",
            "test_21_6.jpg",
            "test_21_7.jpg",
            "test_21_3.jpg",
            "test_21_4.jpg",
            "test_21_0.jpg",
            "test_21_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.46666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 22,
      "prompt": "A spoon dressed up with eyes and a smile.",
      "image_filenames": [
        "test_22_0.jpg",
        "test_22_1.jpg",
        "test_22_2.jpg",
        "test_22_3.jpg",
        "test_22_4.jpg",
        "test_22_5.jpg",
        "test_22_6.jpg",
        "test_22_7.jpg",
        "test_22_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          8,
          6,
          7,
          2,
          3,
          4,
          5,
          0
        ],
        "order_filenames": [
          "test_22_1.jpg",
          "test_22_8.jpg",
          "test_22_6.jpg",
          "test_22_7.jpg",
          "test_22_2.jpg",
          "test_22_3.jpg",
          "test_22_4.jpg",
          "test_22_5.jpg",
          "test_22_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1,
          8
        ],
        "winner_filenames": [
          "test_22_1.jpg",
          "test_22_8.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_22_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_22_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1839599609375,
            0.19140625,
            0.2222900390625,
            0.1590576171875,
            0.17822265625,
            0.1600341796875,
            0.2044677734375,
            0.2099609375,
            0.271240234375
          ],
          "order_indices": [
            8,
            2,
            7,
            6,
            1,
            0,
            4,
            5,
            3
          ],
          "order_filenames": [
            "test_22_8.jpg",
            "test_22_2.jpg",
            "test_22_7.jpg",
            "test_22_6.jpg",
            "test_22_1.jpg",
            "test_22_0.jpg",
            "test_22_4.jpg",
            "test_22_5.jpg",
            "test_22_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.6166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.84375,
            40.5625,
            43.8125,
            25.625,
            31.25,
            32.65625,
            40.71875,
            43.75,
            43.875
          ],
          "order_indices": [
            8,
            2,
            7,
            6,
            1,
            0,
            5,
            4,
            3
          ],
          "order_filenames": [
            "test_22_8.jpg",
            "test_22_2.jpg",
            "test_22_7.jpg",
            "test_22_6.jpg",
            "test_22_1.jpg",
            "test_22_0.jpg",
            "test_22_5.jpg",
            "test_22_4.jpg",
            "test_22_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2777777777777778,
            "spearman_rho": 0.6,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.2505919933319092,
            -1.4127185344696045,
            0.11526808142662048,
            -2.159224033355713,
            -0.7279995083808899,
            -1.1637935638427734,
            -0.09032507985830307,
            -0.6748224496841431,
            1.224307656288147
          ],
          "order_indices": [
            8,
            0,
            2,
            6,
            7,
            4,
            5,
            1,
            3
          ],
          "order_filenames": [
            "test_22_8.jpg",
            "test_22_0.jpg",
            "test_22_2.jpg",
            "test_22_6.jpg",
            "test_22_7.jpg",
            "test_22_4.jpg",
            "test_22_5.jpg",
            "test_22_1.jpg",
            "test_22_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.033333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 23,
      "prompt": "Keqing from Genshin Impact.",
      "image_filenames": [
        "test_23_0.jpg",
        "test_23_1.jpg",
        "test_23_2.jpg",
        "test_23_3.jpg",
        "test_23_4.jpg",
        "test_23_5.jpg",
        "test_23_6.jpg",
        "test_23_7.jpg",
        "test_23_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          0,
          2,
          3,
          5,
          6,
          7,
          8,
          1
        ],
        "order_filenames": [
          "test_23_4.jpg",
          "test_23_0.jpg",
          "test_23_2.jpg",
          "test_23_3.jpg",
          "test_23_5.jpg",
          "test_23_6.jpg",
          "test_23_7.jpg",
          "test_23_8.jpg",
          "test_23_1.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_23_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_23_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0,
            4
          ],
          "winner_filenames": [
            "test_23_0.jpg",
            "test_23_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2001953125,
            0.208251953125,
            0.27294921875,
            0.1485595703125,
            0.1463623046875,
            0.129150390625,
            0.21435546875,
            0.2197265625,
            0.17333984375
          ],
          "order_indices": [
            2,
            7,
            6,
            1,
            0,
            8,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_23_2.jpg",
            "test_23_7.jpg",
            "test_23_6.jpg",
            "test_23_1.jpg",
            "test_23_0.jpg",
            "test_23_8.jpg",
            "test_23_3.jpg",
            "test_23_4.jpg",
            "test_23_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.25,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            23.15625,
            19.625,
            36.5,
            9.3515625,
            16.953125,
            14.703125,
            15.0,
            19.390625,
            30.890625
          ],
          "order_indices": [
            2,
            8,
            0,
            1,
            7,
            4,
            6,
            5,
            3
          ],
          "order_filenames": [
            "test_23_2.jpg",
            "test_23_8.jpg",
            "test_23_0.jpg",
            "test_23_1.jpg",
            "test_23_7.jpg",
            "test_23_4.jpg",
            "test_23_6.jpg",
            "test_23_5.jpg",
            "test_23_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.08333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.06786389648914337,
            -0.4364703297615051,
            0.5117847323417664,
            -2.110229253768921,
            -1.5894534587860107,
            -0.7043097019195557,
            -0.2920839190483093,
            -0.8964130878448486,
            -0.6991609930992126
          ],
          "order_indices": [
            2,
            0,
            6,
            1,
            8,
            5,
            7,
            4,
            3
          ],
          "order_filenames": [
            "test_23_2.jpg",
            "test_23_0.jpg",
            "test_23_6.jpg",
            "test_23_1.jpg",
            "test_23_8.jpg",
            "test_23_5.jpg",
            "test_23_7.jpg",
            "test_23_4.jpg",
            "test_23_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.016666666666666607,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 24,
      "prompt": "a papaya fruit dressed as a sailor.",
      "image_filenames": [
        "test_24_0.jpg",
        "test_24_1.jpg",
        "test_24_2.jpg",
        "test_24_3.jpg",
        "test_24_4.jpg",
        "test_24_5.jpg",
        "test_24_6.jpg",
        "test_24_7.jpg",
        "test_24_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          2,
          3,
          1,
          5,
          7,
          8,
          6,
          0
        ],
        "order_filenames": [
          "test_24_4.jpg",
          "test_24_2.jpg",
          "test_24_3.jpg",
          "test_24_1.jpg",
          "test_24_5.jpg",
          "test_24_7.jpg",
          "test_24_8.jpg",
          "test_24_6.jpg",
          "test_24_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_24_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_24_2.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_24_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1884765625,
            0.1639404296875,
            0.210205078125,
            0.1768798828125,
            0.182373046875,
            0.1810302734375,
            0.1932373046875,
            0.2332763671875,
            0.23779296875
          ],
          "order_indices": [
            8,
            7,
            2,
            6,
            0,
            4,
            5,
            3,
            1
          ],
          "order_filenames": [
            "test_24_8.jpg",
            "test_24_7.jpg",
            "test_24_2.jpg",
            "test_24_6.jpg",
            "test_24_0.jpg",
            "test_24_4.jpg",
            "test_24_5.jpg",
            "test_24_3.jpg",
            "test_24_1.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.3666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.96875,
            22.265625,
            31.5,
            25.5,
            28.421875,
            28.8125,
            27.984375,
            43.34375,
            44.59375
          ],
          "order_indices": [
            8,
            7,
            0,
            2,
            5,
            4,
            6,
            3,
            1
          ],
          "order_filenames": [
            "test_24_8.jpg",
            "test_24_7.jpg",
            "test_24_0.jpg",
            "test_24_2.jpg",
            "test_24_5.jpg",
            "test_24_4.jpg",
            "test_24_6.jpg",
            "test_24_3.jpg",
            "test_24_1.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.3999999999999999,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.8138576745986938,
            -2.1836183071136475,
            -1.9008636474609375,
            -1.0532073974609375,
            -1.4156361818313599,
            -1.3594146966934204,
            -1.6739051342010498,
            0.8863094449043274,
            -0.0470401793718338
          ],
          "order_indices": [
            7,
            8,
            0,
            3,
            5,
            4,
            6,
            2,
            1
          ],
          "order_filenames": [
            "test_24_7.jpg",
            "test_24_8.jpg",
            "test_24_0.jpg",
            "test_24_3.jpg",
            "test_24_5.jpg",
            "test_24_4.jpg",
            "test_24_6.jpg",
            "test_24_2.jpg",
            "test_24_1.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.44999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 25,
      "prompt": "The image features artwork in the style of Neon Genesis Evangelion, with a colorful anime design of John Key.",
      "image_filenames": [
        "test_25_0.jpg",
        "test_25_1.jpg",
        "test_25_2.jpg",
        "test_25_3.jpg",
        "test_25_4.jpg",
        "test_25_5.jpg",
        "test_25_6.jpg",
        "test_25_7.jpg",
        "test_25_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          4,
          0,
          5,
          7,
          6,
          8,
          2,
          3
        ],
        "order_filenames": [
          "test_25_1.jpg",
          "test_25_4.jpg",
          "test_25_0.jpg",
          "test_25_5.jpg",
          "test_25_7.jpg",
          "test_25_6.jpg",
          "test_25_8.jpg",
          "test_25_2.jpg",
          "test_25_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_25_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4,
            5
          ],
          "winner_filenames": [
            "test_25_4.jpg",
            "test_25_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_25_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.166015625,
            0.255615234375,
            0.2154541015625,
            0.1553955078125,
            0.17333984375,
            0.12841796875,
            0.196044921875,
            0.1978759765625,
            0.2281494140625
          ],
          "order_indices": [
            1,
            8,
            2,
            7,
            6,
            4,
            0,
            3,
            5
          ],
          "order_filenames": [
            "test_25_1.jpg",
            "test_25_8.jpg",
            "test_25_2.jpg",
            "test_25_7.jpg",
            "test_25_6.jpg",
            "test_25_4.jpg",
            "test_25_0.jpg",
            "test_25_3.jpg",
            "test_25_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.08333333333333337,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.625,
            32.65625,
            39.15625,
            28.5625,
            17.03125,
            16.046875,
            36.40625,
            45.5,
            37.0
          ],
          "order_indices": [
            7,
            0,
            2,
            8,
            6,
            1,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_25_7.jpg",
            "test_25_0.jpg",
            "test_25_2.jpg",
            "test_25_8.jpg",
            "test_25_6.jpg",
            "test_25_1.jpg",
            "test_25_3.jpg",
            "test_25_4.jpg",
            "test_25_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.02274770848453045,
            0.16003020107746124,
            1.5892786979675293,
            -1.1473132371902466,
            -0.29862627387046814,
            -1.7557464838027954,
            -0.8147628903388977,
            0.2101883888244629,
            1.0190516710281372
          ],
          "order_indices": [
            2,
            8,
            7,
            1,
            0,
            4,
            6,
            3,
            5
          ],
          "order_filenames": [
            "test_25_2.jpg",
            "test_25_8.jpg",
            "test_25_7.jpg",
            "test_25_1.jpg",
            "test_25_0.jpg",
            "test_25_4.jpg",
            "test_25_6.jpg",
            "test_25_3.jpg",
            "test_25_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.1166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 26,
      "prompt": "A still of Doraemon from \"Shaun the Sheep\" by Aardman Animation.",
      "image_filenames": [
        "test_26_0.jpg",
        "test_26_1.jpg",
        "test_26_2.jpg",
        "test_26_3.jpg",
        "test_26_4.jpg",
        "test_26_5.jpg",
        "test_26_6.jpg",
        "test_26_7.jpg",
        "test_26_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          3,
          2,
          6,
          7,
          4,
          8,
          1,
          0
        ],
        "order_filenames": [
          "test_26_5.jpg",
          "test_26_3.jpg",
          "test_26_2.jpg",
          "test_26_6.jpg",
          "test_26_7.jpg",
          "test_26_4.jpg",
          "test_26_8.jpg",
          "test_26_1.jpg",
          "test_26_0.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_26_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_26_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_26_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1563720703125,
            0.20361328125,
            0.25390625,
            0.19140625,
            0.1402587890625,
            0.1982421875,
            0.2379150390625,
            0.1688232421875,
            0.25927734375
          ],
          "order_indices": [
            8,
            2,
            6,
            1,
            5,
            3,
            7,
            0,
            4
          ],
          "order_filenames": [
            "test_26_8.jpg",
            "test_26_2.jpg",
            "test_26_6.jpg",
            "test_26_1.jpg",
            "test_26_5.jpg",
            "test_26_3.jpg",
            "test_26_7.jpg",
            "test_26_0.jpg",
            "test_26_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.16666666666666663,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.5625,
            34.15625,
            33.09375,
            28.46875,
            22.921875,
            25.3125,
            34.9375,
            33.75,
            35.5
          ],
          "order_indices": [
            8,
            6,
            0,
            1,
            7,
            2,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_26_8.jpg",
            "test_26_6.jpg",
            "test_26_0.jpg",
            "test_26_1.jpg",
            "test_26_7.jpg",
            "test_26_2.jpg",
            "test_26_3.jpg",
            "test_26_5.jpg",
            "test_26_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.5333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.0358400344848633,
            -0.5247856974601746,
            -0.7295828461647034,
            -1.8991364240646362,
            -2.1016101837158203,
            -1.404841423034668,
            -0.2725698947906494,
            -1.1910381317138672,
            0.02203983999788761
          ],
          "order_indices": [
            8,
            6,
            1,
            2,
            0,
            7,
            5,
            3,
            4
          ],
          "order_filenames": [
            "test_26_8.jpg",
            "test_26_6.jpg",
            "test_26_1.jpg",
            "test_26_2.jpg",
            "test_26_0.jpg",
            "test_26_7.jpg",
            "test_26_5.jpg",
            "test_26_3.jpg",
            "test_26_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.3666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 27,
      "prompt": "Rosario Dawson minimalist portrait by Jean Giraud in a comic book style.",
      "image_filenames": [
        "test_27_0.jpg",
        "test_27_1.jpg",
        "test_27_2.jpg",
        "test_27_3.jpg",
        "test_27_4.jpg",
        "test_27_5.jpg",
        "test_27_6.jpg",
        "test_27_7.jpg",
        "test_27_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          6,
          4,
          7,
          2,
          5,
          8,
          0,
          1
        ],
        "order_filenames": [
          "test_27_3.jpg",
          "test_27_6.jpg",
          "test_27_4.jpg",
          "test_27_7.jpg",
          "test_27_2.jpg",
          "test_27_5.jpg",
          "test_27_8.jpg",
          "test_27_0.jpg",
          "test_27_1.jpg"
        ],
        "condorcet_winner": 6,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_27_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_27_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_27_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.191650390625,
            0.186767578125,
            0.1822509765625,
            0.1903076171875,
            0.143310546875,
            0.0799560546875,
            0.2215576171875,
            0.210693359375,
            0.229736328125
          ],
          "order_indices": [
            8,
            6,
            7,
            0,
            3,
            1,
            2,
            4,
            5
          ],
          "order_filenames": [
            "test_27_8.jpg",
            "test_27_6.jpg",
            "test_27_7.jpg",
            "test_27_0.jpg",
            "test_27_3.jpg",
            "test_27_1.jpg",
            "test_27_2.jpg",
            "test_27_4.jpg",
            "test_27_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.033333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            41.53125,
            37.75,
            45.75,
            32.4375,
            15.6015625,
            14.0859375,
            43.0,
            39.59375,
            40.625
          ],
          "order_indices": [
            2,
            6,
            0,
            8,
            7,
            1,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_27_2.jpg",
            "test_27_6.jpg",
            "test_27_0.jpg",
            "test_27_8.jpg",
            "test_27_7.jpg",
            "test_27_1.jpg",
            "test_27_3.jpg",
            "test_27_4.jpg",
            "test_27_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.08333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.10887579619884491,
            -0.5525967478752136,
            -1.0371216535568237,
            -0.08745496720075607,
            -1.48103666305542,
            -2.280975103378296,
            -0.12989908456802368,
            -1.0570878982543945,
            1.250929594039917
          ],
          "order_indices": [
            8,
            3,
            0,
            6,
            1,
            2,
            7,
            4,
            5
          ],
          "order_filenames": [
            "test_27_8.jpg",
            "test_27_3.jpg",
            "test_27_0.jpg",
            "test_27_6.jpg",
            "test_27_1.jpg",
            "test_27_2.jpg",
            "test_27_7.jpg",
            "test_27_4.jpg",
            "test_27_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.050000000000000044,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 28,
      "prompt": "Totem pole made out of cats.",
      "image_filenames": [
        "test_28_0.jpg",
        "test_28_1.jpg",
        "test_28_2.jpg",
        "test_28_3.jpg",
        "test_28_4.jpg",
        "test_28_5.jpg",
        "test_28_6.jpg",
        "test_28_7.jpg",
        "test_28_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          2,
          4,
          0,
          5,
          6,
          3,
          7,
          8
        ],
        "order_filenames": [
          "test_28_1.jpg",
          "test_28_2.jpg",
          "test_28_4.jpg",
          "test_28_0.jpg",
          "test_28_5.jpg",
          "test_28_6.jpg",
          "test_28_3.jpg",
          "test_28_7.jpg",
          "test_28_8.jpg"
        ],
        "condorcet_winner": 1,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_28_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_28_3.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_28_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2259521484375,
            0.29833984375,
            0.327880859375,
            0.263427734375,
            0.2484130859375,
            0.1861572265625,
            0.300537109375,
            0.2646484375,
            0.2330322265625
          ],
          "order_indices": [
            2,
            6,
            1,
            7,
            3,
            4,
            8,
            0,
            5
          ],
          "order_filenames": [
            "test_28_2.jpg",
            "test_28_6.jpg",
            "test_28_1.jpg",
            "test_28_7.jpg",
            "test_28_3.jpg",
            "test_28_4.jpg",
            "test_28_8.jpg",
            "test_28_0.jpg",
            "test_28_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.2833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            33.90625,
            45.71875,
            45.15625,
            43.125,
            39.28125,
            33.5,
            38.09375,
            43.6875,
            41.0625
          ],
          "order_indices": [
            1,
            2,
            7,
            3,
            8,
            4,
            6,
            0,
            5
          ],
          "order_filenames": [
            "test_28_1.jpg",
            "test_28_2.jpg",
            "test_28_7.jpg",
            "test_28_3.jpg",
            "test_28_8.jpg",
            "test_28_4.jpg",
            "test_28_6.jpg",
            "test_28_0.jpg",
            "test_28_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.23333333333333328,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 1.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.582105278968811,
            1.501700758934021,
            1.5579949617385864,
            -0.3571227490901947,
            -0.31586945056915283,
            -0.8585423231124878,
            0.7062522172927856,
            1.275933861732483,
            0.895976722240448
          ],
          "order_indices": [
            2,
            1,
            7,
            8,
            6,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_28_2.jpg",
            "test_28_1.jpg",
            "test_28_7.jpg",
            "test_28_8.jpg",
            "test_28_6.jpg",
            "test_28_0.jpg",
            "test_28_4.jpg",
            "test_28_3.jpg",
            "test_28_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.25,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 29,
      "prompt": "Paul Chuckle bowling on a pirate ship during a storm.",
      "image_filenames": [
        "test_29_0.jpg",
        "test_29_1.jpg",
        "test_29_2.jpg",
        "test_29_3.jpg",
        "test_29_4.jpg",
        "test_29_5.jpg",
        "test_29_6.jpg",
        "test_29_7.jpg",
        "test_29_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          6,
          0,
          7,
          3,
          4,
          2,
          1,
          8
        ],
        "order_filenames": [
          "test_29_5.jpg",
          "test_29_6.jpg",
          "test_29_0.jpg",
          "test_29_7.jpg",
          "test_29_3.jpg",
          "test_29_4.jpg",
          "test_29_2.jpg",
          "test_29_1.jpg",
          "test_29_8.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_29_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_29_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_29_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2210693359375,
            0.271240234375,
            0.2203369140625,
            0.2059326171875,
            0.2037353515625,
            0.150634765625,
            0.298583984375,
            0.26220703125,
            0.272216796875
          ],
          "order_indices": [
            6,
            8,
            1,
            7,
            0,
            2,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_29_6.jpg",
            "test_29_8.jpg",
            "test_29_1.jpg",
            "test_29_7.jpg",
            "test_29_0.jpg",
            "test_29_2.jpg",
            "test_29_3.jpg",
            "test_29_4.jpg",
            "test_29_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.2666666666666666,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            49.59375,
            44.1875,
            41.75,
            27.609375,
            29.859375,
            21.90625,
            39.8125,
            55.9375,
            34.125
          ],
          "order_indices": [
            7,
            0,
            1,
            2,
            6,
            8,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_29_7.jpg",
            "test_29_0.jpg",
            "test_29_1.jpg",
            "test_29_2.jpg",
            "test_29_6.jpg",
            "test_29_8.jpg",
            "test_29_4.jpg",
            "test_29_3.jpg",
            "test_29_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.1333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.03005620837211609,
            1.5331835746765137,
            -1.401931643486023,
            -1.1579355001449585,
            -0.24793964624404907,
            -2.0181217193603516,
            0.7188144326210022,
            1.4916318655014038,
            1.0487561225891113
          ],
          "order_indices": [
            1,
            7,
            8,
            6,
            0,
            4,
            3,
            2,
            5
          ],
          "order_filenames": [
            "test_29_1.jpg",
            "test_29_7.jpg",
            "test_29_8.jpg",
            "test_29_6.jpg",
            "test_29_0.jpg",
            "test_29_4.jpg",
            "test_29_3.jpg",
            "test_29_2.jpg",
            "test_29_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.3833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 30,
      "prompt": "Cartoonish serpent cephalopod mutants emerge from a fiery hell.",
      "image_filenames": [
        "test_30_0.jpg",
        "test_30_1.jpg",
        "test_30_2.jpg",
        "test_30_3.jpg",
        "test_30_4.jpg",
        "test_30_5.jpg",
        "test_30_6.jpg",
        "test_30_7.jpg",
        "test_30_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          1,
          5,
          8,
          7,
          6,
          3,
          2,
          0
        ],
        "order_filenames": [
          "test_30_4.jpg",
          "test_30_1.jpg",
          "test_30_5.jpg",
          "test_30_8.jpg",
          "test_30_7.jpg",
          "test_30_6.jpg",
          "test_30_3.jpg",
          "test_30_2.jpg",
          "test_30_0.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_30_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_30_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_30_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2042236328125,
            0.1590576171875,
            0.2685546875,
            0.206298828125,
            0.17041015625,
            0.1732177734375,
            0.25048828125,
            0.23974609375,
            0.2900390625
          ],
          "order_indices": [
            8,
            2,
            6,
            7,
            3,
            0,
            5,
            4,
            1
          ],
          "order_filenames": [
            "test_30_8.jpg",
            "test_30_2.jpg",
            "test_30_6.jpg",
            "test_30_7.jpg",
            "test_30_3.jpg",
            "test_30_0.jpg",
            "test_30_5.jpg",
            "test_30_4.jpg",
            "test_30_1.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.5166666666666666,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.28125,
            21.984375,
            36.375,
            27.796875,
            23.171875,
            27.671875,
            29.90625,
            38.875,
            40.5625
          ],
          "order_indices": [
            8,
            7,
            0,
            2,
            6,
            3,
            5,
            4,
            1
          ],
          "order_filenames": [
            "test_30_8.jpg",
            "test_30_7.jpg",
            "test_30_0.jpg",
            "test_30_2.jpg",
            "test_30_6.jpg",
            "test_30_3.jpg",
            "test_30_5.jpg",
            "test_30_4.jpg",
            "test_30_1.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.55,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.3929955959320068,
            -1.5195780992507935,
            0.5751814842224121,
            0.7027691006660461,
            -1.6244754791259766,
            -1.1728780269622803,
            1.3773584365844727,
            1.6943501234054565,
            1.4979087114334106
          ],
          "order_indices": [
            7,
            8,
            0,
            6,
            3,
            2,
            5,
            1,
            4
          ],
          "order_filenames": [
            "test_30_7.jpg",
            "test_30_8.jpg",
            "test_30_0.jpg",
            "test_30_6.jpg",
            "test_30_3.jpg",
            "test_30_2.jpg",
            "test_30_5.jpg",
            "test_30_1.jpg",
            "test_30_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.5333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 31,
      "prompt": "A gummy chameleon hanging on a tree branch.",
      "image_filenames": [
        "test_31_0.jpg",
        "test_31_1.jpg",
        "test_31_2.jpg",
        "test_31_3.jpg",
        "test_31_4.jpg",
        "test_31_5.jpg",
        "test_31_6.jpg",
        "test_31_7.jpg",
        "test_31_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          0,
          3,
          7,
          8,
          6,
          2,
          4,
          1
        ],
        "order_filenames": [
          "test_31_5.jpg",
          "test_31_0.jpg",
          "test_31_3.jpg",
          "test_31_7.jpg",
          "test_31_8.jpg",
          "test_31_6.jpg",
          "test_31_2.jpg",
          "test_31_4.jpg",
          "test_31_1.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_31_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_31_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_31_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2137451171875,
            0.2069091796875,
            0.2998046875,
            0.18896484375,
            0.233154296875,
            0.1964111328125,
            0.2183837890625,
            0.2275390625,
            0.2021484375
          ],
          "order_indices": [
            2,
            4,
            7,
            6,
            0,
            1,
            8,
            5,
            3
          ],
          "order_filenames": [
            "test_31_2.jpg",
            "test_31_4.jpg",
            "test_31_7.jpg",
            "test_31_6.jpg",
            "test_31_0.jpg",
            "test_31_1.jpg",
            "test_31_8.jpg",
            "test_31_5.jpg",
            "test_31_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.5333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            44.125,
            36.625,
            33.03125,
            28.65625,
            29.234375,
            37.65625,
            36.34375,
            40.03125,
            31.5625
          ],
          "order_indices": [
            0,
            7,
            5,
            1,
            6,
            2,
            8,
            4,
            3
          ],
          "order_filenames": [
            "test_31_0.jpg",
            "test_31_7.jpg",
            "test_31_5.jpg",
            "test_31_1.jpg",
            "test_31_6.jpg",
            "test_31_2.jpg",
            "test_31_8.jpg",
            "test_31_4.jpg",
            "test_31_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.3666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.5030809640884399,
            -1.111920952796936,
            -0.13131321966648102,
            -1.8985118865966797,
            -1.437179684638977,
            -1.6608835458755493,
            -1.3216410875320435,
            -0.23204995691776276,
            -0.8730672001838684
          ],
          "order_indices": [
            2,
            7,
            0,
            8,
            1,
            6,
            4,
            5,
            3
          ],
          "order_filenames": [
            "test_31_2.jpg",
            "test_31_7.jpg",
            "test_31_0.jpg",
            "test_31_8.jpg",
            "test_31_1.jpg",
            "test_31_6.jpg",
            "test_31_4.jpg",
            "test_31_5.jpg",
            "test_31_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.19999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 32,
      "prompt": "A portrait of Nyan Cat, styled after Annie Leibovitz's dramatic photography.",
      "image_filenames": [
        "test_32_0.jpg",
        "test_32_1.jpg",
        "test_32_2.jpg",
        "test_32_3.jpg",
        "test_32_4.jpg",
        "test_32_5.jpg",
        "test_32_6.jpg",
        "test_32_7.jpg",
        "test_32_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          4,
          5,
          2,
          8,
          7,
          6,
          1,
          0
        ],
        "order_filenames": [
          "test_32_3.jpg",
          "test_32_4.jpg",
          "test_32_5.jpg",
          "test_32_2.jpg",
          "test_32_8.jpg",
          "test_32_7.jpg",
          "test_32_6.jpg",
          "test_32_1.jpg",
          "test_32_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_32_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_32_3.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_32_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.158935546875,
            0.16357421875,
            0.2332763671875,
            0.1256103515625,
            0.1700439453125,
            0.264892578125,
            0.15869140625,
            0.19580078125,
            0.235107421875
          ],
          "order_indices": [
            5,
            8,
            2,
            7,
            4,
            1,
            0,
            6,
            3
          ],
          "order_filenames": [
            "test_32_5.jpg",
            "test_32_8.jpg",
            "test_32_2.jpg",
            "test_32_7.jpg",
            "test_32_4.jpg",
            "test_32_1.jpg",
            "test_32_0.jpg",
            "test_32_6.jpg",
            "test_32_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.16666666666666663,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.03125,
            28.203125,
            30.796875,
            27.703125,
            32.09375,
            30.65625,
            29.015625,
            42.8125,
            38.28125
          ],
          "order_indices": [
            7,
            0,
            8,
            4,
            2,
            5,
            6,
            1,
            3
          ],
          "order_filenames": [
            "test_32_7.jpg",
            "test_32_0.jpg",
            "test_32_8.jpg",
            "test_32_4.jpg",
            "test_32_2.jpg",
            "test_32_5.jpg",
            "test_32_6.jpg",
            "test_32_1.jpg",
            "test_32_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.30000000000000004,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.0254745483398438,
            -2.1526198387145996,
            -0.4819665849208832,
            -2.120384454727173,
            -0.6198170185089111,
            -0.07093729078769684,
            -2.171381950378418,
            -0.7346243262290955,
            -0.630946159362793
          ],
          "order_indices": [
            5,
            2,
            4,
            8,
            7,
            0,
            3,
            1,
            6
          ],
          "order_filenames": [
            "test_32_5.jpg",
            "test_32_2.jpg",
            "test_32_4.jpg",
            "test_32_8.jpg",
            "test_32_7.jpg",
            "test_32_0.jpg",
            "test_32_3.jpg",
            "test_32_1.jpg",
            "test_32_6.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3888888888888889,
            "spearman_rho": 0.5,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 33,
      "prompt": "An anime girl is riding a bicycle in Akihabara, resembling the style seen in Studio Ghibli films, and the depiction is detailed.",
      "image_filenames": [
        "test_33_0.jpg",
        "test_33_1.jpg",
        "test_33_2.jpg",
        "test_33_3.jpg",
        "test_33_4.jpg",
        "test_33_5.jpg",
        "test_33_6.jpg",
        "test_33_7.jpg",
        "test_33_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          3,
          5,
          7,
          2,
          6,
          1,
          8,
          0
        ],
        "order_filenames": [
          "test_33_4.jpg",
          "test_33_3.jpg",
          "test_33_5.jpg",
          "test_33_7.jpg",
          "test_33_2.jpg",
          "test_33_6.jpg",
          "test_33_1.jpg",
          "test_33_8.jpg",
          "test_33_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_33_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_33_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_33_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.181640625,
            0.254638671875,
            0.26611328125,
            0.2222900390625,
            0.18310546875,
            0.1585693359375,
            0.2763671875,
            0.1932373046875,
            0.259521484375
          ],
          "order_indices": [
            6,
            2,
            8,
            1,
            3,
            7,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_33_6.jpg",
            "test_33_2.jpg",
            "test_33_8.jpg",
            "test_33_1.jpg",
            "test_33_3.jpg",
            "test_33_7.jpg",
            "test_33_4.jpg",
            "test_33_0.jpg",
            "test_33_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.28333333333333344,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            43.25,
            38.15625,
            43.875,
            40.5,
            30.625,
            24.53125,
            39.75,
            46.65625,
            37.90625
          ],
          "order_indices": [
            7,
            2,
            0,
            3,
            6,
            1,
            8,
            4,
            5
          ],
          "order_filenames": [
            "test_33_7.jpg",
            "test_33_2.jpg",
            "test_33_0.jpg",
            "test_33_3.jpg",
            "test_33_6.jpg",
            "test_33_1.jpg",
            "test_33_8.jpg",
            "test_33_4.jpg",
            "test_33_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.21666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.11110808700323105,
            0.31201595067977905,
            1.0284879207611084,
            0.4602310359477997,
            0.1964120715856552,
            -1.8312374353408813,
            0.9570456147193909,
            -0.9026217460632324,
            1.5006641149520874
          ],
          "order_indices": [
            8,
            2,
            6,
            3,
            1,
            4,
            0,
            7,
            5
          ],
          "order_filenames": [
            "test_33_8.jpg",
            "test_33_2.jpg",
            "test_33_6.jpg",
            "test_33_3.jpg",
            "test_33_1.jpg",
            "test_33_4.jpg",
            "test_33_0.jpg",
            "test_33_7.jpg",
            "test_33_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.30000000000000004,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 34,
      "prompt": "A full body portrait of Andre the Giant in the style of Justin Roiland.",
      "image_filenames": [
        "test_34_0.jpg",
        "test_34_1.jpg",
        "test_34_2.jpg",
        "test_34_3.jpg",
        "test_34_4.jpg",
        "test_34_5.jpg",
        "test_34_6.jpg",
        "test_34_7.jpg",
        "test_34_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          0,
          1,
          2,
          5,
          6,
          7,
          8,
          3
        ],
        "order_filenames": [
          "test_34_4.jpg",
          "test_34_0.jpg",
          "test_34_1.jpg",
          "test_34_2.jpg",
          "test_34_5.jpg",
          "test_34_6.jpg",
          "test_34_7.jpg",
          "test_34_8.jpg",
          "test_34_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_34_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_34_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_34_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1634521484375,
            0.2103271484375,
            0.189453125,
            0.1319580078125,
            0.1282958984375,
            0.08709716796875,
            0.1680908203125,
            0.160888671875,
            0.1978759765625
          ],
          "order_indices": [
            1,
            8,
            2,
            6,
            0,
            7,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_34_1.jpg",
            "test_34_8.jpg",
            "test_34_2.jpg",
            "test_34_6.jpg",
            "test_34_0.jpg",
            "test_34_7.jpg",
            "test_34_3.jpg",
            "test_34_4.jpg",
            "test_34_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.03333333333333344,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.6875,
            38.03125,
            37.5625,
            23.328125,
            19.125,
            10.4375,
            36.65625,
            40.875,
            37.0
          ],
          "order_indices": [
            7,
            1,
            2,
            8,
            6,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_34_7.jpg",
            "test_34_1.jpg",
            "test_34_2.jpg",
            "test_34_8.jpg",
            "test_34_6.jpg",
            "test_34_0.jpg",
            "test_34_3.jpg",
            "test_34_4.jpg",
            "test_34_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.16666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.12184283137321472,
            1.3950932025909424,
            0.9046018719673157,
            -1.7968344688415527,
            -0.6651126146316528,
            -2.095848321914673,
            0.5828683376312256,
            0.4805518686771393,
            1.0116634368896484
          ],
          "order_indices": [
            1,
            8,
            2,
            6,
            7,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_34_1.jpg",
            "test_34_8.jpg",
            "test_34_2.jpg",
            "test_34_6.jpg",
            "test_34_7.jpg",
            "test_34_0.jpg",
            "test_34_4.jpg",
            "test_34_3.jpg",
            "test_34_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.01666666666666672,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 35,
      "prompt": "An image of an emo with dark brown hair in a messy pixie cut, large entirely-black eyes, wearing black clothing and boots.",
      "image_filenames": [
        "test_35_0.jpg",
        "test_35_1.jpg",
        "test_35_2.jpg",
        "test_35_3.jpg",
        "test_35_4.jpg",
        "test_35_5.jpg",
        "test_35_6.jpg",
        "test_35_7.jpg",
        "test_35_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          2,
          0,
          5,
          6,
          1,
          7,
          8,
          3
        ],
        "order_filenames": [
          "test_35_4.jpg",
          "test_35_2.jpg",
          "test_35_0.jpg",
          "test_35_5.jpg",
          "test_35_6.jpg",
          "test_35_1.jpg",
          "test_35_7.jpg",
          "test_35_8.jpg",
          "test_35_3.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_35_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_35_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_35_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.162353515625,
            0.222900390625,
            0.2451171875,
            0.1578369140625,
            0.1688232421875,
            0.058990478515625,
            0.234130859375,
            0.1639404296875,
            0.2264404296875
          ],
          "order_indices": [
            2,
            6,
            8,
            1,
            4,
            7,
            0,
            3,
            5
          ],
          "order_filenames": [
            "test_35_2.jpg",
            "test_35_6.jpg",
            "test_35_8.jpg",
            "test_35_1.jpg",
            "test_35_4.jpg",
            "test_35_7.jpg",
            "test_35_0.jpg",
            "test_35_3.jpg",
            "test_35_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            33.09375,
            38.15625,
            37.5625,
            25.953125,
            30.421875,
            10.703125,
            37.625,
            34.625,
            39.84375
          ],
          "order_indices": [
            8,
            1,
            6,
            2,
            7,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_35_8.jpg",
            "test_35_1.jpg",
            "test_35_6.jpg",
            "test_35_2.jpg",
            "test_35_7.jpg",
            "test_35_0.jpg",
            "test_35_4.jpg",
            "test_35_3.jpg",
            "test_35_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.2333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.7744911909103394,
            -1.2784817218780518,
            -1.1640840768814087,
            -2.0157666206359863,
            -1.9363133907318115,
            -2.2749221324920654,
            -1.6103214025497437,
            -1.7238506078720093,
            -1.221954345703125
          ],
          "order_indices": [
            2,
            8,
            1,
            6,
            7,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_35_2.jpg",
            "test_35_8.jpg",
            "test_35_1.jpg",
            "test_35_6.jpg",
            "test_35_7.jpg",
            "test_35_0.jpg",
            "test_35_4.jpg",
            "test_35_3.jpg",
            "test_35_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.016666666666666607,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 36,
      "prompt": "A fruit basket on a kitchen table with a Studio Ghibli reference.",
      "image_filenames": [
        "test_36_0.jpg",
        "test_36_1.jpg",
        "test_36_2.jpg",
        "test_36_3.jpg",
        "test_36_4.jpg",
        "test_36_5.jpg",
        "test_36_6.jpg",
        "test_36_7.jpg",
        "test_36_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          1,
          4,
          3,
          2,
          5,
          7,
          0,
          8
        ],
        "order_filenames": [
          "test_36_6.jpg",
          "test_36_1.jpg",
          "test_36_4.jpg",
          "test_36_3.jpg",
          "test_36_2.jpg",
          "test_36_5.jpg",
          "test_36_7.jpg",
          "test_36_0.jpg",
          "test_36_8.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_36_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            1,
            3,
            6
          ],
          "winner_filenames": [
            "test_36_1.jpg",
            "test_36_3.jpg",
            "test_36_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_36_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2039794921875,
            0.2666015625,
            0.2454833984375,
            0.2308349609375,
            0.2161865234375,
            0.2266845703125,
            0.24267578125,
            0.2254638671875,
            0.242919921875
          ],
          "order_indices": [
            1,
            2,
            8,
            6,
            3,
            5,
            7,
            4,
            0
          ],
          "order_filenames": [
            "test_36_1.jpg",
            "test_36_2.jpg",
            "test_36_8.jpg",
            "test_36_6.jpg",
            "test_36_3.jpg",
            "test_36_5.jpg",
            "test_36_7.jpg",
            "test_36_4.jpg",
            "test_36_0.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2777777777777778,
            "spearman_rho": 0.31666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.1875,
            45.09375,
            36.46875,
            26.671875,
            34.28125,
            32.125,
            42.5625,
            46.28125,
            40.0625
          ],
          "order_indices": [
            7,
            1,
            6,
            8,
            0,
            2,
            4,
            5,
            3
          ],
          "order_filenames": [
            "test_36_7.jpg",
            "test_36_1.jpg",
            "test_36_6.jpg",
            "test_36_8.jpg",
            "test_36_0.jpg",
            "test_36_2.jpg",
            "test_36_4.jpg",
            "test_36_5.jpg",
            "test_36_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": 0.0,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.5753124356269836,
            0.8858740329742432,
            -1.2510533332824707,
            -1.0184987783432007,
            -0.2938920259475708,
            -1.061949372291565,
            0.03648851066827774,
            0.3217689096927643,
            0.3215745985507965
          ],
          "order_indices": [
            1,
            7,
            8,
            6,
            4,
            0,
            3,
            5,
            2
          ],
          "order_filenames": [
            "test_36_1.jpg",
            "test_36_7.jpg",
            "test_36_8.jpg",
            "test_36_6.jpg",
            "test_36_4.jpg",
            "test_36_0.jpg",
            "test_36_3.jpg",
            "test_36_5.jpg",
            "test_36_2.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.09999999999999998,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 37,
      "prompt": "A corgi puppy with many eyes depicted in a horror manga drawn by Junji Ito.",
      "image_filenames": [
        "test_37_0.jpg",
        "test_37_1.jpg",
        "test_37_2.jpg",
        "test_37_3.jpg",
        "test_37_4.jpg",
        "test_37_5.jpg",
        "test_37_6.jpg",
        "test_37_7.jpg",
        "test_37_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          3,
          4,
          2,
          5,
          6,
          8,
          7,
          0
        ],
        "order_filenames": [
          "test_37_1.jpg",
          "test_37_3.jpg",
          "test_37_4.jpg",
          "test_37_2.jpg",
          "test_37_5.jpg",
          "test_37_6.jpg",
          "test_37_8.jpg",
          "test_37_7.jpg",
          "test_37_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1,
          3
        ],
        "winner_filenames": [
          "test_37_1.jpg",
          "test_37_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            1,
            3
          ],
          "winner_filenames": [
            "test_37_1.jpg",
            "test_37_3.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_37_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.265869140625,
            0.1973876953125,
            0.2020263671875,
            0.1669921875,
            0.184814453125,
            0.1348876953125,
            0.28759765625,
            0.2193603515625,
            0.217529296875
          ],
          "order_indices": [
            6,
            0,
            7,
            8,
            2,
            1,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_37_6.jpg",
            "test_37_0.jpg",
            "test_37_7.jpg",
            "test_37_8.jpg",
            "test_37_2.jpg",
            "test_37_1.jpg",
            "test_37_4.jpg",
            "test_37_3.jpg",
            "test_37_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.6833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            42.8125,
            44.65625,
            42.6875,
            29.078125,
            23.109375,
            30.765625,
            40.71875,
            47.96875,
            38.625
          ],
          "order_indices": [
            7,
            1,
            0,
            2,
            6,
            8,
            5,
            3,
            4
          ],
          "order_filenames": [
            "test_37_7.jpg",
            "test_37_1.jpg",
            "test_37_0.jpg",
            "test_37_2.jpg",
            "test_37_6.jpg",
            "test_37_8.jpg",
            "test_37_5.jpg",
            "test_37_3.jpg",
            "test_37_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.3666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.2876950204372406,
            -1.4417012929916382,
            -1.4102435111999512,
            -1.9728682041168213,
            -1.6921050548553467,
            -2.2338547706604004,
            0.8323296308517456,
            -0.7585844397544861,
            -0.7462143898010254
          ],
          "order_indices": [
            6,
            0,
            8,
            7,
            2,
            1,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_37_6.jpg",
            "test_37_0.jpg",
            "test_37_8.jpg",
            "test_37_7.jpg",
            "test_37_2.jpg",
            "test_37_1.jpg",
            "test_37_4.jpg",
            "test_37_3.jpg",
            "test_37_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.6666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 38,
      "prompt": "A young woman witch cosplaying with a magic wand and broom, wearing boots, and posing in a full body shot with a detailed face.",
      "image_filenames": [
        "test_38_0.jpg",
        "test_38_1.jpg",
        "test_38_2.jpg",
        "test_38_3.jpg",
        "test_38_4.jpg",
        "test_38_5.jpg",
        "test_38_6.jpg",
        "test_38_7.jpg",
        "test_38_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          6,
          4,
          5,
          1,
          3,
          7,
          8,
          0
        ],
        "order_filenames": [
          "test_38_2.jpg",
          "test_38_6.jpg",
          "test_38_4.jpg",
          "test_38_5.jpg",
          "test_38_1.jpg",
          "test_38_3.jpg",
          "test_38_7.jpg",
          "test_38_8.jpg",
          "test_38_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          2,
          6
        ],
        "winner_filenames": [
          "test_38_2.jpg",
          "test_38_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_38_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2,
            4
          ],
          "winner_filenames": [
            "test_38_2.jpg",
            "test_38_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.16552734375,
            0.21044921875,
            0.2685546875,
            0.138427734375,
            0.150634765625,
            0.10382080078125,
            0.2220458984375,
            0.189208984375,
            0.26708984375
          ],
          "order_indices": [
            2,
            8,
            6,
            1,
            7,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_38_2.jpg",
            "test_38_8.jpg",
            "test_38_6.jpg",
            "test_38_1.jpg",
            "test_38_7.jpg",
            "test_38_0.jpg",
            "test_38_4.jpg",
            "test_38_3.jpg",
            "test_38_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.19999999999999996,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.53125,
            32.3125,
            34.125,
            22.03125,
            18.265625,
            8.5625,
            32.625,
            36.53125,
            35.78125
          ],
          "order_indices": [
            0,
            7,
            8,
            2,
            6,
            1,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_38_0.jpg",
            "test_38_7.jpg",
            "test_38_8.jpg",
            "test_38_2.jpg",
            "test_38_6.jpg",
            "test_38_1.jpg",
            "test_38_3.jpg",
            "test_38_4.jpg",
            "test_38_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.5333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.17845161259174347,
            0.2080814242362976,
            0.9669736623764038,
            -2.060495615005493,
            -1.2823580503463745,
            -2.2628366947174072,
            -0.07660677284002304,
            0.510653555393219,
            1.489814043045044
          ],
          "order_indices": [
            8,
            2,
            7,
            1,
            6,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_38_8.jpg",
            "test_38_2.jpg",
            "test_38_7.jpg",
            "test_38_1.jpg",
            "test_38_6.jpg",
            "test_38_0.jpg",
            "test_38_4.jpg",
            "test_38_3.jpg",
            "test_38_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.08333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 39,
      "prompt": "There is a Michael J. Fox Funko Pop figurine depicted in the image.",
      "image_filenames": [
        "test_39_0.jpg",
        "test_39_1.jpg",
        "test_39_2.jpg",
        "test_39_3.jpg",
        "test_39_4.jpg",
        "test_39_5.jpg",
        "test_39_6.jpg",
        "test_39_7.jpg",
        "test_39_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          6,
          4,
          8,
          3,
          7,
          2,
          5,
          1
        ],
        "order_filenames": [
          "test_39_0.jpg",
          "test_39_6.jpg",
          "test_39_4.jpg",
          "test_39_8.jpg",
          "test_39_3.jpg",
          "test_39_7.jpg",
          "test_39_2.jpg",
          "test_39_5.jpg",
          "test_39_1.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0,
          6
        ],
        "winner_filenames": [
          "test_39_0.jpg",
          "test_39_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_39_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0,
            4,
            6
          ],
          "winner_filenames": [
            "test_39_0.jpg",
            "test_39_4.jpg",
            "test_39_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.14892578125,
            0.20263671875,
            0.26416015625,
            0.158203125,
            0.1378173828125,
            0.141845703125,
            0.2132568359375,
            0.1668701171875,
            0.228759765625
          ],
          "order_indices": [
            2,
            8,
            6,
            1,
            7,
            3,
            0,
            5,
            4
          ],
          "order_filenames": [
            "test_39_2.jpg",
            "test_39_8.jpg",
            "test_39_6.jpg",
            "test_39_1.jpg",
            "test_39_7.jpg",
            "test_39_3.jpg",
            "test_39_0.jpg",
            "test_39_5.jpg",
            "test_39_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.16666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.0625,
            34.15625,
            37.3125,
            23.296875,
            17.234375,
            17.03125,
            32.53125,
            42.96875,
            34.375
          ],
          "order_indices": [
            7,
            2,
            8,
            1,
            0,
            6,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_39_7.jpg",
            "test_39_2.jpg",
            "test_39_8.jpg",
            "test_39_1.jpg",
            "test_39_0.jpg",
            "test_39_6.jpg",
            "test_39_3.jpg",
            "test_39_4.jpg",
            "test_39_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.1499999999999999,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.5545110702514648,
            -0.5671547651290894,
            0.7893485426902771,
            -0.9085891842842102,
            -1.9220901727676392,
            -1.8030552864074707,
            -1.062827706336975,
            -0.9370065331459045,
            0.664961576461792
          ],
          "order_indices": [
            2,
            8,
            1,
            3,
            7,
            6,
            0,
            5,
            4
          ],
          "order_filenames": [
            "test_39_2.jpg",
            "test_39_8.jpg",
            "test_39_1.jpg",
            "test_39_3.jpg",
            "test_39_7.jpg",
            "test_39_6.jpg",
            "test_39_0.jpg",
            "test_39_5.jpg",
            "test_39_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.3833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 40,
      "prompt": "Girl shooting fireballs at a dragon in a battle pose, Madhouse studio anime style.",
      "image_filenames": [
        "test_40_0.jpg",
        "test_40_1.jpg",
        "test_40_2.jpg",
        "test_40_3.jpg",
        "test_40_4.jpg",
        "test_40_5.jpg",
        "test_40_6.jpg",
        "test_40_7.jpg",
        "test_40_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          4,
          7,
          3,
          2,
          8,
          1,
          6,
          5
        ],
        "order_filenames": [
          "test_40_0.jpg",
          "test_40_4.jpg",
          "test_40_7.jpg",
          "test_40_3.jpg",
          "test_40_2.jpg",
          "test_40_8.jpg",
          "test_40_1.jpg",
          "test_40_6.jpg",
          "test_40_5.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_40_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_40_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_40_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1673583984375,
            0.286865234375,
            0.2359619140625,
            0.189453125,
            0.1783447265625,
            0.0972900390625,
            0.24755859375,
            0.25927734375,
            0.2491455078125
          ],
          "order_indices": [
            1,
            7,
            8,
            6,
            2,
            3,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_40_1.jpg",
            "test_40_7.jpg",
            "test_40_8.jpg",
            "test_40_6.jpg",
            "test_40_2.jpg",
            "test_40_3.jpg",
            "test_40_4.jpg",
            "test_40_0.jpg",
            "test_40_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.16666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.9375,
            40.46875,
            36.25,
            30.203125,
            25.75,
            18.1875,
            37.0625,
            51.625,
            44.9375
          ],
          "order_indices": [
            7,
            8,
            0,
            1,
            6,
            2,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_40_7.jpg",
            "test_40_8.jpg",
            "test_40_0.jpg",
            "test_40_1.jpg",
            "test_40_6.jpg",
            "test_40_2.jpg",
            "test_40_3.jpg",
            "test_40_4.jpg",
            "test_40_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.2666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.5736739039421082,
            0.5876874327659607,
            0.32777929306030273,
            -0.5921580195426941,
            -0.4090084135532379,
            -2.2741448879241943,
            1.1392672061920166,
            1.621360182762146,
            0.7573010921478271
          ],
          "order_indices": [
            7,
            6,
            8,
            1,
            0,
            2,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_40_7.jpg",
            "test_40_6.jpg",
            "test_40_8.jpg",
            "test_40_1.jpg",
            "test_40_0.jpg",
            "test_40_2.jpg",
            "test_40_4.jpg",
            "test_40_3.jpg",
            "test_40_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.033333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 41,
      "prompt": "Portrait of anime girl in mechanic armor in night Tokyo.",
      "image_filenames": [
        "test_41_0.jpg",
        "test_41_1.jpg",
        "test_41_2.jpg",
        "test_41_3.jpg",
        "test_41_4.jpg",
        "test_41_5.jpg",
        "test_41_6.jpg",
        "test_41_7.jpg",
        "test_41_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          4,
          6,
          0,
          7,
          2,
          3,
          8,
          1
        ],
        "order_filenames": [
          "test_41_5.jpg",
          "test_41_4.jpg",
          "test_41_6.jpg",
          "test_41_0.jpg",
          "test_41_7.jpg",
          "test_41_2.jpg",
          "test_41_3.jpg",
          "test_41_8.jpg",
          "test_41_1.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_41_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_41_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_41_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2230224609375,
            0.2064208984375,
            0.288818359375,
            0.2225341796875,
            0.181396484375,
            0.110595703125,
            0.2314453125,
            0.27294921875,
            0.307861328125
          ],
          "order_indices": [
            8,
            2,
            7,
            6,
            0,
            3,
            1,
            4,
            5
          ],
          "order_filenames": [
            "test_41_8.jpg",
            "test_41_2.jpg",
            "test_41_7.jpg",
            "test_41_6.jpg",
            "test_41_0.jpg",
            "test_41_3.jpg",
            "test_41_1.jpg",
            "test_41_4.jpg",
            "test_41_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.46666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            41.6875,
            31.359375,
            38.46875,
            32.3125,
            33.53125,
            19.890625,
            26.515625,
            46.6875,
            40.90625
          ],
          "order_indices": [
            7,
            0,
            8,
            2,
            4,
            3,
            1,
            6,
            5
          ],
          "order_filenames": [
            "test_41_7.jpg",
            "test_41_0.jpg",
            "test_41_8.jpg",
            "test_41_2.jpg",
            "test_41_4.jpg",
            "test_41_3.jpg",
            "test_41_1.jpg",
            "test_41_6.jpg",
            "test_41_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.2666666666666666,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.3904004096984863,
            -0.1440981924533844,
            0.9956451654434204,
            1.5928727388381958,
            0.9495965838432312,
            -2.228701591491699,
            -0.45469218492507935,
            1.7013871669769287,
            1.8495644330978394
          ],
          "order_indices": [
            8,
            7,
            3,
            0,
            2,
            4,
            1,
            6,
            5
          ],
          "order_filenames": [
            "test_41_8.jpg",
            "test_41_7.jpg",
            "test_41_3.jpg",
            "test_41_0.jpg",
            "test_41_2.jpg",
            "test_41_4.jpg",
            "test_41_1.jpg",
            "test_41_6.jpg",
            "test_41_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.5333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 42,
      "prompt": "Mugshot of Superman with unkempt appearance and green skin.",
      "image_filenames": [
        "test_42_0.jpg",
        "test_42_1.jpg",
        "test_42_2.jpg",
        "test_42_3.jpg",
        "test_42_4.jpg",
        "test_42_5.jpg",
        "test_42_6.jpg",
        "test_42_7.jpg",
        "test_42_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          2,
          3,
          4,
          0,
          7,
          6,
          8,
          1
        ],
        "order_filenames": [
          "test_42_5.jpg",
          "test_42_2.jpg",
          "test_42_3.jpg",
          "test_42_4.jpg",
          "test_42_0.jpg",
          "test_42_7.jpg",
          "test_42_6.jpg",
          "test_42_8.jpg",
          "test_42_1.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_42_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4,
            5
          ],
          "winner_filenames": [
            "test_42_4.jpg",
            "test_42_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2,
            4,
            5
          ],
          "winner_filenames": [
            "test_42_2.jpg",
            "test_42_4.jpg",
            "test_42_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.194580078125,
            0.2734375,
            0.2427978515625,
            0.271484375,
            0.1680908203125,
            0.12841796875,
            0.26220703125,
            0.223388671875,
            0.269287109375
          ],
          "order_indices": [
            1,
            3,
            8,
            6,
            2,
            7,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_42_1.jpg",
            "test_42_3.jpg",
            "test_42_8.jpg",
            "test_42_6.jpg",
            "test_42_2.jpg",
            "test_42_7.jpg",
            "test_42_0.jpg",
            "test_42_4.jpg",
            "test_42_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5555555555555556,
            "spearman_rho": -0.6000000000000001,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            43.75,
            31.96875,
            33.78125,
            34.59375,
            23.109375,
            16.59375,
            34.3125,
            47.65625,
            40.5625
          ],
          "order_indices": [
            7,
            0,
            8,
            3,
            6,
            2,
            1,
            4,
            5
          ],
          "order_filenames": [
            "test_42_7.jpg",
            "test_42_0.jpg",
            "test_42_8.jpg",
            "test_42_3.jpg",
            "test_42_6.jpg",
            "test_42_2.jpg",
            "test_42_1.jpg",
            "test_42_4.jpg",
            "test_42_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.3666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.6662851572036743,
            -0.814448893070221,
            0.10388713330030441,
            -1.2146960496902466,
            -1.9072891473770142,
            -2.277273654937744,
            1.3238787651062012,
            -0.16979056596755981,
            -0.7027880549430847
          ],
          "order_indices": [
            6,
            2,
            7,
            0,
            8,
            1,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_42_6.jpg",
            "test_42_2.jpg",
            "test_42_7.jpg",
            "test_42_0.jpg",
            "test_42_8.jpg",
            "test_42_1.jpg",
            "test_42_3.jpg",
            "test_42_4.jpg",
            "test_42_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.33333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 43,
      "prompt": "The image is of dancing potatoes in a cute cartoony style.",
      "image_filenames": [
        "test_43_0.jpg",
        "test_43_1.jpg",
        "test_43_2.jpg",
        "test_43_3.jpg",
        "test_43_4.jpg",
        "test_43_5.jpg",
        "test_43_6.jpg",
        "test_43_7.jpg",
        "test_43_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          8,
          2,
          1,
          6,
          7,
          3,
          5,
          0
        ],
        "order_filenames": [
          "test_43_4.jpg",
          "test_43_8.jpg",
          "test_43_2.jpg",
          "test_43_1.jpg",
          "test_43_6.jpg",
          "test_43_7.jpg",
          "test_43_3.jpg",
          "test_43_5.jpg",
          "test_43_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_43_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_43_1.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_43_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.193603515625,
            0.2529296875,
            0.2025146484375,
            0.1988525390625,
            0.159423828125,
            0.2100830078125,
            0.2091064453125,
            0.24951171875,
            0.22802734375
          ],
          "order_indices": [
            1,
            7,
            8,
            5,
            6,
            2,
            3,
            0,
            4
          ],
          "order_filenames": [
            "test_43_1.jpg",
            "test_43_7.jpg",
            "test_43_8.jpg",
            "test_43_5.jpg",
            "test_43_6.jpg",
            "test_43_2.jpg",
            "test_43_3.jpg",
            "test_43_0.jpg",
            "test_43_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.033333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.78125,
            33.53125,
            20.265625,
            30.046875,
            26.671875,
            35.34375,
            28.546875,
            44.03125,
            45.59375
          ],
          "order_indices": [
            8,
            7,
            0,
            5,
            1,
            3,
            6,
            4,
            2
          ],
          "order_filenames": [
            "test_43_8.jpg",
            "test_43_7.jpg",
            "test_43_0.jpg",
            "test_43_5.jpg",
            "test_43_1.jpg",
            "test_43_3.jpg",
            "test_43_6.jpg",
            "test_43_4.jpg",
            "test_43_2.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.33333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.1350586414337158,
            -0.2467082291841507,
            -2.0949840545654297,
            -0.04440877586603165,
            0.5750485062599182,
            -1.4342776536941528,
            -0.9806720614433289,
            1.3589812517166138,
            1.452537178993225
          ],
          "order_indices": [
            8,
            7,
            0,
            4,
            3,
            1,
            6,
            5,
            2
          ],
          "order_filenames": [
            "test_43_8.jpg",
            "test_43_7.jpg",
            "test_43_0.jpg",
            "test_43_4.jpg",
            "test_43_3.jpg",
            "test_43_1.jpg",
            "test_43_6.jpg",
            "test_43_5.jpg",
            "test_43_2.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.08333333333333337,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 44,
      "prompt": "Miss Piggy dressed in futuristic outfit resembling Leeloo from The Fifth Element.",
      "image_filenames": [
        "test_44_0.jpg",
        "test_44_1.jpg",
        "test_44_2.jpg",
        "test_44_3.jpg",
        "test_44_4.jpg",
        "test_44_5.jpg",
        "test_44_6.jpg",
        "test_44_7.jpg",
        "test_44_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          3,
          2,
          4,
          1,
          6,
          8,
          7,
          0
        ],
        "order_filenames": [
          "test_44_5.jpg",
          "test_44_3.jpg",
          "test_44_2.jpg",
          "test_44_4.jpg",
          "test_44_1.jpg",
          "test_44_6.jpg",
          "test_44_8.jpg",
          "test_44_7.jpg",
          "test_44_0.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_44_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_44_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_44_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.180908203125,
            0.245849609375,
            0.26171875,
            0.1942138671875,
            0.182373046875,
            0.133056640625,
            0.26708984375,
            0.223388671875,
            0.26708984375
          ],
          "order_indices": [
            6,
            8,
            2,
            1,
            7,
            3,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_44_6.jpg",
            "test_44_8.jpg",
            "test_44_2.jpg",
            "test_44_1.jpg",
            "test_44_7.jpg",
            "test_44_3.jpg",
            "test_44_4.jpg",
            "test_44_0.jpg",
            "test_44_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.25,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.75,
            25.125,
            37.3125,
            35.125,
            31.15625,
            7.26171875,
            33.09375,
            39.65625,
            30.59375
          ],
          "order_indices": [
            0,
            7,
            2,
            3,
            6,
            4,
            8,
            1,
            5
          ],
          "order_filenames": [
            "test_44_0.jpg",
            "test_44_7.jpg",
            "test_44_2.jpg",
            "test_44_3.jpg",
            "test_44_6.jpg",
            "test_44_4.jpg",
            "test_44_8.jpg",
            "test_44_1.jpg",
            "test_44_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.5166666666666666,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.1570635735988617,
            -0.341376930475235,
            0.49812114238739014,
            -0.5498563647270203,
            -0.34202340245246887,
            -1.702140212059021,
            1.087013602256775,
            0.8035517334938049,
            0.45195725560188293
          ],
          "order_indices": [
            6,
            7,
            2,
            8,
            0,
            1,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_44_6.jpg",
            "test_44_7.jpg",
            "test_44_2.jpg",
            "test_44_8.jpg",
            "test_44_0.jpg",
            "test_44_1.jpg",
            "test_44_4.jpg",
            "test_44_3.jpg",
            "test_44_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.6333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 45,
      "prompt": "The image is of a raccoon wearing a Peaky Blinders hat, surrounded by swirling mist and rendered with fine detail.",
      "image_filenames": [
        "test_45_0.jpg",
        "test_45_1.jpg",
        "test_45_2.jpg",
        "test_45_3.jpg",
        "test_45_4.jpg",
        "test_45_5.jpg",
        "test_45_6.jpg",
        "test_45_7.jpg",
        "test_45_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          8,
          2,
          4,
          7,
          1,
          5,
          3,
          6,
          0
        ],
        "order_filenames": [
          "test_45_8.jpg",
          "test_45_2.jpg",
          "test_45_4.jpg",
          "test_45_7.jpg",
          "test_45_1.jpg",
          "test_45_5.jpg",
          "test_45_3.jpg",
          "test_45_6.jpg",
          "test_45_0.jpg"
        ],
        "condorcet_winner": 8,
        "winner_indices": [
          8
        ],
        "winner_filenames": [
          "test_45_8.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            8
          ],
          "winner_filenames": [
            "test_45_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            8
          ],
          "winner_filenames": [
            "test_45_8.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.13623046875,
            0.2685546875,
            0.28564453125,
            0.219482421875,
            0.1614990234375,
            0.1700439453125,
            0.31005859375,
            0.2109375,
            0.260498046875
          ],
          "order_indices": [
            6,
            2,
            1,
            8,
            3,
            7,
            5,
            4,
            0
          ],
          "order_filenames": [
            "test_45_6.jpg",
            "test_45_2.jpg",
            "test_45_1.jpg",
            "test_45_8.jpg",
            "test_45_3.jpg",
            "test_45_7.jpg",
            "test_45_5.jpg",
            "test_45_4.jpg",
            "test_45_0.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.19999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            33.46875,
            40.375,
            38.90625,
            20.453125,
            35.3125,
            26.171875,
            42.53125,
            44.875,
            44.84375
          ],
          "order_indices": [
            7,
            8,
            6,
            1,
            2,
            4,
            0,
            5,
            3
          ],
          "order_filenames": [
            "test_45_7.jpg",
            "test_45_8.jpg",
            "test_45_6.jpg",
            "test_45_1.jpg",
            "test_45_2.jpg",
            "test_45_4.jpg",
            "test_45_0.jpg",
            "test_45_5.jpg",
            "test_45_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.44999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.3072023391723633,
            0.428349107503891,
            1.3541287183761597,
            -0.8678529858589172,
            -2.1545910835266113,
            -2.2413783073425293,
            1.6871235370635986,
            0.3494906723499298,
            1.8837970495224
          ],
          "order_indices": [
            8,
            6,
            2,
            1,
            7,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_45_8.jpg",
            "test_45_6.jpg",
            "test_45_2.jpg",
            "test_45_1.jpg",
            "test_45_7.jpg",
            "test_45_3.jpg",
            "test_45_0.jpg",
            "test_45_4.jpg",
            "test_45_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2777777777777778,
            "spearman_rho": 0.35,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 1.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 46,
      "prompt": "A green Gundam in an action pose that resembles Shrek.",
      "image_filenames": [
        "test_46_0.jpg",
        "test_46_1.jpg",
        "test_46_2.jpg",
        "test_46_3.jpg",
        "test_46_4.jpg",
        "test_46_5.jpg",
        "test_46_6.jpg",
        "test_46_7.jpg",
        "test_46_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          4,
          5,
          6,
          0,
          8,
          3,
          7,
          2
        ],
        "order_filenames": [
          "test_46_1.jpg",
          "test_46_4.jpg",
          "test_46_5.jpg",
          "test_46_6.jpg",
          "test_46_0.jpg",
          "test_46_8.jpg",
          "test_46_3.jpg",
          "test_46_7.jpg",
          "test_46_2.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_46_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_46_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1,
            4,
            5
          ],
          "winner_filenames": [
            "test_46_1.jpg",
            "test_46_4.jpg",
            "test_46_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.201904296875,
            0.275390625,
            0.288818359375,
            0.2247314453125,
            0.1810302734375,
            0.1900634765625,
            0.313232421875,
            0.2261962890625,
            0.23779296875
          ],
          "order_indices": [
            6,
            2,
            1,
            8,
            7,
            3,
            0,
            5,
            4
          ],
          "order_filenames": [
            "test_46_6.jpg",
            "test_46_2.jpg",
            "test_46_1.jpg",
            "test_46_8.jpg",
            "test_46_7.jpg",
            "test_46_3.jpg",
            "test_46_0.jpg",
            "test_46_5.jpg",
            "test_46_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.28333333333333344,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            32.125,
            37.28125,
            41.0,
            39.34375,
            31.34375,
            30.90625,
            39.09375,
            38.25,
            33.0
          ],
          "order_indices": [
            2,
            3,
            6,
            7,
            1,
            8,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_46_2.jpg",
            "test_46_3.jpg",
            "test_46_6.jpg",
            "test_46_7.jpg",
            "test_46_1.jpg",
            "test_46_8.jpg",
            "test_46_0.jpg",
            "test_46_4.jpg",
            "test_46_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.6499999999999999,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.10754550248384476,
            0.44722044467926025,
            0.3242492377758026,
            0.20365433394908905,
            -1.1578483581542969,
            -1.3719819784164429,
            0.6591002941131592,
            0.39773237705230713,
            -0.2189069539308548
          ],
          "order_indices": [
            6,
            1,
            7,
            2,
            3,
            0,
            8,
            4,
            5
          ],
          "order_filenames": [
            "test_46_6.jpg",
            "test_46_1.jpg",
            "test_46_7.jpg",
            "test_46_2.jpg",
            "test_46_3.jpg",
            "test_46_0.jpg",
            "test_46_8.jpg",
            "test_46_4.jpg",
            "test_46_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.1499999999999999,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 47,
      "prompt": "Digital anime art of mattress-man with a serious expression in an empty warehouse, highly detailed and spotlighted.",
      "image_filenames": [
        "test_47_0.jpg",
        "test_47_1.jpg",
        "test_47_2.jpg",
        "test_47_3.jpg",
        "test_47_4.jpg",
        "test_47_5.jpg",
        "test_47_6.jpg",
        "test_47_7.jpg",
        "test_47_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          7,
          3,
          4,
          5,
          1,
          2,
          8,
          0
        ],
        "order_filenames": [
          "test_47_6.jpg",
          "test_47_7.jpg",
          "test_47_3.jpg",
          "test_47_4.jpg",
          "test_47_5.jpg",
          "test_47_1.jpg",
          "test_47_2.jpg",
          "test_47_8.jpg",
          "test_47_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          6,
          7
        ],
        "winner_filenames": [
          "test_47_6.jpg",
          "test_47_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3,
            4,
            5
          ],
          "winner_filenames": [
            "test_47_3.jpg",
            "test_47_4.jpg",
            "test_47_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_47_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1693115234375,
            0.126220703125,
            0.2548828125,
            0.156005859375,
            0.1529541015625,
            0.11328125,
            0.1412353515625,
            0.196533203125,
            0.268798828125
          ],
          "order_indices": [
            8,
            2,
            7,
            0,
            3,
            4,
            6,
            1,
            5
          ],
          "order_filenames": [
            "test_47_8.jpg",
            "test_47_2.jpg",
            "test_47_7.jpg",
            "test_47_0.jpg",
            "test_47_3.jpg",
            "test_47_4.jpg",
            "test_47_6.jpg",
            "test_47_1.jpg",
            "test_47_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.3666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.40625,
            34.1875,
            40.4375,
            26.46875,
            37.65625,
            29.546875,
            38.75,
            46.78125,
            45.78125
          ],
          "order_indices": [
            7,
            8,
            2,
            6,
            0,
            4,
            1,
            5,
            3
          ],
          "order_filenames": [
            "test_47_7.jpg",
            "test_47_8.jpg",
            "test_47_2.jpg",
            "test_47_6.jpg",
            "test_47_0.jpg",
            "test_47_4.jpg",
            "test_47_1.jpg",
            "test_47_5.jpg",
            "test_47_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.8402876853942871,
            -1.248199701309204,
            0.5698062181472778,
            -1.6066852807998657,
            -0.4805838167667389,
            -2.027019500732422,
            -1.557723045349121,
            0.7696327567100525,
            0.8557444214820862
          ],
          "order_indices": [
            8,
            7,
            2,
            4,
            0,
            1,
            6,
            3,
            5
          ],
          "order_filenames": [
            "test_47_8.jpg",
            "test_47_7.jpg",
            "test_47_2.jpg",
            "test_47_4.jpg",
            "test_47_0.jpg",
            "test_47_1.jpg",
            "test_47_6.jpg",
            "test_47_3.jpg",
            "test_47_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.31666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 48,
      "prompt": "Portrait of an anime maid by Krenz Cushart, Alphonse Mucha, and Ilya Kuvshinov.",
      "image_filenames": [
        "test_48_0.jpg",
        "test_48_1.jpg",
        "test_48_2.jpg",
        "test_48_3.jpg",
        "test_48_4.jpg",
        "test_48_5.jpg",
        "test_48_6.jpg",
        "test_48_7.jpg",
        "test_48_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          6,
          1,
          2,
          4,
          3,
          7,
          8,
          0
        ],
        "order_filenames": [
          "test_48_5.jpg",
          "test_48_6.jpg",
          "test_48_1.jpg",
          "test_48_2.jpg",
          "test_48_4.jpg",
          "test_48_3.jpg",
          "test_48_7.jpg",
          "test_48_8.jpg",
          "test_48_0.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_48_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_48_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_48_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1497802734375,
            0.232177734375,
            0.23779296875,
            0.159912109375,
            0.1500244140625,
            0.0859375,
            0.2230224609375,
            0.17626953125,
            0.26025390625
          ],
          "order_indices": [
            8,
            2,
            1,
            6,
            7,
            3,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_48_8.jpg",
            "test_48_2.jpg",
            "test_48_1.jpg",
            "test_48_6.jpg",
            "test_48_7.jpg",
            "test_48_3.jpg",
            "test_48_4.jpg",
            "test_48_0.jpg",
            "test_48_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.08333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            32.34375,
            36.875,
            44.0,
            28.625,
            24.734375,
            17.703125,
            40.4375,
            40.4375,
            37.375
          ],
          "order_indices": [
            2,
            6,
            7,
            8,
            1,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_48_2.jpg",
            "test_48_6.jpg",
            "test_48_7.jpg",
            "test_48_8.jpg",
            "test_48_1.jpg",
            "test_48_0.jpg",
            "test_48_3.jpg",
            "test_48_4.jpg",
            "test_48_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.9475663304328918,
            0.3094102442264557,
            -0.6724268198013306,
            -1.3146291971206665,
            -0.818854033946991,
            -2.25711727142334,
            -0.30191296339035034,
            -1.407008171081543,
            0.872281014919281
          ],
          "order_indices": [
            8,
            1,
            6,
            2,
            4,
            0,
            3,
            7,
            5
          ],
          "order_filenames": [
            "test_48_8.jpg",
            "test_48_1.jpg",
            "test_48_6.jpg",
            "test_48_2.jpg",
            "test_48_4.jpg",
            "test_48_0.jpg",
            "test_48_3.jpg",
            "test_48_7.jpg",
            "test_48_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": -0.050000000000000044,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 49,
      "prompt": "Siamese twins enjoying pickled eggs at a pub.",
      "image_filenames": [
        "test_49_0.jpg",
        "test_49_1.jpg",
        "test_49_2.jpg",
        "test_49_3.jpg",
        "test_49_4.jpg",
        "test_49_5.jpg",
        "test_49_6.jpg",
        "test_49_7.jpg",
        "test_49_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          2,
          0,
          1,
          5,
          4,
          8,
          6,
          7
        ],
        "order_filenames": [
          "test_49_3.jpg",
          "test_49_2.jpg",
          "test_49_0.jpg",
          "test_49_1.jpg",
          "test_49_5.jpg",
          "test_49_4.jpg",
          "test_49_8.jpg",
          "test_49_6.jpg",
          "test_49_7.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_49_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_49_3.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2,
            3
          ],
          "winner_filenames": [
            "test_49_2.jpg",
            "test_49_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.192138671875,
            0.1951904296875,
            0.2281494140625,
            0.1795654296875,
            0.18017578125,
            0.133056640625,
            0.2509765625,
            0.2052001953125,
            0.203857421875
          ],
          "order_indices": [
            6,
            2,
            7,
            8,
            1,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_49_6.jpg",
            "test_49_2.jpg",
            "test_49_7.jpg",
            "test_49_8.jpg",
            "test_49_1.jpg",
            "test_49_0.jpg",
            "test_49_4.jpg",
            "test_49_3.jpg",
            "test_49_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.41666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            52.0625,
            41.0,
            44.71875,
            25.921875,
            40.03125,
            26.796875,
            37.71875,
            45.125,
            39.75
          ],
          "order_indices": [
            0,
            7,
            2,
            1,
            4,
            8,
            6,
            5,
            3
          ],
          "order_filenames": [
            "test_49_0.jpg",
            "test_49_7.jpg",
            "test_49_2.jpg",
            "test_49_1.jpg",
            "test_49_4.jpg",
            "test_49_8.jpg",
            "test_49_6.jpg",
            "test_49_5.jpg",
            "test_49_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.08333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.4098761081695557,
            0.22732578217983246,
            -0.5500955581665039,
            -1.8663510084152222,
            -0.06210801377892494,
            -2.045132875442505,
            -0.6495471000671387,
            -1.135550618171692,
            -1.645850658416748
          ],
          "order_indices": [
            0,
            1,
            4,
            2,
            6,
            7,
            8,
            3,
            5
          ],
          "order_filenames": [
            "test_49_0.jpg",
            "test_49_1.jpg",
            "test_49_4.jpg",
            "test_49_2.jpg",
            "test_49_6.jpg",
            "test_49_7.jpg",
            "test_49_8.jpg",
            "test_49_3.jpg",
            "test_49_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.1333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 50,
      "prompt": "An anime furry anthro dragon in a deep forest, depicted in a realistic and detailed cel shading style.",
      "image_filenames": [
        "test_50_0.jpg",
        "test_50_1.jpg",
        "test_50_2.jpg",
        "test_50_3.jpg",
        "test_50_4.jpg",
        "test_50_5.jpg",
        "test_50_6.jpg",
        "test_50_7.jpg",
        "test_50_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          2,
          4,
          6,
          1,
          0,
          7,
          8,
          3
        ],
        "order_filenames": [
          "test_50_5.jpg",
          "test_50_2.jpg",
          "test_50_4.jpg",
          "test_50_6.jpg",
          "test_50_1.jpg",
          "test_50_0.jpg",
          "test_50_7.jpg",
          "test_50_8.jpg",
          "test_50_3.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_50_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_50_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_50_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.200927734375,
            0.228515625,
            0.281005859375,
            0.1810302734375,
            0.169677734375,
            0.11395263671875,
            0.18701171875,
            0.2314453125,
            0.283935546875
          ],
          "order_indices": [
            8,
            2,
            7,
            1,
            0,
            6,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_50_8.jpg",
            "test_50_2.jpg",
            "test_50_7.jpg",
            "test_50_1.jpg",
            "test_50_0.jpg",
            "test_50_6.jpg",
            "test_50_3.jpg",
            "test_50_4.jpg",
            "test_50_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.3666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            43.5625,
            39.65625,
            39.25,
            33.53125,
            31.53125,
            20.96875,
            31.875,
            41.5,
            39.1875
          ],
          "order_indices": [
            0,
            7,
            1,
            2,
            8,
            3,
            6,
            4,
            5
          ],
          "order_filenames": [
            "test_50_0.jpg",
            "test_50_7.jpg",
            "test_50_1.jpg",
            "test_50_2.jpg",
            "test_50_8.jpg",
            "test_50_3.jpg",
            "test_50_6.jpg",
            "test_50_4.jpg",
            "test_50_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.44999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.407386839389801,
            1.1961411237716675,
            1.4774823188781738,
            -0.5932095646858215,
            -1.4361408948898315,
            -2.271541118621826,
            0.8841145038604736,
            0.3811537027359009,
            0.9758082628250122
          ],
          "order_indices": [
            2,
            1,
            8,
            6,
            0,
            7,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_50_2.jpg",
            "test_50_1.jpg",
            "test_50_8.jpg",
            "test_50_6.jpg",
            "test_50_0.jpg",
            "test_50_7.jpg",
            "test_50_3.jpg",
            "test_50_4.jpg",
            "test_50_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.08333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 51,
      "prompt": "Gnomes are playing music during Independence Day festivities in a forest near Lake George.",
      "image_filenames": [
        "test_51_0.jpg",
        "test_51_1.jpg",
        "test_51_2.jpg",
        "test_51_3.jpg",
        "test_51_4.jpg",
        "test_51_5.jpg",
        "test_51_6.jpg",
        "test_51_7.jpg",
        "test_51_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          5,
          7,
          2,
          4,
          3,
          6,
          1,
          8
        ],
        "order_filenames": [
          "test_51_0.jpg",
          "test_51_5.jpg",
          "test_51_7.jpg",
          "test_51_2.jpg",
          "test_51_4.jpg",
          "test_51_3.jpg",
          "test_51_6.jpg",
          "test_51_1.jpg",
          "test_51_8.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_51_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_51_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_51_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2061767578125,
            0.26220703125,
            0.271728515625,
            0.1912841796875,
            0.1947021484375,
            0.1346435546875,
            0.2724609375,
            0.25439453125,
            0.2958984375
          ],
          "order_indices": [
            8,
            6,
            2,
            1,
            7,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_51_8.jpg",
            "test_51_6.jpg",
            "test_51_2.jpg",
            "test_51_1.jpg",
            "test_51_7.jpg",
            "test_51_0.jpg",
            "test_51_4.jpg",
            "test_51_3.jpg",
            "test_51_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.6000000000000001,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            45.46875,
            39.5625,
            40.65625,
            31.40625,
            33.5625,
            29.390625,
            40.0,
            44.5,
            44.71875
          ],
          "order_indices": [
            0,
            8,
            7,
            2,
            6,
            1,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_51_0.jpg",
            "test_51_8.jpg",
            "test_51_7.jpg",
            "test_51_2.jpg",
            "test_51_6.jpg",
            "test_51_1.jpg",
            "test_51_4.jpg",
            "test_51_3.jpg",
            "test_51_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.050000000000000044,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.1769825220108032,
            1.291851282119751,
            1.4008384943008423,
            -0.04316341504454613,
            0.7879155278205872,
            -1.6159532070159912,
            1.4547312259674072,
            1.6390552520751953,
            1.6223126649856567
          ],
          "order_indices": [
            7,
            8,
            6,
            2,
            1,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_51_7.jpg",
            "test_51_8.jpg",
            "test_51_6.jpg",
            "test_51_2.jpg",
            "test_51_1.jpg",
            "test_51_0.jpg",
            "test_51_4.jpg",
            "test_51_3.jpg",
            "test_51_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.33333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 52,
      "prompt": "Spider-Man holding a ginger cat.",
      "image_filenames": [
        "test_52_0.jpg",
        "test_52_1.jpg",
        "test_52_2.jpg",
        "test_52_3.jpg",
        "test_52_4.jpg",
        "test_52_5.jpg",
        "test_52_6.jpg",
        "test_52_7.jpg",
        "test_52_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          7,
          2,
          5,
          6,
          8,
          3,
          0,
          4
        ],
        "order_filenames": [
          "test_52_1.jpg",
          "test_52_7.jpg",
          "test_52_2.jpg",
          "test_52_5.jpg",
          "test_52_6.jpg",
          "test_52_8.jpg",
          "test_52_3.jpg",
          "test_52_0.jpg",
          "test_52_4.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_52_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6,
            7
          ],
          "winner_filenames": [
            "test_52_6.jpg",
            "test_52_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_52_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1959228515625,
            0.30224609375,
            0.296142578125,
            0.24462890625,
            0.181884765625,
            0.15625,
            0.2822265625,
            0.194091796875,
            0.2388916015625
          ],
          "order_indices": [
            1,
            2,
            6,
            3,
            8,
            0,
            7,
            4,
            5
          ],
          "order_filenames": [
            "test_52_1.jpg",
            "test_52_2.jpg",
            "test_52_6.jpg",
            "test_52_3.jpg",
            "test_52_8.jpg",
            "test_52_0.jpg",
            "test_52_7.jpg",
            "test_52_4.jpg",
            "test_52_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3888888888888889,
            "spearman_rho": 0.41666666666666663,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.375,
            36.65625,
            35.1875,
            30.6875,
            29.421875,
            15.390625,
            37.84375,
            27.796875,
            33.625
          ],
          "order_indices": [
            6,
            0,
            1,
            2,
            8,
            3,
            4,
            7,
            5
          ],
          "order_filenames": [
            "test_52_6.jpg",
            "test_52_0.jpg",
            "test_52_1.jpg",
            "test_52_2.jpg",
            "test_52_8.jpg",
            "test_52_3.jpg",
            "test_52_4.jpg",
            "test_52_7.jpg",
            "test_52_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": -0.03333333333333344,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.3686605989933014,
            -0.23495621979236603,
            0.28495022654533386,
            -1.251729965209961,
            -2.028696298599243,
            -2.2322590351104736,
            0.0010534385219216347,
            -0.5893431305885315,
            -0.16707919538021088
          ],
          "order_indices": [
            2,
            6,
            8,
            1,
            0,
            7,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_52_2.jpg",
            "test_52_6.jpg",
            "test_52_8.jpg",
            "test_52_1.jpg",
            "test_52_0.jpg",
            "test_52_7.jpg",
            "test_52_3.jpg",
            "test_52_4.jpg",
            "test_52_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2777777777777778,
            "spearman_rho": 0.31666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 53,
      "prompt": "Close-up of Cad Bane, with bad flash.",
      "image_filenames": [
        "test_53_0.jpg",
        "test_53_1.jpg",
        "test_53_2.jpg",
        "test_53_3.jpg",
        "test_53_4.jpg",
        "test_53_5.jpg",
        "test_53_6.jpg",
        "test_53_7.jpg",
        "test_53_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          3,
          1,
          5,
          6,
          4,
          2,
          8,
          7
        ],
        "order_filenames": [
          "test_53_0.jpg",
          "test_53_3.jpg",
          "test_53_1.jpg",
          "test_53_5.jpg",
          "test_53_6.jpg",
          "test_53_4.jpg",
          "test_53_2.jpg",
          "test_53_8.jpg",
          "test_53_7.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_53_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_53_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_53_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.192138671875,
            0.1903076171875,
            0.270263671875,
            0.18994140625,
            0.1790771484375,
            0.143310546875,
            0.220947265625,
            0.2125244140625,
            0.157958984375
          ],
          "order_indices": [
            2,
            6,
            7,
            0,
            1,
            3,
            4,
            8,
            5
          ],
          "order_filenames": [
            "test_53_2.jpg",
            "test_53_6.jpg",
            "test_53_7.jpg",
            "test_53_0.jpg",
            "test_53_1.jpg",
            "test_53_3.jpg",
            "test_53_4.jpg",
            "test_53_8.jpg",
            "test_53_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.1333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            42.59375,
            25.453125,
            37.5,
            29.46875,
            33.53125,
            18.0,
            32.96875,
            41.625,
            10.53125
          ],
          "order_indices": [
            0,
            7,
            2,
            4,
            6,
            3,
            1,
            5,
            8
          ],
          "order_filenames": [
            "test_53_0.jpg",
            "test_53_7.jpg",
            "test_53_2.jpg",
            "test_53_4.jpg",
            "test_53_6.jpg",
            "test_53_3.jpg",
            "test_53_1.jpg",
            "test_53_5.jpg",
            "test_53_8.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": 0.01666666666666672,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.07981646806001663,
            -0.12179290503263474,
            0.6146471500396729,
            -0.5420702695846558,
            -0.6229462623596191,
            -2.15761399269104,
            0.48628610372543335,
            -0.1063835546374321,
            -1.1561105251312256
          ],
          "order_indices": [
            2,
            6,
            0,
            7,
            1,
            3,
            4,
            8,
            5
          ],
          "order_filenames": [
            "test_53_2.jpg",
            "test_53_6.jpg",
            "test_53_0.jpg",
            "test_53_7.jpg",
            "test_53_1.jpg",
            "test_53_3.jpg",
            "test_53_4.jpg",
            "test_53_8.jpg",
            "test_53_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.0,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 54,
      "prompt": "Claymation of Futurama characters.",
      "image_filenames": [
        "test_54_0.jpg",
        "test_54_1.jpg",
        "test_54_2.jpg",
        "test_54_3.jpg",
        "test_54_4.jpg",
        "test_54_5.jpg",
        "test_54_6.jpg",
        "test_54_7.jpg",
        "test_54_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          4,
          7,
          6,
          0,
          3,
          8,
          1,
          2
        ],
        "order_filenames": [
          "test_54_5.jpg",
          "test_54_4.jpg",
          "test_54_7.jpg",
          "test_54_6.jpg",
          "test_54_0.jpg",
          "test_54_3.jpg",
          "test_54_8.jpg",
          "test_54_1.jpg",
          "test_54_2.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_54_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_54_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_54_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.15185546875,
            0.2105712890625,
            0.24853515625,
            0.158935546875,
            0.160400390625,
            0.152587890625,
            0.255615234375,
            0.2025146484375,
            0.23681640625
          ],
          "order_indices": [
            6,
            2,
            8,
            1,
            7,
            4,
            3,
            5,
            0
          ],
          "order_filenames": [
            "test_54_6.jpg",
            "test_54_2.jpg",
            "test_54_8.jpg",
            "test_54_1.jpg",
            "test_54_7.jpg",
            "test_54_4.jpg",
            "test_54_3.jpg",
            "test_54_5.jpg",
            "test_54_0.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.46666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            45.03125,
            34.875,
            40.125,
            31.40625,
            23.53125,
            29.0,
            37.78125,
            49.15625,
            43.09375
          ],
          "order_indices": [
            7,
            0,
            8,
            2,
            6,
            1,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_54_7.jpg",
            "test_54_0.jpg",
            "test_54_8.jpg",
            "test_54_2.jpg",
            "test_54_6.jpg",
            "test_54_1.jpg",
            "test_54_3.jpg",
            "test_54_5.jpg",
            "test_54_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.31666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.036908864974975586,
            0.0013185286661610007,
            1.0961672067642212,
            -0.6662607192993164,
            -0.5076430439949036,
            -0.8867259621620178,
            0.5263957381248474,
            -0.3951983153820038,
            0.550163984298706
          ],
          "order_indices": [
            2,
            8,
            6,
            1,
            0,
            7,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_54_2.jpg",
            "test_54_8.jpg",
            "test_54_6.jpg",
            "test_54_1.jpg",
            "test_54_0.jpg",
            "test_54_7.jpg",
            "test_54_4.jpg",
            "test_54_3.jpg",
            "test_54_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.6111111111111112,
            "spearman_rho": -0.7333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 55,
      "prompt": "The image is a highly-detailed, symmetrical concept art depicting a full-body illustration of a character from the anime Saitama, with vibrant colors and a galaxy background.",
      "image_filenames": [
        "test_55_0.jpg",
        "test_55_1.jpg",
        "test_55_2.jpg",
        "test_55_3.jpg",
        "test_55_4.jpg",
        "test_55_5.jpg",
        "test_55_6.jpg",
        "test_55_7.jpg",
        "test_55_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          3,
          4,
          1,
          6,
          2,
          7,
          8,
          0
        ],
        "order_filenames": [
          "test_55_5.jpg",
          "test_55_3.jpg",
          "test_55_4.jpg",
          "test_55_1.jpg",
          "test_55_6.jpg",
          "test_55_2.jpg",
          "test_55_7.jpg",
          "test_55_8.jpg",
          "test_55_0.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_55_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_55_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_55_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1876220703125,
            0.190673828125,
            0.252685546875,
            0.14892578125,
            0.1441650390625,
            0.151123046875,
            0.2451171875,
            0.19091796875,
            0.239990234375
          ],
          "order_indices": [
            2,
            6,
            8,
            7,
            1,
            0,
            5,
            3,
            4
          ],
          "order_filenames": [
            "test_55_2.jpg",
            "test_55_6.jpg",
            "test_55_8.jpg",
            "test_55_7.jpg",
            "test_55_1.jpg",
            "test_55_0.jpg",
            "test_55_5.jpg",
            "test_55_3.jpg",
            "test_55_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.55,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.5625,
            35.8125,
            38.78125,
            29.265625,
            21.640625,
            19.8125,
            38.71875,
            43.71875,
            41.46875
          ],
          "order_indices": [
            7,
            8,
            2,
            6,
            0,
            1,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_55_7.jpg",
            "test_55_8.jpg",
            "test_55_2.jpg",
            "test_55_6.jpg",
            "test_55_0.jpg",
            "test_55_1.jpg",
            "test_55_3.jpg",
            "test_55_4.jpg",
            "test_55_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.6666666666666666,
            "spearman_rho": -0.8,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.5430671572685242,
            0.2018458992242813,
            -0.057798903435468674,
            -1.201864242553711,
            -1.217893123626709,
            -1.7388238906860352,
            0.3611506521701813,
            -0.1500406712293625,
            1.7732454538345337
          ],
          "order_indices": [
            8,
            6,
            1,
            2,
            7,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_55_8.jpg",
            "test_55_6.jpg",
            "test_55_1.jpg",
            "test_55_2.jpg",
            "test_55_7.jpg",
            "test_55_0.jpg",
            "test_55_3.jpg",
            "test_55_4.jpg",
            "test_55_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.5833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 56,
      "prompt": "A full body pic of a comic character drawn by Rob Liefield.",
      "image_filenames": [
        "test_56_0.jpg",
        "test_56_1.jpg",
        "test_56_2.jpg",
        "test_56_3.jpg",
        "test_56_4.jpg",
        "test_56_5.jpg",
        "test_56_6.jpg",
        "test_56_7.jpg",
        "test_56_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          4,
          3,
          7,
          8,
          2,
          1,
          0,
          6
        ],
        "order_filenames": [
          "test_56_5.jpg",
          "test_56_4.jpg",
          "test_56_3.jpg",
          "test_56_7.jpg",
          "test_56_8.jpg",
          "test_56_2.jpg",
          "test_56_1.jpg",
          "test_56_0.jpg",
          "test_56_6.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_56_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4,
            5
          ],
          "winner_filenames": [
            "test_56_4.jpg",
            "test_56_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_56_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1435546875,
            0.2071533203125,
            0.226806640625,
            0.13134765625,
            0.15478515625,
            0.10986328125,
            0.264892578125,
            0.1746826171875,
            0.19775390625
          ],
          "order_indices": [
            6,
            2,
            1,
            8,
            7,
            4,
            0,
            3,
            5
          ],
          "order_filenames": [
            "test_56_6.jpg",
            "test_56_2.jpg",
            "test_56_1.jpg",
            "test_56_8.jpg",
            "test_56_7.jpg",
            "test_56_4.jpg",
            "test_56_0.jpg",
            "test_56_3.jpg",
            "test_56_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.6111111111111112,
            "spearman_rho": -0.7,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            28.5,
            32.40625,
            33.5,
            31.9375,
            19.734375,
            29.875,
            29.109375,
            40.3125,
            32.34375
          ],
          "order_indices": [
            7,
            2,
            1,
            8,
            3,
            5,
            6,
            0,
            4
          ],
          "order_filenames": [
            "test_56_7.jpg",
            "test_56_2.jpg",
            "test_56_1.jpg",
            "test_56_8.jpg",
            "test_56_3.jpg",
            "test_56_5.jpg",
            "test_56_6.jpg",
            "test_56_0.jpg",
            "test_56_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.03333333333333344,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.4618852138519287,
            0.18552528321743011,
            1.432942271232605,
            -2.2362425327301025,
            -1.2126283645629883,
            -1.1705089807510376,
            0.797185480594635,
            -1.497705101966858,
            0.535253643989563
          ],
          "order_indices": [
            2,
            6,
            8,
            1,
            5,
            4,
            0,
            7,
            3
          ],
          "order_filenames": [
            "test_56_2.jpg",
            "test_56_6.jpg",
            "test_56_8.jpg",
            "test_56_1.jpg",
            "test_56_5.jpg",
            "test_56_4.jpg",
            "test_56_0.jpg",
            "test_56_7.jpg",
            "test_56_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.43333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 57,
      "prompt": "A still frame from the anime film Akira.",
      "image_filenames": [
        "test_57_0.jpg",
        "test_57_1.jpg",
        "test_57_2.jpg",
        "test_57_3.jpg",
        "test_57_4.jpg",
        "test_57_5.jpg",
        "test_57_6.jpg",
        "test_57_7.jpg",
        "test_57_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          6,
          3,
          0,
          7,
          5,
          8,
          4,
          1
        ],
        "order_filenames": [
          "test_57_2.jpg",
          "test_57_6.jpg",
          "test_57_3.jpg",
          "test_57_0.jpg",
          "test_57_7.jpg",
          "test_57_5.jpg",
          "test_57_8.jpg",
          "test_57_4.jpg",
          "test_57_1.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_57_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_57_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_57_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.175048828125,
            0.1982421875,
            0.275146484375,
            0.1754150390625,
            0.148193359375,
            0.11602783203125,
            0.2181396484375,
            0.1881103515625,
            0.16845703125
          ],
          "order_indices": [
            2,
            6,
            1,
            7,
            3,
            0,
            8,
            4,
            5
          ],
          "order_filenames": [
            "test_57_2.jpg",
            "test_57_6.jpg",
            "test_57_1.jpg",
            "test_57_7.jpg",
            "test_57_3.jpg",
            "test_57_0.jpg",
            "test_57_8.jpg",
            "test_57_4.jpg",
            "test_57_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.4444444444444444,
            "spearman_rho": 0.55,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.4444444444444444,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.96875,
            31.46875,
            36.53125,
            30.734375,
            24.390625,
            16.703125,
            36.71875,
            39.40625,
            28.671875
          ],
          "order_indices": [
            0,
            7,
            6,
            2,
            1,
            3,
            8,
            4,
            5
          ],
          "order_filenames": [
            "test_57_0.jpg",
            "test_57_7.jpg",
            "test_57_6.jpg",
            "test_57_2.jpg",
            "test_57_1.jpg",
            "test_57_3.jpg",
            "test_57_8.jpg",
            "test_57_4.jpg",
            "test_57_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2777777777777778,
            "spearman_rho": 0.4833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.36016303300857544,
            -0.317136287689209,
            1.2928965091705322,
            -0.2423841953277588,
            -1.3098433017730713,
            -1.7476738691329956,
            -0.29287952184677124,
            0.28923970460891724,
            -0.009601573459804058
          ],
          "order_indices": [
            2,
            0,
            7,
            8,
            3,
            6,
            1,
            4,
            5
          ],
          "order_filenames": [
            "test_57_2.jpg",
            "test_57_0.jpg",
            "test_57_7.jpg",
            "test_57_8.jpg",
            "test_57_3.jpg",
            "test_57_6.jpg",
            "test_57_1.jpg",
            "test_57_4.jpg",
            "test_57_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3888888888888889,
            "spearman_rho": 0.5833333333333333,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 58,
      "prompt": "A small green dinosaur toy with orange spots standing on its hind legs and roaring with its mouth open.",
      "image_filenames": [
        "test_58_0.jpg",
        "test_58_1.jpg",
        "test_58_2.jpg",
        "test_58_3.jpg",
        "test_58_4.jpg",
        "test_58_5.jpg",
        "test_58_6.jpg",
        "test_58_7.jpg",
        "test_58_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          5,
          1,
          8,
          7,
          3,
          6,
          4,
          0
        ],
        "order_filenames": [
          "test_58_2.jpg",
          "test_58_5.jpg",
          "test_58_1.jpg",
          "test_58_8.jpg",
          "test_58_7.jpg",
          "test_58_3.jpg",
          "test_58_6.jpg",
          "test_58_4.jpg",
          "test_58_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_58_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_58_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_58_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1932373046875,
            0.290771484375,
            0.2548828125,
            0.18603515625,
            0.1875,
            0.2467041015625,
            0.257568359375,
            0.209716796875,
            0.29052734375
          ],
          "order_indices": [
            1,
            8,
            6,
            2,
            5,
            7,
            0,
            4,
            3
          ],
          "order_filenames": [
            "test_58_1.jpg",
            "test_58_8.jpg",
            "test_58_6.jpg",
            "test_58_2.jpg",
            "test_58_5.jpg",
            "test_58_7.jpg",
            "test_58_0.jpg",
            "test_58_4.jpg",
            "test_58_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3888888888888889,
            "spearman_rho": 0.5333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.6875,
            33.5625,
            40.625,
            33.71875,
            21.46875,
            37.15625,
            29.90625,
            35.875,
            38.90625
          ],
          "order_indices": [
            2,
            8,
            0,
            5,
            7,
            3,
            1,
            6,
            4
          ],
          "order_filenames": [
            "test_58_2.jpg",
            "test_58_8.jpg",
            "test_58_0.jpg",
            "test_58_5.jpg",
            "test_58_7.jpg",
            "test_58_3.jpg",
            "test_58_1.jpg",
            "test_58_6.jpg",
            "test_58_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.4444444444444444,
            "spearman_rho": 0.4833333333333333,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.0010000467300415,
            0.7397401928901672,
            1.3161735534667969,
            -0.5969947576522827,
            -1.9620381593704224,
            -0.44841375946998596,
            -1.7383277416229248,
            -1.0965914726257324,
            1.1533610820770264
          ],
          "order_indices": [
            2,
            8,
            1,
            5,
            3,
            0,
            7,
            6,
            4
          ],
          "order_filenames": [
            "test_58_2.jpg",
            "test_58_8.jpg",
            "test_58_1.jpg",
            "test_58_5.jpg",
            "test_58_3.jpg",
            "test_58_0.jpg",
            "test_58_7.jpg",
            "test_58_6.jpg",
            "test_58_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.6111111111111112,
            "spearman_rho": 0.8,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 59,
      "prompt": "An anime Spider-Man girl.",
      "image_filenames": [
        "test_59_0.jpg",
        "test_59_1.jpg",
        "test_59_2.jpg",
        "test_59_3.jpg",
        "test_59_4.jpg",
        "test_59_5.jpg",
        "test_59_6.jpg",
        "test_59_7.jpg",
        "test_59_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          1,
          2,
          7,
          6,
          0,
          5,
          8,
          3
        ],
        "order_filenames": [
          "test_59_4.jpg",
          "test_59_1.jpg",
          "test_59_2.jpg",
          "test_59_7.jpg",
          "test_59_6.jpg",
          "test_59_0.jpg",
          "test_59_5.jpg",
          "test_59_8.jpg",
          "test_59_3.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_59_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_59_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_59_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.199951171875,
            0.25634765625,
            0.268310546875,
            0.18212890625,
            0.1630859375,
            0.088134765625,
            0.261474609375,
            0.2158203125,
            0.27734375
          ],
          "order_indices": [
            8,
            2,
            6,
            1,
            7,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_59_8.jpg",
            "test_59_2.jpg",
            "test_59_6.jpg",
            "test_59_1.jpg",
            "test_59_7.jpg",
            "test_59_0.jpg",
            "test_59_3.jpg",
            "test_59_4.jpg",
            "test_59_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.033333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.1875,
            21.921875,
            27.765625,
            33.9375,
            18.875,
            15.7421875,
            25.609375,
            40.6875,
            42.9375
          ],
          "order_indices": [
            8,
            7,
            0,
            3,
            2,
            6,
            1,
            4,
            5
          ],
          "order_filenames": [
            "test_59_8.jpg",
            "test_59_7.jpg",
            "test_59_0.jpg",
            "test_59_3.jpg",
            "test_59_2.jpg",
            "test_59_6.jpg",
            "test_59_1.jpg",
            "test_59_4.jpg",
            "test_59_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.41666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.1380503922700882,
            -1.4478148221969604,
            -0.834749698638916,
            -0.3206086754798889,
            -1.9753772020339966,
            -2.276128053665161,
            -1.2962844371795654,
            -0.6140278577804565,
            0.51450514793396
          ],
          "order_indices": [
            8,
            0,
            3,
            7,
            2,
            6,
            1,
            4,
            5
          ],
          "order_filenames": [
            "test_59_8.jpg",
            "test_59_0.jpg",
            "test_59_3.jpg",
            "test_59_7.jpg",
            "test_59_2.jpg",
            "test_59_6.jpg",
            "test_59_1.jpg",
            "test_59_4.jpg",
            "test_59_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.5333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 60,
      "prompt": "A 3D rendering of anime schoolgirls with a sad expression underwater, surrounded by dramatic lighting.",
      "image_filenames": [
        "test_60_0.jpg",
        "test_60_1.jpg",
        "test_60_2.jpg",
        "test_60_3.jpg",
        "test_60_4.jpg",
        "test_60_5.jpg",
        "test_60_6.jpg",
        "test_60_7.jpg",
        "test_60_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          3,
          7,
          5,
          6,
          1,
          8,
          0,
          2
        ],
        "order_filenames": [
          "test_60_4.jpg",
          "test_60_3.jpg",
          "test_60_7.jpg",
          "test_60_5.jpg",
          "test_60_6.jpg",
          "test_60_1.jpg",
          "test_60_8.jpg",
          "test_60_0.jpg",
          "test_60_2.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_60_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_60_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_60_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1673583984375,
            0.1727294921875,
            0.258544921875,
            0.1942138671875,
            0.207763671875,
            0.1038818359375,
            0.2408447265625,
            0.2196044921875,
            0.2734375
          ],
          "order_indices": [
            8,
            2,
            6,
            7,
            4,
            3,
            1,
            0,
            5
          ],
          "order_filenames": [
            "test_60_8.jpg",
            "test_60_2.jpg",
            "test_60_6.jpg",
            "test_60_7.jpg",
            "test_60_4.jpg",
            "test_60_3.jpg",
            "test_60_1.jpg",
            "test_60_0.jpg",
            "test_60_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.2333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.25,
            24.859375,
            37.40625,
            36.0625,
            34.375,
            19.71875,
            34.625,
            46.40625,
            42.875
          ],
          "order_indices": [
            7,
            8,
            0,
            2,
            3,
            6,
            4,
            1,
            5
          ],
          "order_filenames": [
            "test_60_7.jpg",
            "test_60_8.jpg",
            "test_60_0.jpg",
            "test_60_2.jpg",
            "test_60_3.jpg",
            "test_60_6.jpg",
            "test_60_4.jpg",
            "test_60_1.jpg",
            "test_60_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.28333333333333344,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.7140811681747437,
            -1.971600890159607,
            -0.07503420114517212,
            -0.3556811511516571,
            -0.7907371520996094,
            -2.171788215637207,
            -1.2104369401931763,
            -0.02398604527115822,
            0.5684719681739807
          ],
          "order_indices": [
            8,
            7,
            2,
            3,
            0,
            4,
            6,
            1,
            5
          ],
          "order_filenames": [
            "test_60_8.jpg",
            "test_60_7.jpg",
            "test_60_2.jpg",
            "test_60_3.jpg",
            "test_60_0.jpg",
            "test_60_4.jpg",
            "test_60_6.jpg",
            "test_60_1.jpg",
            "test_60_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.19999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 61,
      "prompt": "Teenage boy wearing a skull mask and smoking.",
      "image_filenames": [
        "test_61_0.jpg",
        "test_61_1.jpg",
        "test_61_2.jpg",
        "test_61_3.jpg",
        "test_61_4.jpg",
        "test_61_5.jpg",
        "test_61_6.jpg",
        "test_61_7.jpg",
        "test_61_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          1,
          5,
          6,
          7,
          3,
          8,
          2,
          0
        ],
        "order_filenames": [
          "test_61_4.jpg",
          "test_61_1.jpg",
          "test_61_5.jpg",
          "test_61_6.jpg",
          "test_61_7.jpg",
          "test_61_3.jpg",
          "test_61_8.jpg",
          "test_61_2.jpg",
          "test_61_0.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_61_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_61_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_61_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.180419921875,
            0.2003173828125,
            0.262451171875,
            0.2005615234375,
            0.171630859375,
            0.142578125,
            0.200927734375,
            0.2342529296875,
            0.27490234375
          ],
          "order_indices": [
            8,
            2,
            7,
            6,
            3,
            1,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_61_8.jpg",
            "test_61_2.jpg",
            "test_61_7.jpg",
            "test_61_6.jpg",
            "test_61_3.jpg",
            "test_61_1.jpg",
            "test_61_0.jpg",
            "test_61_4.jpg",
            "test_61_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.5166666666666666,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.9375,
            30.921875,
            43.1875,
            22.546875,
            24.046875,
            18.609375,
            42.90625,
            40.78125,
            34.78125
          ],
          "order_indices": [
            2,
            6,
            7,
            0,
            8,
            1,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_61_2.jpg",
            "test_61_6.jpg",
            "test_61_7.jpg",
            "test_61_0.jpg",
            "test_61_8.jpg",
            "test_61_1.jpg",
            "test_61_4.jpg",
            "test_61_3.jpg",
            "test_61_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.4833333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.3531380891799927,
            -2.241140604019165,
            1.1962313652038574,
            -1.6129719018936157,
            0.5623160600662231,
            -2.2799251079559326,
            -0.3929780423641205,
            0.8468404412269592,
            1.489444375038147
          ],
          "order_indices": [
            8,
            0,
            2,
            7,
            4,
            6,
            3,
            1,
            5
          ],
          "order_filenames": [
            "test_61_8.jpg",
            "test_61_0.jpg",
            "test_61_2.jpg",
            "test_61_7.jpg",
            "test_61_4.jpg",
            "test_61_6.jpg",
            "test_61_3.jpg",
            "test_61_1.jpg",
            "test_61_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.7,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 62,
      "prompt": "A colorful digital painting with a front view and anime-inspired vibes featuring a magical composition.",
      "image_filenames": [
        "test_62_0.jpg",
        "test_62_1.jpg",
        "test_62_2.jpg",
        "test_62_3.jpg",
        "test_62_4.jpg",
        "test_62_5.jpg",
        "test_62_6.jpg",
        "test_62_7.jpg",
        "test_62_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          6,
          3,
          2,
          7,
          1,
          4,
          8,
          0
        ],
        "order_filenames": [
          "test_62_5.jpg",
          "test_62_6.jpg",
          "test_62_3.jpg",
          "test_62_2.jpg",
          "test_62_7.jpg",
          "test_62_1.jpg",
          "test_62_4.jpg",
          "test_62_8.jpg",
          "test_62_0.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_62_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_62_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_62_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.188232421875,
            0.2489013671875,
            0.294921875,
            0.1953125,
            0.1531982421875,
            0.1798095703125,
            0.227294921875,
            0.2548828125,
            0.274169921875
          ],
          "order_indices": [
            2,
            8,
            7,
            1,
            6,
            3,
            0,
            5,
            4
          ],
          "order_filenames": [
            "test_62_2.jpg",
            "test_62_8.jpg",
            "test_62_7.jpg",
            "test_62_1.jpg",
            "test_62_6.jpg",
            "test_62_3.jpg",
            "test_62_0.jpg",
            "test_62_5.jpg",
            "test_62_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.46875,
            35.6875,
            35.15625,
            30.78125,
            29.875,
            29.40625,
            30.8125,
            46.0,
            40.4375
          ],
          "order_indices": [
            7,
            8,
            1,
            2,
            0,
            6,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_62_7.jpg",
            "test_62_8.jpg",
            "test_62_1.jpg",
            "test_62_2.jpg",
            "test_62_0.jpg",
            "test_62_6.jpg",
            "test_62_3.jpg",
            "test_62_4.jpg",
            "test_62_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.44999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.1077847480773926,
            -0.28088128566741943,
            -0.08613396435976028,
            -0.5325431227684021,
            -1.2084697484970093,
            -1.048858404159546,
            -0.8026883602142334,
            -0.1155913695693016,
            1.2021007537841797
          ],
          "order_indices": [
            8,
            2,
            7,
            1,
            3,
            6,
            5,
            0,
            4
          ],
          "order_filenames": [
            "test_62_8.jpg",
            "test_62_2.jpg",
            "test_62_7.jpg",
            "test_62_1.jpg",
            "test_62_3.jpg",
            "test_62_6.jpg",
            "test_62_5.jpg",
            "test_62_0.jpg",
            "test_62_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.016666666666666607,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 63,
      "prompt": "A vampire wearing Dr. Martens shoes.",
      "image_filenames": [
        "test_63_0.jpg",
        "test_63_1.jpg",
        "test_63_2.jpg",
        "test_63_3.jpg",
        "test_63_4.jpg",
        "test_63_5.jpg",
        "test_63_6.jpg",
        "test_63_7.jpg",
        "test_63_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          0,
          4,
          7,
          5,
          8,
          6,
          2,
          3
        ],
        "order_filenames": [
          "test_63_1.jpg",
          "test_63_0.jpg",
          "test_63_4.jpg",
          "test_63_7.jpg",
          "test_63_5.jpg",
          "test_63_8.jpg",
          "test_63_6.jpg",
          "test_63_2.jpg",
          "test_63_3.jpg"
        ],
        "condorcet_winner": 1,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_63_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_63_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_63_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1700439453125,
            0.2388916015625,
            0.275146484375,
            0.1805419921875,
            0.132568359375,
            0.1490478515625,
            0.2156982421875,
            0.2037353515625,
            0.1917724609375
          ],
          "order_indices": [
            2,
            1,
            6,
            7,
            8,
            3,
            0,
            5,
            4
          ],
          "order_filenames": [
            "test_63_2.jpg",
            "test_63_1.jpg",
            "test_63_6.jpg",
            "test_63_7.jpg",
            "test_63_8.jpg",
            "test_63_3.jpg",
            "test_63_0.jpg",
            "test_63_5.jpg",
            "test_63_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.21666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.3125,
            29.6875,
            41.375,
            23.765625,
            20.5,
            24.0625,
            37.5,
            38.875,
            34.21875
          ],
          "order_indices": [
            2,
            7,
            0,
            6,
            8,
            1,
            5,
            3,
            4
          ],
          "order_filenames": [
            "test_63_2.jpg",
            "test_63_7.jpg",
            "test_63_0.jpg",
            "test_63_6.jpg",
            "test_63_8.jpg",
            "test_63_1.jpg",
            "test_63_5.jpg",
            "test_63_3.jpg",
            "test_63_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.08333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.48018017411231995,
            1.131756067276001,
            1.6742336750030518,
            -1.9924004077911377,
            -2.0,
            -2.252359390258789,
            -1.4876784086227417,
            0.02308557741343975,
            -1.8458495140075684
          ],
          "order_indices": [
            2,
            1,
            7,
            0,
            6,
            8,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_63_2.jpg",
            "test_63_1.jpg",
            "test_63_7.jpg",
            "test_63_0.jpg",
            "test_63_6.jpg",
            "test_63_8.jpg",
            "test_63_3.jpg",
            "test_63_4.jpg",
            "test_63_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.1333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 64,
      "prompt": "Jack Pumpkinhead in the Land of Oz.",
      "image_filenames": [
        "test_64_0.jpg",
        "test_64_1.jpg",
        "test_64_2.jpg",
        "test_64_3.jpg",
        "test_64_4.jpg",
        "test_64_5.jpg",
        "test_64_6.jpg",
        "test_64_7.jpg",
        "test_64_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          0,
          1,
          6,
          8,
          2,
          5,
          3,
          7
        ],
        "order_filenames": [
          "test_64_4.jpg",
          "test_64_0.jpg",
          "test_64_1.jpg",
          "test_64_6.jpg",
          "test_64_8.jpg",
          "test_64_2.jpg",
          "test_64_5.jpg",
          "test_64_3.jpg",
          "test_64_7.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_64_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_64_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_64_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2197265625,
            0.257568359375,
            0.29931640625,
            0.207763671875,
            0.1683349609375,
            0.232666015625,
            0.244873046875,
            0.240478515625,
            0.22314453125
          ],
          "order_indices": [
            2,
            1,
            6,
            7,
            5,
            8,
            0,
            3,
            4
          ],
          "order_filenames": [
            "test_64_2.jpg",
            "test_64_1.jpg",
            "test_64_6.jpg",
            "test_64_7.jpg",
            "test_64_5.jpg",
            "test_64_8.jpg",
            "test_64_0.jpg",
            "test_64_3.jpg",
            "test_64_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.21666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            29.671875,
            30.65625,
            36.40625,
            22.875,
            23.203125,
            25.234375,
            28.796875,
            44.5625,
            29.546875
          ],
          "order_indices": [
            7,
            2,
            1,
            0,
            8,
            6,
            5,
            4,
            3
          ],
          "order_filenames": [
            "test_64_7.jpg",
            "test_64_2.jpg",
            "test_64_1.jpg",
            "test_64_0.jpg",
            "test_64_8.jpg",
            "test_64_6.jpg",
            "test_64_5.jpg",
            "test_64_4.jpg",
            "test_64_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.1499999999999999,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.035996098071336746,
            1.3630839586257935,
            1.437753677368164,
            -1.9714850187301636,
            -2.1703426837921143,
            0.6775080561637878,
            0.5661753416061401,
            0.09872426092624664,
            -0.11808475852012634
          ],
          "order_indices": [
            2,
            1,
            5,
            6,
            7,
            0,
            8,
            3,
            4
          ],
          "order_filenames": [
            "test_64_2.jpg",
            "test_64_1.jpg",
            "test_64_5.jpg",
            "test_64_6.jpg",
            "test_64_7.jpg",
            "test_64_0.jpg",
            "test_64_8.jpg",
            "test_64_3.jpg",
            "test_64_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 65,
      "prompt": "Portrait of young Jerry Lewis in comic style, colorized and created digitally by four artists.",
      "image_filenames": [
        "test_65_0.jpg",
        "test_65_1.jpg",
        "test_65_2.jpg",
        "test_65_3.jpg",
        "test_65_4.jpg",
        "test_65_5.jpg",
        "test_65_6.jpg",
        "test_65_7.jpg",
        "test_65_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          4,
          3,
          7,
          6,
          0,
          1,
          8,
          2
        ],
        "order_filenames": [
          "test_65_5.jpg",
          "test_65_4.jpg",
          "test_65_3.jpg",
          "test_65_7.jpg",
          "test_65_6.jpg",
          "test_65_0.jpg",
          "test_65_1.jpg",
          "test_65_8.jpg",
          "test_65_2.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_65_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_65_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_65_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1778564453125,
            0.180419921875,
            0.261962890625,
            0.208251953125,
            0.146240234375,
            0.06414794921875,
            0.2216796875,
            0.236328125,
            0.2325439453125
          ],
          "order_indices": [
            2,
            7,
            8,
            6,
            3,
            1,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_65_2.jpg",
            "test_65_7.jpg",
            "test_65_8.jpg",
            "test_65_6.jpg",
            "test_65_3.jpg",
            "test_65_1.jpg",
            "test_65_0.jpg",
            "test_65_4.jpg",
            "test_65_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5555555555555556,
            "spearman_rho": -0.6666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            42.21875,
            34.84375,
            44.28125,
            37.75,
            23.984375,
            17.890625,
            38.09375,
            51.5625,
            39.78125
          ],
          "order_indices": [
            7,
            2,
            0,
            8,
            6,
            3,
            1,
            4,
            5
          ],
          "order_filenames": [
            "test_65_7.jpg",
            "test_65_2.jpg",
            "test_65_0.jpg",
            "test_65_8.jpg",
            "test_65_6.jpg",
            "test_65_3.jpg",
            "test_65_1.jpg",
            "test_65_4.jpg",
            "test_65_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.6000000000000001,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.7070019841194153,
            0.3091900050640106,
            1.2739022970199585,
            0.43955665826797485,
            -0.8917543292045593,
            -2.278005599975586,
            -0.36395126581192017,
            0.3574409782886505,
            0.887839138507843
          ],
          "order_indices": [
            2,
            8,
            0,
            3,
            7,
            1,
            6,
            4,
            5
          ],
          "order_filenames": [
            "test_65_2.jpg",
            "test_65_8.jpg",
            "test_65_0.jpg",
            "test_65_3.jpg",
            "test_65_7.jpg",
            "test_65_1.jpg",
            "test_65_6.jpg",
            "test_65_4.jpg",
            "test_65_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.6666666666666666,
            "spearman_rho": -0.8,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 66,
      "prompt": "A happy daffodil with big eyes, multiple leaf arms and vine legs, rendered in 3D Pixar style.",
      "image_filenames": [
        "test_66_0.jpg",
        "test_66_1.jpg",
        "test_66_2.jpg",
        "test_66_3.jpg",
        "test_66_4.jpg",
        "test_66_5.jpg",
        "test_66_6.jpg",
        "test_66_7.jpg",
        "test_66_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          6,
          7,
          2,
          0,
          5,
          8,
          4,
          3
        ],
        "order_filenames": [
          "test_66_1.jpg",
          "test_66_6.jpg",
          "test_66_7.jpg",
          "test_66_2.jpg",
          "test_66_0.jpg",
          "test_66_5.jpg",
          "test_66_8.jpg",
          "test_66_4.jpg",
          "test_66_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1,
          6
        ],
        "winner_filenames": [
          "test_66_1.jpg",
          "test_66_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_66_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_66_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.23193359375,
            0.251220703125,
            0.2490234375,
            0.196533203125,
            0.16455078125,
            0.23046875,
            0.2225341796875,
            0.22607421875,
            0.281005859375
          ],
          "order_indices": [
            8,
            1,
            2,
            0,
            5,
            7,
            6,
            3,
            4
          ],
          "order_filenames": [
            "test_66_8.jpg",
            "test_66_1.jpg",
            "test_66_2.jpg",
            "test_66_0.jpg",
            "test_66_5.jpg",
            "test_66_7.jpg",
            "test_66_6.jpg",
            "test_66_3.jpg",
            "test_66_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.3666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            45.1875,
            45.125,
            38.875,
            38.09375,
            28.71875,
            37.375,
            35.96875,
            44.03125,
            44.03125
          ],
          "order_indices": [
            0,
            1,
            7,
            8,
            2,
            3,
            5,
            6,
            4
          ],
          "order_filenames": [
            "test_66_0.jpg",
            "test_66_1.jpg",
            "test_66_7.jpg",
            "test_66_8.jpg",
            "test_66_2.jpg",
            "test_66_3.jpg",
            "test_66_5.jpg",
            "test_66_6.jpg",
            "test_66_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2777777777777778,
            "spearman_rho": 0.3833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.5366395115852356,
            -0.3881693184375763,
            -1.9904680252075195,
            -1.8016505241394043,
            -2.0114121437072754,
            -1.5420217514038086,
            -1.5488914251327515,
            0.3017895817756653,
            -0.7136691212654114
          ],
          "order_indices": [
            7,
            1,
            0,
            8,
            5,
            6,
            3,
            2,
            4
          ],
          "order_filenames": [
            "test_66_7.jpg",
            "test_66_1.jpg",
            "test_66_0.jpg",
            "test_66_8.jpg",
            "test_66_5.jpg",
            "test_66_6.jpg",
            "test_66_3.jpg",
            "test_66_2.jpg",
            "test_66_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3888888888888889,
            "spearman_rho": 0.5333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 67,
      "prompt": "Head and shoulders portrait of Jinx from League of Legends of Arcane animated Series.",
      "image_filenames": [
        "test_67_0.jpg",
        "test_67_1.jpg",
        "test_67_2.jpg",
        "test_67_3.jpg",
        "test_67_4.jpg",
        "test_67_5.jpg",
        "test_67_6.jpg",
        "test_67_7.jpg",
        "test_67_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          6,
          4,
          1,
          5,
          7,
          8,
          3,
          2
        ],
        "order_filenames": [
          "test_67_0.jpg",
          "test_67_6.jpg",
          "test_67_4.jpg",
          "test_67_1.jpg",
          "test_67_5.jpg",
          "test_67_7.jpg",
          "test_67_8.jpg",
          "test_67_3.jpg",
          "test_67_2.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_67_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_67_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_67_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.15576171875,
            0.254638671875,
            0.2484130859375,
            0.1624755859375,
            0.1495361328125,
            0.049560546875,
            0.22705078125,
            0.178955078125,
            0.1876220703125
          ],
          "order_indices": [
            1,
            2,
            6,
            8,
            7,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_67_1.jpg",
            "test_67_2.jpg",
            "test_67_6.jpg",
            "test_67_8.jpg",
            "test_67_7.jpg",
            "test_67_3.jpg",
            "test_67_0.jpg",
            "test_67_4.jpg",
            "test_67_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.25,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.34375,
            33.4375,
            39.28125,
            31.640625,
            16.03125,
            9.7578125,
            31.140625,
            31.34375,
            37.09375
          ],
          "order_indices": [
            2,
            8,
            0,
            1,
            3,
            7,
            6,
            4,
            5
          ],
          "order_filenames": [
            "test_67_2.jpg",
            "test_67_8.jpg",
            "test_67_0.jpg",
            "test_67_1.jpg",
            "test_67_3.jpg",
            "test_67_7.jpg",
            "test_67_6.jpg",
            "test_67_4.jpg",
            "test_67_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.3999999999999999,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.18441142141819,
            0.03614668920636177,
            0.18714191019535065,
            -0.8676743507385254,
            -1.1323922872543335,
            -2.281526565551758,
            0.4987666606903076,
            -1.3293466567993164,
            0.09212099015712738
          ],
          "order_indices": [
            6,
            2,
            8,
            1,
            0,
            3,
            4,
            7,
            5
          ],
          "order_filenames": [
            "test_67_6.jpg",
            "test_67_2.jpg",
            "test_67_8.jpg",
            "test_67_1.jpg",
            "test_67_0.jpg",
            "test_67_3.jpg",
            "test_67_4.jpg",
            "test_67_7.jpg",
            "test_67_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.016666666666666607,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 68,
      "prompt": "A one-eyed dwarf wizard holding a flagon in clean cel shaded vector art.",
      "image_filenames": [
        "test_68_0.jpg",
        "test_68_1.jpg",
        "test_68_2.jpg",
        "test_68_3.jpg",
        "test_68_4.jpg",
        "test_68_5.jpg",
        "test_68_6.jpg",
        "test_68_7.jpg",
        "test_68_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          5,
          3,
          2,
          7,
          0,
          1,
          6,
          8
        ],
        "order_filenames": [
          "test_68_4.jpg",
          "test_68_5.jpg",
          "test_68_3.jpg",
          "test_68_2.jpg",
          "test_68_7.jpg",
          "test_68_0.jpg",
          "test_68_1.jpg",
          "test_68_6.jpg",
          "test_68_8.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_68_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_68_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_68_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1561279296875,
            0.1890869140625,
            0.239013671875,
            0.1527099609375,
            0.162353515625,
            0.12432861328125,
            0.2459716796875,
            0.155517578125,
            0.2374267578125
          ],
          "order_indices": [
            6,
            2,
            8,
            1,
            4,
            0,
            7,
            3,
            5
          ],
          "order_filenames": [
            "test_68_6.jpg",
            "test_68_2.jpg",
            "test_68_8.jpg",
            "test_68_1.jpg",
            "test_68_4.jpg",
            "test_68_0.jpg",
            "test_68_7.jpg",
            "test_68_3.jpg",
            "test_68_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.6000000000000001,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            32.8125,
            34.6875,
            32.15625,
            18.21875,
            23.34375,
            15.7578125,
            40.4375,
            36.75,
            33.0
          ],
          "order_indices": [
            6,
            7,
            1,
            8,
            0,
            2,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_68_6.jpg",
            "test_68_7.jpg",
            "test_68_1.jpg",
            "test_68_8.jpg",
            "test_68_0.jpg",
            "test_68_2.jpg",
            "test_68_4.jpg",
            "test_68_3.jpg",
            "test_68_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.6111111111111112,
            "spearman_rho": -0.7833333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.4023190438747406,
            -1.0196549892425537,
            0.672294557094574,
            -1.4453742504119873,
            -0.6460248231887817,
            -2.030212879180908,
            0.24458645284175873,
            -2.0779545307159424,
            0.20624694228172302
          ],
          "order_indices": [
            2,
            6,
            8,
            0,
            4,
            1,
            3,
            5,
            7
          ],
          "order_filenames": [
            "test_68_2.jpg",
            "test_68_6.jpg",
            "test_68_8.jpg",
            "test_68_0.jpg",
            "test_68_4.jpg",
            "test_68_1.jpg",
            "test_68_3.jpg",
            "test_68_5.jpg",
            "test_68_7.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.41666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 69,
      "prompt": "A painting of a koala wearing a princess dress and crown, with a confetti background.",
      "image_filenames": [
        "test_69_0.jpg",
        "test_69_1.jpg",
        "test_69_2.jpg",
        "test_69_3.jpg",
        "test_69_4.jpg",
        "test_69_5.jpg",
        "test_69_6.jpg",
        "test_69_7.jpg",
        "test_69_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          4,
          5,
          1,
          3,
          7,
          2,
          0,
          8
        ],
        "order_filenames": [
          "test_69_6.jpg",
          "test_69_4.jpg",
          "test_69_5.jpg",
          "test_69_1.jpg",
          "test_69_3.jpg",
          "test_69_7.jpg",
          "test_69_2.jpg",
          "test_69_0.jpg",
          "test_69_8.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_69_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_69_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_69_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1942138671875,
            0.2215576171875,
            0.234375,
            0.2169189453125,
            0.22900390625,
            0.15869140625,
            0.278076171875,
            0.224365234375,
            0.283935546875
          ],
          "order_indices": [
            8,
            6,
            2,
            4,
            7,
            1,
            3,
            0,
            5
          ],
          "order_filenames": [
            "test_69_8.jpg",
            "test_69_6.jpg",
            "test_69_2.jpg",
            "test_69_4.jpg",
            "test_69_7.jpg",
            "test_69_1.jpg",
            "test_69_3.jpg",
            "test_69_0.jpg",
            "test_69_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.08333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            41.21875,
            34.84375,
            40.1875,
            36.71875,
            38.5625,
            22.015625,
            43.21875,
            45.09375,
            45.75
          ],
          "order_indices": [
            8,
            7,
            6,
            0,
            2,
            4,
            3,
            1,
            5
          ],
          "order_filenames": [
            "test_69_8.jpg",
            "test_69_7.jpg",
            "test_69_6.jpg",
            "test_69_0.jpg",
            "test_69_2.jpg",
            "test_69_4.jpg",
            "test_69_3.jpg",
            "test_69_1.jpg",
            "test_69_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.46666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.3129661977291107,
            -1.4240639209747314,
            1.7224619388580322,
            1.9011871814727783,
            0.6714194416999817,
            -2.2519326210021973,
            1.7417511940002441,
            1.3516845703125,
            1.7846696376800537
          ],
          "order_indices": [
            3,
            8,
            6,
            2,
            7,
            4,
            0,
            1,
            5
          ],
          "order_filenames": [
            "test_69_3.jpg",
            "test_69_8.jpg",
            "test_69_6.jpg",
            "test_69_2.jpg",
            "test_69_7.jpg",
            "test_69_4.jpg",
            "test_69_0.jpg",
            "test_69_1.jpg",
            "test_69_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.2333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 70,
      "prompt": "A lemon with a McDonald's hat.",
      "image_filenames": [
        "test_70_0.jpg",
        "test_70_1.jpg",
        "test_70_2.jpg",
        "test_70_3.jpg",
        "test_70_4.jpg",
        "test_70_5.jpg",
        "test_70_6.jpg",
        "test_70_7.jpg",
        "test_70_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          4,
          5,
          3,
          8,
          1,
          6,
          2,
          0
        ],
        "order_filenames": [
          "test_70_7.jpg",
          "test_70_4.jpg",
          "test_70_5.jpg",
          "test_70_3.jpg",
          "test_70_8.jpg",
          "test_70_1.jpg",
          "test_70_6.jpg",
          "test_70_2.jpg",
          "test_70_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_70_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_70_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_70_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1917724609375,
            0.194091796875,
            0.22119140625,
            0.1884765625,
            0.156005859375,
            0.1905517578125,
            0.2054443359375,
            0.192138671875,
            0.286865234375
          ],
          "order_indices": [
            8,
            2,
            6,
            1,
            7,
            0,
            5,
            3,
            4
          ],
          "order_filenames": [
            "test_70_8.jpg",
            "test_70_2.jpg",
            "test_70_6.jpg",
            "test_70_1.jpg",
            "test_70_7.jpg",
            "test_70_0.jpg",
            "test_70_5.jpg",
            "test_70_3.jpg",
            "test_70_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.4833333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.5,
            38.34375,
            34.0,
            29.5625,
            25.25,
            26.4375,
            29.1875,
            37.0625,
            46.03125
          ],
          "order_indices": [
            8,
            1,
            0,
            7,
            2,
            3,
            6,
            5,
            4
          ],
          "order_filenames": [
            "test_70_8.jpg",
            "test_70_1.jpg",
            "test_70_0.jpg",
            "test_70_7.jpg",
            "test_70_2.jpg",
            "test_70_3.jpg",
            "test_70_6.jpg",
            "test_70_5.jpg",
            "test_70_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.3666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.8968042135238647,
            -1.0491666793823242,
            -1.619140386581421,
            -2.0583879947662354,
            -1.5303068161010742,
            -2.1844115257263184,
            -2.032453775405884,
            -0.6691963076591492,
            1.8630061149597168
          ],
          "order_indices": [
            8,
            7,
            0,
            1,
            4,
            2,
            6,
            3,
            5
          ],
          "order_filenames": [
            "test_70_8.jpg",
            "test_70_7.jpg",
            "test_70_0.jpg",
            "test_70_1.jpg",
            "test_70_4.jpg",
            "test_70_2.jpg",
            "test_70_6.jpg",
            "test_70_3.jpg",
            "test_70_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.016666666666666607,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 71,
      "prompt": "Ewoks swinging from Walmart rafters.",
      "image_filenames": [
        "test_71_0.jpg",
        "test_71_1.jpg",
        "test_71_2.jpg",
        "test_71_3.jpg",
        "test_71_4.jpg",
        "test_71_5.jpg",
        "test_71_6.jpg",
        "test_71_7.jpg",
        "test_71_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          7,
          1,
          4,
          2,
          5,
          8,
          0,
          6
        ],
        "order_filenames": [
          "test_71_3.jpg",
          "test_71_7.jpg",
          "test_71_1.jpg",
          "test_71_4.jpg",
          "test_71_2.jpg",
          "test_71_5.jpg",
          "test_71_8.jpg",
          "test_71_0.jpg",
          "test_71_6.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_71_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_71_3.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_71_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.219482421875,
            0.244140625,
            0.297119140625,
            0.1988525390625,
            0.2120361328125,
            0.1456298828125,
            0.29248046875,
            0.2462158203125,
            0.23486328125
          ],
          "order_indices": [
            2,
            6,
            7,
            1,
            8,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_71_2.jpg",
            "test_71_6.jpg",
            "test_71_7.jpg",
            "test_71_1.jpg",
            "test_71_8.jpg",
            "test_71_0.jpg",
            "test_71_4.jpg",
            "test_71_3.jpg",
            "test_71_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.9375,
            36.0,
            42.53125,
            20.75,
            26.59375,
            20.90625,
            39.3125,
            52.6875,
            49.15625
          ],
          "order_indices": [
            7,
            8,
            2,
            0,
            6,
            1,
            4,
            5,
            3
          ],
          "order_filenames": [
            "test_71_7.jpg",
            "test_71_8.jpg",
            "test_71_2.jpg",
            "test_71_0.jpg",
            "test_71_6.jpg",
            "test_71_1.jpg",
            "test_71_4.jpg",
            "test_71_5.jpg",
            "test_71_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.2333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.019733283668756485,
            -0.42213475704193115,
            0.3122130334377289,
            -1.916326642036438,
            -1.7670047283172607,
            -2.254734992980957,
            -0.32905805110931396,
            0.542461633682251,
            -0.3817059397697449
          ],
          "order_indices": [
            7,
            2,
            0,
            6,
            8,
            1,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_71_7.jpg",
            "test_71_2.jpg",
            "test_71_0.jpg",
            "test_71_6.jpg",
            "test_71_8.jpg",
            "test_71_1.jpg",
            "test_71_4.jpg",
            "test_71_3.jpg",
            "test_71_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.16666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 72,
      "prompt": "The image is of Pixel Art Huggy Wuggy performing a jumpscare.",
      "image_filenames": [
        "test_72_0.jpg",
        "test_72_1.jpg",
        "test_72_2.jpg",
        "test_72_3.jpg",
        "test_72_4.jpg",
        "test_72_5.jpg",
        "test_72_6.jpg",
        "test_72_7.jpg",
        "test_72_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          8,
          7,
          6,
          0,
          1,
          2,
          3,
          5,
          4
        ],
        "order_filenames": [
          "test_72_8.jpg",
          "test_72_7.jpg",
          "test_72_6.jpg",
          "test_72_0.jpg",
          "test_72_1.jpg",
          "test_72_2.jpg",
          "test_72_3.jpg",
          "test_72_5.jpg",
          "test_72_4.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          8
        ],
        "winner_filenames": [
          "test_72_8.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7,
            8
          ],
          "winner_filenames": [
            "test_72_7.jpg",
            "test_72_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7,
            8
          ],
          "winner_filenames": [
            "test_72_7.jpg",
            "test_72_8.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1279296875,
            0.19921875,
            0.208740234375,
            0.1307373046875,
            0.1473388671875,
            0.1326904296875,
            0.1876220703125,
            0.1793212890625,
            0.182861328125
          ],
          "order_indices": [
            2,
            1,
            6,
            8,
            7,
            4,
            5,
            3,
            0
          ],
          "order_filenames": [
            "test_72_2.jpg",
            "test_72_1.jpg",
            "test_72_6.jpg",
            "test_72_8.jpg",
            "test_72_7.jpg",
            "test_72_4.jpg",
            "test_72_5.jpg",
            "test_72_3.jpg",
            "test_72_0.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.2666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            33.15625,
            27.65625,
            33.6875,
            28.09375,
            18.515625,
            21.6875,
            33.09375,
            39.84375,
            31.953125
          ],
          "order_indices": [
            7,
            2,
            0,
            6,
            8,
            3,
            1,
            5,
            4
          ],
          "order_filenames": [
            "test_72_7.jpg",
            "test_72_2.jpg",
            "test_72_0.jpg",
            "test_72_6.jpg",
            "test_72_8.jpg",
            "test_72_3.jpg",
            "test_72_1.jpg",
            "test_72_5.jpg",
            "test_72_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.5,
            "spearman_rho": 0.6666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.8862249851226807,
            -1.9166843891143799,
            -0.004070054739713669,
            -2.0525448322296143,
            -1.1241475343704224,
            -0.2915254831314087,
            -0.40922248363494873,
            -0.21868018805980682,
            -0.5280734300613403
          ],
          "order_indices": [
            2,
            7,
            5,
            6,
            8,
            0,
            4,
            1,
            3
          ],
          "order_filenames": [
            "test_72_2.jpg",
            "test_72_7.jpg",
            "test_72_5.jpg",
            "test_72_6.jpg",
            "test_72_8.jpg",
            "test_72_0.jpg",
            "test_72_4.jpg",
            "test_72_1.jpg",
            "test_72_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.2666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 73,
      "prompt": "Cartoonish illustration of a sci-fi machine shop inside a shipping container.",
      "image_filenames": [
        "test_73_0.jpg",
        "test_73_1.jpg",
        "test_73_2.jpg",
        "test_73_3.jpg",
        "test_73_4.jpg",
        "test_73_5.jpg",
        "test_73_6.jpg",
        "test_73_7.jpg",
        "test_73_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          1,
          7,
          2,
          5,
          3,
          0,
          8,
          4
        ],
        "order_filenames": [
          "test_73_6.jpg",
          "test_73_1.jpg",
          "test_73_7.jpg",
          "test_73_2.jpg",
          "test_73_5.jpg",
          "test_73_3.jpg",
          "test_73_0.jpg",
          "test_73_8.jpg",
          "test_73_4.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_73_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_73_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_73_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2122802734375,
            0.2493896484375,
            0.253662109375,
            0.1778564453125,
            0.2135009765625,
            0.1529541015625,
            0.2489013671875,
            0.271240234375,
            0.21533203125
          ],
          "order_indices": [
            7,
            2,
            1,
            6,
            8,
            4,
            0,
            3,
            5
          ],
          "order_filenames": [
            "test_73_7.jpg",
            "test_73_2.jpg",
            "test_73_1.jpg",
            "test_73_6.jpg",
            "test_73_8.jpg",
            "test_73_4.jpg",
            "test_73_0.jpg",
            "test_73_3.jpg",
            "test_73_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.5333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            44.0625,
            42.25,
            46.25,
            31.015625,
            30.828125,
            30.03125,
            43.625,
            50.8125,
            39.1875
          ],
          "order_indices": [
            7,
            2,
            0,
            6,
            1,
            8,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_73_7.jpg",
            "test_73_2.jpg",
            "test_73_0.jpg",
            "test_73_6.jpg",
            "test_73_1.jpg",
            "test_73_8.jpg",
            "test_73_3.jpg",
            "test_73_4.jpg",
            "test_73_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.4666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.5363262891769409,
            0.7541015148162842,
            0.17229242622852325,
            -0.7557536363601685,
            -0.20740000903606415,
            -1.497395396232605,
            0.08159808069467545,
            1.162919521331787,
            -0.18603627383708954
          ],
          "order_indices": [
            7,
            1,
            0,
            2,
            6,
            8,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_73_7.jpg",
            "test_73_1.jpg",
            "test_73_0.jpg",
            "test_73_2.jpg",
            "test_73_6.jpg",
            "test_73_8.jpg",
            "test_73_4.jpg",
            "test_73_3.jpg",
            "test_73_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2777777777777778,
            "spearman_rho": 0.4666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 74,
      "prompt": "Australian soldiers surrendering to an emu.",
      "image_filenames": [
        "test_74_0.jpg",
        "test_74_1.jpg",
        "test_74_2.jpg",
        "test_74_3.jpg",
        "test_74_4.jpg",
        "test_74_5.jpg",
        "test_74_6.jpg",
        "test_74_7.jpg",
        "test_74_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          8,
          1,
          4,
          3,
          5,
          6,
          7,
          2
        ],
        "order_filenames": [
          "test_74_0.jpg",
          "test_74_8.jpg",
          "test_74_1.jpg",
          "test_74_4.jpg",
          "test_74_3.jpg",
          "test_74_5.jpg",
          "test_74_6.jpg",
          "test_74_7.jpg",
          "test_74_2.jpg"
        ],
        "condorcet_winner": 0,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_74_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4,
            8
          ],
          "winner_filenames": [
            "test_74_4.jpg",
            "test_74_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_74_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1470947265625,
            0.300048828125,
            0.2607421875,
            0.178466796875,
            0.169189453125,
            0.1505126953125,
            0.2393798828125,
            0.225830078125,
            0.1622314453125
          ],
          "order_indices": [
            1,
            2,
            6,
            7,
            3,
            4,
            8,
            5,
            0
          ],
          "order_filenames": [
            "test_74_1.jpg",
            "test_74_2.jpg",
            "test_74_6.jpg",
            "test_74_7.jpg",
            "test_74_3.jpg",
            "test_74_4.jpg",
            "test_74_8.jpg",
            "test_74_5.jpg",
            "test_74_0.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.5166666666666666,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.65625,
            41.09375,
            32.53125,
            34.90625,
            39.71875,
            25.25,
            40.25,
            42.21875,
            34.90625
          ],
          "order_indices": [
            7,
            1,
            6,
            4,
            0,
            3,
            8,
            2,
            5
          ],
          "order_filenames": [
            "test_74_7.jpg",
            "test_74_1.jpg",
            "test_74_6.jpg",
            "test_74_4.jpg",
            "test_74_0.jpg",
            "test_74_3.jpg",
            "test_74_8.jpg",
            "test_74_2.jpg",
            "test_74_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.01666666666666672,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.2926151156425476,
            0.27093955874443054,
            -0.4316560626029968,
            -0.8762995004653931,
            -1.3299589157104492,
            -1.8007577657699585,
            0.3444078862667084,
            0.4081498980522156,
            -0.2708907425403595
          ],
          "order_indices": [
            7,
            6,
            0,
            1,
            8,
            2,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_74_7.jpg",
            "test_74_6.jpg",
            "test_74_0.jpg",
            "test_74_1.jpg",
            "test_74_8.jpg",
            "test_74_2.jpg",
            "test_74_3.jpg",
            "test_74_4.jpg",
            "test_74_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.050000000000000044,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 75,
      "prompt": "A digital anime portrait of tatsumaki with green curly hair and green eyes wearing a jacket, featuring intricate details and atmospheric lighting, by artists wlop, Ilya Kuvshinov, and Krenz Cushart, trending on ArtStation.",
      "image_filenames": [
        "test_75_0.jpg",
        "test_75_1.jpg",
        "test_75_2.jpg",
        "test_75_3.jpg",
        "test_75_4.jpg",
        "test_75_5.jpg",
        "test_75_6.jpg",
        "test_75_7.jpg",
        "test_75_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          2,
          8,
          0,
          4,
          7,
          1,
          3,
          5
        ],
        "order_filenames": [
          "test_75_6.jpg",
          "test_75_2.jpg",
          "test_75_8.jpg",
          "test_75_0.jpg",
          "test_75_4.jpg",
          "test_75_7.jpg",
          "test_75_1.jpg",
          "test_75_3.jpg",
          "test_75_5.jpg"
        ],
        "condorcet_winner": 6,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_75_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_75_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_75_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.16259765625,
            0.27001953125,
            0.2459716796875,
            0.2359619140625,
            0.1483154296875,
            0.15576171875,
            0.19775390625,
            0.22412109375,
            0.257080078125
          ],
          "order_indices": [
            1,
            8,
            2,
            3,
            7,
            6,
            0,
            5,
            4
          ],
          "order_filenames": [
            "test_75_1.jpg",
            "test_75_8.jpg",
            "test_75_2.jpg",
            "test_75_3.jpg",
            "test_75_7.jpg",
            "test_75_6.jpg",
            "test_75_0.jpg",
            "test_75_5.jpg",
            "test_75_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.1166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            45.71875,
            35.15625,
            43.8125,
            29.671875,
            18.96875,
            16.921875,
            36.09375,
            42.03125,
            36.0625
          ],
          "order_indices": [
            0,
            2,
            7,
            6,
            8,
            1,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_75_0.jpg",
            "test_75_2.jpg",
            "test_75_7.jpg",
            "test_75_6.jpg",
            "test_75_8.jpg",
            "test_75_1.jpg",
            "test_75_3.jpg",
            "test_75_4.jpg",
            "test_75_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.5,
            "spearman_rho": 0.65,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.9306104183197021,
            1.0478743314743042,
            1.0150537490844727,
            0.6259475350379944,
            -1.5698778629302979,
            -1.8748128414154053,
            -0.9525327086448669,
            -0.8557261228561401,
            0.7087060809135437
          ],
          "order_indices": [
            1,
            2,
            8,
            3,
            7,
            0,
            6,
            4,
            5
          ],
          "order_filenames": [
            "test_75_1.jpg",
            "test_75_2.jpg",
            "test_75_8.jpg",
            "test_75_3.jpg",
            "test_75_7.jpg",
            "test_75_0.jpg",
            "test_75_6.jpg",
            "test_75_4.jpg",
            "test_75_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.15000000000000002,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 76,
      "prompt": "A book about the history of Pepe the Frog.",
      "image_filenames": [
        "test_76_0.jpg",
        "test_76_1.jpg",
        "test_76_2.jpg",
        "test_76_3.jpg",
        "test_76_4.jpg",
        "test_76_5.jpg",
        "test_76_6.jpg",
        "test_76_7.jpg",
        "test_76_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          3,
          2,
          4,
          6,
          7,
          1,
          8,
          0
        ],
        "order_filenames": [
          "test_76_5.jpg",
          "test_76_3.jpg",
          "test_76_2.jpg",
          "test_76_4.jpg",
          "test_76_6.jpg",
          "test_76_7.jpg",
          "test_76_1.jpg",
          "test_76_8.jpg",
          "test_76_0.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_76_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_76_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_76_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.197998046875,
            0.2154541015625,
            0.20458984375,
            0.1849365234375,
            0.125732421875,
            0.1639404296875,
            0.2120361328125,
            0.1964111328125,
            0.2578125
          ],
          "order_indices": [
            8,
            1,
            6,
            2,
            0,
            7,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_76_8.jpg",
            "test_76_1.jpg",
            "test_76_6.jpg",
            "test_76_2.jpg",
            "test_76_0.jpg",
            "test_76_7.jpg",
            "test_76_3.jpg",
            "test_76_5.jpg",
            "test_76_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.6166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            29.453125,
            35.375,
            34.21875,
            29.34375,
            14.71875,
            28.3125,
            35.28125,
            48.0,
            34.0625
          ],
          "order_indices": [
            7,
            1,
            6,
            2,
            8,
            0,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_76_7.jpg",
            "test_76_1.jpg",
            "test_76_6.jpg",
            "test_76_2.jpg",
            "test_76_8.jpg",
            "test_76_0.jpg",
            "test_76_3.jpg",
            "test_76_5.jpg",
            "test_76_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.43333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.6727643609046936,
            -1.7483015060424805,
            -0.1270884871482849,
            -1.1650906801223755,
            -2.2295498847961426,
            -0.02677004598081112,
            -0.05444579944014549,
            1.5172404050827026,
            1.416526436805725
          ],
          "order_indices": [
            7,
            8,
            0,
            5,
            6,
            2,
            3,
            1,
            4
          ],
          "order_filenames": [
            "test_76_7.jpg",
            "test_76_8.jpg",
            "test_76_0.jpg",
            "test_76_5.jpg",
            "test_76_6.jpg",
            "test_76_2.jpg",
            "test_76_3.jpg",
            "test_76_1.jpg",
            "test_76_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.3833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 77,
      "prompt": "A slime monster.",
      "image_filenames": [
        "test_77_0.jpg",
        "test_77_1.jpg",
        "test_77_2.jpg",
        "test_77_3.jpg",
        "test_77_4.jpg",
        "test_77_5.jpg",
        "test_77_6.jpg",
        "test_77_7.jpg",
        "test_77_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          0,
          5,
          6,
          1,
          8,
          3,
          7,
          2
        ],
        "order_filenames": [
          "test_77_4.jpg",
          "test_77_0.jpg",
          "test_77_5.jpg",
          "test_77_6.jpg",
          "test_77_1.jpg",
          "test_77_8.jpg",
          "test_77_3.jpg",
          "test_77_7.jpg",
          "test_77_2.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_77_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            0,
            1,
            7
          ],
          "winner_filenames": [
            "test_77_0.jpg",
            "test_77_1.jpg",
            "test_77_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_77_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2376708984375,
            0.181640625,
            0.279541015625,
            0.2220458984375,
            0.1949462890625,
            0.2001953125,
            0.21923828125,
            0.265625,
            0.242919921875
          ],
          "order_indices": [
            2,
            7,
            8,
            0,
            3,
            6,
            5,
            4,
            1
          ],
          "order_filenames": [
            "test_77_2.jpg",
            "test_77_7.jpg",
            "test_77_8.jpg",
            "test_77_0.jpg",
            "test_77_3.jpg",
            "test_77_6.jpg",
            "test_77_5.jpg",
            "test_77_4.jpg",
            "test_77_1.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5555555555555556,
            "spearman_rho": -0.6833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            42.5,
            32.15625,
            33.1875,
            37.03125,
            23.078125,
            32.09375,
            38.375,
            40.0625,
            33.3125
          ],
          "order_indices": [
            0,
            7,
            6,
            3,
            8,
            2,
            1,
            5,
            4
          ],
          "order_filenames": [
            "test_77_0.jpg",
            "test_77_7.jpg",
            "test_77_6.jpg",
            "test_77_3.jpg",
            "test_77_8.jpg",
            "test_77_2.jpg",
            "test_77_1.jpg",
            "test_77_5.jpg",
            "test_77_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.25,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.45856139063835144,
            -0.7614256143569946,
            1.2946135997772217,
            -0.19215154647827148,
            -1.7736679315567017,
            -1.355289340019226,
            -0.7076263427734375,
            0.09034635871648788,
            0.6619117259979248
          ],
          "order_indices": [
            2,
            8,
            0,
            7,
            3,
            6,
            1,
            5,
            4
          ],
          "order_filenames": [
            "test_77_2.jpg",
            "test_77_8.jpg",
            "test_77_0.jpg",
            "test_77_7.jpg",
            "test_77_3.jpg",
            "test_77_6.jpg",
            "test_77_1.jpg",
            "test_77_5.jpg",
            "test_77_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5555555555555556,
            "spearman_rho": -0.6499999999999999,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 78,
      "prompt": "Francois Hollande depicted as a manga character in Japan.",
      "image_filenames": [
        "test_78_0.jpg",
        "test_78_1.jpg",
        "test_78_2.jpg",
        "test_78_3.jpg",
        "test_78_4.jpg",
        "test_78_5.jpg",
        "test_78_6.jpg",
        "test_78_7.jpg",
        "test_78_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          3,
          2,
          6,
          7,
          5,
          1,
          8,
          0
        ],
        "order_filenames": [
          "test_78_4.jpg",
          "test_78_3.jpg",
          "test_78_2.jpg",
          "test_78_6.jpg",
          "test_78_7.jpg",
          "test_78_5.jpg",
          "test_78_1.jpg",
          "test_78_8.jpg",
          "test_78_0.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_78_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_78_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_78_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.172607421875,
            0.2666015625,
            0.23095703125,
            0.147216796875,
            0.138427734375,
            0.0650634765625,
            0.263916015625,
            0.1771240234375,
            0.2352294921875
          ],
          "order_indices": [
            1,
            6,
            8,
            2,
            7,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_78_1.jpg",
            "test_78_6.jpg",
            "test_78_8.jpg",
            "test_78_2.jpg",
            "test_78_7.jpg",
            "test_78_0.jpg",
            "test_78_3.jpg",
            "test_78_4.jpg",
            "test_78_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.31666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.03125,
            35.71875,
            40.625,
            16.078125,
            17.96875,
            15.578125,
            42.5,
            43.40625,
            31.0
          ],
          "order_indices": [
            7,
            6,
            2,
            0,
            1,
            8,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_78_7.jpg",
            "test_78_6.jpg",
            "test_78_2.jpg",
            "test_78_0.jpg",
            "test_78_1.jpg",
            "test_78_8.jpg",
            "test_78_4.jpg",
            "test_78_3.jpg",
            "test_78_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.1166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.7220878005027771,
            -0.021917467936873436,
            0.2638704478740692,
            -0.5378057956695557,
            -2.0225284099578857,
            -2.279902696609497,
            0.08334208279848099,
            -1.3521755933761597,
            0.6215632557868958
          ],
          "order_indices": [
            8,
            2,
            6,
            1,
            3,
            0,
            7,
            4,
            5
          ],
          "order_filenames": [
            "test_78_8.jpg",
            "test_78_2.jpg",
            "test_78_6.jpg",
            "test_78_1.jpg",
            "test_78_3.jpg",
            "test_78_0.jpg",
            "test_78_7.jpg",
            "test_78_4.jpg",
            "test_78_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.16666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 79,
      "prompt": "The image features an anime girl in a short skirt and thigh-high socks, with a slim figure and accentuated hips.",
      "image_filenames": [
        "test_79_0.jpg",
        "test_79_1.jpg",
        "test_79_2.jpg",
        "test_79_3.jpg",
        "test_79_4.jpg",
        "test_79_5.jpg",
        "test_79_6.jpg",
        "test_79_7.jpg",
        "test_79_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          5,
          6,
          1,
          4,
          7,
          2,
          8,
          3
        ],
        "order_filenames": [
          "test_79_0.jpg",
          "test_79_5.jpg",
          "test_79_6.jpg",
          "test_79_1.jpg",
          "test_79_4.jpg",
          "test_79_7.jpg",
          "test_79_2.jpg",
          "test_79_8.jpg",
          "test_79_3.jpg"
        ],
        "condorcet_winner": 0,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_79_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_79_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_79_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1527099609375,
            0.253662109375,
            0.26220703125,
            0.1688232421875,
            0.1390380859375,
            0.08197021484375,
            0.23583984375,
            0.197021484375,
            0.2154541015625
          ],
          "order_indices": [
            2,
            1,
            6,
            8,
            7,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_79_2.jpg",
            "test_79_1.jpg",
            "test_79_6.jpg",
            "test_79_8.jpg",
            "test_79_7.jpg",
            "test_79_3.jpg",
            "test_79_0.jpg",
            "test_79_4.jpg",
            "test_79_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.33333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.96875,
            35.53125,
            32.28125,
            29.671875,
            14.0625,
            11.171875,
            32.78125,
            40.5,
            37.4375
          ],
          "order_indices": [
            7,
            8,
            1,
            0,
            6,
            2,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_79_7.jpg",
            "test_79_8.jpg",
            "test_79_1.jpg",
            "test_79_0.jpg",
            "test_79_6.jpg",
            "test_79_2.jpg",
            "test_79_3.jpg",
            "test_79_4.jpg",
            "test_79_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.1499999999999999,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.7471158504486084,
            0.42206379771232605,
            -1.0097609758377075,
            0.23669537901878357,
            -1.1586867570877075,
            -2.2825098037719727,
            -1.303395390510559,
            0.4890841245651245,
            1.050787091255188
          ],
          "order_indices": [
            8,
            0,
            7,
            1,
            3,
            2,
            4,
            6,
            5
          ],
          "order_filenames": [
            "test_79_8.jpg",
            "test_79_0.jpg",
            "test_79_7.jpg",
            "test_79_1.jpg",
            "test_79_3.jpg",
            "test_79_2.jpg",
            "test_79_4.jpg",
            "test_79_6.jpg",
            "test_79_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.28333333333333344,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 80,
      "prompt": "Portrait of an anime princess in white and golden clothes.",
      "image_filenames": [
        "test_80_0.jpg",
        "test_80_1.jpg",
        "test_80_2.jpg",
        "test_80_3.jpg",
        "test_80_4.jpg",
        "test_80_5.jpg",
        "test_80_6.jpg",
        "test_80_7.jpg",
        "test_80_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          4,
          5,
          0,
          2,
          7,
          3,
          8,
          6
        ],
        "order_filenames": [
          "test_80_1.jpg",
          "test_80_4.jpg",
          "test_80_5.jpg",
          "test_80_0.jpg",
          "test_80_2.jpg",
          "test_80_7.jpg",
          "test_80_3.jpg",
          "test_80_8.jpg",
          "test_80_6.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_80_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_80_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_80_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1824951171875,
            0.2431640625,
            0.334228515625,
            0.1903076171875,
            0.1593017578125,
            0.083251953125,
            0.2056884765625,
            0.2423095703125,
            0.268310546875
          ],
          "order_indices": [
            2,
            8,
            1,
            7,
            6,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_80_2.jpg",
            "test_80_8.jpg",
            "test_80_1.jpg",
            "test_80_7.jpg",
            "test_80_6.jpg",
            "test_80_3.jpg",
            "test_80_0.jpg",
            "test_80_4.jpg",
            "test_80_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.31666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.0,
            30.65625,
            43.46875,
            39.1875,
            26.078125,
            1.7939453125,
            29.625,
            36.71875,
            37.53125
          ],
          "order_indices": [
            2,
            3,
            8,
            0,
            7,
            1,
            6,
            4,
            5
          ],
          "order_filenames": [
            "test_80_2.jpg",
            "test_80_3.jpg",
            "test_80_8.jpg",
            "test_80_0.jpg",
            "test_80_7.jpg",
            "test_80_1.jpg",
            "test_80_6.jpg",
            "test_80_4.jpg",
            "test_80_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.3999999999999999,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.9925884008407593,
            0.10405804216861725,
            1.5493817329406738,
            0.1013399139046669,
            -1.2571605443954468,
            -2.2762107849121094,
            -1.1662789583206177,
            0.6442263722419739,
            0.30868715047836304
          ],
          "order_indices": [
            2,
            7,
            8,
            1,
            3,
            0,
            6,
            4,
            5
          ],
          "order_filenames": [
            "test_80_2.jpg",
            "test_80_7.jpg",
            "test_80_8.jpg",
            "test_80_1.jpg",
            "test_80_3.jpg",
            "test_80_0.jpg",
            "test_80_6.jpg",
            "test_80_4.jpg",
            "test_80_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.25,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 81,
      "prompt": "A cute little anthropomorphic Tropical fish knight wearing a cape and a crown in short, pale blue armor.",
      "image_filenames": [
        "test_81_0.jpg",
        "test_81_1.jpg",
        "test_81_2.jpg",
        "test_81_3.jpg",
        "test_81_4.jpg",
        "test_81_5.jpg",
        "test_81_6.jpg",
        "test_81_7.jpg",
        "test_81_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          5,
          4,
          6,
          2,
          7,
          8,
          1,
          0
        ],
        "order_filenames": [
          "test_81_3.jpg",
          "test_81_5.jpg",
          "test_81_4.jpg",
          "test_81_6.jpg",
          "test_81_2.jpg",
          "test_81_7.jpg",
          "test_81_8.jpg",
          "test_81_1.jpg",
          "test_81_0.jpg"
        ],
        "condorcet_winner": 3,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_81_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_81_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_81_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1650390625,
            0.2054443359375,
            0.239013671875,
            0.159423828125,
            0.1676025390625,
            0.11468505859375,
            0.27392578125,
            0.2044677734375,
            0.197998046875
          ],
          "order_indices": [
            6,
            2,
            1,
            7,
            8,
            4,
            0,
            3,
            5
          ],
          "order_filenames": [
            "test_81_6.jpg",
            "test_81_2.jpg",
            "test_81_1.jpg",
            "test_81_7.jpg",
            "test_81_8.jpg",
            "test_81_4.jpg",
            "test_81_0.jpg",
            "test_81_3.jpg",
            "test_81_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.3500000000000001,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.90625,
            32.5625,
            33.5,
            29.234375,
            30.21875,
            22.390625,
            34.125,
            39.78125,
            36.375
          ],
          "order_indices": [
            7,
            8,
            0,
            6,
            2,
            1,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_81_7.jpg",
            "test_81_8.jpg",
            "test_81_0.jpg",
            "test_81_6.jpg",
            "test_81_2.jpg",
            "test_81_1.jpg",
            "test_81_4.jpg",
            "test_81_3.jpg",
            "test_81_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.7,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.8416324853897095,
            -0.4434829652309418,
            0.5626702308654785,
            -0.5548214912414551,
            -0.5933820605278015,
            -1.0708667039871216,
            0.8192409873008728,
            -0.47676724195480347,
            0.9846827983856201
          ],
          "order_indices": [
            8,
            0,
            6,
            2,
            1,
            7,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_81_8.jpg",
            "test_81_0.jpg",
            "test_81_6.jpg",
            "test_81_2.jpg",
            "test_81_1.jpg",
            "test_81_7.jpg",
            "test_81_3.jpg",
            "test_81_4.jpg",
            "test_81_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.7166666666666666,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 82,
      "prompt": "Fullbody portrait of half-mouse anime girl by A-1 Pictures, trending on ArtStation.",
      "image_filenames": [
        "test_82_0.jpg",
        "test_82_1.jpg",
        "test_82_2.jpg",
        "test_82_3.jpg",
        "test_82_4.jpg",
        "test_82_5.jpg",
        "test_82_6.jpg",
        "test_82_7.jpg",
        "test_82_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          3,
          4,
          6,
          2,
          0,
          7,
          1,
          8
        ],
        "order_filenames": [
          "test_82_5.jpg",
          "test_82_3.jpg",
          "test_82_4.jpg",
          "test_82_6.jpg",
          "test_82_2.jpg",
          "test_82_0.jpg",
          "test_82_7.jpg",
          "test_82_1.jpg",
          "test_82_8.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_82_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_82_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_82_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.16259765625,
            0.23828125,
            0.2347412109375,
            0.1768798828125,
            0.1427001953125,
            0.12078857421875,
            0.21875,
            0.2197265625,
            0.224609375
          ],
          "order_indices": [
            1,
            2,
            8,
            7,
            6,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_82_1.jpg",
            "test_82_2.jpg",
            "test_82_8.jpg",
            "test_82_7.jpg",
            "test_82_6.jpg",
            "test_82_3.jpg",
            "test_82_0.jpg",
            "test_82_4.jpg",
            "test_82_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.6111111111111112,
            "spearman_rho": -0.75,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.96875,
            35.625,
            37.625,
            26.515625,
            12.2578125,
            16.1875,
            34.3125,
            39.03125,
            44.6875
          ],
          "order_indices": [
            8,
            7,
            2,
            0,
            1,
            6,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_82_8.jpg",
            "test_82_7.jpg",
            "test_82_2.jpg",
            "test_82_0.jpg",
            "test_82_1.jpg",
            "test_82_6.jpg",
            "test_82_3.jpg",
            "test_82_5.jpg",
            "test_82_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.6666666666666666,
            "spearman_rho": -0.8333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.4420393109321594,
            -0.5635153651237488,
            0.6587345004081726,
            -0.5316929817199707,
            -1.0447487831115723,
            -1.6279220581054688,
            0.11055169254541397,
            -1.3140431642532349,
            0.9747083783149719
          ],
          "order_indices": [
            8,
            2,
            6,
            0,
            3,
            1,
            4,
            7,
            5
          ],
          "order_filenames": [
            "test_82_8.jpg",
            "test_82_2.jpg",
            "test_82_6.jpg",
            "test_82_0.jpg",
            "test_82_3.jpg",
            "test_82_1.jpg",
            "test_82_4.jpg",
            "test_82_7.jpg",
            "test_82_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.43333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 83,
      "prompt": "An anthropomorphized block of tofu cartoon-style busting through a brick wall, inspired by Kool Aid man.",
      "image_filenames": [
        "test_83_0.jpg",
        "test_83_1.jpg",
        "test_83_2.jpg",
        "test_83_3.jpg",
        "test_83_4.jpg",
        "test_83_5.jpg",
        "test_83_6.jpg",
        "test_83_7.jpg",
        "test_83_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          0,
          6,
          2,
          5,
          7,
          8,
          4,
          1
        ],
        "order_filenames": [
          "test_83_3.jpg",
          "test_83_0.jpg",
          "test_83_6.jpg",
          "test_83_2.jpg",
          "test_83_5.jpg",
          "test_83_7.jpg",
          "test_83_8.jpg",
          "test_83_4.jpg",
          "test_83_1.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_83_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_83_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_83_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1727294921875,
            0.205810546875,
            0.170654296875,
            0.1650390625,
            0.15576171875,
            0.1729736328125,
            0.2156982421875,
            0.21337890625,
            0.208251953125
          ],
          "order_indices": [
            6,
            7,
            8,
            1,
            5,
            0,
            2,
            3,
            4
          ],
          "order_filenames": [
            "test_83_6.jpg",
            "test_83_7.jpg",
            "test_83_8.jpg",
            "test_83_1.jpg",
            "test_83_5.jpg",
            "test_83_0.jpg",
            "test_83_2.jpg",
            "test_83_3.jpg",
            "test_83_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.1333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.4375,
            37.625,
            35.3125,
            32.28125,
            30.1875,
            31.046875,
            31.28125,
            43.46875,
            45.0
          ],
          "order_indices": [
            8,
            7,
            0,
            1,
            2,
            3,
            6,
            5,
            4
          ],
          "order_filenames": [
            "test_83_8.jpg",
            "test_83_7.jpg",
            "test_83_0.jpg",
            "test_83_1.jpg",
            "test_83_2.jpg",
            "test_83_3.jpg",
            "test_83_6.jpg",
            "test_83_5.jpg",
            "test_83_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.08333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.20249037444591522,
            0.16371209919452667,
            -1.353803038597107,
            -0.6915668249130249,
            -0.8232980966567993,
            -1.6222891807556152,
            0.05423342436552048,
            0.12723660469055176,
            0.7167953848838806
          ],
          "order_indices": [
            8,
            1,
            7,
            6,
            0,
            3,
            4,
            2,
            5
          ],
          "order_filenames": [
            "test_83_8.jpg",
            "test_83_1.jpg",
            "test_83_7.jpg",
            "test_83_6.jpg",
            "test_83_0.jpg",
            "test_83_3.jpg",
            "test_83_4.jpg",
            "test_83_2.jpg",
            "test_83_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.3500000000000001,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 84,
      "prompt": "A kitten with a panda coloring eating bamboo.",
      "image_filenames": [
        "test_84_0.jpg",
        "test_84_1.jpg",
        "test_84_2.jpg",
        "test_84_3.jpg",
        "test_84_4.jpg",
        "test_84_5.jpg",
        "test_84_6.jpg",
        "test_84_7.jpg",
        "test_84_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          3,
          2,
          7,
          6,
          5,
          0,
          8,
          1
        ],
        "order_filenames": [
          "test_84_4.jpg",
          "test_84_3.jpg",
          "test_84_2.jpg",
          "test_84_7.jpg",
          "test_84_6.jpg",
          "test_84_5.jpg",
          "test_84_0.jpg",
          "test_84_8.jpg",
          "test_84_1.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_84_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_84_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_84_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.160400390625,
            0.2568359375,
            0.262451171875,
            0.2122802734375,
            0.1685791015625,
            0.1983642578125,
            0.2396240234375,
            0.184326171875,
            0.266845703125
          ],
          "order_indices": [
            8,
            2,
            1,
            6,
            3,
            5,
            7,
            4,
            0
          ],
          "order_filenames": [
            "test_84_8.jpg",
            "test_84_2.jpg",
            "test_84_1.jpg",
            "test_84_6.jpg",
            "test_84_3.jpg",
            "test_84_5.jpg",
            "test_84_7.jpg",
            "test_84_4.jpg",
            "test_84_0.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.31666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.78125,
            30.984375,
            28.34375,
            20.109375,
            28.9375,
            29.28125,
            33.6875,
            36.375,
            33.0625
          ],
          "order_indices": [
            7,
            0,
            6,
            8,
            1,
            5,
            4,
            2,
            3
          ],
          "order_filenames": [
            "test_84_7.jpg",
            "test_84_0.jpg",
            "test_84_6.jpg",
            "test_84_8.jpg",
            "test_84_1.jpg",
            "test_84_5.jpg",
            "test_84_4.jpg",
            "test_84_2.jpg",
            "test_84_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.5,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.3883702754974365,
            -0.4474698603153229,
            -1.552669882774353,
            -1.9592441320419312,
            -1.231959581375122,
            -1.508973240852356,
            -1.0375151634216309,
            -0.6879510879516602,
            0.5086697936058044
          ],
          "order_indices": [
            8,
            1,
            7,
            6,
            4,
            0,
            5,
            2,
            3
          ],
          "order_filenames": [
            "test_84_8.jpg",
            "test_84_1.jpg",
            "test_84_7.jpg",
            "test_84_6.jpg",
            "test_84_4.jpg",
            "test_84_0.jpg",
            "test_84_5.jpg",
            "test_84_2.jpg",
            "test_84_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.6000000000000001,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 85,
      "prompt": "The image is of Aunt Jemima in period attire on stage at Van's Warped Tour at 40 years old, throwing pancakes to the crowd.",
      "image_filenames": [
        "test_85_0.jpg",
        "test_85_1.jpg",
        "test_85_2.jpg",
        "test_85_3.jpg",
        "test_85_4.jpg",
        "test_85_5.jpg",
        "test_85_6.jpg",
        "test_85_7.jpg",
        "test_85_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          7,
          6,
          2,
          5,
          0,
          8,
          4,
          3
        ],
        "order_filenames": [
          "test_85_1.jpg",
          "test_85_7.jpg",
          "test_85_6.jpg",
          "test_85_2.jpg",
          "test_85_5.jpg",
          "test_85_0.jpg",
          "test_85_8.jpg",
          "test_85_4.jpg",
          "test_85_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_85_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_85_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_85_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1719970703125,
            0.2076416015625,
            0.27880859375,
            0.1768798828125,
            0.1368408203125,
            0.031982421875,
            0.2371826171875,
            0.20556640625,
            0.228515625
          ],
          "order_indices": [
            2,
            6,
            8,
            1,
            7,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_85_2.jpg",
            "test_85_6.jpg",
            "test_85_8.jpg",
            "test_85_1.jpg",
            "test_85_7.jpg",
            "test_85_3.jpg",
            "test_85_0.jpg",
            "test_85_4.jpg",
            "test_85_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.41666666666666663,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            44.71875,
            41.875,
            48.46875,
            31.4375,
            27.9375,
            1.3251953125,
            43.46875,
            47.84375,
            47.09375
          ],
          "order_indices": [
            2,
            7,
            8,
            0,
            6,
            1,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_85_2.jpg",
            "test_85_7.jpg",
            "test_85_8.jpg",
            "test_85_0.jpg",
            "test_85_6.jpg",
            "test_85_1.jpg",
            "test_85_3.jpg",
            "test_85_4.jpg",
            "test_85_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.35,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.279739111661911,
            -0.520584225654602,
            0.1394616663455963,
            -0.8611836433410645,
            0.3635098338127136,
            -2.273189067840576,
            0.17734847962856293,
            -0.04839787259697914,
            0.18908913433551788
          ],
          "order_indices": [
            4,
            0,
            8,
            6,
            2,
            7,
            1,
            3,
            5
          ],
          "order_filenames": [
            "test_85_4.jpg",
            "test_85_0.jpg",
            "test_85_8.jpg",
            "test_85_6.jpg",
            "test_85_2.jpg",
            "test_85_7.jpg",
            "test_85_1.jpg",
            "test_85_3.jpg",
            "test_85_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.2666666666666666,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 86,
      "prompt": "A demon boy smiling while reading a book in a library.",
      "image_filenames": [
        "test_86_0.jpg",
        "test_86_1.jpg",
        "test_86_2.jpg",
        "test_86_3.jpg",
        "test_86_4.jpg",
        "test_86_5.jpg",
        "test_86_6.jpg",
        "test_86_7.jpg",
        "test_86_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          0,
          2,
          6,
          7,
          1,
          4,
          8,
          3
        ],
        "order_filenames": [
          "test_86_5.jpg",
          "test_86_0.jpg",
          "test_86_2.jpg",
          "test_86_6.jpg",
          "test_86_7.jpg",
          "test_86_1.jpg",
          "test_86_4.jpg",
          "test_86_8.jpg",
          "test_86_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_86_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_86_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_86_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1966552734375,
            0.289306640625,
            0.2861328125,
            0.1995849609375,
            0.2208251953125,
            0.1275634765625,
            0.27490234375,
            0.2296142578125,
            0.253173828125
          ],
          "order_indices": [
            1,
            2,
            6,
            8,
            7,
            4,
            3,
            0,
            5
          ],
          "order_filenames": [
            "test_86_1.jpg",
            "test_86_2.jpg",
            "test_86_6.jpg",
            "test_86_8.jpg",
            "test_86_7.jpg",
            "test_86_4.jpg",
            "test_86_3.jpg",
            "test_86_0.jpg",
            "test_86_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.2333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            42.9375,
            34.875,
            40.65625,
            33.25,
            39.03125,
            15.8203125,
            34.21875,
            47.09375,
            44.53125
          ],
          "order_indices": [
            7,
            8,
            0,
            2,
            4,
            1,
            6,
            3,
            5
          ],
          "order_filenames": [
            "test_86_7.jpg",
            "test_86_8.jpg",
            "test_86_0.jpg",
            "test_86_2.jpg",
            "test_86_4.jpg",
            "test_86_1.jpg",
            "test_86_6.jpg",
            "test_86_3.jpg",
            "test_86_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.10000000000000009,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.4496120512485504,
            0.17929546535015106,
            0.40460139513015747,
            -0.46992719173431396,
            0.5337268710136414,
            -2.159489870071411,
            0.14017054438591003,
            1.8410863876342773,
            1.8067970275878906
          ],
          "order_indices": [
            7,
            8,
            4,
            0,
            2,
            1,
            6,
            3,
            5
          ],
          "order_filenames": [
            "test_86_7.jpg",
            "test_86_8.jpg",
            "test_86_4.jpg",
            "test_86_0.jpg",
            "test_86_2.jpg",
            "test_86_1.jpg",
            "test_86_6.jpg",
            "test_86_3.jpg",
            "test_86_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.25,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 87,
      "prompt": "Uncanny creatures with yin yang flagella in a surreal 1930s cartoon style.",
      "image_filenames": [
        "test_87_0.jpg",
        "test_87_1.jpg",
        "test_87_2.jpg",
        "test_87_3.jpg",
        "test_87_4.jpg",
        "test_87_5.jpg",
        "test_87_6.jpg",
        "test_87_7.jpg",
        "test_87_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          3,
          1,
          5,
          6,
          2,
          7,
          8,
          0
        ],
        "order_filenames": [
          "test_87_4.jpg",
          "test_87_3.jpg",
          "test_87_1.jpg",
          "test_87_5.jpg",
          "test_87_6.jpg",
          "test_87_2.jpg",
          "test_87_7.jpg",
          "test_87_8.jpg",
          "test_87_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_87_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_87_1.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_87_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1617431640625,
            0.17822265625,
            0.156982421875,
            0.1405029296875,
            0.1475830078125,
            0.1302490234375,
            0.1943359375,
            0.186279296875,
            0.212158203125
          ],
          "order_indices": [
            8,
            6,
            7,
            1,
            0,
            2,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_87_8.jpg",
            "test_87_6.jpg",
            "test_87_7.jpg",
            "test_87_1.jpg",
            "test_87_0.jpg",
            "test_87_2.jpg",
            "test_87_4.jpg",
            "test_87_3.jpg",
            "test_87_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.5666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.9375,
            29.71875,
            39.5625,
            24.265625,
            23.125,
            22.828125,
            32.59375,
            40.59375,
            29.328125
          ],
          "order_indices": [
            7,
            2,
            0,
            6,
            1,
            8,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_87_7.jpg",
            "test_87_2.jpg",
            "test_87_0.jpg",
            "test_87_6.jpg",
            "test_87_1.jpg",
            "test_87_8.jpg",
            "test_87_3.jpg",
            "test_87_4.jpg",
            "test_87_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.6333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.2219592332839966,
            -1.827890396118164,
            -2.145545244216919,
            -2.2169747352600098,
            -2.069794178009033,
            -1.9274952411651611,
            -0.9716827869415283,
            -0.3986874520778656,
            -0.6957879066467285
          ],
          "order_indices": [
            7,
            8,
            6,
            0,
            1,
            5,
            4,
            2,
            3
          ],
          "order_filenames": [
            "test_87_7.jpg",
            "test_87_8.jpg",
            "test_87_6.jpg",
            "test_87_0.jpg",
            "test_87_1.jpg",
            "test_87_5.jpg",
            "test_87_4.jpg",
            "test_87_2.jpg",
            "test_87_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.6499999999999999,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 88,
      "prompt": "Popcorn in mouth.",
      "image_filenames": [
        "test_88_0.jpg",
        "test_88_1.jpg",
        "test_88_2.jpg",
        "test_88_3.jpg",
        "test_88_4.jpg",
        "test_88_5.jpg",
        "test_88_6.jpg",
        "test_88_7.jpg",
        "test_88_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          7,
          4,
          3,
          6,
          5,
          1,
          8,
          0
        ],
        "order_filenames": [
          "test_88_2.jpg",
          "test_88_7.jpg",
          "test_88_4.jpg",
          "test_88_3.jpg",
          "test_88_6.jpg",
          "test_88_5.jpg",
          "test_88_1.jpg",
          "test_88_8.jpg",
          "test_88_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_88_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_88_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_88_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1907958984375,
            0.283935546875,
            0.301513671875,
            0.184326171875,
            0.1959228515625,
            0.1617431640625,
            0.302978515625,
            0.210205078125,
            0.267333984375
          ],
          "order_indices": [
            6,
            2,
            1,
            8,
            7,
            4,
            0,
            3,
            5
          ],
          "order_filenames": [
            "test_88_6.jpg",
            "test_88_2.jpg",
            "test_88_1.jpg",
            "test_88_8.jpg",
            "test_88_7.jpg",
            "test_88_4.jpg",
            "test_88_0.jpg",
            "test_88_3.jpg",
            "test_88_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.19999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            27.375,
            35.0,
            31.03125,
            22.015625,
            28.3125,
            15.8828125,
            31.234375,
            38.84375,
            35.65625
          ],
          "order_indices": [
            7,
            8,
            1,
            6,
            2,
            4,
            0,
            3,
            5
          ],
          "order_filenames": [
            "test_88_7.jpg",
            "test_88_8.jpg",
            "test_88_1.jpg",
            "test_88_6.jpg",
            "test_88_2.jpg",
            "test_88_4.jpg",
            "test_88_0.jpg",
            "test_88_3.jpg",
            "test_88_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.09999999999999998,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.37512141466140747,
            1.8661562204360962,
            1.825750708580017,
            -1.4607486724853516,
            -1.4934686422348022,
            -0.8076415657997131,
            1.8154586553573608,
            0.45045390725135803,
            1.3727352619171143
          ],
          "order_indices": [
            1,
            2,
            6,
            8,
            7,
            0,
            5,
            3,
            4
          ],
          "order_filenames": [
            "test_88_1.jpg",
            "test_88_2.jpg",
            "test_88_6.jpg",
            "test_88_8.jpg",
            "test_88_7.jpg",
            "test_88_0.jpg",
            "test_88_5.jpg",
            "test_88_3.jpg",
            "test_88_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 89,
      "prompt": "An anime-style demon princess is depicted in a digital painting.",
      "image_filenames": [
        "test_89_0.jpg",
        "test_89_1.jpg",
        "test_89_2.jpg",
        "test_89_3.jpg",
        "test_89_4.jpg",
        "test_89_5.jpg",
        "test_89_6.jpg",
        "test_89_7.jpg",
        "test_89_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          4,
          3,
          7,
          1,
          0,
          5,
          8,
          6
        ],
        "order_filenames": [
          "test_89_2.jpg",
          "test_89_4.jpg",
          "test_89_3.jpg",
          "test_89_7.jpg",
          "test_89_1.jpg",
          "test_89_0.jpg",
          "test_89_5.jpg",
          "test_89_8.jpg",
          "test_89_6.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_89_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_89_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_89_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1888427734375,
            0.258056640625,
            0.228271484375,
            0.19580078125,
            0.16015625,
            0.10003662109375,
            0.2061767578125,
            0.21875,
            0.269287109375
          ],
          "order_indices": [
            8,
            1,
            2,
            7,
            6,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_89_8.jpg",
            "test_89_1.jpg",
            "test_89_2.jpg",
            "test_89_7.jpg",
            "test_89_6.jpg",
            "test_89_3.jpg",
            "test_89_0.jpg",
            "test_89_4.jpg",
            "test_89_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.6875,
            36.15625,
            32.53125,
            33.71875,
            26.28125,
            21.421875,
            32.59375,
            34.5625,
            35.75
          ],
          "order_indices": [
            0,
            1,
            8,
            7,
            3,
            6,
            2,
            4,
            5
          ],
          "order_filenames": [
            "test_89_0.jpg",
            "test_89_1.jpg",
            "test_89_8.jpg",
            "test_89_7.jpg",
            "test_89_3.jpg",
            "test_89_6.jpg",
            "test_89_2.jpg",
            "test_89_4.jpg",
            "test_89_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.2333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.46247729659080505,
            -1.2421274185180664,
            -0.6055529117584229,
            -0.6868780255317688,
            -1.1665537357330322,
            -1.6970146894454956,
            -0.8386660218238831,
            0.5058992505073547,
            0.5729951858520508
          ],
          "order_indices": [
            8,
            7,
            0,
            2,
            3,
            6,
            4,
            1,
            5
          ],
          "order_filenames": [
            "test_89_8.jpg",
            "test_89_7.jpg",
            "test_89_0.jpg",
            "test_89_2.jpg",
            "test_89_3.jpg",
            "test_89_6.jpg",
            "test_89_4.jpg",
            "test_89_1.jpg",
            "test_89_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.016666666666666607,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 90,
      "prompt": "A white polar bear cub wearing sunglasses sits in a meadow with flowers.",
      "image_filenames": [
        "test_90_0.jpg",
        "test_90_1.jpg",
        "test_90_2.jpg",
        "test_90_3.jpg",
        "test_90_4.jpg",
        "test_90_5.jpg",
        "test_90_6.jpg",
        "test_90_7.jpg",
        "test_90_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          2,
          4,
          5,
          7,
          6,
          3,
          8,
          0
        ],
        "order_filenames": [
          "test_90_1.jpg",
          "test_90_2.jpg",
          "test_90_4.jpg",
          "test_90_5.jpg",
          "test_90_7.jpg",
          "test_90_6.jpg",
          "test_90_3.jpg",
          "test_90_8.jpg",
          "test_90_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_90_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_90_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_90_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.24951171875,
            0.287109375,
            0.27490234375,
            0.197998046875,
            0.20556640625,
            0.19873046875,
            0.264892578125,
            0.18798828125,
            0.3251953125
          ],
          "order_indices": [
            8,
            1,
            2,
            6,
            0,
            4,
            5,
            3,
            7
          ],
          "order_filenames": [
            "test_90_8.jpg",
            "test_90_1.jpg",
            "test_90_2.jpg",
            "test_90_6.jpg",
            "test_90_0.jpg",
            "test_90_4.jpg",
            "test_90_5.jpg",
            "test_90_3.jpg",
            "test_90_7.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.1166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            44.96875,
            35.875,
            36.21875,
            29.421875,
            35.15625,
            30.796875,
            34.9375,
            36.8125,
            45.53125
          ],
          "order_indices": [
            8,
            0,
            7,
            2,
            1,
            4,
            6,
            5,
            3
          ],
          "order_filenames": [
            "test_90_8.jpg",
            "test_90_0.jpg",
            "test_90_7.jpg",
            "test_90_2.jpg",
            "test_90_1.jpg",
            "test_90_4.jpg",
            "test_90_6.jpg",
            "test_90_5.jpg",
            "test_90_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.2666666666666666,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.4834710359573364,
            -0.5534679293632507,
            -0.5778546929359436,
            -1.9782133102416992,
            -0.6853058934211731,
            -1.7690503597259521,
            -0.7126389741897583,
            -0.5652293562889099,
            1.2464216947555542
          ],
          "order_indices": [
            0,
            8,
            1,
            7,
            2,
            4,
            6,
            5,
            3
          ],
          "order_filenames": [
            "test_90_0.jpg",
            "test_90_8.jpg",
            "test_90_1.jpg",
            "test_90_7.jpg",
            "test_90_2.jpg",
            "test_90_4.jpg",
            "test_90_6.jpg",
            "test_90_5.jpg",
            "test_90_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.19999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 91,
      "prompt": "A plush of a cute sun-eating creature.",
      "image_filenames": [
        "test_91_0.jpg",
        "test_91_1.jpg",
        "test_91_2.jpg",
        "test_91_3.jpg",
        "test_91_4.jpg",
        "test_91_5.jpg",
        "test_91_6.jpg",
        "test_91_7.jpg",
        "test_91_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          4,
          1,
          2,
          7,
          5,
          8,
          6,
          0
        ],
        "order_filenames": [
          "test_91_3.jpg",
          "test_91_4.jpg",
          "test_91_1.jpg",
          "test_91_2.jpg",
          "test_91_7.jpg",
          "test_91_5.jpg",
          "test_91_8.jpg",
          "test_91_6.jpg",
          "test_91_0.jpg"
        ],
        "condorcet_winner": 3,
        "winner_indices": [
          3,
          4
        ],
        "winner_filenames": [
          "test_91_3.jpg",
          "test_91_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_91_3.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_91_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2169189453125,
            0.22998046875,
            0.2374267578125,
            0.211181640625,
            0.160888671875,
            0.18896484375,
            0.2113037109375,
            0.2471923828125,
            0.2783203125
          ],
          "order_indices": [
            8,
            7,
            2,
            1,
            0,
            6,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_91_8.jpg",
            "test_91_7.jpg",
            "test_91_2.jpg",
            "test_91_1.jpg",
            "test_91_0.jpg",
            "test_91_6.jpg",
            "test_91_3.jpg",
            "test_91_5.jpg",
            "test_91_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.30000000000000004,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            42.09375,
            30.96875,
            41.90625,
            33.375,
            31.5,
            32.0625,
            37.4375,
            38.75,
            42.625
          ],
          "order_indices": [
            8,
            0,
            2,
            7,
            6,
            3,
            5,
            4,
            1
          ],
          "order_filenames": [
            "test_91_8.jpg",
            "test_91_0.jpg",
            "test_91_2.jpg",
            "test_91_7.jpg",
            "test_91_6.jpg",
            "test_91_3.jpg",
            "test_91_5.jpg",
            "test_91_4.jpg",
            "test_91_1.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.6166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.1266106516122818,
            -0.15141814947128296,
            0.2270749807357788,
            -0.3453677296638489,
            -1.893669605255127,
            -1.5084960460662842,
            -0.6606929898262024,
            0.8374689221382141,
            -0.1159665435552597
          ],
          "order_indices": [
            7,
            2,
            8,
            0,
            1,
            3,
            6,
            5,
            4
          ],
          "order_filenames": [
            "test_91_7.jpg",
            "test_91_2.jpg",
            "test_91_8.jpg",
            "test_91_0.jpg",
            "test_91_1.jpg",
            "test_91_3.jpg",
            "test_91_6.jpg",
            "test_91_5.jpg",
            "test_91_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.19999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 92,
      "prompt": "A cute rainbow kitten with different colored eyes in the chibi-style of Studio Ghibli is featured on a postcard.",
      "image_filenames": [
        "test_92_0.jpg",
        "test_92_1.jpg",
        "test_92_2.jpg",
        "test_92_3.jpg",
        "test_92_4.jpg",
        "test_92_5.jpg",
        "test_92_6.jpg",
        "test_92_7.jpg",
        "test_92_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          2,
          5,
          6,
          7,
          1,
          0,
          8,
          3
        ],
        "order_filenames": [
          "test_92_4.jpg",
          "test_92_2.jpg",
          "test_92_5.jpg",
          "test_92_6.jpg",
          "test_92_7.jpg",
          "test_92_1.jpg",
          "test_92_0.jpg",
          "test_92_8.jpg",
          "test_92_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_92_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_92_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_92_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1412353515625,
            0.29443359375,
            0.239990234375,
            0.20166015625,
            0.1773681640625,
            0.167236328125,
            0.275390625,
            0.2008056640625,
            0.28125
          ],
          "order_indices": [
            1,
            8,
            6,
            2,
            3,
            7,
            4,
            5,
            0
          ],
          "order_filenames": [
            "test_92_1.jpg",
            "test_92_8.jpg",
            "test_92_6.jpg",
            "test_92_2.jpg",
            "test_92_3.jpg",
            "test_92_7.jpg",
            "test_92_4.jpg",
            "test_92_5.jpg",
            "test_92_0.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.2333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.8125,
            39.59375,
            36.625,
            29.46875,
            24.078125,
            29.671875,
            34.4375,
            44.59375,
            31.6875
          ],
          "order_indices": [
            7,
            1,
            0,
            2,
            6,
            8,
            5,
            3,
            4
          ],
          "order_filenames": [
            "test_92_7.jpg",
            "test_92_1.jpg",
            "test_92_0.jpg",
            "test_92_2.jpg",
            "test_92_6.jpg",
            "test_92_8.jpg",
            "test_92_5.jpg",
            "test_92_3.jpg",
            "test_92_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.1499999999999999,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.8611021041870117,
            0.6905612349510193,
            -0.21117955446243286,
            -1.2886466979980469,
            -1.971206784248352,
            -1.790259838104248,
            -0.5008022785186768,
            -1.1448715925216675,
            0.8934879899024963
          ],
          "order_indices": [
            8,
            1,
            2,
            6,
            7,
            3,
            5,
            0,
            4
          ],
          "order_filenames": [
            "test_92_8.jpg",
            "test_92_1.jpg",
            "test_92_2.jpg",
            "test_92_6.jpg",
            "test_92_7.jpg",
            "test_92_3.jpg",
            "test_92_5.jpg",
            "test_92_0.jpg",
            "test_92_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.30000000000000004,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 93,
      "prompt": "Two Somali friends sitting and watching a Studio Ghibli movie.",
      "image_filenames": [
        "test_93_0.jpg",
        "test_93_1.jpg",
        "test_93_2.jpg",
        "test_93_3.jpg",
        "test_93_4.jpg",
        "test_93_5.jpg",
        "test_93_6.jpg",
        "test_93_7.jpg",
        "test_93_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          2,
          7,
          4,
          0,
          6,
          5,
          8,
          3
        ],
        "order_filenames": [
          "test_93_1.jpg",
          "test_93_2.jpg",
          "test_93_7.jpg",
          "test_93_4.jpg",
          "test_93_0.jpg",
          "test_93_6.jpg",
          "test_93_5.jpg",
          "test_93_8.jpg",
          "test_93_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_93_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            1,
            4
          ],
          "winner_filenames": [
            "test_93_1.jpg",
            "test_93_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_93_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2021484375,
            0.26953125,
            0.2587890625,
            0.1851806640625,
            0.1810302734375,
            0.202392578125,
            0.25927734375,
            0.2174072265625,
            0.2489013671875
          ],
          "order_indices": [
            1,
            6,
            2,
            8,
            7,
            5,
            0,
            3,
            4
          ],
          "order_filenames": [
            "test_93_1.jpg",
            "test_93_6.jpg",
            "test_93_2.jpg",
            "test_93_8.jpg",
            "test_93_7.jpg",
            "test_93_5.jpg",
            "test_93_0.jpg",
            "test_93_3.jpg",
            "test_93_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.43333333333333335,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.8125,
            31.453125,
            38.53125,
            23.984375,
            23.734375,
            20.4375,
            35.78125,
            43.3125,
            35.75
          ],
          "order_indices": [
            7,
            2,
            0,
            6,
            8,
            1,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_93_7.jpg",
            "test_93_2.jpg",
            "test_93_0.jpg",
            "test_93_6.jpg",
            "test_93_8.jpg",
            "test_93_1.jpg",
            "test_93_3.jpg",
            "test_93_4.jpg",
            "test_93_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.41666666666666663,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.5473624467849731,
            -1.4467401504516602,
            -1.8431756496429443,
            -1.8852853775024414,
            -1.8656699657440186,
            -1.245194435119629,
            -1.6059657335281372,
            -0.2700938880443573,
            -1.3305964469909668
          ],
          "order_indices": [
            7,
            0,
            5,
            8,
            1,
            6,
            2,
            4,
            3
          ],
          "order_filenames": [
            "test_93_7.jpg",
            "test_93_0.jpg",
            "test_93_5.jpg",
            "test_93_8.jpg",
            "test_93_1.jpg",
            "test_93_6.jpg",
            "test_93_2.jpg",
            "test_93_4.jpg",
            "test_93_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.15000000000000002,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 94,
      "prompt": "An image of an aircraft carrier made of cheese.",
      "image_filenames": [
        "test_94_0.jpg",
        "test_94_1.jpg",
        "test_94_2.jpg",
        "test_94_3.jpg",
        "test_94_4.jpg",
        "test_94_5.jpg",
        "test_94_6.jpg",
        "test_94_7.jpg",
        "test_94_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          8,
          4,
          7,
          2,
          6,
          5,
          3,
          1,
          0
        ],
        "order_filenames": [
          "test_94_8.jpg",
          "test_94_4.jpg",
          "test_94_7.jpg",
          "test_94_2.jpg",
          "test_94_6.jpg",
          "test_94_5.jpg",
          "test_94_3.jpg",
          "test_94_1.jpg",
          "test_94_0.jpg"
        ],
        "condorcet_winner": 8,
        "winner_indices": [
          8
        ],
        "winner_filenames": [
          "test_94_8.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            8
          ],
          "winner_filenames": [
            "test_94_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            8
          ],
          "winner_filenames": [
            "test_94_8.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1910400390625,
            0.25146484375,
            0.247802734375,
            0.211669921875,
            0.1866455078125,
            0.18017578125,
            0.203369140625,
            0.25146484375,
            0.251953125
          ],
          "order_indices": [
            8,
            1,
            7,
            2,
            3,
            6,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_94_8.jpg",
            "test_94_1.jpg",
            "test_94_7.jpg",
            "test_94_2.jpg",
            "test_94_3.jpg",
            "test_94_6.jpg",
            "test_94_0.jpg",
            "test_94_4.jpg",
            "test_94_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.25,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 1.0,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            43.09375,
            44.53125,
            32.375,
            42.84375,
            27.609375,
            33.75,
            36.4375,
            54.75,
            43.28125
          ],
          "order_indices": [
            7,
            1,
            8,
            0,
            3,
            6,
            5,
            2,
            4
          ],
          "order_filenames": [
            "test_94_7.jpg",
            "test_94_1.jpg",
            "test_94_8.jpg",
            "test_94_0.jpg",
            "test_94_3.jpg",
            "test_94_6.jpg",
            "test_94_5.jpg",
            "test_94_2.jpg",
            "test_94_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.16666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.7491482496261597,
            1.520747423171997,
            -1.607825756072998,
            -0.4529181122779846,
            -2.026035785675049,
            -2.212301254272461,
            0.9965888261795044,
            1.6288412809371948,
            -0.3558815121650696
          ],
          "order_indices": [
            7,
            1,
            6,
            0,
            8,
            3,
            2,
            4,
            5
          ],
          "order_filenames": [
            "test_94_7.jpg",
            "test_94_1.jpg",
            "test_94_6.jpg",
            "test_94_0.jpg",
            "test_94_8.jpg",
            "test_94_3.jpg",
            "test_94_2.jpg",
            "test_94_4.jpg",
            "test_94_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.16666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 95,
      "prompt": "Scene from Muppet Mad Max-Fury Road.",
      "image_filenames": [
        "test_95_0.jpg",
        "test_95_1.jpg",
        "test_95_2.jpg",
        "test_95_3.jpg",
        "test_95_4.jpg",
        "test_95_5.jpg",
        "test_95_6.jpg",
        "test_95_7.jpg",
        "test_95_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          0,
          1,
          3,
          4,
          6,
          2,
          8,
          7
        ],
        "order_filenames": [
          "test_95_5.jpg",
          "test_95_0.jpg",
          "test_95_1.jpg",
          "test_95_3.jpg",
          "test_95_4.jpg",
          "test_95_6.jpg",
          "test_95_2.jpg",
          "test_95_8.jpg",
          "test_95_7.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_95_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_95_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_95_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2159423828125,
            0.289794921875,
            0.31494140625,
            0.20068359375,
            0.1488037109375,
            0.11199951171875,
            0.19921875,
            0.2117919921875,
            0.26953125
          ],
          "order_indices": [
            2,
            1,
            8,
            0,
            7,
            3,
            6,
            4,
            5
          ],
          "order_filenames": [
            "test_95_2.jpg",
            "test_95_1.jpg",
            "test_95_8.jpg",
            "test_95_0.jpg",
            "test_95_7.jpg",
            "test_95_3.jpg",
            "test_95_6.jpg",
            "test_95_4.jpg",
            "test_95_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.33333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            43.09375,
            39.3125,
            36.1875,
            29.859375,
            23.640625,
            20.203125,
            33.6875,
            46.53125,
            37.8125
          ],
          "order_indices": [
            7,
            0,
            1,
            8,
            2,
            6,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_95_7.jpg",
            "test_95_0.jpg",
            "test_95_1.jpg",
            "test_95_8.jpg",
            "test_95_2.jpg",
            "test_95_6.jpg",
            "test_95_3.jpg",
            "test_95_4.jpg",
            "test_95_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.3833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.787501335144043,
            1.1453038454055786,
            0.19301681220531464,
            -0.7398474812507629,
            -1.544724941253662,
            -1.7800214290618896,
            -1.0119057893753052,
            1.0801656246185303,
            0.4971579313278198
          ],
          "order_indices": [
            1,
            7,
            0,
            8,
            2,
            3,
            6,
            4,
            5
          ],
          "order_filenames": [
            "test_95_1.jpg",
            "test_95_7.jpg",
            "test_95_0.jpg",
            "test_95_8.jpg",
            "test_95_2.jpg",
            "test_95_3.jpg",
            "test_95_6.jpg",
            "test_95_4.jpg",
            "test_95_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.2666666666666666,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 96,
      "prompt": "Family assembling missile in living room.",
      "image_filenames": [
        "test_96_0.jpg",
        "test_96_1.jpg",
        "test_96_2.jpg",
        "test_96_3.jpg",
        "test_96_4.jpg",
        "test_96_5.jpg",
        "test_96_6.jpg",
        "test_96_7.jpg",
        "test_96_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          2,
          4,
          1,
          3,
          8,
          6,
          5,
          0
        ],
        "order_filenames": [
          "test_96_7.jpg",
          "test_96_2.jpg",
          "test_96_4.jpg",
          "test_96_1.jpg",
          "test_96_3.jpg",
          "test_96_8.jpg",
          "test_96_6.jpg",
          "test_96_5.jpg",
          "test_96_0.jpg"
        ],
        "condorcet_winner": 7,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_96_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_96_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_96_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1746826171875,
            0.228759765625,
            0.2276611328125,
            0.1436767578125,
            0.1566162109375,
            0.13134765625,
            0.2056884765625,
            0.2298583984375,
            0.28271484375
          ],
          "order_indices": [
            8,
            7,
            1,
            2,
            6,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_96_8.jpg",
            "test_96_7.jpg",
            "test_96_1.jpg",
            "test_96_2.jpg",
            "test_96_6.jpg",
            "test_96_0.jpg",
            "test_96_4.jpg",
            "test_96_3.jpg",
            "test_96_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.41666666666666663,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            41.375,
            35.15625,
            32.875,
            19.484375,
            28.265625,
            19.8125,
            39.40625,
            49.0,
            42.125
          ],
          "order_indices": [
            7,
            8,
            0,
            6,
            1,
            2,
            4,
            5,
            3
          ],
          "order_filenames": [
            "test_96_7.jpg",
            "test_96_8.jpg",
            "test_96_0.jpg",
            "test_96_6.jpg",
            "test_96_1.jpg",
            "test_96_2.jpg",
            "test_96_4.jpg",
            "test_96_5.jpg",
            "test_96_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.08333333333333337,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 1.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.9303716421127319,
            -0.6731762290000916,
            -1.126030445098877,
            -1.7954306602478027,
            -1.270331859588623,
            -2.1732892990112305,
            -0.5356432795524597,
            0.6396328210830688,
            1.198685646057129
          ],
          "order_indices": [
            8,
            7,
            6,
            1,
            0,
            2,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_96_8.jpg",
            "test_96_7.jpg",
            "test_96_6.jpg",
            "test_96_1.jpg",
            "test_96_0.jpg",
            "test_96_2.jpg",
            "test_96_4.jpg",
            "test_96_3.jpg",
            "test_96_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.16666666666666663,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 97,
      "prompt": "A lemon wearing a suit and tie, full body portrait.",
      "image_filenames": [
        "test_97_0.jpg",
        "test_97_1.jpg",
        "test_97_2.jpg",
        "test_97_3.jpg",
        "test_97_4.jpg",
        "test_97_5.jpg",
        "test_97_6.jpg",
        "test_97_7.jpg",
        "test_97_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          5,
          3,
          2,
          4,
          6,
          8,
          7,
          0
        ],
        "order_filenames": [
          "test_97_1.jpg",
          "test_97_5.jpg",
          "test_97_3.jpg",
          "test_97_2.jpg",
          "test_97_4.jpg",
          "test_97_6.jpg",
          "test_97_8.jpg",
          "test_97_7.jpg",
          "test_97_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1,
          5
        ],
        "winner_filenames": [
          "test_97_1.jpg",
          "test_97_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_97_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_97_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.164794921875,
            0.230224609375,
            0.2261962890625,
            0.128173828125,
            0.169921875,
            0.1185302734375,
            0.1500244140625,
            0.1348876953125,
            0.227294921875
          ],
          "order_indices": [
            1,
            8,
            2,
            4,
            0,
            6,
            7,
            3,
            5
          ],
          "order_filenames": [
            "test_97_1.jpg",
            "test_97_8.jpg",
            "test_97_2.jpg",
            "test_97_4.jpg",
            "test_97_0.jpg",
            "test_97_6.jpg",
            "test_97_7.jpg",
            "test_97_3.jpg",
            "test_97_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.01666666666666672,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            33.6875,
            45.0,
            36.84375,
            20.015625,
            32.0625,
            22.0625,
            25.96875,
            24.109375,
            36.5
          ],
          "order_indices": [
            1,
            2,
            8,
            0,
            4,
            6,
            7,
            5,
            3
          ],
          "order_filenames": [
            "test_97_1.jpg",
            "test_97_2.jpg",
            "test_97_8.jpg",
            "test_97_0.jpg",
            "test_97_4.jpg",
            "test_97_6.jpg",
            "test_97_7.jpg",
            "test_97_5.jpg",
            "test_97_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.01666666666666672,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.48993387818336487,
            0.38852807879447937,
            -1.7318236827850342,
            -2.2818379402160645,
            -1.5898023843765259,
            -2.2794740200042725,
            -1.2723939418792725,
            -1.3600313663482666,
            1.4960631132125854
          ],
          "order_indices": [
            8,
            1,
            0,
            6,
            7,
            4,
            2,
            5,
            3
          ],
          "order_filenames": [
            "test_97_8.jpg",
            "test_97_1.jpg",
            "test_97_0.jpg",
            "test_97_6.jpg",
            "test_97_7.jpg",
            "test_97_4.jpg",
            "test_97_2.jpg",
            "test_97_5.jpg",
            "test_97_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.3999999999999999,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 98,
      "prompt": "Astolfo, an anime character, wearing a witch hat and lab coat, is flying on a broom while hexing in a forest.",
      "image_filenames": [
        "test_98_0.jpg",
        "test_98_1.jpg",
        "test_98_2.jpg",
        "test_98_3.jpg",
        "test_98_4.jpg",
        "test_98_5.jpg",
        "test_98_6.jpg",
        "test_98_7.jpg",
        "test_98_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          1,
          2,
          5,
          7,
          6,
          8,
          0,
          3
        ],
        "order_filenames": [
          "test_98_4.jpg",
          "test_98_1.jpg",
          "test_98_2.jpg",
          "test_98_5.jpg",
          "test_98_7.jpg",
          "test_98_6.jpg",
          "test_98_8.jpg",
          "test_98_0.jpg",
          "test_98_3.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_98_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_98_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_98_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2027587890625,
            0.2802734375,
            0.26318359375,
            0.1981201171875,
            0.1505126953125,
            0.09918212890625,
            0.2408447265625,
            0.1915283203125,
            0.2325439453125
          ],
          "order_indices": [
            1,
            2,
            6,
            8,
            0,
            3,
            7,
            4,
            5
          ],
          "order_filenames": [
            "test_98_1.jpg",
            "test_98_2.jpg",
            "test_98_6.jpg",
            "test_98_8.jpg",
            "test_98_0.jpg",
            "test_98_3.jpg",
            "test_98_7.jpg",
            "test_98_4.jpg",
            "test_98_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.033333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            46.1875,
            31.453125,
            37.34375,
            28.890625,
            32.96875,
            14.5234375,
            34.1875,
            41.90625,
            36.875
          ],
          "order_indices": [
            0,
            7,
            2,
            8,
            6,
            4,
            1,
            3,
            5
          ],
          "order_filenames": [
            "test_98_0.jpg",
            "test_98_7.jpg",
            "test_98_2.jpg",
            "test_98_8.jpg",
            "test_98_6.jpg",
            "test_98_4.jpg",
            "test_98_1.jpg",
            "test_98_3.jpg",
            "test_98_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.19999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.8154401183128357,
            -0.3715348243713379,
            -0.0857725664973259,
            -0.4487733840942383,
            -1.9636846780776978,
            -2.2805793285369873,
            -0.8176583051681519,
            -0.11106622964143753,
            0.34764277935028076
          ],
          "order_indices": [
            8,
            2,
            7,
            1,
            3,
            0,
            6,
            4,
            5
          ],
          "order_filenames": [
            "test_98_8.jpg",
            "test_98_2.jpg",
            "test_98_7.jpg",
            "test_98_1.jpg",
            "test_98_3.jpg",
            "test_98_0.jpg",
            "test_98_6.jpg",
            "test_98_4.jpg",
            "test_98_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.16666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 99,
      "prompt": "A sci-fi machine shop in a shipping container, depicted in a manga-style digital painting with intricate details.",
      "image_filenames": [
        "test_99_0.jpg",
        "test_99_1.jpg",
        "test_99_2.jpg",
        "test_99_3.jpg",
        "test_99_4.jpg",
        "test_99_5.jpg",
        "test_99_6.jpg",
        "test_99_7.jpg",
        "test_99_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          6,
          7,
          1,
          2,
          8,
          4,
          5,
          3
        ],
        "order_filenames": [
          "test_99_0.jpg",
          "test_99_6.jpg",
          "test_99_7.jpg",
          "test_99_1.jpg",
          "test_99_2.jpg",
          "test_99_8.jpg",
          "test_99_4.jpg",
          "test_99_5.jpg",
          "test_99_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_99_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_99_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0,
            6
          ],
          "winner_filenames": [
            "test_99_0.jpg",
            "test_99_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.22900390625,
            0.287353515625,
            0.27490234375,
            0.185546875,
            0.194091796875,
            0.18310546875,
            0.248291015625,
            0.2322998046875,
            0.25146484375
          ],
          "order_indices": [
            1,
            2,
            8,
            6,
            7,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_99_1.jpg",
            "test_99_2.jpg",
            "test_99_8.jpg",
            "test_99_6.jpg",
            "test_99_7.jpg",
            "test_99_0.jpg",
            "test_99_4.jpg",
            "test_99_3.jpg",
            "test_99_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.4833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.625,
            38.84375,
            42.375,
            30.671875,
            30.484375,
            31.75,
            42.90625,
            43.34375,
            44.9375
          ],
          "order_indices": [
            8,
            7,
            6,
            2,
            0,
            1,
            5,
            3,
            4
          ],
          "order_filenames": [
            "test_99_8.jpg",
            "test_99_7.jpg",
            "test_99_6.jpg",
            "test_99_2.jpg",
            "test_99_0.jpg",
            "test_99_1.jpg",
            "test_99_5.jpg",
            "test_99_3.jpg",
            "test_99_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.55,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.028392961248755455,
            0.8150275945663452,
            0.15027007460594177,
            -0.7792902588844299,
            -0.1478087306022644,
            -1.450300931930542,
            0.855404794216156,
            0.798233687877655,
            1.1043468713760376
          ],
          "order_indices": [
            8,
            6,
            1,
            7,
            2,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_99_8.jpg",
            "test_99_6.jpg",
            "test_99_1.jpg",
            "test_99_7.jpg",
            "test_99_2.jpg",
            "test_99_0.jpg",
            "test_99_4.jpg",
            "test_99_3.jpg",
            "test_99_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3888888888888889,
            "spearman_rho": 0.55,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 100,
      "prompt": "The image shows centric diatoms.",
      "image_filenames": [
        "test_100_0.jpg",
        "test_100_1.jpg",
        "test_100_2.jpg",
        "test_100_3.jpg",
        "test_100_4.jpg",
        "test_100_5.jpg",
        "test_100_6.jpg",
        "test_100_7.jpg",
        "test_100_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          0,
          4,
          6,
          5,
          8,
          3,
          1,
          2
        ],
        "order_filenames": [
          "test_100_7.jpg",
          "test_100_0.jpg",
          "test_100_4.jpg",
          "test_100_6.jpg",
          "test_100_5.jpg",
          "test_100_8.jpg",
          "test_100_3.jpg",
          "test_100_1.jpg",
          "test_100_2.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_100_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_100_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4,
            7
          ],
          "winner_filenames": [
            "test_100_4.jpg",
            "test_100_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1968994140625,
            0.1580810546875,
            0.1822509765625,
            0.210693359375,
            0.1551513671875,
            0.152099609375,
            0.1910400390625,
            0.20849609375,
            0.1981201171875
          ],
          "order_indices": [
            3,
            7,
            8,
            0,
            6,
            2,
            1,
            4,
            5
          ],
          "order_filenames": [
            "test_100_3.jpg",
            "test_100_7.jpg",
            "test_100_8.jpg",
            "test_100_0.jpg",
            "test_100_6.jpg",
            "test_100_2.jpg",
            "test_100_1.jpg",
            "test_100_4.jpg",
            "test_100_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.15000000000000002,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            31.921875,
            25.296875,
            28.40625,
            30.921875,
            26.328125,
            30.015625,
            37.9375,
            41.75,
            38.5625
          ],
          "order_indices": [
            7,
            8,
            6,
            0,
            3,
            5,
            2,
            4,
            1
          ],
          "order_filenames": [
            "test_100_7.jpg",
            "test_100_8.jpg",
            "test_100_6.jpg",
            "test_100_0.jpg",
            "test_100_3.jpg",
            "test_100_5.jpg",
            "test_100_2.jpg",
            "test_100_4.jpg",
            "test_100_1.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3888888888888889,
            "spearman_rho": 0.5333333333333333,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.6690094470977783,
            -0.7327628135681152,
            -0.7817307710647583,
            0.030524885281920433,
            -0.7940874695777893,
            -0.33606424927711487,
            0.5398069620132446,
            0.494882732629776,
            0.5519979000091553
          ],
          "order_indices": [
            0,
            8,
            6,
            7,
            3,
            5,
            1,
            2,
            4
          ],
          "order_filenames": [
            "test_100_0.jpg",
            "test_100_8.jpg",
            "test_100_6.jpg",
            "test_100_7.jpg",
            "test_100_3.jpg",
            "test_100_5.jpg",
            "test_100_1.jpg",
            "test_100_2.jpg",
            "test_100_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.41666666666666663,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 101,
      "prompt": "A spaceship in an empty landscape.",
      "image_filenames": [
        "test_101_0.jpg",
        "test_101_1.jpg",
        "test_101_2.jpg",
        "test_101_3.jpg",
        "test_101_4.jpg",
        "test_101_5.jpg",
        "test_101_6.jpg",
        "test_101_7.jpg",
        "test_101_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          2,
          1,
          3,
          4,
          5,
          8,
          7,
          6
        ],
        "order_filenames": [
          "test_101_0.jpg",
          "test_101_2.jpg",
          "test_101_1.jpg",
          "test_101_3.jpg",
          "test_101_4.jpg",
          "test_101_5.jpg",
          "test_101_8.jpg",
          "test_101_7.jpg",
          "test_101_6.jpg"
        ],
        "condorcet_winner": 0,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_101_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_101_3.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_101_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.207275390625,
            0.1990966796875,
            0.2147216796875,
            0.2049560546875,
            0.2086181640625,
            0.205322265625,
            0.1417236328125,
            0.2069091796875,
            0.1724853515625
          ],
          "order_indices": [
            2,
            4,
            0,
            7,
            5,
            3,
            1,
            8,
            6
          ],
          "order_filenames": [
            "test_101_2.jpg",
            "test_101_4.jpg",
            "test_101_0.jpg",
            "test_101_7.jpg",
            "test_101_5.jpg",
            "test_101_3.jpg",
            "test_101_1.jpg",
            "test_101_8.jpg",
            "test_101_6.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3888888888888889,
            "spearman_rho": 0.5666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.375,
            32.40625,
            38.40625,
            31.09375,
            36.28125,
            32.65625,
            28.765625,
            35.84375,
            42.75
          ],
          "order_indices": [
            8,
            2,
            0,
            4,
            7,
            5,
            1,
            3,
            6
          ],
          "order_filenames": [
            "test_101_8.jpg",
            "test_101_2.jpg",
            "test_101_0.jpg",
            "test_101_4.jpg",
            "test_101_7.jpg",
            "test_101_5.jpg",
            "test_101_1.jpg",
            "test_101_3.jpg",
            "test_101_6.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.31666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.3379454612731934,
            0.037046853452920914,
            0.8927547335624695,
            0.34930184483528137,
            0.4760318696498871,
            0.9164214134216309,
            -1.571746826171875,
            0.447922945022583,
            0.22769038379192352
          ],
          "order_indices": [
            0,
            5,
            2,
            4,
            7,
            3,
            8,
            1,
            6
          ],
          "order_filenames": [
            "test_101_0.jpg",
            "test_101_5.jpg",
            "test_101_2.jpg",
            "test_101_4.jpg",
            "test_101_7.jpg",
            "test_101_3.jpg",
            "test_101_8.jpg",
            "test_101_1.jpg",
            "test_101_6.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3888888888888889,
            "spearman_rho": 0.5333333333333333,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 1.0,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 102,
      "prompt": "A mechanical planet amidst a space war with superships and exploding stars, featuring steampunk and clockpunk elements.",
      "image_filenames": [
        "test_102_0.jpg",
        "test_102_1.jpg",
        "test_102_2.jpg",
        "test_102_3.jpg",
        "test_102_4.jpg",
        "test_102_5.jpg",
        "test_102_6.jpg",
        "test_102_7.jpg",
        "test_102_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          5,
          1,
          3,
          0,
          2,
          8,
          7,
          6
        ],
        "order_filenames": [
          "test_102_4.jpg",
          "test_102_5.jpg",
          "test_102_1.jpg",
          "test_102_3.jpg",
          "test_102_0.jpg",
          "test_102_2.jpg",
          "test_102_8.jpg",
          "test_102_7.jpg",
          "test_102_6.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_102_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_102_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_102_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.216552734375,
            0.2486572265625,
            0.281005859375,
            0.2158203125,
            0.16259765625,
            0.171142578125,
            0.254150390625,
            0.213623046875,
            0.2440185546875
          ],
          "order_indices": [
            2,
            6,
            1,
            8,
            0,
            3,
            7,
            5,
            4
          ],
          "order_filenames": [
            "test_102_2.jpg",
            "test_102_6.jpg",
            "test_102_1.jpg",
            "test_102_8.jpg",
            "test_102_0.jpg",
            "test_102_3.jpg",
            "test_102_7.jpg",
            "test_102_5.jpg",
            "test_102_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.5666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.75,
            34.125,
            38.40625,
            32.9375,
            17.890625,
            23.578125,
            29.921875,
            37.78125,
            37.1875
          ],
          "order_indices": [
            2,
            7,
            8,
            0,
            1,
            3,
            6,
            5,
            4
          ],
          "order_filenames": [
            "test_102_2.jpg",
            "test_102_7.jpg",
            "test_102_8.jpg",
            "test_102_0.jpg",
            "test_102_1.jpg",
            "test_102_3.jpg",
            "test_102_6.jpg",
            "test_102_5.jpg",
            "test_102_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.5833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.7822719812393188,
            1.060820460319519,
            0.43432337045669556,
            -0.23794323205947876,
            -1.8894710540771484,
            -1.0342808961868286,
            0.6811707019805908,
            -0.25352370738983154,
            0.7354607582092285
          ],
          "order_indices": [
            1,
            8,
            6,
            2,
            3,
            7,
            0,
            5,
            4
          ],
          "order_filenames": [
            "test_102_1.jpg",
            "test_102_8.jpg",
            "test_102_6.jpg",
            "test_102_2.jpg",
            "test_102_3.jpg",
            "test_102_7.jpg",
            "test_102_0.jpg",
            "test_102_5.jpg",
            "test_102_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.4833333333333334,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 103,
      "prompt": "A photo of a mechanical angel woman with crystal wings, in the sci-fi style of Stefan Kostic, created by Stanley Lau and Artgerm.",
      "image_filenames": [
        "test_103_0.jpg",
        "test_103_1.jpg",
        "test_103_2.jpg",
        "test_103_3.jpg",
        "test_103_4.jpg",
        "test_103_5.jpg",
        "test_103_6.jpg",
        "test_103_7.jpg",
        "test_103_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          1,
          2,
          4,
          0,
          6,
          7,
          8,
          3
        ],
        "order_filenames": [
          "test_103_5.jpg",
          "test_103_1.jpg",
          "test_103_2.jpg",
          "test_103_4.jpg",
          "test_103_0.jpg",
          "test_103_6.jpg",
          "test_103_7.jpg",
          "test_103_8.jpg",
          "test_103_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_103_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_103_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1,
            5
          ],
          "winner_filenames": [
            "test_103_1.jpg",
            "test_103_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2342529296875,
            0.3125,
            0.27099609375,
            0.197998046875,
            0.1875,
            0.127685546875,
            0.262939453125,
            0.25927734375,
            0.2467041015625
          ],
          "order_indices": [
            1,
            2,
            6,
            7,
            8,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_103_1.jpg",
            "test_103_2.jpg",
            "test_103_6.jpg",
            "test_103_7.jpg",
            "test_103_8.jpg",
            "test_103_0.jpg",
            "test_103_3.jpg",
            "test_103_4.jpg",
            "test_103_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.050000000000000044,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.6875,
            34.09375,
            40.375,
            30.46875,
            25.046875,
            19.90625,
            40.3125,
            41.90625,
            37.5625
          ],
          "order_indices": [
            7,
            2,
            6,
            8,
            0,
            1,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_103_7.jpg",
            "test_103_2.jpg",
            "test_103_6.jpg",
            "test_103_8.jpg",
            "test_103_0.jpg",
            "test_103_1.jpg",
            "test_103_3.jpg",
            "test_103_4.jpg",
            "test_103_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.3500000000000001,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.5925259590148926,
            1.399114966392517,
            0.5954381227493286,
            -0.27051934599876404,
            0.46723514795303345,
            -1.3908189535140991,
            1.4844132661819458,
            0.061264362186193466,
            1.7532222270965576
          ],
          "order_indices": [
            8,
            0,
            6,
            1,
            2,
            4,
            7,
            3,
            5
          ],
          "order_filenames": [
            "test_103_8.jpg",
            "test_103_0.jpg",
            "test_103_6.jpg",
            "test_103_1.jpg",
            "test_103_2.jpg",
            "test_103_4.jpg",
            "test_103_7.jpg",
            "test_103_3.jpg",
            "test_103_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.19999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 104,
      "prompt": "Anthropomorphic alien plant creature with big eyes and leafy limbs depicted in a detailed painting.",
      "image_filenames": [
        "test_104_0.jpg",
        "test_104_1.jpg",
        "test_104_2.jpg",
        "test_104_3.jpg",
        "test_104_4.jpg",
        "test_104_5.jpg",
        "test_104_6.jpg",
        "test_104_7.jpg",
        "test_104_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          8,
          4,
          5,
          3,
          6,
          2,
          7,
          1
        ],
        "order_filenames": [
          "test_104_0.jpg",
          "test_104_8.jpg",
          "test_104_4.jpg",
          "test_104_5.jpg",
          "test_104_3.jpg",
          "test_104_6.jpg",
          "test_104_2.jpg",
          "test_104_7.jpg",
          "test_104_1.jpg"
        ],
        "condorcet_winner": 0,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_104_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            8
          ],
          "winner_filenames": [
            "test_104_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_104_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.220703125,
            0.2091064453125,
            0.302490234375,
            0.1676025390625,
            0.2147216796875,
            0.1669921875,
            0.2255859375,
            0.2178955078125,
            0.261474609375
          ],
          "order_indices": [
            2,
            8,
            6,
            0,
            7,
            4,
            1,
            3,
            5
          ],
          "order_filenames": [
            "test_104_2.jpg",
            "test_104_8.jpg",
            "test_104_6.jpg",
            "test_104_0.jpg",
            "test_104_7.jpg",
            "test_104_4.jpg",
            "test_104_1.jpg",
            "test_104_3.jpg",
            "test_104_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.08333333333333337,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.9375,
            38.0625,
            46.5,
            31.328125,
            29.34375,
            33.09375,
            43.0,
            40.28125,
            34.8125
          ],
          "order_indices": [
            2,
            6,
            7,
            1,
            0,
            8,
            5,
            3,
            4
          ],
          "order_filenames": [
            "test_104_2.jpg",
            "test_104_6.jpg",
            "test_104_7.jpg",
            "test_104_1.jpg",
            "test_104_0.jpg",
            "test_104_8.jpg",
            "test_104_5.jpg",
            "test_104_3.jpg",
            "test_104_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.5666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.5360056161880493,
            -0.9564835429191589,
            0.6576599478721619,
            -1.477049708366394,
            -0.03568192198872566,
            -0.826999843120575,
            -0.05077844113111496,
            1.1615787744522095,
            1.0436632633209229
          ],
          "order_indices": [
            7,
            8,
            2,
            4,
            6,
            0,
            5,
            1,
            3
          ],
          "order_filenames": [
            "test_104_7.jpg",
            "test_104_8.jpg",
            "test_104_2.jpg",
            "test_104_4.jpg",
            "test_104_6.jpg",
            "test_104_0.jpg",
            "test_104_5.jpg",
            "test_104_1.jpg",
            "test_104_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.01666666666666672,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 105,
      "prompt": "A cyber girl with demon horns holds a black feather in front of a cybercity with a gloomy expression.",
      "image_filenames": [
        "test_105_0.jpg",
        "test_105_1.jpg",
        "test_105_2.jpg",
        "test_105_3.jpg",
        "test_105_4.jpg",
        "test_105_5.jpg",
        "test_105_6.jpg",
        "test_105_7.jpg",
        "test_105_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          2,
          1,
          6,
          4,
          7,
          3,
          8,
          0
        ],
        "order_filenames": [
          "test_105_5.jpg",
          "test_105_2.jpg",
          "test_105_1.jpg",
          "test_105_6.jpg",
          "test_105_4.jpg",
          "test_105_7.jpg",
          "test_105_3.jpg",
          "test_105_8.jpg",
          "test_105_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_105_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6,
            7
          ],
          "winner_filenames": [
            "test_105_6.jpg",
            "test_105_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_105_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1885986328125,
            0.23828125,
            0.2861328125,
            0.196533203125,
            0.1883544921875,
            0.105224609375,
            0.26220703125,
            0.2156982421875,
            0.290771484375
          ],
          "order_indices": [
            8,
            2,
            6,
            1,
            7,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_105_8.jpg",
            "test_105_2.jpg",
            "test_105_6.jpg",
            "test_105_1.jpg",
            "test_105_7.jpg",
            "test_105_3.jpg",
            "test_105_0.jpg",
            "test_105_4.jpg",
            "test_105_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.08333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.9375,
            35.0,
            41.0,
            29.796875,
            33.1875,
            19.65625,
            37.75,
            39.4375,
            42.125
          ],
          "order_indices": [
            8,
            2,
            0,
            7,
            6,
            1,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_105_8.jpg",
            "test_105_2.jpg",
            "test_105_0.jpg",
            "test_105_7.jpg",
            "test_105_6.jpg",
            "test_105_1.jpg",
            "test_105_4.jpg",
            "test_105_3.jpg",
            "test_105_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.3999999999999999,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.5895177721977234,
            0.41295841336250305,
            1.5789141654968262,
            -0.2878396809101105,
            -0.7804921269416809,
            -2.1939611434936523,
            0.41705334186553955,
            1.153630018234253,
            0.21493808925151825
          ],
          "order_indices": [
            2,
            7,
            0,
            6,
            1,
            8,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_105_2.jpg",
            "test_105_7.jpg",
            "test_105_0.jpg",
            "test_105_6.jpg",
            "test_105_1.jpg",
            "test_105_8.jpg",
            "test_105_3.jpg",
            "test_105_4.jpg",
            "test_105_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.1166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 106,
      "prompt": "A massive and brightly colored spacecraft in a deserted landscape, depicted in retro 1960s sci-fi art.",
      "image_filenames": [
        "test_106_0.jpg",
        "test_106_1.jpg",
        "test_106_2.jpg",
        "test_106_3.jpg",
        "test_106_4.jpg",
        "test_106_5.jpg",
        "test_106_6.jpg",
        "test_106_7.jpg",
        "test_106_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          5,
          4,
          0,
          6,
          7,
          8,
          2,
          1
        ],
        "order_filenames": [
          "test_106_3.jpg",
          "test_106_5.jpg",
          "test_106_4.jpg",
          "test_106_0.jpg",
          "test_106_6.jpg",
          "test_106_7.jpg",
          "test_106_8.jpg",
          "test_106_2.jpg",
          "test_106_1.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_106_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_106_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_106_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.205810546875,
            0.18798828125,
            0.244873046875,
            0.1702880859375,
            0.2080078125,
            0.1427001953125,
            0.222900390625,
            0.2425537109375,
            0.2384033203125
          ],
          "order_indices": [
            2,
            7,
            8,
            6,
            4,
            0,
            1,
            3,
            5
          ],
          "order_filenames": [
            "test_106_2.jpg",
            "test_106_7.jpg",
            "test_106_8.jpg",
            "test_106_6.jpg",
            "test_106_4.jpg",
            "test_106_0.jpg",
            "test_106_1.jpg",
            "test_106_3.jpg",
            "test_106_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.6000000000000001,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.96875,
            38.125,
            37.84375,
            31.375,
            26.328125,
            29.109375,
            40.40625,
            41.9375,
            40.1875
          ],
          "order_indices": [
            7,
            6,
            8,
            1,
            2,
            0,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_106_7.jpg",
            "test_106_6.jpg",
            "test_106_8.jpg",
            "test_106_1.jpg",
            "test_106_2.jpg",
            "test_106_0.jpg",
            "test_106_3.jpg",
            "test_106_5.jpg",
            "test_106_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.6333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.7445138692855835,
            -0.4592258632183075,
            0.4832414388656616,
            -0.6686764359474182,
            -1.0219053030014038,
            -1.738672137260437,
            0.12572938203811646,
            -0.10736283659934998,
            0.7313253879547119
          ],
          "order_indices": [
            8,
            2,
            6,
            7,
            1,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_106_8.jpg",
            "test_106_2.jpg",
            "test_106_6.jpg",
            "test_106_7.jpg",
            "test_106_1.jpg",
            "test_106_3.jpg",
            "test_106_0.jpg",
            "test_106_4.jpg",
            "test_106_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.7,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 107,
      "prompt": "A photorealistic image from a furry fandom convention set in a biopunk era after the genetic revolution and quantum singularity.",
      "image_filenames": [
        "test_107_0.jpg",
        "test_107_1.jpg",
        "test_107_2.jpg",
        "test_107_3.jpg",
        "test_107_4.jpg",
        "test_107_5.jpg",
        "test_107_6.jpg",
        "test_107_7.jpg",
        "test_107_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          4,
          5,
          6,
          8,
          7,
          0,
          2,
          1
        ],
        "order_filenames": [
          "test_107_3.jpg",
          "test_107_4.jpg",
          "test_107_5.jpg",
          "test_107_6.jpg",
          "test_107_8.jpg",
          "test_107_7.jpg",
          "test_107_0.jpg",
          "test_107_2.jpg",
          "test_107_1.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_107_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3,
            5
          ],
          "winner_filenames": [
            "test_107_3.jpg",
            "test_107_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3,
            4
          ],
          "winner_filenames": [
            "test_107_3.jpg",
            "test_107_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2003173828125,
            0.2135009765625,
            0.2332763671875,
            0.21533203125,
            0.18994140625,
            0.1148681640625,
            0.2315673828125,
            0.242431640625,
            0.26611328125
          ],
          "order_indices": [
            8,
            7,
            2,
            6,
            3,
            1,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_107_8.jpg",
            "test_107_7.jpg",
            "test_107_2.jpg",
            "test_107_6.jpg",
            "test_107_3.jpg",
            "test_107_1.jpg",
            "test_107_0.jpg",
            "test_107_4.jpg",
            "test_107_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.28333333333333344,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.5,
            27.59375,
            49.875,
            27.171875,
            32.59375,
            10.3671875,
            45.90625,
            45.65625,
            37.375
          ],
          "order_indices": [
            2,
            6,
            7,
            0,
            8,
            4,
            1,
            3,
            5
          ],
          "order_filenames": [
            "test_107_2.jpg",
            "test_107_6.jpg",
            "test_107_7.jpg",
            "test_107_0.jpg",
            "test_107_8.jpg",
            "test_107_4.jpg",
            "test_107_1.jpg",
            "test_107_3.jpg",
            "test_107_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.46666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.20800545811653137,
            -0.43820250034332275,
            0.5546048283576965,
            -0.03708544373512268,
            -0.32607120275497437,
            -1.7948271036148071,
            0.4767019748687744,
            1.1101658344268799,
            -0.06805821508169174
          ],
          "order_indices": [
            7,
            2,
            6,
            3,
            8,
            0,
            4,
            1,
            5
          ],
          "order_filenames": [
            "test_107_7.jpg",
            "test_107_2.jpg",
            "test_107_6.jpg",
            "test_107_3.jpg",
            "test_107_8.jpg",
            "test_107_0.jpg",
            "test_107_4.jpg",
            "test_107_1.jpg",
            "test_107_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.1166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 108,
      "prompt": "Gillian Anderson in a science fiction film directed by John Carpenter.",
      "image_filenames": [
        "test_108_0.jpg",
        "test_108_1.jpg",
        "test_108_2.jpg",
        "test_108_3.jpg",
        "test_108_4.jpg",
        "test_108_5.jpg",
        "test_108_6.jpg",
        "test_108_7.jpg",
        "test_108_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          0,
          1,
          6,
          4,
          2,
          7,
          8,
          3
        ],
        "order_filenames": [
          "test_108_5.jpg",
          "test_108_0.jpg",
          "test_108_1.jpg",
          "test_108_6.jpg",
          "test_108_4.jpg",
          "test_108_2.jpg",
          "test_108_7.jpg",
          "test_108_8.jpg",
          "test_108_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_108_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_108_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_108_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1739501953125,
            0.292724609375,
            0.246337890625,
            0.1439208984375,
            0.1268310546875,
            0.09759521484375,
            0.30419921875,
            0.2431640625,
            0.2196044921875
          ],
          "order_indices": [
            6,
            1,
            2,
            7,
            8,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_108_6.jpg",
            "test_108_1.jpg",
            "test_108_2.jpg",
            "test_108_7.jpg",
            "test_108_8.jpg",
            "test_108_0.jpg",
            "test_108_3.jpg",
            "test_108_4.jpg",
            "test_108_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.08333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.21875,
            33.34375,
            39.84375,
            11.7109375,
            19.140625,
            6.2109375,
            35.90625,
            38.71875,
            30.796875
          ],
          "order_indices": [
            2,
            7,
            0,
            6,
            1,
            8,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_108_2.jpg",
            "test_108_7.jpg",
            "test_108_0.jpg",
            "test_108_6.jpg",
            "test_108_1.jpg",
            "test_108_8.jpg",
            "test_108_4.jpg",
            "test_108_3.jpg",
            "test_108_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.03464115783572197,
            0.4005977213382721,
            0.0015520957531407475,
            -1.603519082069397,
            -1.6511412858963013,
            -2.2799699306488037,
            0.980548620223999,
            -0.2445128709077835,
            -0.6075895428657532
          ],
          "order_indices": [
            6,
            1,
            0,
            2,
            7,
            8,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_108_6.jpg",
            "test_108_1.jpg",
            "test_108_0.jpg",
            "test_108_2.jpg",
            "test_108_7.jpg",
            "test_108_8.jpg",
            "test_108_3.jpg",
            "test_108_4.jpg",
            "test_108_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.16666666666666663,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 109,
      "prompt": "The image depicts a muscular blonde butch tomboy engineer wearing a patched flight suit, set in a detailed sci-fi environment with cinematic lighting and crepuscular rays.",
      "image_filenames": [
        "test_109_0.jpg",
        "test_109_1.jpg",
        "test_109_2.jpg",
        "test_109_3.jpg",
        "test_109_4.jpg",
        "test_109_5.jpg",
        "test_109_6.jpg",
        "test_109_7.jpg",
        "test_109_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          3,
          4,
          6,
          5,
          7,
          8,
          1,
          0
        ],
        "order_filenames": [
          "test_109_2.jpg",
          "test_109_3.jpg",
          "test_109_4.jpg",
          "test_109_6.jpg",
          "test_109_5.jpg",
          "test_109_7.jpg",
          "test_109_8.jpg",
          "test_109_1.jpg",
          "test_109_0.jpg"
        ],
        "condorcet_winner": 2,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_109_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_109_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_109_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.20458984375,
            0.228271484375,
            0.2529296875,
            0.1939697265625,
            0.15283203125,
            0.11907958984375,
            0.265869140625,
            0.19140625,
            0.277099609375
          ],
          "order_indices": [
            8,
            6,
            2,
            1,
            0,
            3,
            7,
            4,
            5
          ],
          "order_filenames": [
            "test_109_8.jpg",
            "test_109_6.jpg",
            "test_109_2.jpg",
            "test_109_1.jpg",
            "test_109_0.jpg",
            "test_109_3.jpg",
            "test_109_7.jpg",
            "test_109_4.jpg",
            "test_109_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.1166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            49.53125,
            37.71875,
            37.71875,
            28.8125,
            27.53125,
            19.921875,
            37.65625,
            41.59375,
            42.15625
          ],
          "order_indices": [
            0,
            8,
            7,
            1,
            2,
            6,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_109_0.jpg",
            "test_109_8.jpg",
            "test_109_7.jpg",
            "test_109_1.jpg",
            "test_109_2.jpg",
            "test_109_6.jpg",
            "test_109_3.jpg",
            "test_109_4.jpg",
            "test_109_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.6666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.5908244848251343,
            0.7531880140304565,
            -0.8448020815849304,
            -1.640668511390686,
            -1.708296775817871,
            -2.238405466079712,
            0.47880905866622925,
            -0.3180016875267029,
            1.2174551486968994
          ],
          "order_indices": [
            8,
            1,
            0,
            6,
            7,
            2,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_109_8.jpg",
            "test_109_1.jpg",
            "test_109_0.jpg",
            "test_109_6.jpg",
            "test_109_7.jpg",
            "test_109_2.jpg",
            "test_109_3.jpg",
            "test_109_4.jpg",
            "test_109_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.6666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 110,
      "prompt": "A digital art image of a detailed surreal alien biomechanical temple interior by Giger.",
      "image_filenames": [
        "test_110_0.jpg",
        "test_110_1.jpg",
        "test_110_2.jpg",
        "test_110_3.jpg",
        "test_110_4.jpg",
        "test_110_5.jpg",
        "test_110_6.jpg",
        "test_110_7.jpg",
        "test_110_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          2,
          1,
          0,
          4,
          5,
          6,
          8,
          7
        ],
        "order_filenames": [
          "test_110_3.jpg",
          "test_110_2.jpg",
          "test_110_1.jpg",
          "test_110_0.jpg",
          "test_110_4.jpg",
          "test_110_5.jpg",
          "test_110_6.jpg",
          "test_110_8.jpg",
          "test_110_7.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_110_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_110_3.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_110_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2305908203125,
            0.2447509765625,
            0.24365234375,
            0.1943359375,
            0.1790771484375,
            0.2078857421875,
            0.2225341796875,
            0.2437744140625,
            0.19970703125
          ],
          "order_indices": [
            1,
            7,
            2,
            0,
            6,
            5,
            8,
            3,
            4
          ],
          "order_filenames": [
            "test_110_1.jpg",
            "test_110_7.jpg",
            "test_110_2.jpg",
            "test_110_0.jpg",
            "test_110_6.jpg",
            "test_110_5.jpg",
            "test_110_8.jpg",
            "test_110_3.jpg",
            "test_110_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.03333333333333344,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            42.09375,
            38.21875,
            40.9375,
            39.75,
            34.6875,
            31.921875,
            40.3125,
            38.1875,
            33.9375
          ],
          "order_indices": [
            0,
            2,
            6,
            3,
            1,
            7,
            4,
            8,
            5
          ],
          "order_filenames": [
            "test_110_0.jpg",
            "test_110_2.jpg",
            "test_110_6.jpg",
            "test_110_3.jpg",
            "test_110_1.jpg",
            "test_110_7.jpg",
            "test_110_4.jpg",
            "test_110_8.jpg",
            "test_110_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.5,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.5288310050964355,
            -0.20098446309566498,
            -0.12709182500839233,
            -0.4596676826477051,
            -0.2191038876771927,
            -0.23999929428100586,
            -0.016554394736886024,
            -0.09146658331155777,
            -0.9421961903572083
          ],
          "order_indices": [
            0,
            6,
            7,
            2,
            1,
            4,
            5,
            3,
            8
          ],
          "order_filenames": [
            "test_110_0.jpg",
            "test_110_6.jpg",
            "test_110_7.jpg",
            "test_110_2.jpg",
            "test_110_1.jpg",
            "test_110_4.jpg",
            "test_110_5.jpg",
            "test_110_3.jpg",
            "test_110_8.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.08333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 111,
      "prompt": "A key visual of a young female swat officer with a neon futuristic gas mask in a cyberpunk setting.",
      "image_filenames": [
        "test_111_0.jpg",
        "test_111_1.jpg",
        "test_111_2.jpg",
        "test_111_3.jpg",
        "test_111_4.jpg",
        "test_111_5.jpg",
        "test_111_6.jpg",
        "test_111_7.jpg",
        "test_111_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          0,
          1,
          6,
          2,
          8,
          7,
          4,
          3
        ],
        "order_filenames": [
          "test_111_5.jpg",
          "test_111_0.jpg",
          "test_111_1.jpg",
          "test_111_6.jpg",
          "test_111_2.jpg",
          "test_111_8.jpg",
          "test_111_7.jpg",
          "test_111_4.jpg",
          "test_111_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_111_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_111_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_111_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1673583984375,
            0.2352294921875,
            0.263916015625,
            0.2071533203125,
            0.16064453125,
            0.1060791015625,
            0.248291015625,
            0.21337890625,
            0.2119140625
          ],
          "order_indices": [
            2,
            6,
            1,
            7,
            8,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_111_2.jpg",
            "test_111_6.jpg",
            "test_111_1.jpg",
            "test_111_7.jpg",
            "test_111_8.jpg",
            "test_111_3.jpg",
            "test_111_0.jpg",
            "test_111_4.jpg",
            "test_111_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.40625,
            35.625,
            43.34375,
            32.53125,
            26.53125,
            18.234375,
            30.4375,
            34.84375,
            34.8125
          ],
          "order_indices": [
            2,
            1,
            7,
            8,
            0,
            3,
            6,
            4,
            5
          ],
          "order_filenames": [
            "test_111_2.jpg",
            "test_111_1.jpg",
            "test_111_7.jpg",
            "test_111_8.jpg",
            "test_111_0.jpg",
            "test_111_3.jpg",
            "test_111_6.jpg",
            "test_111_4.jpg",
            "test_111_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.17969702184200287,
            -0.4496845006942749,
            0.39606013894081116,
            0.2803371548652649,
            -1.0612208843231201,
            -2.1489017009735107,
            -0.348982572555542,
            -0.21910417079925537,
            -0.4693935811519623
          ],
          "order_indices": [
            2,
            3,
            0,
            7,
            6,
            1,
            8,
            4,
            5
          ],
          "order_filenames": [
            "test_111_2.jpg",
            "test_111_3.jpg",
            "test_111_0.jpg",
            "test_111_7.jpg",
            "test_111_6.jpg",
            "test_111_1.jpg",
            "test_111_8.jpg",
            "test_111_4.jpg",
            "test_111_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.25,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 112,
      "prompt": "A person wearing a lab coat holding a green apple and standing in front of a whiteboard filled with equations and diagrams.",
      "image_filenames": [
        "test_112_0.jpg",
        "test_112_1.jpg",
        "test_112_2.jpg",
        "test_112_3.jpg",
        "test_112_4.jpg",
        "test_112_5.jpg",
        "test_112_6.jpg",
        "test_112_7.jpg",
        "test_112_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          4,
          5,
          6,
          2,
          1,
          0,
          8,
          7
        ],
        "order_filenames": [
          "test_112_3.jpg",
          "test_112_4.jpg",
          "test_112_5.jpg",
          "test_112_6.jpg",
          "test_112_2.jpg",
          "test_112_1.jpg",
          "test_112_0.jpg",
          "test_112_8.jpg",
          "test_112_7.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_112_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_112_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_112_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1790771484375,
            0.251220703125,
            0.29833984375,
            0.1671142578125,
            0.163330078125,
            0.0828857421875,
            0.21923828125,
            0.1688232421875,
            0.271240234375
          ],
          "order_indices": [
            2,
            8,
            1,
            6,
            0,
            7,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_112_2.jpg",
            "test_112_8.jpg",
            "test_112_1.jpg",
            "test_112_6.jpg",
            "test_112_0.jpg",
            "test_112_7.jpg",
            "test_112_3.jpg",
            "test_112_4.jpg",
            "test_112_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.5166666666666666,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.96875,
            39.5625,
            41.71875,
            28.296875,
            26.671875,
            19.109375,
            37.90625,
            30.578125,
            41.90625
          ],
          "order_indices": [
            8,
            2,
            0,
            1,
            6,
            7,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_112_8.jpg",
            "test_112_2.jpg",
            "test_112_0.jpg",
            "test_112_1.jpg",
            "test_112_6.jpg",
            "test_112_7.jpg",
            "test_112_3.jpg",
            "test_112_4.jpg",
            "test_112_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.6333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.8268933296203613,
            -1.4303327798843384,
            1.9241771697998047,
            -2.0072834491729736,
            -1.0722235441207886,
            -2.2823023796081543,
            1.001356840133667,
            -0.1123877465724945,
            1.8743716478347778
          ],
          "order_indices": [
            2,
            8,
            0,
            6,
            7,
            4,
            1,
            3,
            5
          ],
          "order_filenames": [
            "test_112_2.jpg",
            "test_112_8.jpg",
            "test_112_0.jpg",
            "test_112_6.jpg",
            "test_112_7.jpg",
            "test_112_4.jpg",
            "test_112_1.jpg",
            "test_112_3.jpg",
            "test_112_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.55,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 113,
      "prompt": "Scene from the 1931 science fiction film \"Escape from New York.\"",
      "image_filenames": [
        "test_113_0.jpg",
        "test_113_1.jpg",
        "test_113_2.jpg",
        "test_113_3.jpg",
        "test_113_4.jpg",
        "test_113_5.jpg",
        "test_113_6.jpg",
        "test_113_7.jpg",
        "test_113_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          7,
          5,
          2,
          0,
          1,
          8,
          6,
          3
        ],
        "order_filenames": [
          "test_113_4.jpg",
          "test_113_7.jpg",
          "test_113_5.jpg",
          "test_113_2.jpg",
          "test_113_0.jpg",
          "test_113_1.jpg",
          "test_113_8.jpg",
          "test_113_6.jpg",
          "test_113_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_113_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4,
            7
          ],
          "winner_filenames": [
            "test_113_4.jpg",
            "test_113_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_113_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.165283203125,
            0.1943359375,
            0.209228515625,
            0.1529541015625,
            0.1507568359375,
            0.1507568359375,
            0.2139892578125,
            0.1773681640625,
            0.16748046875
          ],
          "order_indices": [
            6,
            2,
            1,
            7,
            8,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_113_6.jpg",
            "test_113_2.jpg",
            "test_113_1.jpg",
            "test_113_7.jpg",
            "test_113_8.jpg",
            "test_113_0.jpg",
            "test_113_3.jpg",
            "test_113_4.jpg",
            "test_113_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.33333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            30.890625,
            32.78125,
            36.25,
            32.28125,
            23.578125,
            24.671875,
            32.125,
            36.65625,
            29.21875
          ],
          "order_indices": [
            7,
            2,
            1,
            3,
            6,
            0,
            8,
            5,
            4
          ],
          "order_filenames": [
            "test_113_7.jpg",
            "test_113_2.jpg",
            "test_113_1.jpg",
            "test_113_3.jpg",
            "test_113_6.jpg",
            "test_113_0.jpg",
            "test_113_8.jpg",
            "test_113_5.jpg",
            "test_113_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.1499999999999999,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.645736038684845,
            -0.3911954164505005,
            -0.16085892915725708,
            -0.4969593286514282,
            -1.3271980285644531,
            -0.9055776000022888,
            -0.6076304912567139,
            0.47537851333618164,
            -0.7753224968910217
          ],
          "order_indices": [
            7,
            2,
            1,
            3,
            6,
            0,
            8,
            5,
            4
          ],
          "order_filenames": [
            "test_113_7.jpg",
            "test_113_2.jpg",
            "test_113_1.jpg",
            "test_113_3.jpg",
            "test_113_6.jpg",
            "test_113_0.jpg",
            "test_113_8.jpg",
            "test_113_5.jpg",
            "test_113_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.1499999999999999,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 114,
      "prompt": "Sandman wearing black clothing, in a sci-fi themed digital painting by Greg Rutkowski.",
      "image_filenames": [
        "test_114_0.jpg",
        "test_114_1.jpg",
        "test_114_2.jpg",
        "test_114_3.jpg",
        "test_114_4.jpg",
        "test_114_5.jpg",
        "test_114_6.jpg",
        "test_114_7.jpg",
        "test_114_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          1,
          5,
          3,
          4,
          6,
          7,
          8,
          0
        ],
        "order_filenames": [
          "test_114_2.jpg",
          "test_114_1.jpg",
          "test_114_5.jpg",
          "test_114_3.jpg",
          "test_114_4.jpg",
          "test_114_6.jpg",
          "test_114_7.jpg",
          "test_114_8.jpg",
          "test_114_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_114_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_114_2.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_114_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.203125,
            0.1689453125,
            0.229248046875,
            0.16748046875,
            0.1707763671875,
            0.11907958984375,
            0.1669921875,
            0.2171630859375,
            0.219482421875
          ],
          "order_indices": [
            2,
            8,
            7,
            0,
            4,
            1,
            3,
            6,
            5
          ],
          "order_filenames": [
            "test_114_2.jpg",
            "test_114_8.jpg",
            "test_114_7.jpg",
            "test_114_0.jpg",
            "test_114_4.jpg",
            "test_114_1.jpg",
            "test_114_3.jpg",
            "test_114_6.jpg",
            "test_114_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.18333333333333335,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.96875,
            35.96875,
            40.5625,
            36.3125,
            30.0625,
            15.4765625,
            26.546875,
            44.71875,
            28.96875
          ],
          "order_indices": [
            7,
            2,
            0,
            3,
            1,
            4,
            8,
            6,
            5
          ],
          "order_filenames": [
            "test_114_7.jpg",
            "test_114_2.jpg",
            "test_114_0.jpg",
            "test_114_3.jpg",
            "test_114_1.jpg",
            "test_114_4.jpg",
            "test_114_8.jpg",
            "test_114_6.jpg",
            "test_114_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.03333333333333344,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.06061718985438347,
            0.28053411841392517,
            0.5741623044013977,
            0.24750706553459167,
            -0.6036993861198425,
            -2.2178308963775635,
            -0.9729273915290833,
            1.2094146013259888,
            0.955082356929779
          ],
          "order_indices": [
            7,
            8,
            2,
            1,
            3,
            0,
            4,
            6,
            5
          ],
          "order_filenames": [
            "test_114_7.jpg",
            "test_114_8.jpg",
            "test_114_2.jpg",
            "test_114_1.jpg",
            "test_114_3.jpg",
            "test_114_0.jpg",
            "test_114_4.jpg",
            "test_114_6.jpg",
            "test_114_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.1166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 115,
      "prompt": "A man watches an old TV while toxic slime and debris pour from the cracked steampunk ceiling into a glowing, neon-lit room.",
      "image_filenames": [
        "test_115_0.jpg",
        "test_115_1.jpg",
        "test_115_2.jpg",
        "test_115_3.jpg",
        "test_115_4.jpg",
        "test_115_5.jpg",
        "test_115_6.jpg",
        "test_115_7.jpg",
        "test_115_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          4,
          3,
          6,
          1,
          5,
          7,
          8,
          0
        ],
        "order_filenames": [
          "test_115_2.jpg",
          "test_115_4.jpg",
          "test_115_3.jpg",
          "test_115_6.jpg",
          "test_115_1.jpg",
          "test_115_5.jpg",
          "test_115_7.jpg",
          "test_115_8.jpg",
          "test_115_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_115_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4,
            5
          ],
          "winner_filenames": [
            "test_115_4.jpg",
            "test_115_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2,
            4
          ],
          "winner_filenames": [
            "test_115_2.jpg",
            "test_115_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.201171875,
            0.2298583984375,
            0.271728515625,
            0.1448974609375,
            0.2469482421875,
            0.120361328125,
            0.25634765625,
            0.2425537109375,
            0.283203125
          ],
          "order_indices": [
            8,
            2,
            6,
            4,
            7,
            1,
            0,
            3,
            5
          ],
          "order_filenames": [
            "test_115_8.jpg",
            "test_115_2.jpg",
            "test_115_6.jpg",
            "test_115_4.jpg",
            "test_115_7.jpg",
            "test_115_1.jpg",
            "test_115_0.jpg",
            "test_115_3.jpg",
            "test_115_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.5625,
            37.0,
            41.125,
            33.125,
            39.71875,
            27.484375,
            40.75,
            46.84375,
            42.78125
          ],
          "order_indices": [
            7,
            8,
            2,
            6,
            4,
            0,
            1,
            3,
            5
          ],
          "order_filenames": [
            "test_115_7.jpg",
            "test_115_8.jpg",
            "test_115_2.jpg",
            "test_115_6.jpg",
            "test_115_4.jpg",
            "test_115_0.jpg",
            "test_115_1.jpg",
            "test_115_3.jpg",
            "test_115_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.10000000000000009,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.3160695731639862,
            0.18976619839668274,
            -0.41915541887283325,
            -0.8893411755561829,
            1.074642300605774,
            -1.8750206232070923,
            0.6246230602264404,
            0.7651742696762085,
            0.4542624354362488
          ],
          "order_indices": [
            4,
            7,
            6,
            8,
            0,
            1,
            2,
            3,
            5
          ],
          "order_filenames": [
            "test_115_4.jpg",
            "test_115_7.jpg",
            "test_115_6.jpg",
            "test_115_8.jpg",
            "test_115_0.jpg",
            "test_115_1.jpg",
            "test_115_2.jpg",
            "test_115_3.jpg",
            "test_115_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.08333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 116,
      "prompt": "A jellyfish sleeping in a space station pod.",
      "image_filenames": [
        "test_116_0.jpg",
        "test_116_1.jpg",
        "test_116_2.jpg",
        "test_116_3.jpg",
        "test_116_4.jpg",
        "test_116_5.jpg",
        "test_116_6.jpg",
        "test_116_7.jpg",
        "test_116_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          4,
          1,
          5,
          3,
          8,
          2,
          7,
          6
        ],
        "order_filenames": [
          "test_116_0.jpg",
          "test_116_4.jpg",
          "test_116_1.jpg",
          "test_116_5.jpg",
          "test_116_3.jpg",
          "test_116_8.jpg",
          "test_116_2.jpg",
          "test_116_7.jpg",
          "test_116_6.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_116_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_116_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0,
            4
          ],
          "winner_filenames": [
            "test_116_0.jpg",
            "test_116_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.224609375,
            0.299560546875,
            0.264404296875,
            0.2313232421875,
            0.2161865234375,
            0.2012939453125,
            0.2418212890625,
            0.270263671875,
            0.20703125
          ],
          "order_indices": [
            1,
            7,
            2,
            6,
            3,
            0,
            4,
            8,
            5
          ],
          "order_filenames": [
            "test_116_1.jpg",
            "test_116_7.jpg",
            "test_116_2.jpg",
            "test_116_6.jpg",
            "test_116_3.jpg",
            "test_116_0.jpg",
            "test_116_4.jpg",
            "test_116_8.jpg",
            "test_116_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.33333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            33.90625,
            38.96875,
            43.28125,
            36.03125,
            34.15625,
            33.84375,
            33.40625,
            42.84375,
            35.5625
          ],
          "order_indices": [
            2,
            7,
            1,
            3,
            8,
            4,
            0,
            5,
            6
          ],
          "order_filenames": [
            "test_116_2.jpg",
            "test_116_7.jpg",
            "test_116_1.jpg",
            "test_116_3.jpg",
            "test_116_8.jpg",
            "test_116_4.jpg",
            "test_116_0.jpg",
            "test_116_5.jpg",
            "test_116_6.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.8861197233200073,
            0.2888629734516144,
            0.1206861138343811,
            -1.9143450260162354,
            -0.9441243410110474,
            -0.9774167537689209,
            -1.1561570167541504,
            -0.12124013155698776,
            -1.3060705661773682
          ],
          "order_indices": [
            1,
            2,
            7,
            0,
            4,
            5,
            6,
            8,
            3
          ],
          "order_filenames": [
            "test_116_1.jpg",
            "test_116_2.jpg",
            "test_116_7.jpg",
            "test_116_0.jpg",
            "test_116_4.jpg",
            "test_116_5.jpg",
            "test_116_6.jpg",
            "test_116_8.jpg",
            "test_116_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.16666666666666663,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 117,
      "prompt": "Dr. Pepper floating in space, viewed through the window of a spaceship.",
      "image_filenames": [
        "test_117_0.jpg",
        "test_117_1.jpg",
        "test_117_2.jpg",
        "test_117_3.jpg",
        "test_117_4.jpg",
        "test_117_5.jpg",
        "test_117_6.jpg",
        "test_117_7.jpg",
        "test_117_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          8,
          1,
          3,
          6,
          0,
          7,
          2,
          4,
          5
        ],
        "order_filenames": [
          "test_117_8.jpg",
          "test_117_1.jpg",
          "test_117_3.jpg",
          "test_117_6.jpg",
          "test_117_0.jpg",
          "test_117_7.jpg",
          "test_117_2.jpg",
          "test_117_4.jpg",
          "test_117_5.jpg"
        ],
        "condorcet_winner": 8,
        "winner_indices": [
          8
        ],
        "winner_filenames": [
          "test_117_8.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            8
          ],
          "winner_filenames": [
            "test_117_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            8
          ],
          "winner_filenames": [
            "test_117_8.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.185546875,
            0.264404296875,
            0.2490234375,
            0.185302734375,
            0.1925048828125,
            0.1392822265625,
            0.2215576171875,
            0.2254638671875,
            0.237548828125
          ],
          "order_indices": [
            1,
            2,
            8,
            7,
            6,
            4,
            0,
            3,
            5
          ],
          "order_filenames": [
            "test_117_1.jpg",
            "test_117_2.jpg",
            "test_117_8.jpg",
            "test_117_7.jpg",
            "test_117_6.jpg",
            "test_117_4.jpg",
            "test_117_0.jpg",
            "test_117_3.jpg",
            "test_117_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2777777777777778,
            "spearman_rho": 0.43333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            33.125,
            41.5625,
            32.875,
            23.875,
            34.59375,
            31.671875,
            39.0,
            52.59375,
            40.09375
          ],
          "order_indices": [
            7,
            1,
            8,
            6,
            4,
            0,
            2,
            5,
            3
          ],
          "order_filenames": [
            "test_117_7.jpg",
            "test_117_1.jpg",
            "test_117_8.jpg",
            "test_117_6.jpg",
            "test_117_4.jpg",
            "test_117_0.jpg",
            "test_117_2.jpg",
            "test_117_5.jpg",
            "test_117_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2777777777777778,
            "spearman_rho": 0.3666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.5794317722320557,
            0.2805878520011902,
            -0.470887690782547,
            -2.0213773250579834,
            -1.954323410987854,
            -2.194371223449707,
            -1.3467766046524048,
            -0.12200713902711868,
            -1.9021046161651611
          ],
          "order_indices": [
            1,
            7,
            2,
            6,
            0,
            8,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_117_1.jpg",
            "test_117_7.jpg",
            "test_117_2.jpg",
            "test_117_6.jpg",
            "test_117_0.jpg",
            "test_117_8.jpg",
            "test_117_4.jpg",
            "test_117_3.jpg",
            "test_117_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.30000000000000004,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 118,
      "prompt": "Alien abduction depicted in a blurry, old polaroid with lost and later found footage.",
      "image_filenames": [
        "test_118_0.jpg",
        "test_118_1.jpg",
        "test_118_2.jpg",
        "test_118_3.jpg",
        "test_118_4.jpg",
        "test_118_5.jpg",
        "test_118_6.jpg",
        "test_118_7.jpg",
        "test_118_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          3,
          5,
          1,
          6,
          7,
          2,
          8,
          0
        ],
        "order_filenames": [
          "test_118_4.jpg",
          "test_118_3.jpg",
          "test_118_5.jpg",
          "test_118_1.jpg",
          "test_118_6.jpg",
          "test_118_7.jpg",
          "test_118_2.jpg",
          "test_118_8.jpg",
          "test_118_0.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_118_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3,
            4
          ],
          "winner_filenames": [
            "test_118_3.jpg",
            "test_118_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_118_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2015380859375,
            0.2177734375,
            0.1810302734375,
            0.1923828125,
            0.18896484375,
            0.1756591796875,
            0.187744140625,
            0.2225341796875,
            0.18701171875
          ],
          "order_indices": [
            7,
            1,
            0,
            3,
            4,
            6,
            8,
            2,
            5
          ],
          "order_filenames": [
            "test_118_7.jpg",
            "test_118_1.jpg",
            "test_118_0.jpg",
            "test_118_3.jpg",
            "test_118_4.jpg",
            "test_118_6.jpg",
            "test_118_8.jpg",
            "test_118_2.jpg",
            "test_118_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.03333333333333344,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.6875,
            34.875,
            38.6875,
            34.28125,
            27.984375,
            39.4375,
            31.71875,
            45.90625,
            37.0
          ],
          "order_indices": [
            7,
            5,
            0,
            2,
            8,
            1,
            3,
            6,
            4
          ],
          "order_filenames": [
            "test_118_7.jpg",
            "test_118_5.jpg",
            "test_118_0.jpg",
            "test_118_2.jpg",
            "test_118_8.jpg",
            "test_118_1.jpg",
            "test_118_3.jpg",
            "test_118_6.jpg",
            "test_118_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.5166666666666666,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.20315057039260864,
            -0.0976276621222496,
            0.08585942536592484,
            -0.71392422914505,
            -0.5015752911567688,
            0.7181299328804016,
            -0.10029736161231995,
            0.34743964672088623,
            -0.5115475058555603
          ],
          "order_indices": [
            5,
            7,
            2,
            1,
            6,
            0,
            4,
            8,
            3
          ],
          "order_filenames": [
            "test_118_5.jpg",
            "test_118_7.jpg",
            "test_118_2.jpg",
            "test_118_1.jpg",
            "test_118_6.jpg",
            "test_118_0.jpg",
            "test_118_4.jpg",
            "test_118_8.jpg",
            "test_118_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.08333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 119,
      "prompt": "A ginger haired mouse mechanic in blue overalls in a cyberpunk scene with neon slums in the background.",
      "image_filenames": [
        "test_119_0.jpg",
        "test_119_1.jpg",
        "test_119_2.jpg",
        "test_119_3.jpg",
        "test_119_4.jpg",
        "test_119_5.jpg",
        "test_119_6.jpg",
        "test_119_7.jpg",
        "test_119_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          4,
          6,
          2,
          5,
          8,
          7,
          0,
          1
        ],
        "order_filenames": [
          "test_119_3.jpg",
          "test_119_4.jpg",
          "test_119_6.jpg",
          "test_119_2.jpg",
          "test_119_5.jpg",
          "test_119_8.jpg",
          "test_119_7.jpg",
          "test_119_0.jpg",
          "test_119_1.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_119_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_119_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_119_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.213623046875,
            0.2266845703125,
            0.274658203125,
            0.16650390625,
            0.1993408203125,
            0.1439208984375,
            0.30078125,
            0.2178955078125,
            0.30908203125
          ],
          "order_indices": [
            8,
            6,
            2,
            1,
            7,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_119_8.jpg",
            "test_119_6.jpg",
            "test_119_2.jpg",
            "test_119_1.jpg",
            "test_119_7.jpg",
            "test_119_0.jpg",
            "test_119_4.jpg",
            "test_119_3.jpg",
            "test_119_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.25,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            42.09375,
            37.34375,
            41.09375,
            34.40625,
            33.65625,
            29.015625,
            37.09375,
            45.65625,
            39.09375
          ],
          "order_indices": [
            7,
            0,
            2,
            8,
            1,
            6,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_119_7.jpg",
            "test_119_0.jpg",
            "test_119_2.jpg",
            "test_119_8.jpg",
            "test_119_1.jpg",
            "test_119_6.jpg",
            "test_119_3.jpg",
            "test_119_4.jpg",
            "test_119_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.5833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.9519205689430237,
            0.24230718612670898,
            0.5078033804893494,
            -0.4956614375114441,
            -0.6573001742362976,
            -2.1448726654052734,
            1.6639649868011475,
            0.288685142993927,
            1.8668292760849
          ],
          "order_indices": [
            8,
            6,
            0,
            2,
            7,
            1,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_119_8.jpg",
            "test_119_6.jpg",
            "test_119_0.jpg",
            "test_119_2.jpg",
            "test_119_7.jpg",
            "test_119_1.jpg",
            "test_119_3.jpg",
            "test_119_4.jpg",
            "test_119_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.2666666666666666,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 120,
      "prompt": "The image is a symmetrical barge with a clearheaded textured fractal pattern.",
      "image_filenames": [
        "test_120_0.jpg",
        "test_120_1.jpg",
        "test_120_2.jpg",
        "test_120_3.jpg",
        "test_120_4.jpg",
        "test_120_5.jpg",
        "test_120_6.jpg",
        "test_120_7.jpg",
        "test_120_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          6,
          2,
          1,
          5,
          4,
          7,
          8,
          0
        ],
        "order_filenames": [
          "test_120_3.jpg",
          "test_120_6.jpg",
          "test_120_2.jpg",
          "test_120_1.jpg",
          "test_120_5.jpg",
          "test_120_4.jpg",
          "test_120_7.jpg",
          "test_120_8.jpg",
          "test_120_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_120_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_120_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_120_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.17626953125,
            0.2427978515625,
            0.1732177734375,
            0.17138671875,
            0.196044921875,
            0.160888671875,
            0.2060546875,
            0.214111328125,
            0.1826171875
          ],
          "order_indices": [
            1,
            7,
            6,
            4,
            8,
            0,
            2,
            3,
            5
          ],
          "order_filenames": [
            "test_120_1.jpg",
            "test_120_7.jpg",
            "test_120_6.jpg",
            "test_120_4.jpg",
            "test_120_8.jpg",
            "test_120_0.jpg",
            "test_120_2.jpg",
            "test_120_3.jpg",
            "test_120_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.1499999999999999,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.40625,
            35.21875,
            39.4375,
            31.375,
            35.40625,
            28.734375,
            30.4375,
            45.625,
            9.046875
          ],
          "order_indices": [
            7,
            2,
            4,
            1,
            0,
            3,
            6,
            5,
            8
          ],
          "order_filenames": [
            "test_120_7.jpg",
            "test_120_2.jpg",
            "test_120_4.jpg",
            "test_120_1.jpg",
            "test_120_0.jpg",
            "test_120_3.jpg",
            "test_120_6.jpg",
            "test_120_5.jpg",
            "test_120_8.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.016666666666666607,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.8865084052085876,
            0.251291960477829,
            -0.4610992968082428,
            -1.4241305589675903,
            -0.08363323658704758,
            -0.1145198792219162,
            -0.43811899423599243,
            0.4838329553604126,
            -1.0818909406661987
          ],
          "order_indices": [
            7,
            1,
            4,
            5,
            6,
            2,
            0,
            8,
            3
          ],
          "order_filenames": [
            "test_120_7.jpg",
            "test_120_1.jpg",
            "test_120_4.jpg",
            "test_120_5.jpg",
            "test_120_6.jpg",
            "test_120_2.jpg",
            "test_120_0.jpg",
            "test_120_8.jpg",
            "test_120_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.1333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 121,
      "prompt": "Looking down at a destroyed city from a plane.",
      "image_filenames": [
        "test_121_0.jpg",
        "test_121_1.jpg",
        "test_121_2.jpg",
        "test_121_3.jpg",
        "test_121_4.jpg",
        "test_121_5.jpg",
        "test_121_6.jpg",
        "test_121_7.jpg",
        "test_121_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          3,
          4,
          0,
          5,
          1,
          6,
          7,
          8
        ],
        "order_filenames": [
          "test_121_2.jpg",
          "test_121_3.jpg",
          "test_121_4.jpg",
          "test_121_0.jpg",
          "test_121_5.jpg",
          "test_121_1.jpg",
          "test_121_6.jpg",
          "test_121_7.jpg",
          "test_121_8.jpg"
        ],
        "condorcet_winner": 2,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_121_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_121_2.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_121_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2216796875,
            0.2401123046875,
            0.215576171875,
            0.2294921875,
            0.184326171875,
            0.1326904296875,
            0.2353515625,
            0.253173828125,
            0.0992431640625
          ],
          "order_indices": [
            7,
            1,
            6,
            3,
            0,
            2,
            4,
            5,
            8
          ],
          "order_filenames": [
            "test_121_7.jpg",
            "test_121_1.jpg",
            "test_121_6.jpg",
            "test_121_3.jpg",
            "test_121_0.jpg",
            "test_121_2.jpg",
            "test_121_4.jpg",
            "test_121_5.jpg",
            "test_121_8.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.1333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            33.59375,
            34.6875,
            37.65625,
            26.140625,
            26.15625,
            34.8125,
            32.96875,
            38.4375,
            -0.0657958984375
          ],
          "order_indices": [
            7,
            2,
            5,
            1,
            0,
            6,
            4,
            3,
            8
          ],
          "order_filenames": [
            "test_121_7.jpg",
            "test_121_2.jpg",
            "test_121_5.jpg",
            "test_121_1.jpg",
            "test_121_0.jpg",
            "test_121_6.jpg",
            "test_121_4.jpg",
            "test_121_3.jpg",
            "test_121_8.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.30159246921539307,
            1.0060882568359375,
            0.6285645961761475,
            -1.0114498138427734,
            -0.0411122590303421,
            -0.7177164554595947,
            0.8959804177284241,
            0.7523724436759949,
            -2.2793357372283936
          ],
          "order_indices": [
            1,
            6,
            7,
            2,
            0,
            4,
            5,
            3,
            8
          ],
          "order_filenames": [
            "test_121_1.jpg",
            "test_121_6.jpg",
            "test_121_7.jpg",
            "test_121_2.jpg",
            "test_121_0.jpg",
            "test_121_4.jpg",
            "test_121_5.jpg",
            "test_121_3.jpg",
            "test_121_8.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.1166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 122,
      "prompt": "Witches performing a ritual in a dark mall.",
      "image_filenames": [
        "test_122_0.jpg",
        "test_122_1.jpg",
        "test_122_2.jpg",
        "test_122_3.jpg",
        "test_122_4.jpg",
        "test_122_5.jpg",
        "test_122_6.jpg",
        "test_122_7.jpg",
        "test_122_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          5,
          1,
          0,
          4,
          2,
          8,
          6,
          7
        ],
        "order_filenames": [
          "test_122_3.jpg",
          "test_122_5.jpg",
          "test_122_1.jpg",
          "test_122_0.jpg",
          "test_122_4.jpg",
          "test_122_2.jpg",
          "test_122_8.jpg",
          "test_122_6.jpg",
          "test_122_7.jpg"
        ],
        "condorcet_winner": 3,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_122_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_122_3.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_122_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2113037109375,
            0.326904296875,
            0.2132568359375,
            0.2208251953125,
            0.21728515625,
            0.1646728515625,
            0.26025390625,
            0.241943359375,
            0.201416015625
          ],
          "order_indices": [
            1,
            6,
            7,
            3,
            4,
            2,
            0,
            8,
            5
          ],
          "order_filenames": [
            "test_122_1.jpg",
            "test_122_6.jpg",
            "test_122_7.jpg",
            "test_122_3.jpg",
            "test_122_4.jpg",
            "test_122_2.jpg",
            "test_122_0.jpg",
            "test_122_8.jpg",
            "test_122_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.19999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.59375,
            47.0625,
            38.0,
            33.5,
            31.375,
            24.46875,
            41.40625,
            51.03125,
            10.90625
          ],
          "order_indices": [
            7,
            1,
            6,
            0,
            2,
            3,
            4,
            5,
            8
          ],
          "order_filenames": [
            "test_122_7.jpg",
            "test_122_1.jpg",
            "test_122_6.jpg",
            "test_122_0.jpg",
            "test_122_2.jpg",
            "test_122_3.jpg",
            "test_122_4.jpg",
            "test_122_5.jpg",
            "test_122_8.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.33333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.1208382844924927,
            1.1489368677139282,
            -1.2892009019851685,
            -0.541198194026947,
            -0.6095716953277588,
            -1.5854268074035645,
            0.7128542065620422,
            1.5055921077728271,
            -2.224954605102539
          ],
          "order_indices": [
            7,
            1,
            0,
            6,
            3,
            4,
            2,
            5,
            8
          ],
          "order_filenames": [
            "test_122_7.jpg",
            "test_122_1.jpg",
            "test_122_0.jpg",
            "test_122_6.jpg",
            "test_122_3.jpg",
            "test_122_4.jpg",
            "test_122_2.jpg",
            "test_122_5.jpg",
            "test_122_8.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.16666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 123,
      "prompt": "The image depicts a concept car resembling a supercar or hypercar with a chrome reflection and global illumination.",
      "image_filenames": [
        "test_123_0.jpg",
        "test_123_1.jpg",
        "test_123_2.jpg",
        "test_123_3.jpg",
        "test_123_4.jpg",
        "test_123_5.jpg",
        "test_123_6.jpg",
        "test_123_7.jpg",
        "test_123_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          5,
          1,
          3,
          2,
          6,
          0,
          8,
          7
        ],
        "order_filenames": [
          "test_123_4.jpg",
          "test_123_5.jpg",
          "test_123_1.jpg",
          "test_123_3.jpg",
          "test_123_2.jpg",
          "test_123_6.jpg",
          "test_123_0.jpg",
          "test_123_8.jpg",
          "test_123_7.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_123_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_123_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_123_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.232177734375,
            0.2198486328125,
            0.2464599609375,
            0.1861572265625,
            0.15869140625,
            0.2286376953125,
            0.2276611328125,
            0.1845703125,
            0.2401123046875
          ],
          "order_indices": [
            2,
            8,
            0,
            5,
            6,
            1,
            3,
            7,
            4
          ],
          "order_filenames": [
            "test_123_2.jpg",
            "test_123_8.jpg",
            "test_123_0.jpg",
            "test_123_5.jpg",
            "test_123_6.jpg",
            "test_123_1.jpg",
            "test_123_3.jpg",
            "test_123_7.jpg",
            "test_123_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.30000000000000004,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.46875,
            26.078125,
            31.375,
            28.5625,
            26.4375,
            31.375,
            27.140625,
            30.609375,
            34.46875
          ],
          "order_indices": [
            0,
            8,
            2,
            5,
            7,
            3,
            6,
            4,
            1
          ],
          "order_filenames": [
            "test_123_0.jpg",
            "test_123_8.jpg",
            "test_123_2.jpg",
            "test_123_5.jpg",
            "test_123_7.jpg",
            "test_123_3.jpg",
            "test_123_6.jpg",
            "test_123_4.jpg",
            "test_123_1.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.55,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.8411034345626831,
            -0.1444953829050064,
            0.6272057294845581,
            -0.3107539713382721,
            -0.0602400004863739,
            -0.21365508437156677,
            -0.07989165186882019,
            0.04806050285696983,
            0.40809398889541626
          ],
          "order_indices": [
            0,
            2,
            8,
            7,
            4,
            6,
            1,
            5,
            3
          ],
          "order_filenames": [
            "test_123_0.jpg",
            "test_123_2.jpg",
            "test_123_8.jpg",
            "test_123_7.jpg",
            "test_123_4.jpg",
            "test_123_6.jpg",
            "test_123_1.jpg",
            "test_123_5.jpg",
            "test_123_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.5666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 124,
      "prompt": "The image is a front view of a mutant from Doom Eternal, with tubes fused to its body, and is a digital art masterpiece painted by Stanley Lau (Artgerm) and Greg Rutkowski.",
      "image_filenames": [
        "test_124_0.jpg",
        "test_124_1.jpg",
        "test_124_2.jpg",
        "test_124_3.jpg",
        "test_124_4.jpg",
        "test_124_5.jpg",
        "test_124_6.jpg",
        "test_124_7.jpg",
        "test_124_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          7,
          5,
          3,
          4,
          2,
          8,
          6,
          1
        ],
        "order_filenames": [
          "test_124_0.jpg",
          "test_124_7.jpg",
          "test_124_5.jpg",
          "test_124_3.jpg",
          "test_124_4.jpg",
          "test_124_2.jpg",
          "test_124_8.jpg",
          "test_124_6.jpg",
          "test_124_1.jpg"
        ],
        "condorcet_winner": 0,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_124_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_124_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_124_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1737060546875,
            0.259521484375,
            0.294677734375,
            0.18115234375,
            0.11761474609375,
            0.1534423828125,
            0.284423828125,
            0.2298583984375,
            0.2119140625
          ],
          "order_indices": [
            2,
            6,
            1,
            7,
            8,
            3,
            0,
            5,
            4
          ],
          "order_filenames": [
            "test_124_2.jpg",
            "test_124_6.jpg",
            "test_124_1.jpg",
            "test_124_7.jpg",
            "test_124_8.jpg",
            "test_124_3.jpg",
            "test_124_0.jpg",
            "test_124_5.jpg",
            "test_124_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.55,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.71875,
            33.40625,
            36.90625,
            38.0625,
            19.203125,
            23.796875,
            35.75,
            38.03125,
            31.015625
          ],
          "order_indices": [
            3,
            7,
            0,
            2,
            6,
            1,
            8,
            5,
            4
          ],
          "order_filenames": [
            "test_124_3.jpg",
            "test_124_7.jpg",
            "test_124_0.jpg",
            "test_124_2.jpg",
            "test_124_6.jpg",
            "test_124_1.jpg",
            "test_124_8.jpg",
            "test_124_5.jpg",
            "test_124_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.3666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.496083378791809,
            0.5699418187141418,
            1.620185136795044,
            -0.2549603283405304,
            -1.8744405508041382,
            -0.7289966940879822,
            1.338241457939148,
            -0.9173009991645813,
            0.7780663967132568
          ],
          "order_indices": [
            2,
            6,
            8,
            1,
            3,
            5,
            7,
            0,
            4
          ],
          "order_filenames": [
            "test_124_2.jpg",
            "test_124_6.jpg",
            "test_124_8.jpg",
            "test_124_1.jpg",
            "test_124_3.jpg",
            "test_124_5.jpg",
            "test_124_7.jpg",
            "test_124_0.jpg",
            "test_124_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.6833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 125,
      "prompt": "A detailed and realistic fantasy Proto-Slavic skinny red troll creature.",
      "image_filenames": [
        "test_125_0.jpg",
        "test_125_1.jpg",
        "test_125_2.jpg",
        "test_125_3.jpg",
        "test_125_4.jpg",
        "test_125_5.jpg",
        "test_125_6.jpg",
        "test_125_7.jpg",
        "test_125_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          3,
          4,
          5,
          2,
          8,
          6,
          7,
          1
        ],
        "order_filenames": [
          "test_125_0.jpg",
          "test_125_3.jpg",
          "test_125_4.jpg",
          "test_125_5.jpg",
          "test_125_2.jpg",
          "test_125_8.jpg",
          "test_125_6.jpg",
          "test_125_7.jpg",
          "test_125_1.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_125_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_125_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0,
            3
          ],
          "winner_filenames": [
            "test_125_0.jpg",
            "test_125_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.22509765625,
            0.224853515625,
            0.31689453125,
            0.219970703125,
            0.20068359375,
            0.1961669921875,
            0.253173828125,
            0.254638671875,
            0.265869140625
          ],
          "order_indices": [
            2,
            8,
            7,
            6,
            0,
            1,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_125_2.jpg",
            "test_125_8.jpg",
            "test_125_7.jpg",
            "test_125_6.jpg",
            "test_125_0.jpg",
            "test_125_1.jpg",
            "test_125_3.jpg",
            "test_125_4.jpg",
            "test_125_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.3833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.96875,
            37.46875,
            39.25,
            34.84375,
            24.515625,
            30.4375,
            35.46875,
            43.4375,
            37.78125
          ],
          "order_indices": [
            7,
            2,
            0,
            8,
            1,
            6,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_125_7.jpg",
            "test_125_2.jpg",
            "test_125_0.jpg",
            "test_125_8.jpg",
            "test_125_1.jpg",
            "test_125_6.jpg",
            "test_125_3.jpg",
            "test_125_5.jpg",
            "test_125_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.33333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.6992390751838684,
            0.39316222071647644,
            1.8897172212600708,
            1.1527220010757446,
            -2.2535440921783447,
            -0.4776557385921478,
            1.1940184831619263,
            -0.10293804854154587,
            1.500267505645752
          ],
          "order_indices": [
            2,
            8,
            6,
            3,
            0,
            1,
            7,
            5,
            4
          ],
          "order_filenames": [
            "test_125_2.jpg",
            "test_125_8.jpg",
            "test_125_6.jpg",
            "test_125_3.jpg",
            "test_125_0.jpg",
            "test_125_1.jpg",
            "test_125_7.jpg",
            "test_125_5.jpg",
            "test_125_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.08333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 126,
      "prompt": "A teddy bear mad scientist mixing chemicals depicted in oil painting style as a fantasy concept art piece.",
      "image_filenames": [
        "test_126_0.jpg",
        "test_126_1.jpg",
        "test_126_2.jpg",
        "test_126_3.jpg",
        "test_126_4.jpg",
        "test_126_5.jpg",
        "test_126_6.jpg",
        "test_126_7.jpg",
        "test_126_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          3,
          4,
          2,
          5,
          1,
          7,
          8,
          0
        ],
        "order_filenames": [
          "test_126_6.jpg",
          "test_126_3.jpg",
          "test_126_4.jpg",
          "test_126_2.jpg",
          "test_126_5.jpg",
          "test_126_1.jpg",
          "test_126_7.jpg",
          "test_126_8.jpg",
          "test_126_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_126_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4,
            5,
            6
          ],
          "winner_filenames": [
            "test_126_4.jpg",
            "test_126_5.jpg",
            "test_126_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_126_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2083740234375,
            0.279296875,
            0.273193359375,
            0.238037109375,
            0.1871337890625,
            0.14892578125,
            0.286376953125,
            0.24169921875,
            0.28857421875
          ],
          "order_indices": [
            8,
            6,
            1,
            2,
            7,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_126_8.jpg",
            "test_126_6.jpg",
            "test_126_1.jpg",
            "test_126_2.jpg",
            "test_126_7.jpg",
            "test_126_3.jpg",
            "test_126_0.jpg",
            "test_126_4.jpg",
            "test_126_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.03333333333333344,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            46.71875,
            34.25,
            34.9375,
            37.59375,
            35.53125,
            26.140625,
            31.015625,
            48.8125,
            46.46875
          ],
          "order_indices": [
            7,
            0,
            8,
            3,
            4,
            2,
            1,
            6,
            5
          ],
          "order_filenames": [
            "test_126_7.jpg",
            "test_126_0.jpg",
            "test_126_8.jpg",
            "test_126_3.jpg",
            "test_126_4.jpg",
            "test_126_2.jpg",
            "test_126_1.jpg",
            "test_126_6.jpg",
            "test_126_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.5666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.404349446296692,
            -0.11992090940475464,
            0.056765761226415634,
            0.3373675048351288,
            -0.6259616017341614,
            -1.9373029470443726,
            -0.48496970534324646,
            1.6009522676467896,
            1.7077901363372803
          ],
          "order_indices": [
            8,
            7,
            0,
            3,
            2,
            1,
            6,
            4,
            5
          ],
          "order_filenames": [
            "test_126_8.jpg",
            "test_126_7.jpg",
            "test_126_0.jpg",
            "test_126_3.jpg",
            "test_126_2.jpg",
            "test_126_1.jpg",
            "test_126_6.jpg",
            "test_126_4.jpg",
            "test_126_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.6000000000000001,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 127,
      "prompt": "Lava falls upon a crumbling stadium as crowds panic.",
      "image_filenames": [
        "test_127_0.jpg",
        "test_127_1.jpg",
        "test_127_2.jpg",
        "test_127_3.jpg",
        "test_127_4.jpg",
        "test_127_5.jpg",
        "test_127_6.jpg",
        "test_127_7.jpg",
        "test_127_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          6,
          3,
          0,
          2,
          8,
          7,
          4,
          1
        ],
        "order_filenames": [
          "test_127_5.jpg",
          "test_127_6.jpg",
          "test_127_3.jpg",
          "test_127_0.jpg",
          "test_127_2.jpg",
          "test_127_8.jpg",
          "test_127_7.jpg",
          "test_127_4.jpg",
          "test_127_1.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_127_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_127_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_127_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1702880859375,
            0.251953125,
            0.28857421875,
            0.218994140625,
            0.181396484375,
            0.1641845703125,
            0.275390625,
            0.26416015625,
            0.247802734375
          ],
          "order_indices": [
            2,
            6,
            7,
            1,
            8,
            3,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_127_2.jpg",
            "test_127_6.jpg",
            "test_127_7.jpg",
            "test_127_1.jpg",
            "test_127_8.jpg",
            "test_127_3.jpg",
            "test_127_4.jpg",
            "test_127_0.jpg",
            "test_127_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.2333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.0,
            34.1875,
            40.84375,
            24.796875,
            27.96875,
            29.875,
            36.6875,
            45.21875,
            34.96875
          ],
          "order_indices": [
            7,
            2,
            0,
            6,
            8,
            1,
            5,
            4,
            3
          ],
          "order_filenames": [
            "test_127_7.jpg",
            "test_127_2.jpg",
            "test_127_0.jpg",
            "test_127_6.jpg",
            "test_127_8.jpg",
            "test_127_1.jpg",
            "test_127_5.jpg",
            "test_127_4.jpg",
            "test_127_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.10000000000000009,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.7538089752197266,
            0.7214345932006836,
            1.706763505935669,
            -0.5186828970909119,
            0.02482600510120392,
            -0.2778170704841614,
            0.6216769814491272,
            1.5329184532165527,
            1.2740452289581299
          ],
          "order_indices": [
            2,
            7,
            8,
            0,
            1,
            6,
            4,
            5,
            3
          ],
          "order_filenames": [
            "test_127_2.jpg",
            "test_127_7.jpg",
            "test_127_8.jpg",
            "test_127_0.jpg",
            "test_127_1.jpg",
            "test_127_6.jpg",
            "test_127_4.jpg",
            "test_127_5.jpg",
            "test_127_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.3999999999999999,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 128,
      "prompt": "Image of a woman with snakes in her mouth, surrounded by flowers and a twisted branch background, created by various artists, with a dark and moody atmosphere.",
      "image_filenames": [
        "test_128_0.jpg",
        "test_128_1.jpg",
        "test_128_2.jpg",
        "test_128_3.jpg",
        "test_128_4.jpg",
        "test_128_5.jpg",
        "test_128_6.jpg",
        "test_128_7.jpg",
        "test_128_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          4,
          6,
          3,
          5,
          1,
          8,
          7,
          0
        ],
        "order_filenames": [
          "test_128_2.jpg",
          "test_128_4.jpg",
          "test_128_6.jpg",
          "test_128_3.jpg",
          "test_128_5.jpg",
          "test_128_1.jpg",
          "test_128_8.jpg",
          "test_128_7.jpg",
          "test_128_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_128_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_128_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_128_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.229736328125,
            0.266357421875,
            0.261474609375,
            0.2353515625,
            0.22021484375,
            0.166015625,
            0.2425537109375,
            0.28759765625,
            0.256103515625
          ],
          "order_indices": [
            7,
            1,
            2,
            8,
            6,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_128_7.jpg",
            "test_128_1.jpg",
            "test_128_2.jpg",
            "test_128_8.jpg",
            "test_128_6.jpg",
            "test_128_3.jpg",
            "test_128_0.jpg",
            "test_128_4.jpg",
            "test_128_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            43.59375,
            40.09375,
            44.3125,
            40.34375,
            34.0625,
            32.875,
            40.84375,
            47.625,
            45.15625
          ],
          "order_indices": [
            7,
            8,
            2,
            0,
            6,
            3,
            1,
            4,
            5
          ],
          "order_filenames": [
            "test_128_7.jpg",
            "test_128_8.jpg",
            "test_128_2.jpg",
            "test_128_0.jpg",
            "test_128_6.jpg",
            "test_128_3.jpg",
            "test_128_1.jpg",
            "test_128_4.jpg",
            "test_128_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.3666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.862350344657898,
            0.5760636925697327,
            1.9289536476135254,
            0.7254055142402649,
            -0.1620568335056305,
            -1.2164803743362427,
            0.8917607665061951,
            1.0330259799957275,
            1.601825475692749
          ],
          "order_indices": [
            2,
            0,
            8,
            7,
            6,
            3,
            1,
            4,
            5
          ],
          "order_filenames": [
            "test_128_2.jpg",
            "test_128_0.jpg",
            "test_128_8.jpg",
            "test_128_7.jpg",
            "test_128_6.jpg",
            "test_128_3.jpg",
            "test_128_1.jpg",
            "test_128_4.jpg",
            "test_128_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.18333333333333335,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 129,
      "prompt": "A portrait of Childe Hassam in digital art style surrounded by other famous artists in HD.",
      "image_filenames": [
        "test_129_0.jpg",
        "test_129_1.jpg",
        "test_129_2.jpg",
        "test_129_3.jpg",
        "test_129_4.jpg",
        "test_129_5.jpg",
        "test_129_6.jpg",
        "test_129_7.jpg",
        "test_129_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          0,
          3,
          5,
          4,
          7,
          2,
          8,
          1
        ],
        "order_filenames": [
          "test_129_6.jpg",
          "test_129_0.jpg",
          "test_129_3.jpg",
          "test_129_5.jpg",
          "test_129_4.jpg",
          "test_129_7.jpg",
          "test_129_2.jpg",
          "test_129_8.jpg",
          "test_129_1.jpg"
        ],
        "condorcet_winner": 6,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_129_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_129_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_129_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1380615234375,
            0.209716796875,
            0.20654296875,
            0.1600341796875,
            0.133056640625,
            0.123046875,
            0.1934814453125,
            0.2037353515625,
            0.2056884765625
          ],
          "order_indices": [
            1,
            2,
            8,
            7,
            6,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_129_1.jpg",
            "test_129_2.jpg",
            "test_129_8.jpg",
            "test_129_7.jpg",
            "test_129_6.jpg",
            "test_129_3.jpg",
            "test_129_0.jpg",
            "test_129_4.jpg",
            "test_129_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.6833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.40625,
            35.8125,
            25.65625,
            19.984375,
            18.59375,
            24.453125,
            28.84375,
            42.46875,
            41.0625
          ],
          "order_indices": [
            7,
            8,
            1,
            0,
            6,
            2,
            5,
            3,
            4
          ],
          "order_filenames": [
            "test_129_7.jpg",
            "test_129_8.jpg",
            "test_129_1.jpg",
            "test_129_0.jpg",
            "test_129_6.jpg",
            "test_129_2.jpg",
            "test_129_5.jpg",
            "test_129_3.jpg",
            "test_129_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.3999999999999999,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.8316361308097839,
            0.1725783348083496,
            -0.4475327432155609,
            -0.5707211494445801,
            -1.8474719524383545,
            -1.9469212293624878,
            -0.818886935710907,
            1.414595603942871,
            0.09348677098751068
          ],
          "order_indices": [
            7,
            1,
            8,
            2,
            3,
            6,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_129_7.jpg",
            "test_129_1.jpg",
            "test_129_8.jpg",
            "test_129_2.jpg",
            "test_129_3.jpg",
            "test_129_6.jpg",
            "test_129_0.jpg",
            "test_129_4.jpg",
            "test_129_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.6333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 130,
      "prompt": "Mixed media collage with broken glass photo and torn paper textures in a contemporary art style.",
      "image_filenames": [
        "test_130_0.jpg",
        "test_130_1.jpg",
        "test_130_2.jpg",
        "test_130_3.jpg",
        "test_130_4.jpg",
        "test_130_5.jpg",
        "test_130_6.jpg",
        "test_130_7.jpg",
        "test_130_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          4,
          1,
          6,
          0,
          8,
          5,
          2,
          7
        ],
        "order_filenames": [
          "test_130_3.jpg",
          "test_130_4.jpg",
          "test_130_1.jpg",
          "test_130_6.jpg",
          "test_130_0.jpg",
          "test_130_8.jpg",
          "test_130_5.jpg",
          "test_130_2.jpg",
          "test_130_7.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_130_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3,
            4
          ],
          "winner_filenames": [
            "test_130_3.jpg",
            "test_130_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_130_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2265625,
            0.24072265625,
            0.2161865234375,
            0.214599609375,
            0.1568603515625,
            0.167236328125,
            0.23681640625,
            0.238525390625,
            0.23681640625
          ],
          "order_indices": [
            1,
            7,
            6,
            8,
            0,
            2,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_130_1.jpg",
            "test_130_7.jpg",
            "test_130_6.jpg",
            "test_130_8.jpg",
            "test_130_0.jpg",
            "test_130_2.jpg",
            "test_130_3.jpg",
            "test_130_5.jpg",
            "test_130_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.2333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.3125,
            37.8125,
            38.6875,
            31.28125,
            20.03125,
            25.546875,
            34.0625,
            32.875,
            39.40625
          ],
          "order_indices": [
            8,
            2,
            1,
            0,
            6,
            7,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_130_8.jpg",
            "test_130_2.jpg",
            "test_130_1.jpg",
            "test_130_0.jpg",
            "test_130_6.jpg",
            "test_130_7.jpg",
            "test_130_3.jpg",
            "test_130_5.jpg",
            "test_130_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.31666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.4983500838279724,
            0.3142900764942169,
            0.1695193350315094,
            -0.30511051416397095,
            -0.6657209396362305,
            -0.6401452422142029,
            0.2356979250907898,
            1.0436456203460693,
            0.5730034708976746
          ],
          "order_indices": [
            7,
            8,
            0,
            1,
            6,
            2,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_130_7.jpg",
            "test_130_8.jpg",
            "test_130_0.jpg",
            "test_130_1.jpg",
            "test_130_6.jpg",
            "test_130_2.jpg",
            "test_130_3.jpg",
            "test_130_5.jpg",
            "test_130_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.46666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 131,
      "prompt": "A cyber goth elf priestess strikes dramatic poses in a post-apocalyptic cyberpunk city with overgrown vegetation.",
      "image_filenames": [
        "test_131_0.jpg",
        "test_131_1.jpg",
        "test_131_2.jpg",
        "test_131_3.jpg",
        "test_131_4.jpg",
        "test_131_5.jpg",
        "test_131_6.jpg",
        "test_131_7.jpg",
        "test_131_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          1,
          4,
          7,
          3,
          2,
          6,
          8,
          0
        ],
        "order_filenames": [
          "test_131_5.jpg",
          "test_131_1.jpg",
          "test_131_4.jpg",
          "test_131_7.jpg",
          "test_131_3.jpg",
          "test_131_2.jpg",
          "test_131_6.jpg",
          "test_131_8.jpg",
          "test_131_0.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_131_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_131_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_131_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.208984375,
            0.2379150390625,
            0.2235107421875,
            0.2344970703125,
            0.2078857421875,
            0.1480712890625,
            0.271484375,
            0.21240234375,
            0.252685546875
          ],
          "order_indices": [
            6,
            8,
            1,
            3,
            2,
            7,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_131_6.jpg",
            "test_131_8.jpg",
            "test_131_1.jpg",
            "test_131_3.jpg",
            "test_131_2.jpg",
            "test_131_7.jpg",
            "test_131_0.jpg",
            "test_131_4.jpg",
            "test_131_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.43333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            41.65625,
            42.96875,
            39.40625,
            39.3125,
            38.78125,
            25.859375,
            40.8125,
            43.1875,
            37.25
          ],
          "order_indices": [
            7,
            1,
            0,
            6,
            2,
            3,
            4,
            8,
            5
          ],
          "order_filenames": [
            "test_131_7.jpg",
            "test_131_1.jpg",
            "test_131_0.jpg",
            "test_131_6.jpg",
            "test_131_2.jpg",
            "test_131_3.jpg",
            "test_131_4.jpg",
            "test_131_8.jpg",
            "test_131_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.1333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.12020585685968399,
            1.5680277347564697,
            0.16229604184627533,
            0.6201078295707703,
            0.10426584631204605,
            -1.6871334314346313,
            1.106088638305664,
            -0.5740260481834412,
            -1.030361294746399
          ],
          "order_indices": [
            1,
            6,
            3,
            2,
            0,
            4,
            7,
            8,
            5
          ],
          "order_filenames": [
            "test_131_1.jpg",
            "test_131_6.jpg",
            "test_131_3.jpg",
            "test_131_2.jpg",
            "test_131_0.jpg",
            "test_131_4.jpg",
            "test_131_7.jpg",
            "test_131_8.jpg",
            "test_131_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.10000000000000009,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 132,
      "prompt": "An alter made of bones with a glowing pineapple lamp on it and surrounded by candles, in front of a swirling mist with epic lighting.",
      "image_filenames": [
        "test_132_0.jpg",
        "test_132_1.jpg",
        "test_132_2.jpg",
        "test_132_3.jpg",
        "test_132_4.jpg",
        "test_132_5.jpg",
        "test_132_6.jpg",
        "test_132_7.jpg",
        "test_132_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          1,
          3,
          6,
          7,
          4,
          5,
          2,
          8
        ],
        "order_filenames": [
          "test_132_0.jpg",
          "test_132_1.jpg",
          "test_132_3.jpg",
          "test_132_6.jpg",
          "test_132_7.jpg",
          "test_132_4.jpg",
          "test_132_5.jpg",
          "test_132_2.jpg",
          "test_132_8.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_132_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3,
            6
          ],
          "winner_filenames": [
            "test_132_3.jpg",
            "test_132_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1,
            3
          ],
          "winner_filenames": [
            "test_132_1.jpg",
            "test_132_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.20068359375,
            0.2462158203125,
            0.303466796875,
            0.19189453125,
            0.16845703125,
            0.2244873046875,
            0.26953125,
            0.2325439453125,
            0.232421875
          ],
          "order_indices": [
            2,
            6,
            1,
            7,
            8,
            5,
            0,
            3,
            4
          ],
          "order_filenames": [
            "test_132_2.jpg",
            "test_132_6.jpg",
            "test_132_1.jpg",
            "test_132_7.jpg",
            "test_132_8.jpg",
            "test_132_5.jpg",
            "test_132_0.jpg",
            "test_132_3.jpg",
            "test_132_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.8125,
            39.8125,
            40.8125,
            29.234375,
            32.8125,
            34.90625,
            44.09375,
            40.875,
            42.25
          ],
          "order_indices": [
            6,
            8,
            7,
            2,
            0,
            1,
            5,
            4,
            3
          ],
          "order_filenames": [
            "test_132_6.jpg",
            "test_132_8.jpg",
            "test_132_7.jpg",
            "test_132_2.jpg",
            "test_132_0.jpg",
            "test_132_1.jpg",
            "test_132_5.jpg",
            "test_132_4.jpg",
            "test_132_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.25,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.5118070244789124,
            0.7650899887084961,
            0.2222009152173996,
            -1.029608130455017,
            -0.7802178859710693,
            -0.42640769481658936,
            1.363781213760376,
            0.6549124121665955,
            0.9098449945449829
          ],
          "order_indices": [
            6,
            8,
            1,
            7,
            0,
            2,
            5,
            4,
            3
          ],
          "order_filenames": [
            "test_132_6.jpg",
            "test_132_8.jpg",
            "test_132_1.jpg",
            "test_132_7.jpg",
            "test_132_0.jpg",
            "test_132_2.jpg",
            "test_132_5.jpg",
            "test_132_4.jpg",
            "test_132_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": 0.0,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 133,
      "prompt": "A 3D render of a volcanic icon on a rocky background, in isometric perspective and darkly lit.",
      "image_filenames": [
        "test_133_0.jpg",
        "test_133_1.jpg",
        "test_133_2.jpg",
        "test_133_3.jpg",
        "test_133_4.jpg",
        "test_133_5.jpg",
        "test_133_6.jpg",
        "test_133_7.jpg",
        "test_133_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          3,
          1,
          8,
          4,
          7,
          6,
          5,
          2
        ],
        "order_filenames": [
          "test_133_0.jpg",
          "test_133_3.jpg",
          "test_133_1.jpg",
          "test_133_8.jpg",
          "test_133_4.jpg",
          "test_133_7.jpg",
          "test_133_6.jpg",
          "test_133_5.jpg",
          "test_133_2.jpg"
        ],
        "condorcet_winner": 0,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_133_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_133_0.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_133_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.26025390625,
            0.1461181640625,
            0.1873779296875,
            0.1695556640625,
            0.177978515625,
            0.2161865234375,
            0.20751953125,
            0.2490234375,
            0.224365234375
          ],
          "order_indices": [
            0,
            7,
            8,
            5,
            6,
            2,
            4,
            3,
            1
          ],
          "order_filenames": [
            "test_133_0.jpg",
            "test_133_7.jpg",
            "test_133_8.jpg",
            "test_133_5.jpg",
            "test_133_6.jpg",
            "test_133_2.jpg",
            "test_133_4.jpg",
            "test_133_3.jpg",
            "test_133_1.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.016666666666666607,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 1.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.875,
            35.78125,
            39.75,
            36.90625,
            25.671875,
            33.78125,
            43.46875,
            40.96875,
            44.71875
          ],
          "order_indices": [
            8,
            6,
            7,
            0,
            2,
            3,
            1,
            5,
            4
          ],
          "order_filenames": [
            "test_133_8.jpg",
            "test_133_6.jpg",
            "test_133_7.jpg",
            "test_133_0.jpg",
            "test_133_2.jpg",
            "test_133_3.jpg",
            "test_133_1.jpg",
            "test_133_5.jpg",
            "test_133_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.033333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.42461031675338745,
            -0.9245370626449585,
            0.3517991602420807,
            -0.016658466309309006,
            -0.38391828536987305,
            -0.1458330601453781,
            0.42941081523895264,
            0.44132840633392334,
            0.3357312083244324
          ],
          "order_indices": [
            7,
            6,
            0,
            2,
            8,
            3,
            5,
            4,
            1
          ],
          "order_filenames": [
            "test_133_7.jpg",
            "test_133_6.jpg",
            "test_133_0.jpg",
            "test_133_2.jpg",
            "test_133_8.jpg",
            "test_133_3.jpg",
            "test_133_5.jpg",
            "test_133_4.jpg",
            "test_133_1.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 134,
      "prompt": "Sonic the Hedgehog depicted as a muscular Greek god in a highly detailed digital painting by Greg Rutkowski and Alphonse Mucha on Artstation.",
      "image_filenames": [
        "test_134_0.jpg",
        "test_134_1.jpg",
        "test_134_2.jpg",
        "test_134_3.jpg",
        "test_134_4.jpg",
        "test_134_5.jpg",
        "test_134_6.jpg",
        "test_134_7.jpg",
        "test_134_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          6,
          4,
          5,
          7,
          2,
          0,
          8,
          1
        ],
        "order_filenames": [
          "test_134_3.jpg",
          "test_134_6.jpg",
          "test_134_4.jpg",
          "test_134_5.jpg",
          "test_134_7.jpg",
          "test_134_2.jpg",
          "test_134_0.jpg",
          "test_134_8.jpg",
          "test_134_1.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3,
          6
        ],
        "winner_filenames": [
          "test_134_3.jpg",
          "test_134_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_134_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_134_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1839599609375,
            0.265869140625,
            0.25830078125,
            0.172119140625,
            0.1695556640625,
            0.1109619140625,
            0.25244140625,
            0.2352294921875,
            0.299072265625
          ],
          "order_indices": [
            8,
            1,
            2,
            6,
            7,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_134_8.jpg",
            "test_134_1.jpg",
            "test_134_2.jpg",
            "test_134_6.jpg",
            "test_134_7.jpg",
            "test_134_0.jpg",
            "test_134_3.jpg",
            "test_134_4.jpg",
            "test_134_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.6499999999999999,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.0625,
            46.5,
            36.53125,
            32.5625,
            21.0,
            20.515625,
            35.84375,
            47.0,
            31.46875
          ],
          "order_indices": [
            7,
            1,
            0,
            2,
            6,
            3,
            8,
            4,
            5
          ],
          "order_filenames": [
            "test_134_7.jpg",
            "test_134_1.jpg",
            "test_134_0.jpg",
            "test_134_2.jpg",
            "test_134_6.jpg",
            "test_134_3.jpg",
            "test_134_8.jpg",
            "test_134_4.jpg",
            "test_134_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.41666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.869100034236908,
            0.7124332189559937,
            0.2305397391319275,
            -1.2062098979949951,
            -0.6876296997070312,
            -1.8138500452041626,
            0.3784351348876953,
            0.24648913741111755,
            1.311803936958313
          ],
          "order_indices": [
            8,
            0,
            1,
            6,
            7,
            2,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_134_8.jpg",
            "test_134_0.jpg",
            "test_134_1.jpg",
            "test_134_6.jpg",
            "test_134_7.jpg",
            "test_134_2.jpg",
            "test_134_4.jpg",
            "test_134_3.jpg",
            "test_134_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.7,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 135,
      "prompt": "The image is a highly detailed concept art of a medieval city, with a cinematic style and painted beautifully in oil by various artists including Wlop, Greg Rutkowski, and Artgerm, and can be viewed on Artstation.",
      "image_filenames": [
        "test_135_0.jpg",
        "test_135_1.jpg",
        "test_135_2.jpg",
        "test_135_3.jpg",
        "test_135_4.jpg",
        "test_135_5.jpg",
        "test_135_6.jpg",
        "test_135_7.jpg",
        "test_135_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          5,
          2,
          4,
          8,
          6,
          7,
          1,
          0
        ],
        "order_filenames": [
          "test_135_3.jpg",
          "test_135_5.jpg",
          "test_135_2.jpg",
          "test_135_4.jpg",
          "test_135_8.jpg",
          "test_135_6.jpg",
          "test_135_7.jpg",
          "test_135_1.jpg",
          "test_135_0.jpg"
        ],
        "condorcet_winner": 3,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_135_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_135_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_135_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.20068359375,
            0.26318359375,
            0.2296142578125,
            0.22314453125,
            0.1624755859375,
            0.1640625,
            0.259765625,
            0.210205078125,
            0.2376708984375
          ],
          "order_indices": [
            1,
            6,
            8,
            2,
            3,
            7,
            0,
            5,
            4
          ],
          "order_filenames": [
            "test_135_1.jpg",
            "test_135_6.jpg",
            "test_135_8.jpg",
            "test_135_2.jpg",
            "test_135_3.jpg",
            "test_135_7.jpg",
            "test_135_0.jpg",
            "test_135_5.jpg",
            "test_135_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.2666666666666666,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.09375,
            35.71875,
            37.09375,
            36.4375,
            13.40625,
            28.09375,
            35.125,
            35.21875,
            34.53125
          ],
          "order_indices": [
            2,
            3,
            1,
            7,
            6,
            0,
            8,
            5,
            4
          ],
          "order_filenames": [
            "test_135_2.jpg",
            "test_135_3.jpg",
            "test_135_1.jpg",
            "test_135_7.jpg",
            "test_135_6.jpg",
            "test_135_0.jpg",
            "test_135_8.jpg",
            "test_135_5.jpg",
            "test_135_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": 0.050000000000000044,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.1521259993314743,
            0.6786727905273438,
            0.5395769476890564,
            0.29796579480171204,
            -1.4182913303375244,
            -0.21301531791687012,
            0.6823137402534485,
            -0.328281044960022,
            0.555217444896698
          ],
          "order_indices": [
            6,
            1,
            8,
            2,
            3,
            0,
            5,
            7,
            4
          ],
          "order_filenames": [
            "test_135_6.jpg",
            "test_135_1.jpg",
            "test_135_8.jpg",
            "test_135_2.jpg",
            "test_135_3.jpg",
            "test_135_0.jpg",
            "test_135_5.jpg",
            "test_135_7.jpg",
            "test_135_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 136,
      "prompt": "An abandoned Israeli bus station in Tel Aviv depicted in a flat, colorful Ghibli-style digital artwork by Makoto Shinkai.",
      "image_filenames": [
        "test_136_0.jpg",
        "test_136_1.jpg",
        "test_136_2.jpg",
        "test_136_3.jpg",
        "test_136_4.jpg",
        "test_136_5.jpg",
        "test_136_6.jpg",
        "test_136_7.jpg",
        "test_136_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          2,
          6,
          1,
          3,
          7,
          0,
          5,
          8
        ],
        "order_filenames": [
          "test_136_4.jpg",
          "test_136_2.jpg",
          "test_136_6.jpg",
          "test_136_1.jpg",
          "test_136_3.jpg",
          "test_136_7.jpg",
          "test_136_0.jpg",
          "test_136_5.jpg",
          "test_136_8.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_136_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_136_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2,
            4
          ],
          "winner_filenames": [
            "test_136_2.jpg",
            "test_136_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.187744140625,
            0.2086181640625,
            0.2252197265625,
            0.1859130859375,
            0.171630859375,
            0.185546875,
            0.2327880859375,
            0.2137451171875,
            0.206787109375
          ],
          "order_indices": [
            6,
            2,
            7,
            1,
            8,
            0,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_136_6.jpg",
            "test_136_2.jpg",
            "test_136_7.jpg",
            "test_136_1.jpg",
            "test_136_8.jpg",
            "test_136_0.jpg",
            "test_136_3.jpg",
            "test_136_5.jpg",
            "test_136_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            48.1875,
            42.46875,
            45.125,
            34.3125,
            31.953125,
            23.6875,
            38.40625,
            45.78125,
            38.71875
          ],
          "order_indices": [
            0,
            7,
            2,
            1,
            8,
            6,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_136_0.jpg",
            "test_136_7.jpg",
            "test_136_2.jpg",
            "test_136_1.jpg",
            "test_136_8.jpg",
            "test_136_6.jpg",
            "test_136_3.jpg",
            "test_136_4.jpg",
            "test_136_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.10000000000000009,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.27062085270881653,
            -0.6531181931495667,
            0.04497511312365532,
            -0.7552080750465393,
            -0.5941938161849976,
            -1.1730616092681885,
            -0.5412604212760925,
            -0.08966127783060074,
            -0.017106177285313606
          ],
          "order_indices": [
            2,
            8,
            7,
            0,
            6,
            4,
            1,
            3,
            5
          ],
          "order_filenames": [
            "test_136_2.jpg",
            "test_136_8.jpg",
            "test_136_7.jpg",
            "test_136_0.jpg",
            "test_136_6.jpg",
            "test_136_4.jpg",
            "test_136_1.jpg",
            "test_136_3.jpg",
            "test_136_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.033333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 137,
      "prompt": "The image depicts alien flowers and plants surrounded by visceral exoskeletal formations in front of mythical mountains with dramatic contrast lighting, created with surreal hyper detailing in a 3D render.",
      "image_filenames": [
        "test_137_0.jpg",
        "test_137_1.jpg",
        "test_137_2.jpg",
        "test_137_3.jpg",
        "test_137_4.jpg",
        "test_137_5.jpg",
        "test_137_6.jpg",
        "test_137_7.jpg",
        "test_137_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          7,
          2,
          1,
          0,
          4,
          5,
          8,
          6
        ],
        "order_filenames": [
          "test_137_3.jpg",
          "test_137_7.jpg",
          "test_137_2.jpg",
          "test_137_1.jpg",
          "test_137_0.jpg",
          "test_137_4.jpg",
          "test_137_5.jpg",
          "test_137_8.jpg",
          "test_137_6.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3,
          7
        ],
        "winner_filenames": [
          "test_137_3.jpg",
          "test_137_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4,
            5,
            6,
            7
          ],
          "winner_filenames": [
            "test_137_4.jpg",
            "test_137_5.jpg",
            "test_137_6.jpg",
            "test_137_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_137_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.236328125,
            0.24658203125,
            0.3046875,
            0.254638671875,
            0.2022705078125,
            0.10552978515625,
            0.250244140625,
            0.27392578125,
            0.21044921875
          ],
          "order_indices": [
            2,
            7,
            3,
            6,
            1,
            0,
            8,
            4,
            5
          ],
          "order_filenames": [
            "test_137_2.jpg",
            "test_137_7.jpg",
            "test_137_3.jpg",
            "test_137_6.jpg",
            "test_137_1.jpg",
            "test_137_0.jpg",
            "test_137_8.jpg",
            "test_137_4.jpg",
            "test_137_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.4444444444444444,
            "spearman_rho": 0.6333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.625,
            38.4375,
            41.375,
            27.40625,
            29.4375,
            29.40625,
            37.9375,
            44.375,
            40.03125
          ],
          "order_indices": [
            7,
            2,
            0,
            8,
            1,
            6,
            4,
            5,
            3
          ],
          "order_filenames": [
            "test_137_7.jpg",
            "test_137_2.jpg",
            "test_137_0.jpg",
            "test_137_8.jpg",
            "test_137_1.jpg",
            "test_137_6.jpg",
            "test_137_4.jpg",
            "test_137_5.jpg",
            "test_137_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.651214838027954,
            0.933123767375946,
            1.669273018836975,
            0.7038999795913696,
            1.1267247200012207,
            -1.1159007549285889,
            1.0901881456375122,
            1.3938114643096924,
            1.2477388381958008
          ],
          "order_indices": [
            2,
            0,
            7,
            8,
            4,
            6,
            1,
            3,
            5
          ],
          "order_filenames": [
            "test_137_2.jpg",
            "test_137_0.jpg",
            "test_137_7.jpg",
            "test_137_8.jpg",
            "test_137_4.jpg",
            "test_137_6.jpg",
            "test_137_1.jpg",
            "test_137_3.jpg",
            "test_137_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.15000000000000002,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 138,
      "prompt": "Grogu is featured in the center of the image, with a cloudy sky, sun, and neon lights in the background, utilizing the rule of thirds and incorporating elements of retrofuturism and Studio Ghibli-inspired aesthetics.",
      "image_filenames": [
        "test_138_0.jpg",
        "test_138_1.jpg",
        "test_138_2.jpg",
        "test_138_3.jpg",
        "test_138_4.jpg",
        "test_138_5.jpg",
        "test_138_6.jpg",
        "test_138_7.jpg",
        "test_138_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          5,
          0,
          7,
          2,
          6,
          8,
          4,
          1
        ],
        "order_filenames": [
          "test_138_3.jpg",
          "test_138_5.jpg",
          "test_138_0.jpg",
          "test_138_7.jpg",
          "test_138_2.jpg",
          "test_138_6.jpg",
          "test_138_8.jpg",
          "test_138_4.jpg",
          "test_138_1.jpg"
        ],
        "condorcet_winner": 3,
        "winner_indices": [
          3,
          5
        ],
        "winner_filenames": [
          "test_138_3.jpg",
          "test_138_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_138_3.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_138_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.193359375,
            0.287109375,
            0.2186279296875,
            0.183349609375,
            0.2064208984375,
            0.1556396484375,
            0.252197265625,
            0.2548828125,
            0.195556640625
          ],
          "order_indices": [
            1,
            7,
            6,
            2,
            4,
            8,
            0,
            3,
            5
          ],
          "order_filenames": [
            "test_138_1.jpg",
            "test_138_7.jpg",
            "test_138_6.jpg",
            "test_138_2.jpg",
            "test_138_4.jpg",
            "test_138_8.jpg",
            "test_138_0.jpg",
            "test_138_3.jpg",
            "test_138_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.6833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.6875,
            34.59375,
            42.65625,
            33.25,
            33.40625,
            29.96875,
            30.140625,
            50.3125,
            35.78125
          ],
          "order_indices": [
            7,
            2,
            8,
            0,
            1,
            4,
            3,
            6,
            5
          ],
          "order_filenames": [
            "test_138_7.jpg",
            "test_138_2.jpg",
            "test_138_8.jpg",
            "test_138_0.jpg",
            "test_138_1.jpg",
            "test_138_4.jpg",
            "test_138_3.jpg",
            "test_138_6.jpg",
            "test_138_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.19999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.38872700929641724,
            0.6377474069595337,
            0.879385769367218,
            -1.3124938011169434,
            -0.48050346970558167,
            -1.004801630973816,
            0.41623368859291077,
            -0.19591024518013,
            -0.0541720949113369
          ],
          "order_indices": [
            2,
            1,
            6,
            8,
            7,
            0,
            4,
            5,
            3
          ],
          "order_filenames": [
            "test_138_2.jpg",
            "test_138_1.jpg",
            "test_138_6.jpg",
            "test_138_8.jpg",
            "test_138_7.jpg",
            "test_138_0.jpg",
            "test_138_4.jpg",
            "test_138_5.jpg",
            "test_138_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.6166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 139,
      "prompt": "Plasticine sculptures of two lovers walking through Paris with strict clothing and bright colors.",
      "image_filenames": [
        "test_139_0.jpg",
        "test_139_1.jpg",
        "test_139_2.jpg",
        "test_139_3.jpg",
        "test_139_4.jpg",
        "test_139_5.jpg",
        "test_139_6.jpg",
        "test_139_7.jpg",
        "test_139_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          5,
          6,
          1,
          3,
          0,
          2,
          8,
          4
        ],
        "order_filenames": [
          "test_139_7.jpg",
          "test_139_5.jpg",
          "test_139_6.jpg",
          "test_139_1.jpg",
          "test_139_3.jpg",
          "test_139_0.jpg",
          "test_139_2.jpg",
          "test_139_8.jpg",
          "test_139_4.jpg"
        ],
        "condorcet_winner": 7,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_139_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_139_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_139_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.173095703125,
            0.234375,
            0.274658203125,
            0.197998046875,
            0.19677734375,
            0.13427734375,
            0.252685546875,
            0.2215576171875,
            0.237060546875
          ],
          "order_indices": [
            2,
            6,
            8,
            1,
            7,
            3,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_139_2.jpg",
            "test_139_6.jpg",
            "test_139_8.jpg",
            "test_139_1.jpg",
            "test_139_7.jpg",
            "test_139_3.jpg",
            "test_139_4.jpg",
            "test_139_0.jpg",
            "test_139_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.1333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            42.25,
            44.53125,
            50.125,
            42.25,
            34.59375,
            28.578125,
            40.25,
            42.375,
            44.71875
          ],
          "order_indices": [
            2,
            8,
            1,
            7,
            0,
            3,
            6,
            4,
            5
          ],
          "order_filenames": [
            "test_139_2.jpg",
            "test_139_8.jpg",
            "test_139_1.jpg",
            "test_139_7.jpg",
            "test_139_0.jpg",
            "test_139_3.jpg",
            "test_139_6.jpg",
            "test_139_4.jpg",
            "test_139_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.25,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.2830171585083008,
            1.5861220359802246,
            1.7228893041610718,
            -0.19671188294887543,
            1.046608328819275,
            -1.4191439151763916,
            0.7999512553215027,
            1.2413610219955444,
            1.602390170097351
          ],
          "order_indices": [
            2,
            8,
            1,
            7,
            4,
            6,
            3,
            0,
            5
          ],
          "order_filenames": [
            "test_139_2.jpg",
            "test_139_8.jpg",
            "test_139_1.jpg",
            "test_139_7.jpg",
            "test_139_4.jpg",
            "test_139_6.jpg",
            "test_139_3.jpg",
            "test_139_0.jpg",
            "test_139_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.3666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 140,
      "prompt": "Undead army on riding beasts with symbols and music.",
      "image_filenames": [
        "test_140_0.jpg",
        "test_140_1.jpg",
        "test_140_2.jpg",
        "test_140_3.jpg",
        "test_140_4.jpg",
        "test_140_5.jpg",
        "test_140_6.jpg",
        "test_140_7.jpg",
        "test_140_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          4,
          3,
          1,
          5,
          7,
          2,
          8,
          6
        ],
        "order_filenames": [
          "test_140_0.jpg",
          "test_140_4.jpg",
          "test_140_3.jpg",
          "test_140_1.jpg",
          "test_140_5.jpg",
          "test_140_7.jpg",
          "test_140_2.jpg",
          "test_140_8.jpg",
          "test_140_6.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0,
          4
        ],
        "winner_filenames": [
          "test_140_0.jpg",
          "test_140_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_140_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0,
            4
          ],
          "winner_filenames": [
            "test_140_0.jpg",
            "test_140_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2288818359375,
            0.1895751953125,
            0.285888671875,
            0.20458984375,
            0.208251953125,
            0.11212158203125,
            0.2457275390625,
            0.2178955078125,
            0.1685791015625
          ],
          "order_indices": [
            2,
            6,
            0,
            7,
            4,
            3,
            1,
            8,
            5
          ],
          "order_filenames": [
            "test_140_2.jpg",
            "test_140_6.jpg",
            "test_140_0.jpg",
            "test_140_7.jpg",
            "test_140_4.jpg",
            "test_140_3.jpg",
            "test_140_1.jpg",
            "test_140_8.jpg",
            "test_140_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.1333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.75,
            25.234375,
            37.6875,
            32.28125,
            24.390625,
            13.7890625,
            33.0625,
            41.53125,
            33.65625
          ],
          "order_indices": [
            7,
            2,
            0,
            8,
            6,
            3,
            1,
            4,
            5
          ],
          "order_filenames": [
            "test_140_7.jpg",
            "test_140_2.jpg",
            "test_140_0.jpg",
            "test_140_8.jpg",
            "test_140_6.jpg",
            "test_140_3.jpg",
            "test_140_1.jpg",
            "test_140_4.jpg",
            "test_140_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.30000000000000004,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.519665539264679,
            -0.7549114227294922,
            1.0253862142562866,
            0.31748491525650024,
            0.13576142489910126,
            -1.9303730726242065,
            -0.4687383770942688,
            0.5747994184494019,
            -0.22291319072246552
          ],
          "order_indices": [
            2,
            7,
            0,
            3,
            4,
            8,
            6,
            1,
            5
          ],
          "order_filenames": [
            "test_140_2.jpg",
            "test_140_7.jpg",
            "test_140_0.jpg",
            "test_140_3.jpg",
            "test_140_4.jpg",
            "test_140_8.jpg",
            "test_140_6.jpg",
            "test_140_1.jpg",
            "test_140_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.1166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 141,
      "prompt": "Kinetic wind sculpture in 3D render.",
      "image_filenames": [
        "test_141_0.jpg",
        "test_141_1.jpg",
        "test_141_2.jpg",
        "test_141_3.jpg",
        "test_141_4.jpg",
        "test_141_5.jpg",
        "test_141_6.jpg",
        "test_141_7.jpg",
        "test_141_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          2,
          1,
          5,
          6,
          3,
          4,
          7,
          8
        ],
        "order_filenames": [
          "test_141_0.jpg",
          "test_141_2.jpg",
          "test_141_1.jpg",
          "test_141_5.jpg",
          "test_141_6.jpg",
          "test_141_3.jpg",
          "test_141_4.jpg",
          "test_141_7.jpg",
          "test_141_8.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_141_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_141_0.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_141_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2054443359375,
            0.2039794921875,
            0.265625,
            0.17724609375,
            0.1856689453125,
            0.15771484375,
            0.2164306640625,
            0.249267578125,
            0.1766357421875
          ],
          "order_indices": [
            2,
            7,
            6,
            0,
            1,
            4,
            3,
            8,
            5
          ],
          "order_filenames": [
            "test_141_2.jpg",
            "test_141_7.jpg",
            "test_141_6.jpg",
            "test_141_0.jpg",
            "test_141_1.jpg",
            "test_141_4.jpg",
            "test_141_3.jpg",
            "test_141_8.jpg",
            "test_141_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.31666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.3125,
            36.375,
            44.25,
            27.484375,
            28.453125,
            35.96875,
            37.3125,
            38.0,
            36.34375
          ],
          "order_indices": [
            2,
            7,
            6,
            1,
            8,
            5,
            0,
            4,
            3
          ],
          "order_filenames": [
            "test_141_2.jpg",
            "test_141_7.jpg",
            "test_141_6.jpg",
            "test_141_1.jpg",
            "test_141_8.jpg",
            "test_141_5.jpg",
            "test_141_0.jpg",
            "test_141_4.jpg",
            "test_141_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.09999999999999998,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.6944999098777771,
            0.7643097639083862,
            0.8183882236480713,
            -0.9131758809089661,
            -0.806268036365509,
            -0.3223240077495575,
            0.8031824231147766,
            1.4546266794204712,
            0.5562148690223694
          ],
          "order_indices": [
            7,
            2,
            6,
            1,
            0,
            8,
            5,
            4,
            3
          ],
          "order_filenames": [
            "test_141_7.jpg",
            "test_141_2.jpg",
            "test_141_6.jpg",
            "test_141_1.jpg",
            "test_141_0.jpg",
            "test_141_8.jpg",
            "test_141_5.jpg",
            "test_141_4.jpg",
            "test_141_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 142,
      "prompt": "A warrior in glowing azure plate armor stands in a doorway to hell sliced by iridescent glass cracks, with crimson clouds and an art deco palace backdrop.",
      "image_filenames": [
        "test_142_0.jpg",
        "test_142_1.jpg",
        "test_142_2.jpg",
        "test_142_3.jpg",
        "test_142_4.jpg",
        "test_142_5.jpg",
        "test_142_6.jpg",
        "test_142_7.jpg",
        "test_142_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          5,
          1,
          6,
          2,
          8,
          7,
          4,
          0
        ],
        "order_filenames": [
          "test_142_3.jpg",
          "test_142_5.jpg",
          "test_142_1.jpg",
          "test_142_6.jpg",
          "test_142_2.jpg",
          "test_142_8.jpg",
          "test_142_7.jpg",
          "test_142_4.jpg",
          "test_142_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_142_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_142_1.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_142_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.271728515625,
            0.2041015625,
            0.2626953125,
            0.178466796875,
            0.17333984375,
            0.1180419921875,
            0.2095947265625,
            0.247314453125,
            0.266357421875
          ],
          "order_indices": [
            0,
            8,
            2,
            7,
            6,
            1,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_142_0.jpg",
            "test_142_8.jpg",
            "test_142_2.jpg",
            "test_142_7.jpg",
            "test_142_6.jpg",
            "test_142_1.jpg",
            "test_142_3.jpg",
            "test_142_4.jpg",
            "test_142_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.5666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.96875,
            38.03125,
            42.96875,
            24.46875,
            26.1875,
            20.84375,
            31.96875,
            38.78125,
            45.78125
          ],
          "order_indices": [
            8,
            2,
            0,
            7,
            1,
            6,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_142_8.jpg",
            "test_142_2.jpg",
            "test_142_0.jpg",
            "test_142_7.jpg",
            "test_142_1.jpg",
            "test_142_6.jpg",
            "test_142_4.jpg",
            "test_142_3.jpg",
            "test_142_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.55,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.2303460836410522,
            0.7529914975166321,
            0.8850612044334412,
            -1.0704598426818848,
            -0.2966039180755615,
            -1.8796494007110596,
            0.05712457001209259,
            1.1216487884521484,
            1.6867961883544922
          ],
          "order_indices": [
            8,
            0,
            7,
            2,
            1,
            6,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_142_8.jpg",
            "test_142_0.jpg",
            "test_142_7.jpg",
            "test_142_2.jpg",
            "test_142_1.jpg",
            "test_142_6.jpg",
            "test_142_4.jpg",
            "test_142_3.jpg",
            "test_142_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.6499999999999999,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 143,
      "prompt": "A male elf wearing heavy armor with a cape and a weathered face portrayed in detailed, smooth illustration.",
      "image_filenames": [
        "test_143_0.jpg",
        "test_143_1.jpg",
        "test_143_2.jpg",
        "test_143_3.jpg",
        "test_143_4.jpg",
        "test_143_5.jpg",
        "test_143_6.jpg",
        "test_143_7.jpg",
        "test_143_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          5,
          3,
          1,
          2,
          6,
          7,
          0,
          8
        ],
        "order_filenames": [
          "test_143_4.jpg",
          "test_143_5.jpg",
          "test_143_3.jpg",
          "test_143_1.jpg",
          "test_143_2.jpg",
          "test_143_6.jpg",
          "test_143_7.jpg",
          "test_143_0.jpg",
          "test_143_8.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_143_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4,
            5
          ],
          "winner_filenames": [
            "test_143_4.jpg",
            "test_143_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_143_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1697998046875,
            0.295166015625,
            0.21484375,
            0.204833984375,
            0.2017822265625,
            0.0693359375,
            0.268310546875,
            0.193115234375,
            0.26708984375
          ],
          "order_indices": [
            1,
            6,
            8,
            2,
            3,
            4,
            7,
            0,
            5
          ],
          "order_filenames": [
            "test_143_1.jpg",
            "test_143_6.jpg",
            "test_143_8.jpg",
            "test_143_2.jpg",
            "test_143_3.jpg",
            "test_143_4.jpg",
            "test_143_7.jpg",
            "test_143_0.jpg",
            "test_143_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.16666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            32.375,
            33.6875,
            33.90625,
            31.796875,
            26.71875,
            17.484375,
            33.65625,
            30.75,
            34.6875
          ],
          "order_indices": [
            8,
            2,
            1,
            6,
            0,
            3,
            7,
            4,
            5
          ],
          "order_filenames": [
            "test_143_8.jpg",
            "test_143_2.jpg",
            "test_143_1.jpg",
            "test_143_6.jpg",
            "test_143_0.jpg",
            "test_143_3.jpg",
            "test_143_7.jpg",
            "test_143_4.jpg",
            "test_143_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.6166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.7384628057479858,
            -0.9262042045593262,
            -0.4999179244041443,
            -0.6077880263328552,
            -1.0605837106704712,
            -2.2791967391967773,
            -0.26419201493263245,
            -1.371409296989441,
            0.5876754522323608
          ],
          "order_indices": [
            8,
            6,
            2,
            3,
            0,
            1,
            4,
            7,
            5
          ],
          "order_filenames": [
            "test_143_8.jpg",
            "test_143_6.jpg",
            "test_143_2.jpg",
            "test_143_3.jpg",
            "test_143_0.jpg",
            "test_143_1.jpg",
            "test_143_4.jpg",
            "test_143_7.jpg",
            "test_143_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.5333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 144,
      "prompt": "A digital painting by Loish featuring a rush of half-body, cyberpunk androids and cyborgs adorned with intricate jewelry and colorful holographic dreads.",
      "image_filenames": [
        "test_144_0.jpg",
        "test_144_1.jpg",
        "test_144_2.jpg",
        "test_144_3.jpg",
        "test_144_4.jpg",
        "test_144_5.jpg",
        "test_144_6.jpg",
        "test_144_7.jpg",
        "test_144_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          0,
          5,
          7,
          1,
          3,
          8,
          2,
          4
        ],
        "order_filenames": [
          "test_144_6.jpg",
          "test_144_0.jpg",
          "test_144_5.jpg",
          "test_144_7.jpg",
          "test_144_1.jpg",
          "test_144_3.jpg",
          "test_144_8.jpg",
          "test_144_2.jpg",
          "test_144_4.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_144_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_144_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_144_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1932373046875,
            0.33154296875,
            0.2415771484375,
            0.220458984375,
            0.197265625,
            0.1358642578125,
            0.268310546875,
            0.299560546875,
            0.279296875
          ],
          "order_indices": [
            1,
            7,
            8,
            6,
            2,
            3,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_144_1.jpg",
            "test_144_7.jpg",
            "test_144_8.jpg",
            "test_144_6.jpg",
            "test_144_2.jpg",
            "test_144_3.jpg",
            "test_144_4.jpg",
            "test_144_0.jpg",
            "test_144_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.08333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.625,
            36.71875,
            42.6875,
            28.578125,
            26.3125,
            24.09375,
            37.09375,
            43.96875,
            35.375
          ],
          "order_indices": [
            7,
            2,
            0,
            6,
            1,
            8,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_144_7.jpg",
            "test_144_2.jpg",
            "test_144_0.jpg",
            "test_144_6.jpg",
            "test_144_1.jpg",
            "test_144_8.jpg",
            "test_144_3.jpg",
            "test_144_4.jpg",
            "test_144_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.21666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.13182035088539124,
            0.6685997843742371,
            1.163872241973877,
            -0.06906499713659286,
            0.0419623926281929,
            -1.6788461208343506,
            0.5846017003059387,
            0.40942955017089844,
            0.4338884651660919
          ],
          "order_indices": [
            2,
            1,
            6,
            8,
            7,
            4,
            3,
            0,
            5
          ],
          "order_filenames": [
            "test_144_2.jpg",
            "test_144_1.jpg",
            "test_144_6.jpg",
            "test_144_8.jpg",
            "test_144_7.jpg",
            "test_144_4.jpg",
            "test_144_3.jpg",
            "test_144_0.jpg",
            "test_144_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.28333333333333344,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 145,
      "prompt": "An investigator fights a tentacled monster in a finely detailed horror film still.",
      "image_filenames": [
        "test_145_0.jpg",
        "test_145_1.jpg",
        "test_145_2.jpg",
        "test_145_3.jpg",
        "test_145_4.jpg",
        "test_145_5.jpg",
        "test_145_6.jpg",
        "test_145_7.jpg",
        "test_145_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          1,
          6,
          4,
          7,
          8,
          5,
          3,
          2
        ],
        "order_filenames": [
          "test_145_0.jpg",
          "test_145_1.jpg",
          "test_145_6.jpg",
          "test_145_4.jpg",
          "test_145_7.jpg",
          "test_145_8.jpg",
          "test_145_5.jpg",
          "test_145_3.jpg",
          "test_145_2.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_145_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_145_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_145_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2076416015625,
            0.2281494140625,
            0.23291015625,
            0.1337890625,
            0.181884765625,
            0.125,
            0.1949462890625,
            0.221923828125,
            0.1895751953125
          ],
          "order_indices": [
            2,
            1,
            7,
            0,
            6,
            8,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_145_2.jpg",
            "test_145_1.jpg",
            "test_145_7.jpg",
            "test_145_0.jpg",
            "test_145_6.jpg",
            "test_145_8.jpg",
            "test_145_4.jpg",
            "test_145_3.jpg",
            "test_145_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.21666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            42.53125,
            40.21875,
            40.03125,
            23.015625,
            29.96875,
            24.28125,
            36.84375,
            44.4375,
            34.0625
          ],
          "order_indices": [
            7,
            0,
            1,
            2,
            6,
            8,
            4,
            5,
            3
          ],
          "order_filenames": [
            "test_145_7.jpg",
            "test_145_0.jpg",
            "test_145_1.jpg",
            "test_145_2.jpg",
            "test_145_6.jpg",
            "test_145_8.jpg",
            "test_145_4.jpg",
            "test_145_5.jpg",
            "test_145_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.4444444444444444,
            "spearman_rho": 0.5166666666666666,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.2168901562690735,
            0.3397722542285919,
            -0.40715232491493225,
            -0.3450057804584503,
            -0.8221750259399414,
            -1.3212072849273682,
            0.6861844062805176,
            0.6016328930854797,
            -1.164162278175354
          ],
          "order_indices": [
            6,
            7,
            1,
            0,
            3,
            2,
            4,
            8,
            5
          ],
          "order_filenames": [
            "test_145_6.jpg",
            "test_145_7.jpg",
            "test_145_1.jpg",
            "test_145_0.jpg",
            "test_145_3.jpg",
            "test_145_2.jpg",
            "test_145_4.jpg",
            "test_145_8.jpg",
            "test_145_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.5166666666666666,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 146,
      "prompt": "The image is a close up portrait of a man and a girl, with vibrant colors and a thermal background, resembling the style of Francis Bacon.",
      "image_filenames": [
        "test_146_0.jpg",
        "test_146_1.jpg",
        "test_146_2.jpg",
        "test_146_3.jpg",
        "test_146_4.jpg",
        "test_146_5.jpg",
        "test_146_6.jpg",
        "test_146_7.jpg",
        "test_146_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          1,
          3,
          5,
          6,
          4,
          8,
          2,
          0
        ],
        "order_filenames": [
          "test_146_7.jpg",
          "test_146_1.jpg",
          "test_146_3.jpg",
          "test_146_5.jpg",
          "test_146_6.jpg",
          "test_146_4.jpg",
          "test_146_8.jpg",
          "test_146_2.jpg",
          "test_146_0.jpg"
        ],
        "condorcet_winner": 7,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_146_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_146_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_146_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1832275390625,
            0.205078125,
            0.278076171875,
            0.15869140625,
            0.22216796875,
            0.107177734375,
            0.229736328125,
            0.274658203125,
            0.2841796875
          ],
          "order_indices": [
            8,
            2,
            7,
            6,
            4,
            1,
            0,
            3,
            5
          ],
          "order_filenames": [
            "test_146_8.jpg",
            "test_146_2.jpg",
            "test_146_7.jpg",
            "test_146_6.jpg",
            "test_146_4.jpg",
            "test_146_1.jpg",
            "test_146_0.jpg",
            "test_146_3.jpg",
            "test_146_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.2333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            41.5625,
            42.5,
            47.375,
            29.46875,
            32.0625,
            21.4375,
            39.0,
            46.375,
            41.4375
          ],
          "order_indices": [
            2,
            7,
            1,
            0,
            8,
            6,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_146_2.jpg",
            "test_146_7.jpg",
            "test_146_1.jpg",
            "test_146_0.jpg",
            "test_146_8.jpg",
            "test_146_6.jpg",
            "test_146_4.jpg",
            "test_146_3.jpg",
            "test_146_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.10000000000000009,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.783257007598877,
            -0.8119151592254639,
            0.3343527317047119,
            -1.0714287757873535,
            -0.4269627034664154,
            -2.2549095153808594,
            -0.6386152505874634,
            1.377087116241455,
            0.8546971678733826
          ],
          "order_indices": [
            7,
            8,
            2,
            4,
            6,
            0,
            1,
            3,
            5
          ],
          "order_filenames": [
            "test_146_7.jpg",
            "test_146_8.jpg",
            "test_146_2.jpg",
            "test_146_4.jpg",
            "test_146_6.jpg",
            "test_146_0.jpg",
            "test_146_1.jpg",
            "test_146_3.jpg",
            "test_146_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.1499999999999999,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 1.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 147,
      "prompt": "An intricate and elegant art deco-inspired metropolis with retrofuturistic elements in a cyberpunk style.",
      "image_filenames": [
        "test_147_0.jpg",
        "test_147_1.jpg",
        "test_147_2.jpg",
        "test_147_3.jpg",
        "test_147_4.jpg",
        "test_147_5.jpg",
        "test_147_6.jpg",
        "test_147_7.jpg",
        "test_147_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          2,
          1,
          3,
          6,
          5,
          8,
          4,
          7
        ],
        "order_filenames": [
          "test_147_0.jpg",
          "test_147_2.jpg",
          "test_147_1.jpg",
          "test_147_3.jpg",
          "test_147_6.jpg",
          "test_147_5.jpg",
          "test_147_8.jpg",
          "test_147_4.jpg",
          "test_147_7.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_147_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            1,
            3
          ],
          "winner_filenames": [
            "test_147_1.jpg",
            "test_147_3.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0,
            2
          ],
          "winner_filenames": [
            "test_147_0.jpg",
            "test_147_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2486572265625,
            0.232177734375,
            0.290283203125,
            0.20703125,
            0.229248046875,
            0.1817626953125,
            0.24462890625,
            0.2496337890625,
            0.2071533203125
          ],
          "order_indices": [
            2,
            7,
            0,
            6,
            1,
            4,
            8,
            3,
            5
          ],
          "order_filenames": [
            "test_147_2.jpg",
            "test_147_7.jpg",
            "test_147_0.jpg",
            "test_147_6.jpg",
            "test_147_1.jpg",
            "test_147_4.jpg",
            "test_147_8.jpg",
            "test_147_3.jpg",
            "test_147_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.2666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.96875,
            33.4375,
            35.78125,
            25.84375,
            34.5,
            21.96875,
            41.1875,
            38.0,
            32.5
          ],
          "order_indices": [
            6,
            0,
            7,
            2,
            4,
            1,
            8,
            3,
            5
          ],
          "order_filenames": [
            "test_147_6.jpg",
            "test_147_0.jpg",
            "test_147_7.jpg",
            "test_147_2.jpg",
            "test_147_4.jpg",
            "test_147_1.jpg",
            "test_147_8.jpg",
            "test_147_3.jpg",
            "test_147_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.16666666666666663,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.6305119395256042,
            0.3891696035861969,
            0.7187390327453613,
            0.08296623080968857,
            0.4059799611568451,
            -0.8663173317909241,
            0.3910384178161621,
            0.3338627219200134,
            -0.07792139053344727
          ],
          "order_indices": [
            2,
            0,
            4,
            6,
            1,
            7,
            3,
            8,
            5
          ],
          "order_filenames": [
            "test_147_2.jpg",
            "test_147_0.jpg",
            "test_147_4.jpg",
            "test_147_6.jpg",
            "test_147_1.jpg",
            "test_147_7.jpg",
            "test_147_3.jpg",
            "test_147_8.jpg",
            "test_147_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.5,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 148,
      "prompt": "American cowboy with a scruffy appearance in a retrofuturistic style, inspired by the animations of Studio Ghibli.",
      "image_filenames": [
        "test_148_0.jpg",
        "test_148_1.jpg",
        "test_148_2.jpg",
        "test_148_3.jpg",
        "test_148_4.jpg",
        "test_148_5.jpg",
        "test_148_6.jpg",
        "test_148_7.jpg",
        "test_148_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          1,
          5,
          2,
          3,
          7,
          6,
          8,
          0
        ],
        "order_filenames": [
          "test_148_4.jpg",
          "test_148_1.jpg",
          "test_148_5.jpg",
          "test_148_2.jpg",
          "test_148_3.jpg",
          "test_148_7.jpg",
          "test_148_6.jpg",
          "test_148_8.jpg",
          "test_148_0.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_148_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_148_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_148_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1898193359375,
            0.2301025390625,
            0.259521484375,
            0.162353515625,
            0.1951904296875,
            0.09393310546875,
            0.2117919921875,
            0.2313232421875,
            0.2607421875
          ],
          "order_indices": [
            8,
            2,
            7,
            1,
            6,
            4,
            0,
            3,
            5
          ],
          "order_filenames": [
            "test_148_8.jpg",
            "test_148_2.jpg",
            "test_148_7.jpg",
            "test_148_1.jpg",
            "test_148_6.jpg",
            "test_148_4.jpg",
            "test_148_0.jpg",
            "test_148_3.jpg",
            "test_148_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.19999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            41.125,
            38.53125,
            41.0625,
            30.578125,
            26.75,
            17.890625,
            40.0625,
            39.84375,
            33.53125
          ],
          "order_indices": [
            0,
            2,
            6,
            7,
            1,
            8,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_148_0.jpg",
            "test_148_2.jpg",
            "test_148_6.jpg",
            "test_148_7.jpg",
            "test_148_1.jpg",
            "test_148_8.jpg",
            "test_148_3.jpg",
            "test_148_4.jpg",
            "test_148_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.5833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.2570244073867798,
            -0.21255747973918915,
            0.27547329664230347,
            -0.8850804567337036,
            -0.30636128783226013,
            -2.221508502960205,
            -0.3796823024749756,
            1.2082867622375488,
            0.5858757495880127
          ],
          "order_indices": [
            7,
            8,
            2,
            1,
            0,
            4,
            6,
            3,
            5
          ],
          "order_filenames": [
            "test_148_7.jpg",
            "test_148_8.jpg",
            "test_148_2.jpg",
            "test_148_1.jpg",
            "test_148_0.jpg",
            "test_148_4.jpg",
            "test_148_6.jpg",
            "test_148_3.jpg",
            "test_148_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.2666666666666666,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 149,
      "prompt": "A dragon standing in a forest, drinking river water.",
      "image_filenames": [
        "test_149_0.jpg",
        "test_149_1.jpg",
        "test_149_2.jpg",
        "test_149_3.jpg",
        "test_149_4.jpg",
        "test_149_5.jpg",
        "test_149_6.jpg",
        "test_149_7.jpg",
        "test_149_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          3,
          1,
          4,
          8,
          7,
          5,
          0,
          6
        ],
        "order_filenames": [
          "test_149_2.jpg",
          "test_149_3.jpg",
          "test_149_1.jpg",
          "test_149_4.jpg",
          "test_149_8.jpg",
          "test_149_7.jpg",
          "test_149_5.jpg",
          "test_149_0.jpg",
          "test_149_6.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_149_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3,
            4
          ],
          "winner_filenames": [
            "test_149_3.jpg",
            "test_149_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_149_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.21826171875,
            0.306884765625,
            0.28076171875,
            0.18798828125,
            0.188232421875,
            0.2308349609375,
            0.302001953125,
            0.248046875,
            0.2467041015625
          ],
          "order_indices": [
            1,
            6,
            2,
            7,
            8,
            5,
            0,
            4,
            3
          ],
          "order_filenames": [
            "test_149_1.jpg",
            "test_149_6.jpg",
            "test_149_2.jpg",
            "test_149_7.jpg",
            "test_149_8.jpg",
            "test_149_5.jpg",
            "test_149_0.jpg",
            "test_149_4.jpg",
            "test_149_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.84375,
            37.84375,
            41.1875,
            32.53125,
            25.4375,
            33.46875,
            40.0,
            40.5625,
            37.5
          ],
          "order_indices": [
            2,
            7,
            6,
            0,
            1,
            8,
            5,
            3,
            4
          ],
          "order_filenames": [
            "test_149_2.jpg",
            "test_149_7.jpg",
            "test_149_6.jpg",
            "test_149_0.jpg",
            "test_149_1.jpg",
            "test_149_8.jpg",
            "test_149_5.jpg",
            "test_149_3.jpg",
            "test_149_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.1166666666666667,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.9985247850418091,
            1.6043145656585693,
            1.53445303440094,
            -0.2580156624317169,
            -0.7608843445777893,
            -0.6029730439186096,
            1.866106390953064,
            1.3324400186538696,
            -0.31123223900794983
          ],
          "order_indices": [
            6,
            1,
            2,
            7,
            0,
            3,
            8,
            5,
            4
          ],
          "order_filenames": [
            "test_149_6.jpg",
            "test_149_1.jpg",
            "test_149_2.jpg",
            "test_149_7.jpg",
            "test_149_0.jpg",
            "test_149_3.jpg",
            "test_149_8.jpg",
            "test_149_5.jpg",
            "test_149_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 150,
      "prompt": "White lines depict topography on a black background.",
      "image_filenames": [
        "test_150_0.jpg",
        "test_150_1.jpg",
        "test_150_2.jpg",
        "test_150_3.jpg",
        "test_150_4.jpg",
        "test_150_5.jpg",
        "test_150_6.jpg",
        "test_150_7.jpg",
        "test_150_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          8,
          4,
          0,
          2,
          3,
          6,
          7,
          5,
          1
        ],
        "order_filenames": [
          "test_150_8.jpg",
          "test_150_4.jpg",
          "test_150_0.jpg",
          "test_150_2.jpg",
          "test_150_3.jpg",
          "test_150_6.jpg",
          "test_150_7.jpg",
          "test_150_5.jpg",
          "test_150_1.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          8
        ],
        "winner_filenames": [
          "test_150_8.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_150_0.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3,
            4
          ],
          "winner_filenames": [
            "test_150_3.jpg",
            "test_150_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.19384765625,
            0.2095947265625,
            0.2196044921875,
            0.187255859375,
            0.1885986328125,
            0.1585693359375,
            0.2020263671875,
            0.2308349609375,
            0.2445068359375
          ],
          "order_indices": [
            8,
            7,
            2,
            1,
            6,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_150_8.jpg",
            "test_150_7.jpg",
            "test_150_2.jpg",
            "test_150_1.jpg",
            "test_150_6.jpg",
            "test_150_0.jpg",
            "test_150_4.jpg",
            "test_150_3.jpg",
            "test_150_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.19999999999999996,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            27.171875,
            32.90625,
            29.78125,
            24.15625,
            15.203125,
            12.859375,
            34.40625,
            31.5,
            43.03125
          ],
          "order_indices": [
            8,
            6,
            1,
            7,
            2,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_150_8.jpg",
            "test_150_6.jpg",
            "test_150_1.jpg",
            "test_150_7.jpg",
            "test_150_2.jpg",
            "test_150_0.jpg",
            "test_150_3.jpg",
            "test_150_4.jpg",
            "test_150_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.06666666666666665,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.2770869731903076,
            0.34051692485809326,
            -0.6323569416999817,
            -1.4441752433776855,
            -2.04789662361145,
            -1.862912654876709,
            -0.4717371463775635,
            -1.2563716173171997,
            0.9286198019981384
          ],
          "order_indices": [
            8,
            1,
            6,
            2,
            7,
            0,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_150_8.jpg",
            "test_150_1.jpg",
            "test_150_6.jpg",
            "test_150_2.jpg",
            "test_150_7.jpg",
            "test_150_0.jpg",
            "test_150_3.jpg",
            "test_150_5.jpg",
            "test_150_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.03333333333333344,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 151,
      "prompt": "A planisphere lavalamp glows inside a glass jar buried in sand with swirling mist around it.",
      "image_filenames": [
        "test_151_0.jpg",
        "test_151_1.jpg",
        "test_151_2.jpg",
        "test_151_3.jpg",
        "test_151_4.jpg",
        "test_151_5.jpg",
        "test_151_6.jpg",
        "test_151_7.jpg",
        "test_151_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          3,
          4,
          5,
          2,
          6,
          8,
          7,
          0
        ],
        "order_filenames": [
          "test_151_1.jpg",
          "test_151_3.jpg",
          "test_151_4.jpg",
          "test_151_5.jpg",
          "test_151_2.jpg",
          "test_151_6.jpg",
          "test_151_8.jpg",
          "test_151_7.jpg",
          "test_151_0.jpg"
        ],
        "condorcet_winner": 1,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_151_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_151_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_151_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2469482421875,
            0.278076171875,
            0.273681640625,
            0.1953125,
            0.174072265625,
            0.174072265625,
            0.2276611328125,
            0.2459716796875,
            0.1917724609375
          ],
          "order_indices": [
            1,
            2,
            0,
            7,
            6,
            3,
            8,
            4,
            5
          ],
          "order_filenames": [
            "test_151_1.jpg",
            "test_151_2.jpg",
            "test_151_0.jpg",
            "test_151_7.jpg",
            "test_151_6.jpg",
            "test_151_3.jpg",
            "test_151_8.jpg",
            "test_151_4.jpg",
            "test_151_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.06666666666666665,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 1.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            43.8125,
            32.625,
            41.59375,
            30.328125,
            26.703125,
            29.640625,
            29.453125,
            37.21875,
            36.84375
          ],
          "order_indices": [
            0,
            2,
            7,
            8,
            1,
            3,
            5,
            6,
            4
          ],
          "order_filenames": [
            "test_151_0.jpg",
            "test_151_2.jpg",
            "test_151_7.jpg",
            "test_151_8.jpg",
            "test_151_1.jpg",
            "test_151_3.jpg",
            "test_151_5.jpg",
            "test_151_6.jpg",
            "test_151_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.5666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.5612523555755615,
            -0.7646992206573486,
            1.3483998775482178,
            -0.9212740063667297,
            0.029387664049863815,
            -1.0013264417648315,
            -0.1132901981472969,
            1.405376672744751,
            0.7289344668388367
          ],
          "order_indices": [
            0,
            7,
            2,
            8,
            4,
            6,
            1,
            3,
            5
          ],
          "order_filenames": [
            "test_151_0.jpg",
            "test_151_7.jpg",
            "test_151_2.jpg",
            "test_151_8.jpg",
            "test_151_4.jpg",
            "test_151_6.jpg",
            "test_151_1.jpg",
            "test_151_3.jpg",
            "test_151_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.6111111111111112,
            "spearman_rho": -0.7833333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 152,
      "prompt": "A full-body wide-angle photo of a wooden art doll by Agostino Arrivabene, depicting a peaceful sleeping pose.",
      "image_filenames": [
        "test_152_0.jpg",
        "test_152_1.jpg",
        "test_152_2.jpg",
        "test_152_3.jpg",
        "test_152_4.jpg",
        "test_152_5.jpg",
        "test_152_6.jpg",
        "test_152_7.jpg",
        "test_152_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          5,
          4,
          6,
          1,
          0,
          8,
          2,
          7
        ],
        "order_filenames": [
          "test_152_3.jpg",
          "test_152_5.jpg",
          "test_152_4.jpg",
          "test_152_6.jpg",
          "test_152_1.jpg",
          "test_152_0.jpg",
          "test_152_8.jpg",
          "test_152_2.jpg",
          "test_152_7.jpg"
        ],
        "condorcet_winner": 3,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_152_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_152_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_152_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1888427734375,
            0.1846923828125,
            0.1866455078125,
            0.148193359375,
            0.169677734375,
            0.11456298828125,
            0.2059326171875,
            0.1898193359375,
            0.19091796875
          ],
          "order_indices": [
            6,
            8,
            7,
            0,
            2,
            1,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_152_6.jpg",
            "test_152_8.jpg",
            "test_152_7.jpg",
            "test_152_0.jpg",
            "test_152_2.jpg",
            "test_152_1.jpg",
            "test_152_4.jpg",
            "test_152_3.jpg",
            "test_152_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.6499999999999999,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.53125,
            30.234375,
            38.59375,
            23.15625,
            33.84375,
            23.421875,
            33.25,
            36.4375,
            26.875
          ],
          "order_indices": [
            0,
            2,
            7,
            4,
            6,
            1,
            8,
            5,
            3
          ],
          "order_filenames": [
            "test_152_0.jpg",
            "test_152_2.jpg",
            "test_152_7.jpg",
            "test_152_4.jpg",
            "test_152_6.jpg",
            "test_152_1.jpg",
            "test_152_8.jpg",
            "test_152_5.jpg",
            "test_152_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.6666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.3872319757938385,
            -1.0468288660049438,
            -0.3593115210533142,
            -1.3691177368164062,
            -0.04779259115457535,
            -1.955000638961792,
            0.6337139010429382,
            -1.2423111200332642,
            -1.0614814758300781
          ],
          "order_indices": [
            6,
            0,
            4,
            2,
            1,
            8,
            7,
            3,
            5
          ],
          "order_filenames": [
            "test_152_6.jpg",
            "test_152_0.jpg",
            "test_152_4.jpg",
            "test_152_2.jpg",
            "test_152_1.jpg",
            "test_152_8.jpg",
            "test_152_7.jpg",
            "test_152_3.jpg",
            "test_152_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.19999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 153,
      "prompt": "A photorealistic 3D render of wooly mammoths grazing in a surreal mystical forest with a bright winding blue creek.",
      "image_filenames": [
        "test_153_0.jpg",
        "test_153_1.jpg",
        "test_153_2.jpg",
        "test_153_3.jpg",
        "test_153_4.jpg",
        "test_153_5.jpg",
        "test_153_6.jpg",
        "test_153_7.jpg",
        "test_153_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          0,
          3,
          8,
          4,
          5,
          1,
          2,
          6
        ],
        "order_filenames": [
          "test_153_7.jpg",
          "test_153_0.jpg",
          "test_153_3.jpg",
          "test_153_8.jpg",
          "test_153_4.jpg",
          "test_153_5.jpg",
          "test_153_1.jpg",
          "test_153_2.jpg",
          "test_153_6.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_153_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_153_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_153_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1802978515625,
            0.26806640625,
            0.261474609375,
            0.200439453125,
            0.2105712890625,
            0.21142578125,
            0.255615234375,
            0.2418212890625,
            0.291015625
          ],
          "order_indices": [
            8,
            1,
            2,
            6,
            7,
            5,
            4,
            3,
            0
          ],
          "order_filenames": [
            "test_153_8.jpg",
            "test_153_1.jpg",
            "test_153_2.jpg",
            "test_153_6.jpg",
            "test_153_7.jpg",
            "test_153_5.jpg",
            "test_153_4.jpg",
            "test_153_3.jpg",
            "test_153_0.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.4833333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.09375,
            38.125,
            35.0,
            39.46875,
            36.9375,
            30.375,
            38.53125,
            41.46875,
            44.6875
          ],
          "order_indices": [
            8,
            7,
            3,
            6,
            1,
            0,
            4,
            2,
            5
          ],
          "order_filenames": [
            "test_153_8.jpg",
            "test_153_7.jpg",
            "test_153_3.jpg",
            "test_153_6.jpg",
            "test_153_1.jpg",
            "test_153_0.jpg",
            "test_153_4.jpg",
            "test_153_2.jpg",
            "test_153_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2777777777777778,
            "spearman_rho": 0.43333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.155565857887268,
            1.1043260097503662,
            -0.21778646111488342,
            -0.10951711237430573,
            -0.3833281993865967,
            -0.6963269114494324,
            -0.7428621649742126,
            0.7520322799682617,
            1.298513650894165
          ],
          "order_indices": [
            8,
            1,
            7,
            3,
            2,
            4,
            5,
            6,
            0
          ],
          "order_filenames": [
            "test_153_8.jpg",
            "test_153_1.jpg",
            "test_153_7.jpg",
            "test_153_3.jpg",
            "test_153_2.jpg",
            "test_153_4.jpg",
            "test_153_5.jpg",
            "test_153_6.jpg",
            "test_153_0.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.16666666666666663,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 154,
      "prompt": "A portrait of a zebra with super detailed eyes and nose by various artists, posted on art platforms.",
      "image_filenames": [
        "test_154_0.jpg",
        "test_154_1.jpg",
        "test_154_2.jpg",
        "test_154_3.jpg",
        "test_154_4.jpg",
        "test_154_5.jpg",
        "test_154_6.jpg",
        "test_154_7.jpg",
        "test_154_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          2,
          5,
          4,
          3,
          6,
          7,
          8,
          0
        ],
        "order_filenames": [
          "test_154_1.jpg",
          "test_154_2.jpg",
          "test_154_5.jpg",
          "test_154_4.jpg",
          "test_154_3.jpg",
          "test_154_6.jpg",
          "test_154_7.jpg",
          "test_154_8.jpg",
          "test_154_0.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          1,
          2
        ],
        "winner_filenames": [
          "test_154_1.jpg",
          "test_154_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_154_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_154_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.189453125,
            0.2427978515625,
            0.2447509765625,
            0.210205078125,
            0.196533203125,
            0.14501953125,
            0.1793212890625,
            0.2177734375,
            0.248046875
          ],
          "order_indices": [
            8,
            2,
            1,
            7,
            3,
            4,
            0,
            6,
            5
          ],
          "order_filenames": [
            "test_154_8.jpg",
            "test_154_2.jpg",
            "test_154_1.jpg",
            "test_154_7.jpg",
            "test_154_3.jpg",
            "test_154_4.jpg",
            "test_154_0.jpg",
            "test_154_6.jpg",
            "test_154_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.08333333333333337,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            31.046875,
            33.71875,
            41.0,
            31.609375,
            23.828125,
            30.140625,
            27.3125,
            38.59375,
            38.34375
          ],
          "order_indices": [
            2,
            7,
            8,
            1,
            3,
            0,
            5,
            6,
            4
          ],
          "order_filenames": [
            "test_154_2.jpg",
            "test_154_7.jpg",
            "test_154_8.jpg",
            "test_154_1.jpg",
            "test_154_3.jpg",
            "test_154_0.jpg",
            "test_154_5.jpg",
            "test_154_6.jpg",
            "test_154_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.050000000000000044,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.14958137273788452,
            -0.0063911615870893,
            -0.4372994601726532,
            0.3991267681121826,
            -1.716048002243042,
            -2.1816329956054688,
            -1.4226582050323486,
            -0.3905390202999115,
            -0.23271150887012482
          ],
          "order_indices": [
            3,
            1,
            0,
            8,
            7,
            2,
            6,
            4,
            5
          ],
          "order_filenames": [
            "test_154_3.jpg",
            "test_154_1.jpg",
            "test_154_0.jpg",
            "test_154_8.jpg",
            "test_154_7.jpg",
            "test_154_2.jpg",
            "test_154_6.jpg",
            "test_154_4.jpg",
            "test_154_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 155,
      "prompt": "The image is titled \"Queen of the Robots,\" created by artists Greg Rutowski, Victo Ngai, and Alphonse Mucha.",
      "image_filenames": [
        "test_155_0.jpg",
        "test_155_1.jpg",
        "test_155_2.jpg",
        "test_155_3.jpg",
        "test_155_4.jpg",
        "test_155_5.jpg",
        "test_155_6.jpg",
        "test_155_7.jpg",
        "test_155_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          1,
          6,
          7,
          3,
          5,
          2,
          8,
          0
        ],
        "order_filenames": [
          "test_155_4.jpg",
          "test_155_1.jpg",
          "test_155_6.jpg",
          "test_155_7.jpg",
          "test_155_3.jpg",
          "test_155_5.jpg",
          "test_155_2.jpg",
          "test_155_8.jpg",
          "test_155_0.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_155_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_155_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_155_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.170166015625,
            0.1971435546875,
            0.18408203125,
            0.1827392578125,
            0.1708984375,
            0.11358642578125,
            0.2451171875,
            0.2342529296875,
            0.2279052734375
          ],
          "order_indices": [
            6,
            7,
            8,
            1,
            2,
            3,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_155_6.jpg",
            "test_155_7.jpg",
            "test_155_8.jpg",
            "test_155_1.jpg",
            "test_155_2.jpg",
            "test_155_3.jpg",
            "test_155_4.jpg",
            "test_155_0.jpg",
            "test_155_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.2666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.28125,
            36.03125,
            40.90625,
            28.171875,
            25.765625,
            22.0625,
            31.0,
            41.03125,
            38.53125
          ],
          "order_indices": [
            7,
            2,
            8,
            0,
            1,
            6,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_155_7.jpg",
            "test_155_2.jpg",
            "test_155_8.jpg",
            "test_155_0.jpg",
            "test_155_1.jpg",
            "test_155_6.jpg",
            "test_155_3.jpg",
            "test_155_4.jpg",
            "test_155_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.3666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.15206113457679749,
            -0.1310291439294815,
            -0.5558417439460754,
            -0.007704743649810553,
            -0.46046388149261475,
            -0.8186163902282715,
            -0.4885672330856323,
            0.2958085238933563,
            0.49015843868255615
          ],
          "order_indices": [
            8,
            7,
            0,
            3,
            1,
            4,
            6,
            2,
            5
          ],
          "order_filenames": [
            "test_155_8.jpg",
            "test_155_7.jpg",
            "test_155_0.jpg",
            "test_155_3.jpg",
            "test_155_1.jpg",
            "test_155_4.jpg",
            "test_155_6.jpg",
            "test_155_2.jpg",
            "test_155_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.25,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 156,
      "prompt": "Close-up shot of a person running on a treadmill with worn running shoes under dramatic lighting and a comic book-style painting effect.",
      "image_filenames": [
        "test_156_0.jpg",
        "test_156_1.jpg",
        "test_156_2.jpg",
        "test_156_3.jpg",
        "test_156_4.jpg",
        "test_156_5.jpg",
        "test_156_6.jpg",
        "test_156_7.jpg",
        "test_156_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          0,
          4,
          6,
          7,
          3,
          2,
          8,
          1
        ],
        "order_filenames": [
          "test_156_5.jpg",
          "test_156_0.jpg",
          "test_156_4.jpg",
          "test_156_6.jpg",
          "test_156_7.jpg",
          "test_156_3.jpg",
          "test_156_2.jpg",
          "test_156_8.jpg",
          "test_156_1.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_156_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_156_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_156_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1446533203125,
            0.180419921875,
            0.2275390625,
            0.1678466796875,
            0.1483154296875,
            0.0765380859375,
            0.2318115234375,
            0.18359375,
            0.1802978515625
          ],
          "order_indices": [
            6,
            2,
            7,
            1,
            8,
            3,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_156_6.jpg",
            "test_156_2.jpg",
            "test_156_7.jpg",
            "test_156_1.jpg",
            "test_156_8.jpg",
            "test_156_3.jpg",
            "test_156_4.jpg",
            "test_156_0.jpg",
            "test_156_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.5666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.34375,
            28.9375,
            32.15625,
            28.671875,
            23.46875,
            28.75,
            33.71875,
            45.875,
            38.90625
          ],
          "order_indices": [
            7,
            0,
            8,
            6,
            2,
            1,
            5,
            3,
            4
          ],
          "order_filenames": [
            "test_156_7.jpg",
            "test_156_0.jpg",
            "test_156_8.jpg",
            "test_156_6.jpg",
            "test_156_2.jpg",
            "test_156_1.jpg",
            "test_156_5.jpg",
            "test_156_3.jpg",
            "test_156_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.08333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.7929308414459229,
            -0.5506606698036194,
            -0.6130024194717407,
            -1.8739395141601562,
            -0.8371546268463135,
            -2.2381157875061035,
            -0.1357007473707199,
            -0.029415611177682877,
            -1.318354606628418
          ],
          "order_indices": [
            7,
            6,
            1,
            2,
            4,
            8,
            0,
            3,
            5
          ],
          "order_filenames": [
            "test_156_7.jpg",
            "test_156_6.jpg",
            "test_156_1.jpg",
            "test_156_2.jpg",
            "test_156_4.jpg",
            "test_156_8.jpg",
            "test_156_0.jpg",
            "test_156_3.jpg",
            "test_156_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.3833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 157,
      "prompt": "A point and click adventure based on Breaking Bad.",
      "image_filenames": [
        "test_157_0.jpg",
        "test_157_1.jpg",
        "test_157_2.jpg",
        "test_157_3.jpg",
        "test_157_4.jpg",
        "test_157_5.jpg",
        "test_157_6.jpg",
        "test_157_7.jpg",
        "test_157_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          0,
          4,
          6,
          1,
          7,
          3,
          2,
          8
        ],
        "order_filenames": [
          "test_157_5.jpg",
          "test_157_0.jpg",
          "test_157_4.jpg",
          "test_157_6.jpg",
          "test_157_1.jpg",
          "test_157_7.jpg",
          "test_157_3.jpg",
          "test_157_2.jpg",
          "test_157_8.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_157_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_157_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_157_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1680908203125,
            0.1846923828125,
            0.18798828125,
            0.17333984375,
            0.165771484375,
            0.11688232421875,
            0.20703125,
            0.210693359375,
            0.195068359375
          ],
          "order_indices": [
            7,
            6,
            8,
            2,
            1,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_157_7.jpg",
            "test_157_6.jpg",
            "test_157_8.jpg",
            "test_157_2.jpg",
            "test_157_1.jpg",
            "test_157_3.jpg",
            "test_157_0.jpg",
            "test_157_4.jpg",
            "test_157_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.6333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.125,
            29.640625,
            36.71875,
            32.0625,
            24.34375,
            22.390625,
            35.5,
            40.5625,
            26.65625
          ],
          "order_indices": [
            7,
            2,
            6,
            0,
            3,
            1,
            8,
            4,
            5
          ],
          "order_filenames": [
            "test_157_7.jpg",
            "test_157_2.jpg",
            "test_157_6.jpg",
            "test_157_0.jpg",
            "test_157_3.jpg",
            "test_157_1.jpg",
            "test_157_8.jpg",
            "test_157_4.jpg",
            "test_157_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.3666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.4805893301963806,
            -0.11955571174621582,
            -0.9047213792800903,
            -1.3788399696350098,
            -1.718509554862976,
            -2.1074376106262207,
            -0.33344849944114685,
            0.677176833152771,
            -1.0926258563995361
          ],
          "order_indices": [
            7,
            1,
            6,
            0,
            2,
            8,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_157_7.jpg",
            "test_157_1.jpg",
            "test_157_6.jpg",
            "test_157_0.jpg",
            "test_157_2.jpg",
            "test_157_8.jpg",
            "test_157_3.jpg",
            "test_157_4.jpg",
            "test_157_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.21666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 158,
      "prompt": "The image depicts a stunning supernova within a fantasy artwork on Artstation.",
      "image_filenames": [
        "test_158_0.jpg",
        "test_158_1.jpg",
        "test_158_2.jpg",
        "test_158_3.jpg",
        "test_158_4.jpg",
        "test_158_5.jpg",
        "test_158_6.jpg",
        "test_158_7.jpg",
        "test_158_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          5,
          6,
          1,
          3,
          7,
          8,
          0,
          2
        ],
        "order_filenames": [
          "test_158_4.jpg",
          "test_158_5.jpg",
          "test_158_6.jpg",
          "test_158_1.jpg",
          "test_158_3.jpg",
          "test_158_7.jpg",
          "test_158_8.jpg",
          "test_158_0.jpg",
          "test_158_2.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_158_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3,
            5,
            6,
            7
          ],
          "winner_filenames": [
            "test_158_3.jpg",
            "test_158_5.jpg",
            "test_158_6.jpg",
            "test_158_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4,
            5
          ],
          "winner_filenames": [
            "test_158_4.jpg",
            "test_158_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.209228515625,
            0.23828125,
            0.278076171875,
            0.22265625,
            0.1600341796875,
            0.2225341796875,
            0.2763671875,
            0.240966796875,
            0.2744140625
          ],
          "order_indices": [
            2,
            6,
            8,
            7,
            1,
            3,
            5,
            0,
            4
          ],
          "order_filenames": [
            "test_158_2.jpg",
            "test_158_6.jpg",
            "test_158_8.jpg",
            "test_158_7.jpg",
            "test_158_1.jpg",
            "test_158_3.jpg",
            "test_158_5.jpg",
            "test_158_0.jpg",
            "test_158_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.46666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.1875,
            30.15625,
            33.84375,
            32.53125,
            17.828125,
            27.375,
            32.65625,
            35.96875,
            29.4375
          ],
          "order_indices": [
            0,
            7,
            2,
            6,
            3,
            1,
            8,
            5,
            4
          ],
          "order_filenames": [
            "test_158_0.jpg",
            "test_158_7.jpg",
            "test_158_2.jpg",
            "test_158_6.jpg",
            "test_158_3.jpg",
            "test_158_1.jpg",
            "test_158_8.jpg",
            "test_158_5.jpg",
            "test_158_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5555555555555556,
            "spearman_rho": -0.7166666666666666,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.1905735731124878,
            -0.3520398437976837,
            0.7028083205223083,
            0.12006586045026779,
            -2.2096917629241943,
            -0.33606404066085815,
            0.39052921533584595,
            -0.3720296323299408,
            0.3994958698749542
          ],
          "order_indices": [
            2,
            8,
            6,
            0,
            3,
            5,
            1,
            7,
            4
          ],
          "order_filenames": [
            "test_158_2.jpg",
            "test_158_8.jpg",
            "test_158_6.jpg",
            "test_158_0.jpg",
            "test_158_3.jpg",
            "test_158_5.jpg",
            "test_158_1.jpg",
            "test_158_7.jpg",
            "test_158_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.6499999999999999,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 159,
      "prompt": "A surreal restaurant floating on water with architecture resembling Salvador Dal\u00ed's art, depicted in a film directed by Denis Villeneuve.",
      "image_filenames": [
        "test_159_0.jpg",
        "test_159_1.jpg",
        "test_159_2.jpg",
        "test_159_3.jpg",
        "test_159_4.jpg",
        "test_159_5.jpg",
        "test_159_6.jpg",
        "test_159_7.jpg",
        "test_159_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          0,
          5,
          3,
          7,
          6,
          1,
          8,
          4
        ],
        "order_filenames": [
          "test_159_2.jpg",
          "test_159_0.jpg",
          "test_159_5.jpg",
          "test_159_3.jpg",
          "test_159_7.jpg",
          "test_159_6.jpg",
          "test_159_1.jpg",
          "test_159_8.jpg",
          "test_159_4.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_159_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_159_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_159_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.19873046875,
            0.2249755859375,
            0.30419921875,
            0.2415771484375,
            0.2298583984375,
            0.2332763671875,
            0.282958984375,
            0.2459716796875,
            0.2529296875
          ],
          "order_indices": [
            2,
            6,
            8,
            7,
            3,
            5,
            4,
            1,
            0
          ],
          "order_filenames": [
            "test_159_2.jpg",
            "test_159_6.jpg",
            "test_159_8.jpg",
            "test_159_7.jpg",
            "test_159_3.jpg",
            "test_159_5.jpg",
            "test_159_4.jpg",
            "test_159_1.jpg",
            "test_159_0.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.1166666666666667,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.9375,
            38.21875,
            35.25,
            35.34375,
            34.90625,
            36.40625,
            42.5625,
            40.625,
            38.53125
          ],
          "order_indices": [
            6,
            0,
            7,
            8,
            1,
            5,
            3,
            2,
            4
          ],
          "order_filenames": [
            "test_159_6.jpg",
            "test_159_0.jpg",
            "test_159_7.jpg",
            "test_159_8.jpg",
            "test_159_1.jpg",
            "test_159_5.jpg",
            "test_159_3.jpg",
            "test_159_2.jpg",
            "test_159_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.033333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.3901628851890564,
            -0.056844908744096756,
            1.6326353549957275,
            -0.5024946331977844,
            0.5590189695358276,
            -0.3342715799808502,
            1.2234463691711426,
            0.7557187080383301,
            0.6516311168670654
          ],
          "order_indices": [
            2,
            6,
            7,
            8,
            4,
            1,
            5,
            0,
            3
          ],
          "order_filenames": [
            "test_159_2.jpg",
            "test_159_6.jpg",
            "test_159_7.jpg",
            "test_159_8.jpg",
            "test_159_4.jpg",
            "test_159_1.jpg",
            "test_159_5.jpg",
            "test_159_0.jpg",
            "test_159_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.08333333333333326,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 160,
      "prompt": "A highly detailed portrait of Yakuza 0's Goro Majima, featuring a variety of talented artists, created using Unreal Engine and featuring intricate environments.",
      "image_filenames": [
        "test_160_0.jpg",
        "test_160_1.jpg",
        "test_160_2.jpg",
        "test_160_3.jpg",
        "test_160_4.jpg",
        "test_160_5.jpg",
        "test_160_6.jpg",
        "test_160_7.jpg",
        "test_160_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          7,
          1,
          2,
          6,
          0,
          4,
          3,
          8
        ],
        "order_filenames": [
          "test_160_5.jpg",
          "test_160_7.jpg",
          "test_160_1.jpg",
          "test_160_2.jpg",
          "test_160_6.jpg",
          "test_160_0.jpg",
          "test_160_4.jpg",
          "test_160_3.jpg",
          "test_160_8.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_160_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_160_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_160_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.11785888671875,
            0.2364501953125,
            0.2406005859375,
            0.171142578125,
            0.12371826171875,
            0.060211181640625,
            0.30615234375,
            0.24072265625,
            0.27587890625
          ],
          "order_indices": [
            6,
            8,
            7,
            2,
            1,
            3,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_160_6.jpg",
            "test_160_8.jpg",
            "test_160_7.jpg",
            "test_160_2.jpg",
            "test_160_1.jpg",
            "test_160_3.jpg",
            "test_160_4.jpg",
            "test_160_0.jpg",
            "test_160_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            30.71875,
            34.875,
            39.40625,
            27.140625,
            21.0625,
            13.890625,
            33.1875,
            44.65625,
            32.3125
          ],
          "order_indices": [
            7,
            2,
            1,
            6,
            8,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_160_7.jpg",
            "test_160_2.jpg",
            "test_160_1.jpg",
            "test_160_6.jpg",
            "test_160_8.jpg",
            "test_160_0.jpg",
            "test_160_3.jpg",
            "test_160_4.jpg",
            "test_160_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2777777777777778,
            "spearman_rho": 0.2666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.8143664598464966,
            0.6450691819190979,
            1.7126004695892334,
            0.311169296503067,
            -0.7938206195831299,
            -2.2549006938934326,
            1.5173498392105103,
            0.3377377688884735,
            1.4248089790344238
          ],
          "order_indices": [
            2,
            6,
            8,
            1,
            7,
            3,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_160_2.jpg",
            "test_160_6.jpg",
            "test_160_8.jpg",
            "test_160_1.jpg",
            "test_160_7.jpg",
            "test_160_3.jpg",
            "test_160_4.jpg",
            "test_160_0.jpg",
            "test_160_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.1333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 161,
      "prompt": "A red-haired female knight with a golden prosthetic arm wields a long golden blade.",
      "image_filenames": [
        "test_161_0.jpg",
        "test_161_1.jpg",
        "test_161_2.jpg",
        "test_161_3.jpg",
        "test_161_4.jpg",
        "test_161_5.jpg",
        "test_161_6.jpg",
        "test_161_7.jpg",
        "test_161_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          1,
          4,
          0,
          6,
          7,
          8,
          2,
          3
        ],
        "order_filenames": [
          "test_161_5.jpg",
          "test_161_1.jpg",
          "test_161_4.jpg",
          "test_161_0.jpg",
          "test_161_6.jpg",
          "test_161_7.jpg",
          "test_161_8.jpg",
          "test_161_2.jpg",
          "test_161_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_161_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_161_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_161_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2181396484375,
            0.31201171875,
            0.322998046875,
            0.212646484375,
            0.18896484375,
            0.1143798828125,
            0.335205078125,
            0.234130859375,
            0.263916015625
          ],
          "order_indices": [
            6,
            2,
            1,
            8,
            7,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_161_6.jpg",
            "test_161_2.jpg",
            "test_161_1.jpg",
            "test_161_8.jpg",
            "test_161_7.jpg",
            "test_161_0.jpg",
            "test_161_3.jpg",
            "test_161_4.jpg",
            "test_161_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.33333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.75,
            39.8125,
            40.875,
            33.5625,
            27.875,
            15.2265625,
            39.625,
            44.6875,
            38.28125
          ],
          "order_indices": [
            7,
            2,
            1,
            6,
            0,
            8,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_161_7.jpg",
            "test_161_2.jpg",
            "test_161_1.jpg",
            "test_161_6.jpg",
            "test_161_0.jpg",
            "test_161_8.jpg",
            "test_161_3.jpg",
            "test_161_4.jpg",
            "test_161_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.31666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.19410936534404755,
            1.5630851984024048,
            0.6048287749290466,
            -1.8683559894561768,
            -0.47453656792640686,
            -2.2808828353881836,
            0.7513197660446167,
            -0.17995604872703552,
            -0.43395543098449707
          ],
          "order_indices": [
            1,
            6,
            2,
            7,
            0,
            8,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_161_1.jpg",
            "test_161_6.jpg",
            "test_161_2.jpg",
            "test_161_7.jpg",
            "test_161_0.jpg",
            "test_161_8.jpg",
            "test_161_4.jpg",
            "test_161_3.jpg",
            "test_161_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.016666666666666607,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 162,
      "prompt": "A key shot of an Australian Shepherd with a pastel color palette and dramatic lighting.",
      "image_filenames": [
        "test_162_0.jpg",
        "test_162_1.jpg",
        "test_162_2.jpg",
        "test_162_3.jpg",
        "test_162_4.jpg",
        "test_162_5.jpg",
        "test_162_6.jpg",
        "test_162_7.jpg",
        "test_162_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          6,
          5,
          4,
          1,
          2,
          3,
          8,
          7
        ],
        "order_filenames": [
          "test_162_0.jpg",
          "test_162_6.jpg",
          "test_162_5.jpg",
          "test_162_4.jpg",
          "test_162_1.jpg",
          "test_162_2.jpg",
          "test_162_3.jpg",
          "test_162_8.jpg",
          "test_162_7.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_162_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4,
            5
          ],
          "winner_filenames": [
            "test_162_4.jpg",
            "test_162_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_162_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.259033203125,
            0.26171875,
            0.262939453125,
            0.188232421875,
            0.151123046875,
            0.21923828125,
            0.28466796875,
            0.1907958984375,
            0.248046875
          ],
          "order_indices": [
            6,
            2,
            1,
            0,
            8,
            5,
            7,
            3,
            4
          ],
          "order_filenames": [
            "test_162_6.jpg",
            "test_162_2.jpg",
            "test_162_1.jpg",
            "test_162_0.jpg",
            "test_162_8.jpg",
            "test_162_5.jpg",
            "test_162_7.jpg",
            "test_162_3.jpg",
            "test_162_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.35,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.53125,
            28.671875,
            33.6875,
            24.78125,
            29.28125,
            29.875,
            38.28125,
            35.96875,
            37.65625
          ],
          "order_indices": [
            6,
            8,
            0,
            7,
            2,
            5,
            4,
            1,
            3
          ],
          "order_filenames": [
            "test_162_6.jpg",
            "test_162_8.jpg",
            "test_162_0.jpg",
            "test_162_7.jpg",
            "test_162_2.jpg",
            "test_162_5.jpg",
            "test_162_4.jpg",
            "test_162_1.jpg",
            "test_162_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.008405327796936,
            0.6773681044578552,
            1.195525050163269,
            -1.1467622518539429,
            -1.6379945278167725,
            0.3567538261413574,
            1.1656347513198853,
            0.14518630504608154,
            0.6325540542602539
          ],
          "order_indices": [
            2,
            6,
            0,
            1,
            8,
            5,
            7,
            3,
            4
          ],
          "order_filenames": [
            "test_162_2.jpg",
            "test_162_6.jpg",
            "test_162_0.jpg",
            "test_162_1.jpg",
            "test_162_8.jpg",
            "test_162_5.jpg",
            "test_162_7.jpg",
            "test_162_3.jpg",
            "test_162_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.35,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 163,
      "prompt": "A black and white drawing of a road splitting the ocean leading to a giant eyeball looking at clouds in the distance.",
      "image_filenames": [
        "test_163_0.jpg",
        "test_163_1.jpg",
        "test_163_2.jpg",
        "test_163_3.jpg",
        "test_163_4.jpg",
        "test_163_5.jpg",
        "test_163_6.jpg",
        "test_163_7.jpg",
        "test_163_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          3,
          1,
          4,
          8,
          5,
          7,
          6,
          0
        ],
        "order_filenames": [
          "test_163_2.jpg",
          "test_163_3.jpg",
          "test_163_1.jpg",
          "test_163_4.jpg",
          "test_163_8.jpg",
          "test_163_5.jpg",
          "test_163_7.jpg",
          "test_163_6.jpg",
          "test_163_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_163_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_163_3.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2,
            3
          ],
          "winner_filenames": [
            "test_163_2.jpg",
            "test_163_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.218505859375,
            0.231201171875,
            0.2193603515625,
            0.1859130859375,
            0.176025390625,
            0.169189453125,
            0.2196044921875,
            0.24658203125,
            0.2861328125
          ],
          "order_indices": [
            8,
            7,
            1,
            6,
            2,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_163_8.jpg",
            "test_163_7.jpg",
            "test_163_1.jpg",
            "test_163_6.jpg",
            "test_163_2.jpg",
            "test_163_0.jpg",
            "test_163_3.jpg",
            "test_163_4.jpg",
            "test_163_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.10000000000000009,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.5625,
            40.625,
            44.21875,
            30.0,
            20.5,
            29.1875,
            36.34375,
            44.28125,
            45.71875
          ],
          "order_indices": [
            8,
            7,
            2,
            1,
            0,
            6,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_163_8.jpg",
            "test_163_7.jpg",
            "test_163_2.jpg",
            "test_163_1.jpg",
            "test_163_0.jpg",
            "test_163_6.jpg",
            "test_163_3.jpg",
            "test_163_5.jpg",
            "test_163_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.0,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.6717416048049927,
            -1.0172204971313477,
            -1.4495718479156494,
            -2.050352096557617,
            -2.2213659286499023,
            -2.278233528137207,
            -1.7738960981369019,
            1.0282163619995117,
            0.5263279676437378
          ],
          "order_indices": [
            7,
            8,
            0,
            1,
            2,
            6,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_163_7.jpg",
            "test_163_8.jpg",
            "test_163_0.jpg",
            "test_163_1.jpg",
            "test_163_2.jpg",
            "test_163_6.jpg",
            "test_163_3.jpg",
            "test_163_4.jpg",
            "test_163_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.2666666666666666,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 164,
      "prompt": "Jim Carrey is eating giant hamburgers in a hyper-detailed, horror-inspired image trending on DeviantArt.",
      "image_filenames": [
        "test_164_0.jpg",
        "test_164_1.jpg",
        "test_164_2.jpg",
        "test_164_3.jpg",
        "test_164_4.jpg",
        "test_164_5.jpg",
        "test_164_6.jpg",
        "test_164_7.jpg",
        "test_164_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          5,
          3,
          2,
          6,
          1,
          8,
          7,
          0
        ],
        "order_filenames": [
          "test_164_4.jpg",
          "test_164_5.jpg",
          "test_164_3.jpg",
          "test_164_2.jpg",
          "test_164_6.jpg",
          "test_164_1.jpg",
          "test_164_8.jpg",
          "test_164_7.jpg",
          "test_164_0.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_164_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_164_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_164_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.25732421875,
            0.270263671875,
            0.2978515625,
            0.259033203125,
            0.22021484375,
            0.156494140625,
            0.308349609375,
            0.2398681640625,
            0.305419921875
          ],
          "order_indices": [
            6,
            8,
            2,
            1,
            3,
            0,
            7,
            4,
            5
          ],
          "order_filenames": [
            "test_164_6.jpg",
            "test_164_8.jpg",
            "test_164_2.jpg",
            "test_164_1.jpg",
            "test_164_3.jpg",
            "test_164_0.jpg",
            "test_164_7.jpg",
            "test_164_4.jpg",
            "test_164_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.31666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            48.03125,
            45.90625,
            44.9375,
            40.4375,
            35.4375,
            24.875,
            49.375,
            46.71875,
            42.96875
          ],
          "order_indices": [
            6,
            0,
            7,
            1,
            2,
            8,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_164_6.jpg",
            "test_164_0.jpg",
            "test_164_7.jpg",
            "test_164_1.jpg",
            "test_164_2.jpg",
            "test_164_8.jpg",
            "test_164_3.jpg",
            "test_164_4.jpg",
            "test_164_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.6111111111111112,
            "spearman_rho": -0.75,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.168831467628479,
            1.6681954860687256,
            1.925841212272644,
            1.8971840143203735,
            -0.11447600275278091,
            -1.5985660552978516,
            1.9436229467391968,
            0.6779394745826721,
            1.9165512323379517
          ],
          "order_indices": [
            6,
            2,
            8,
            3,
            1,
            0,
            7,
            4,
            5
          ],
          "order_filenames": [
            "test_164_6.jpg",
            "test_164_2.jpg",
            "test_164_8.jpg",
            "test_164_3.jpg",
            "test_164_1.jpg",
            "test_164_0.jpg",
            "test_164_7.jpg",
            "test_164_4.jpg",
            "test_164_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.21666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 165,
      "prompt": "A photograph of a giant diamond skull in the ocean, featuring vibrant colors and detailed textures.",
      "image_filenames": [
        "test_165_0.jpg",
        "test_165_1.jpg",
        "test_165_2.jpg",
        "test_165_3.jpg",
        "test_165_4.jpg",
        "test_165_5.jpg",
        "test_165_6.jpg",
        "test_165_7.jpg",
        "test_165_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          6,
          8,
          0,
          7,
          3,
          5,
          4,
          2
        ],
        "order_filenames": [
          "test_165_1.jpg",
          "test_165_6.jpg",
          "test_165_8.jpg",
          "test_165_0.jpg",
          "test_165_7.jpg",
          "test_165_3.jpg",
          "test_165_5.jpg",
          "test_165_4.jpg",
          "test_165_2.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_165_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_165_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_165_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2486572265625,
            0.28955078125,
            0.28662109375,
            0.25048828125,
            0.20068359375,
            0.20361328125,
            0.2294921875,
            0.279052734375,
            0.236328125
          ],
          "order_indices": [
            1,
            2,
            7,
            3,
            0,
            8,
            6,
            5,
            4
          ],
          "order_filenames": [
            "test_165_1.jpg",
            "test_165_2.jpg",
            "test_165_7.jpg",
            "test_165_3.jpg",
            "test_165_0.jpg",
            "test_165_8.jpg",
            "test_165_6.jpg",
            "test_165_5.jpg",
            "test_165_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.21666666666666667,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            45.625,
            32.03125,
            36.4375,
            41.25,
            37.78125,
            42.8125,
            32.03125,
            43.78125,
            47.25
          ],
          "order_indices": [
            8,
            0,
            7,
            5,
            3,
            4,
            2,
            1,
            6
          ],
          "order_filenames": [
            "test_165_8.jpg",
            "test_165_0.jpg",
            "test_165_7.jpg",
            "test_165_5.jpg",
            "test_165_3.jpg",
            "test_165_4.jpg",
            "test_165_2.jpg",
            "test_165_1.jpg",
            "test_165_6.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": -0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.026785388588905334,
            -0.1965126246213913,
            -0.7163679599761963,
            -0.2002466917037964,
            -0.373264878988266,
            -1.007124662399292,
            -1.4050251245498657,
            0.5699728727340698,
            0.39256253838539124
          ],
          "order_indices": [
            7,
            8,
            0,
            1,
            3,
            4,
            2,
            5,
            6
          ],
          "order_filenames": [
            "test_165_7.jpg",
            "test_165_8.jpg",
            "test_165_0.jpg",
            "test_165_1.jpg",
            "test_165_3.jpg",
            "test_165_4.jpg",
            "test_165_2.jpg",
            "test_165_5.jpg",
            "test_165_6.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.2833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 166,
      "prompt": "A woman's face in profile, with white carapace plates extruding from the skin and red kintsurugi.",
      "image_filenames": [
        "test_166_0.jpg",
        "test_166_1.jpg",
        "test_166_2.jpg",
        "test_166_3.jpg",
        "test_166_4.jpg",
        "test_166_5.jpg",
        "test_166_6.jpg",
        "test_166_7.jpg",
        "test_166_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          3,
          7,
          4,
          5,
          6,
          8,
          1,
          0
        ],
        "order_filenames": [
          "test_166_2.jpg",
          "test_166_3.jpg",
          "test_166_7.jpg",
          "test_166_4.jpg",
          "test_166_5.jpg",
          "test_166_6.jpg",
          "test_166_8.jpg",
          "test_166_1.jpg",
          "test_166_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_166_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_166_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2,
            7
          ],
          "winner_filenames": [
            "test_166_2.jpg",
            "test_166_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.19873046875,
            0.19677734375,
            0.19775390625,
            0.1910400390625,
            0.1971435546875,
            0.11212158203125,
            0.2174072265625,
            0.253173828125,
            0.2626953125
          ],
          "order_indices": [
            8,
            7,
            6,
            0,
            2,
            4,
            1,
            3,
            5
          ],
          "order_filenames": [
            "test_166_8.jpg",
            "test_166_7.jpg",
            "test_166_6.jpg",
            "test_166_0.jpg",
            "test_166_2.jpg",
            "test_166_4.jpg",
            "test_166_1.jpg",
            "test_166_3.jpg",
            "test_166_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.19999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            41.21875,
            34.15625,
            39.71875,
            25.140625,
            28.1875,
            22.453125,
            30.671875,
            46.25,
            33.21875
          ],
          "order_indices": [
            7,
            0,
            2,
            1,
            8,
            6,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_166_7.jpg",
            "test_166_0.jpg",
            "test_166_2.jpg",
            "test_166_1.jpg",
            "test_166_8.jpg",
            "test_166_6.jpg",
            "test_166_4.jpg",
            "test_166_3.jpg",
            "test_166_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.1499999999999999,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.26418137550354004,
            -0.10819590091705322,
            -1.9080983400344849,
            0.13385356962680817,
            -0.3663397431373596,
            -2.181248188018799,
            0.5763835906982422,
            1.104656457901001,
            -0.06191341578960419
          ],
          "order_indices": [
            7,
            6,
            0,
            3,
            8,
            1,
            4,
            2,
            5
          ],
          "order_filenames": [
            "test_166_7.jpg",
            "test_166_6.jpg",
            "test_166_0.jpg",
            "test_166_3.jpg",
            "test_166_8.jpg",
            "test_166_1.jpg",
            "test_166_4.jpg",
            "test_166_2.jpg",
            "test_166_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 167,
      "prompt": "Zarya from Overwatch jumping from a tall bridge into action.",
      "image_filenames": [
        "test_167_0.jpg",
        "test_167_1.jpg",
        "test_167_2.jpg",
        "test_167_3.jpg",
        "test_167_4.jpg",
        "test_167_5.jpg",
        "test_167_6.jpg",
        "test_167_7.jpg",
        "test_167_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          4,
          1,
          5,
          6,
          7,
          8,
          2,
          0
        ],
        "order_filenames": [
          "test_167_3.jpg",
          "test_167_4.jpg",
          "test_167_1.jpg",
          "test_167_5.jpg",
          "test_167_6.jpg",
          "test_167_7.jpg",
          "test_167_8.jpg",
          "test_167_2.jpg",
          "test_167_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_167_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_167_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_167_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2147216796875,
            0.280517578125,
            0.2254638671875,
            0.2337646484375,
            0.205078125,
            0.1204833984375,
            0.254638671875,
            0.203125,
            0.2286376953125
          ],
          "order_indices": [
            1,
            6,
            3,
            8,
            2,
            0,
            4,
            7,
            5
          ],
          "order_filenames": [
            "test_167_1.jpg",
            "test_167_6.jpg",
            "test_167_3.jpg",
            "test_167_8.jpg",
            "test_167_2.jpg",
            "test_167_0.jpg",
            "test_167_4.jpg",
            "test_167_7.jpg",
            "test_167_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            42.6875,
            34.84375,
            41.75,
            41.0625,
            36.46875,
            15.3671875,
            32.96875,
            43.03125,
            32.28125
          ],
          "order_indices": [
            7,
            0,
            2,
            3,
            4,
            1,
            6,
            8,
            5
          ],
          "order_filenames": [
            "test_167_7.jpg",
            "test_167_0.jpg",
            "test_167_2.jpg",
            "test_167_3.jpg",
            "test_167_4.jpg",
            "test_167_1.jpg",
            "test_167_6.jpg",
            "test_167_8.jpg",
            "test_167_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.30000000000000004,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.17455171048641205,
            0.8390529751777649,
            0.04591194912791252,
            -0.15150563418865204,
            -0.2705778479576111,
            -2.1226251125335693,
            0.8153470158576965,
            -0.5658295750617981,
            1.2907774448394775
          ],
          "order_indices": [
            8,
            1,
            6,
            0,
            2,
            3,
            4,
            7,
            5
          ],
          "order_filenames": [
            "test_167_8.jpg",
            "test_167_1.jpg",
            "test_167_6.jpg",
            "test_167_0.jpg",
            "test_167_2.jpg",
            "test_167_3.jpg",
            "test_167_4.jpg",
            "test_167_7.jpg",
            "test_167_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.28333333333333344,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 168,
      "prompt": "A minimalist portrait of Rita Ora by Jean Giraud, inspired by the Moebius Starwatcher comic.",
      "image_filenames": [
        "test_168_0.jpg",
        "test_168_1.jpg",
        "test_168_2.jpg",
        "test_168_3.jpg",
        "test_168_4.jpg",
        "test_168_5.jpg",
        "test_168_6.jpg",
        "test_168_7.jpg",
        "test_168_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          4,
          7,
          5,
          6,
          0,
          2,
          8,
          1
        ],
        "order_filenames": [
          "test_168_3.jpg",
          "test_168_4.jpg",
          "test_168_7.jpg",
          "test_168_5.jpg",
          "test_168_6.jpg",
          "test_168_0.jpg",
          "test_168_2.jpg",
          "test_168_8.jpg",
          "test_168_1.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_168_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_168_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_168_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.132080078125,
            0.1353759765625,
            0.221435546875,
            0.1441650390625,
            0.1339111328125,
            0.10479736328125,
            0.1981201171875,
            0.2047119140625,
            0.21044921875
          ],
          "order_indices": [
            2,
            8,
            7,
            6,
            3,
            1,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_168_2.jpg",
            "test_168_8.jpg",
            "test_168_7.jpg",
            "test_168_6.jpg",
            "test_168_3.jpg",
            "test_168_1.jpg",
            "test_168_4.jpg",
            "test_168_0.jpg",
            "test_168_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.2666666666666666,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.3125,
            32.03125,
            37.96875,
            26.46875,
            24.734375,
            22.53125,
            39.59375,
            42.125,
            37.1875
          ],
          "order_indices": [
            7,
            6,
            0,
            2,
            8,
            1,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_168_7.jpg",
            "test_168_6.jpg",
            "test_168_0.jpg",
            "test_168_2.jpg",
            "test_168_8.jpg",
            "test_168_1.jpg",
            "test_168_3.jpg",
            "test_168_4.jpg",
            "test_168_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": -0.21666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.7507997751235962,
            -1.8869982957839966,
            0.39627060294151306,
            -1.8283122777938843,
            -1.0078686475753784,
            -2.274550676345825,
            -0.2143065333366394,
            -0.8432650566101074,
            0.8110141754150391
          ],
          "order_indices": [
            8,
            2,
            6,
            7,
            4,
            0,
            3,
            1,
            5
          ],
          "order_filenames": [
            "test_168_8.jpg",
            "test_168_2.jpg",
            "test_168_6.jpg",
            "test_168_7.jpg",
            "test_168_4.jpg",
            "test_168_0.jpg",
            "test_168_3.jpg",
            "test_168_1.jpg",
            "test_168_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.25,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 169,
      "prompt": "The image features baroque architecture by Escher and Jean Delville in the walled city of Kowloon, lit with golden lighting and displaying ornate details.",
      "image_filenames": [
        "test_169_0.jpg",
        "test_169_1.jpg",
        "test_169_2.jpg",
        "test_169_3.jpg",
        "test_169_4.jpg",
        "test_169_5.jpg",
        "test_169_6.jpg",
        "test_169_7.jpg",
        "test_169_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          1,
          0,
          4,
          6,
          5,
          3,
          7,
          8
        ],
        "order_filenames": [
          "test_169_2.jpg",
          "test_169_1.jpg",
          "test_169_0.jpg",
          "test_169_4.jpg",
          "test_169_6.jpg",
          "test_169_5.jpg",
          "test_169_3.jpg",
          "test_169_7.jpg",
          "test_169_8.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_169_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_169_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_169_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2476806640625,
            0.282470703125,
            0.2626953125,
            0.28369140625,
            0.2099609375,
            0.192626953125,
            0.27001953125,
            0.218017578125,
            0.22265625
          ],
          "order_indices": [
            3,
            1,
            6,
            2,
            0,
            8,
            7,
            4,
            5
          ],
          "order_filenames": [
            "test_169_3.jpg",
            "test_169_1.jpg",
            "test_169_6.jpg",
            "test_169_2.jpg",
            "test_169_0.jpg",
            "test_169_8.jpg",
            "test_169_7.jpg",
            "test_169_4.jpg",
            "test_169_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.2666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            42.3125,
            40.1875,
            34.6875,
            32.5,
            32.59375,
            30.984375,
            38.15625,
            39.625,
            35.125
          ],
          "order_indices": [
            0,
            1,
            7,
            6,
            8,
            2,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_169_0.jpg",
            "test_169_1.jpg",
            "test_169_7.jpg",
            "test_169_6.jpg",
            "test_169_8.jpg",
            "test_169_2.jpg",
            "test_169_4.jpg",
            "test_169_3.jpg",
            "test_169_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.25,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.2568618059158325,
            0.36556434631347656,
            0.33465418219566345,
            1.2291536331176758,
            0.0653197392821312,
            -1.4671317338943481,
            0.8320743441581726,
            0.40298381447792053,
            0.007489750161767006
          ],
          "order_indices": [
            0,
            3,
            6,
            7,
            1,
            2,
            4,
            8,
            5
          ],
          "order_filenames": [
            "test_169_0.jpg",
            "test_169_3.jpg",
            "test_169_6.jpg",
            "test_169_7.jpg",
            "test_169_1.jpg",
            "test_169_2.jpg",
            "test_169_4.jpg",
            "test_169_8.jpg",
            "test_169_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.15000000000000002,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 170,
      "prompt": "A hybrid creature concept painting of a zebra-striped unicorn with bunny ears and a colorful mane.",
      "image_filenames": [
        "test_170_0.jpg",
        "test_170_1.jpg",
        "test_170_2.jpg",
        "test_170_3.jpg",
        "test_170_4.jpg",
        "test_170_5.jpg",
        "test_170_6.jpg",
        "test_170_7.jpg",
        "test_170_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          2,
          1,
          5,
          6,
          8,
          0,
          7,
          3
        ],
        "order_filenames": [
          "test_170_4.jpg",
          "test_170_2.jpg",
          "test_170_1.jpg",
          "test_170_5.jpg",
          "test_170_6.jpg",
          "test_170_8.jpg",
          "test_170_0.jpg",
          "test_170_7.jpg",
          "test_170_3.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_170_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_170_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_170_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2139892578125,
            0.279296875,
            0.290771484375,
            0.221435546875,
            0.204833984375,
            0.2081298828125,
            0.25244140625,
            0.1973876953125,
            0.261962890625
          ],
          "order_indices": [
            2,
            1,
            8,
            6,
            3,
            0,
            5,
            4,
            7
          ],
          "order_filenames": [
            "test_170_2.jpg",
            "test_170_1.jpg",
            "test_170_8.jpg",
            "test_170_6.jpg",
            "test_170_3.jpg",
            "test_170_0.jpg",
            "test_170_5.jpg",
            "test_170_4.jpg",
            "test_170_7.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.2666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            44.75,
            40.9375,
            35.40625,
            43.59375,
            36.9375,
            36.71875,
            33.4375,
            41.625,
            43.15625
          ],
          "order_indices": [
            0,
            3,
            8,
            7,
            1,
            4,
            5,
            2,
            6
          ],
          "order_filenames": [
            "test_170_0.jpg",
            "test_170_3.jpg",
            "test_170_8.jpg",
            "test_170_7.jpg",
            "test_170_1.jpg",
            "test_170_4.jpg",
            "test_170_5.jpg",
            "test_170_2.jpg",
            "test_170_6.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.6666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.34002184867858887,
            0.46736353635787964,
            1.2253503799438477,
            0.19738662242889404,
            0.17173047363758087,
            -0.5304916501045227,
            1.3307456970214844,
            -0.042599521577358246,
            1.624193549156189
          ],
          "order_indices": [
            8,
            6,
            2,
            1,
            0,
            3,
            4,
            7,
            5
          ],
          "order_filenames": [
            "test_170_8.jpg",
            "test_170_6.jpg",
            "test_170_2.jpg",
            "test_170_1.jpg",
            "test_170_0.jpg",
            "test_170_3.jpg",
            "test_170_4.jpg",
            "test_170_7.jpg",
            "test_170_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.08333333333333337,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 171,
      "prompt": "An image of a corn elemental, created as concept art for a high fantasy setting.",
      "image_filenames": [
        "test_171_0.jpg",
        "test_171_1.jpg",
        "test_171_2.jpg",
        "test_171_3.jpg",
        "test_171_4.jpg",
        "test_171_5.jpg",
        "test_171_6.jpg",
        "test_171_7.jpg",
        "test_171_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          5,
          2,
          6,
          4,
          7,
          8,
          1,
          0
        ],
        "order_filenames": [
          "test_171_3.jpg",
          "test_171_5.jpg",
          "test_171_2.jpg",
          "test_171_6.jpg",
          "test_171_4.jpg",
          "test_171_7.jpg",
          "test_171_8.jpg",
          "test_171_1.jpg",
          "test_171_0.jpg"
        ],
        "condorcet_winner": 3,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_171_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_171_3.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_171_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2183837890625,
            0.2164306640625,
            0.19189453125,
            0.190673828125,
            0.1883544921875,
            0.18017578125,
            0.29638671875,
            0.2449951171875,
            0.2449951171875
          ],
          "order_indices": [
            6,
            7,
            8,
            0,
            1,
            2,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_171_6.jpg",
            "test_171_7.jpg",
            "test_171_8.jpg",
            "test_171_0.jpg",
            "test_171_1.jpg",
            "test_171_2.jpg",
            "test_171_3.jpg",
            "test_171_4.jpg",
            "test_171_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.4833333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            43.4375,
            29.8125,
            35.5,
            38.28125,
            31.9375,
            30.03125,
            45.15625,
            47.5,
            41.3125
          ],
          "order_indices": [
            7,
            6,
            0,
            8,
            3,
            2,
            4,
            5,
            1
          ],
          "order_filenames": [
            "test_171_7.jpg",
            "test_171_6.jpg",
            "test_171_0.jpg",
            "test_171_8.jpg",
            "test_171_3.jpg",
            "test_171_2.jpg",
            "test_171_4.jpg",
            "test_171_5.jpg",
            "test_171_1.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.16666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.28733712434768677,
            -0.3055390417575836,
            -0.1996174454689026,
            -0.01936047337949276,
            -1.7666727304458618,
            -1.56879460811615,
            1.3277753591537476,
            0.4034901559352875,
            -0.06787420809268951
          ],
          "order_indices": [
            6,
            7,
            0,
            3,
            8,
            2,
            1,
            5,
            4
          ],
          "order_filenames": [
            "test_171_6.jpg",
            "test_171_7.jpg",
            "test_171_0.jpg",
            "test_171_3.jpg",
            "test_171_8.jpg",
            "test_171_2.jpg",
            "test_171_1.jpg",
            "test_171_5.jpg",
            "test_171_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.1333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 172,
      "prompt": "A raw green gemstone covered in black slime, with a shiny appearance, captured in a photorealistic digital art photograph.",
      "image_filenames": [
        "test_172_0.jpg",
        "test_172_1.jpg",
        "test_172_2.jpg",
        "test_172_3.jpg",
        "test_172_4.jpg",
        "test_172_5.jpg",
        "test_172_6.jpg",
        "test_172_7.jpg",
        "test_172_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          8,
          2,
          7,
          4,
          3,
          0,
          6,
          1,
          5
        ],
        "order_filenames": [
          "test_172_8.jpg",
          "test_172_2.jpg",
          "test_172_7.jpg",
          "test_172_4.jpg",
          "test_172_3.jpg",
          "test_172_0.jpg",
          "test_172_6.jpg",
          "test_172_1.jpg",
          "test_172_5.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          8
        ],
        "winner_filenames": [
          "test_172_8.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_172_2.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2,
            8
          ],
          "winner_filenames": [
            "test_172_2.jpg",
            "test_172_8.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.239501953125,
            0.276123046875,
            0.254150390625,
            0.2322998046875,
            0.207275390625,
            0.2335205078125,
            0.271240234375,
            0.264892578125,
            0.253662109375
          ],
          "order_indices": [
            1,
            6,
            7,
            2,
            8,
            0,
            5,
            3,
            4
          ],
          "order_filenames": [
            "test_172_1.jpg",
            "test_172_6.jpg",
            "test_172_7.jpg",
            "test_172_2.jpg",
            "test_172_8.jpg",
            "test_172_0.jpg",
            "test_172_5.jpg",
            "test_172_3.jpg",
            "test_172_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.10000000000000009,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.1875,
            33.90625,
            37.65625,
            29.25,
            34.96875,
            33.15625,
            41.96875,
            43.28125,
            41.53125
          ],
          "order_indices": [
            7,
            6,
            8,
            0,
            2,
            4,
            1,
            5,
            3
          ],
          "order_filenames": [
            "test_172_7.jpg",
            "test_172_6.jpg",
            "test_172_8.jpg",
            "test_172_0.jpg",
            "test_172_2.jpg",
            "test_172_4.jpg",
            "test_172_1.jpg",
            "test_172_5.jpg",
            "test_172_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.43333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.015194710344076157,
            -0.8344987034797668,
            -0.7323245406150818,
            -0.5486448407173157,
            -0.8746512532234192,
            -0.07662514597177505,
            -0.15363365411758423,
            -0.02107919752597809,
            -0.45065218210220337
          ],
          "order_indices": [
            0,
            7,
            5,
            6,
            8,
            3,
            2,
            1,
            4
          ],
          "order_filenames": [
            "test_172_0.jpg",
            "test_172_7.jpg",
            "test_172_5.jpg",
            "test_172_6.jpg",
            "test_172_8.jpg",
            "test_172_3.jpg",
            "test_172_2.jpg",
            "test_172_1.jpg",
            "test_172_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.1499999999999999,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 173,
      "prompt": "Molten lava hanging from the ceiling creates art with octagons in a museum setting.",
      "image_filenames": [
        "test_173_0.jpg",
        "test_173_1.jpg",
        "test_173_2.jpg",
        "test_173_3.jpg",
        "test_173_4.jpg",
        "test_173_5.jpg",
        "test_173_6.jpg",
        "test_173_7.jpg",
        "test_173_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          5,
          8,
          4,
          6,
          7,
          0,
          1,
          2
        ],
        "order_filenames": [
          "test_173_3.jpg",
          "test_173_5.jpg",
          "test_173_8.jpg",
          "test_173_4.jpg",
          "test_173_6.jpg",
          "test_173_7.jpg",
          "test_173_0.jpg",
          "test_173_1.jpg",
          "test_173_2.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_173_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3,
            6
          ],
          "winner_filenames": [
            "test_173_3.jpg",
            "test_173_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_173_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.22265625,
            0.264892578125,
            0.28515625,
            0.222900390625,
            0.210205078125,
            0.200439453125,
            0.2607421875,
            0.286865234375,
            0.231689453125
          ],
          "order_indices": [
            7,
            2,
            1,
            6,
            8,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_173_7.jpg",
            "test_173_2.jpg",
            "test_173_1.jpg",
            "test_173_6.jpg",
            "test_173_8.jpg",
            "test_173_3.jpg",
            "test_173_0.jpg",
            "test_173_4.jpg",
            "test_173_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.6166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.875,
            39.25,
            43.71875,
            28.71875,
            30.6875,
            32.0625,
            39.4375,
            45.53125,
            43.125
          ],
          "order_indices": [
            7,
            2,
            8,
            6,
            1,
            0,
            5,
            4,
            3
          ],
          "order_filenames": [
            "test_173_7.jpg",
            "test_173_2.jpg",
            "test_173_8.jpg",
            "test_173_6.jpg",
            "test_173_1.jpg",
            "test_173_0.jpg",
            "test_173_5.jpg",
            "test_173_4.jpg",
            "test_173_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.5833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.17058038711547852,
            -1.0314875841140747,
            1.4006807804107666,
            -1.2869150638580322,
            -0.9786288738250732,
            -0.8526022434234619,
            0.33351242542266846,
            1.401753306388855,
            -0.7002625465393066
          ],
          "order_indices": [
            7,
            2,
            6,
            0,
            8,
            5,
            4,
            1,
            3
          ],
          "order_filenames": [
            "test_173_7.jpg",
            "test_173_2.jpg",
            "test_173_6.jpg",
            "test_173_0.jpg",
            "test_173_8.jpg",
            "test_173_5.jpg",
            "test_173_4.jpg",
            "test_173_1.jpg",
            "test_173_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.5,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 174,
      "prompt": "A giant nose made of water in a restaurant is depicted in a film still with unique art direction.",
      "image_filenames": [
        "test_174_0.jpg",
        "test_174_1.jpg",
        "test_174_2.jpg",
        "test_174_3.jpg",
        "test_174_4.jpg",
        "test_174_5.jpg",
        "test_174_6.jpg",
        "test_174_7.jpg",
        "test_174_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          0,
          4,
          6,
          8,
          1,
          5,
          3,
          2
        ],
        "order_filenames": [
          "test_174_7.jpg",
          "test_174_0.jpg",
          "test_174_4.jpg",
          "test_174_6.jpg",
          "test_174_8.jpg",
          "test_174_1.jpg",
          "test_174_5.jpg",
          "test_174_3.jpg",
          "test_174_2.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_174_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_174_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_174_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.18310546875,
            0.270751953125,
            0.228759765625,
            0.178466796875,
            0.195068359375,
            0.1531982421875,
            0.2080078125,
            0.26220703125,
            0.2183837890625
          ],
          "order_indices": [
            1,
            7,
            2,
            8,
            6,
            4,
            0,
            3,
            5
          ],
          "order_filenames": [
            "test_174_1.jpg",
            "test_174_7.jpg",
            "test_174_2.jpg",
            "test_174_8.jpg",
            "test_174_6.jpg",
            "test_174_4.jpg",
            "test_174_0.jpg",
            "test_174_3.jpg",
            "test_174_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.15000000000000002,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.90625,
            36.84375,
            39.4375,
            36.1875,
            33.6875,
            25.03125,
            40.125,
            57.34375,
            40.25
          ],
          "order_indices": [
            7,
            8,
            6,
            2,
            0,
            1,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_174_7.jpg",
            "test_174_8.jpg",
            "test_174_6.jpg",
            "test_174_2.jpg",
            "test_174_0.jpg",
            "test_174_1.jpg",
            "test_174_3.jpg",
            "test_174_4.jpg",
            "test_174_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2777777777777778,
            "spearman_rho": 0.3833333333333333,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -2.1388282775878906,
            -0.9656861424446106,
            -0.48355206847190857,
            -1.7221548557281494,
            -1.20442533493042,
            -2.1021604537963867,
            -1.0062525272369385,
            0.11967697739601135,
            -1.4163548946380615
          ],
          "order_indices": [
            7,
            2,
            1,
            6,
            4,
            8,
            3,
            5,
            0
          ],
          "order_filenames": [
            "test_174_7.jpg",
            "test_174_2.jpg",
            "test_174_1.jpg",
            "test_174_6.jpg",
            "test_174_4.jpg",
            "test_174_8.jpg",
            "test_174_3.jpg",
            "test_174_5.jpg",
            "test_174_0.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.050000000000000044,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 175,
      "prompt": "A red cobweb is seen inside a marble with an hourglass, lightning and intricate details, creating a sense of awe with swirling mist.",
      "image_filenames": [
        "test_175_0.jpg",
        "test_175_1.jpg",
        "test_175_2.jpg",
        "test_175_3.jpg",
        "test_175_4.jpg",
        "test_175_5.jpg",
        "test_175_6.jpg",
        "test_175_7.jpg",
        "test_175_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          6,
          3,
          2,
          4,
          7,
          8,
          0,
          1
        ],
        "order_filenames": [
          "test_175_5.jpg",
          "test_175_6.jpg",
          "test_175_3.jpg",
          "test_175_2.jpg",
          "test_175_4.jpg",
          "test_175_7.jpg",
          "test_175_8.jpg",
          "test_175_0.jpg",
          "test_175_1.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5,
          6
        ],
        "winner_filenames": [
          "test_175_5.jpg",
          "test_175_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_175_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5,
            6
          ],
          "winner_filenames": [
            "test_175_5.jpg",
            "test_175_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2203369140625,
            0.2239990234375,
            0.2369384765625,
            0.215576171875,
            0.18017578125,
            0.1876220703125,
            0.2734375,
            0.2314453125,
            0.2578125
          ],
          "order_indices": [
            6,
            8,
            2,
            7,
            1,
            0,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_175_6.jpg",
            "test_175_8.jpg",
            "test_175_2.jpg",
            "test_175_7.jpg",
            "test_175_1.jpg",
            "test_175_0.jpg",
            "test_175_3.jpg",
            "test_175_5.jpg",
            "test_175_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.10000000000000009,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.375,
            34.9375,
            39.625,
            38.6875,
            29.640625,
            30.90625,
            39.125,
            41.15625,
            37.25
          ],
          "order_indices": [
            7,
            0,
            2,
            6,
            3,
            8,
            1,
            5,
            4
          ],
          "order_filenames": [
            "test_175_7.jpg",
            "test_175_0.jpg",
            "test_175_2.jpg",
            "test_175_6.jpg",
            "test_175_3.jpg",
            "test_175_8.jpg",
            "test_175_1.jpg",
            "test_175_5.jpg",
            "test_175_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.16666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.042074054479599,
            -0.7486649751663208,
            -0.8109163641929626,
            -1.0500328540802002,
            -1.5481494665145874,
            -1.602797508239746,
            -0.4967721402645111,
            0.502931535243988,
            1.2368483543395996
          ],
          "order_indices": [
            8,
            7,
            0,
            6,
            1,
            2,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_175_8.jpg",
            "test_175_7.jpg",
            "test_175_0.jpg",
            "test_175_6.jpg",
            "test_175_1.jpg",
            "test_175_2.jpg",
            "test_175_3.jpg",
            "test_175_4.jpg",
            "test_175_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.5833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 176,
      "prompt": "A village of stone buildings built on the side of a hill glowing with silver light.",
      "image_filenames": [
        "test_176_0.jpg",
        "test_176_1.jpg",
        "test_176_2.jpg",
        "test_176_3.jpg",
        "test_176_4.jpg",
        "test_176_5.jpg",
        "test_176_6.jpg",
        "test_176_7.jpg",
        "test_176_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          0,
          6,
          1,
          2,
          7,
          5,
          8,
          3
        ],
        "order_filenames": [
          "test_176_4.jpg",
          "test_176_0.jpg",
          "test_176_6.jpg",
          "test_176_1.jpg",
          "test_176_2.jpg",
          "test_176_7.jpg",
          "test_176_5.jpg",
          "test_176_8.jpg",
          "test_176_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_176_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_176_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0,
            4
          ],
          "winner_filenames": [
            "test_176_0.jpg",
            "test_176_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2392578125,
            0.2724609375,
            0.24072265625,
            0.2425537109375,
            0.18017578125,
            0.174072265625,
            0.322998046875,
            0.255859375,
            0.278076171875
          ],
          "order_indices": [
            6,
            8,
            1,
            7,
            3,
            2,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_176_6.jpg",
            "test_176_8.jpg",
            "test_176_1.jpg",
            "test_176_7.jpg",
            "test_176_3.jpg",
            "test_176_2.jpg",
            "test_176_0.jpg",
            "test_176_4.jpg",
            "test_176_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.16666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.40625,
            34.65625,
            33.5,
            35.3125,
            30.90625,
            37.0,
            34.5,
            41.5625,
            37.25
          ],
          "order_indices": [
            7,
            0,
            8,
            5,
            3,
            1,
            6,
            2,
            4
          ],
          "order_filenames": [
            "test_176_7.jpg",
            "test_176_0.jpg",
            "test_176_8.jpg",
            "test_176_5.jpg",
            "test_176_3.jpg",
            "test_176_1.jpg",
            "test_176_6.jpg",
            "test_176_2.jpg",
            "test_176_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.3999999999999999,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.363321304321289,
            1.0583282709121704,
            0.007151361089199781,
            0.808326005935669,
            -0.5122674703598022,
            0.12630251049995422,
            0.7766088843345642,
            0.7373728156089783,
            0.8161568641662598
          ],
          "order_indices": [
            0,
            1,
            8,
            3,
            6,
            7,
            5,
            2,
            4
          ],
          "order_filenames": [
            "test_176_0.jpg",
            "test_176_1.jpg",
            "test_176_8.jpg",
            "test_176_3.jpg",
            "test_176_6.jpg",
            "test_176_7.jpg",
            "test_176_5.jpg",
            "test_176_2.jpg",
            "test_176_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.10000000000000009,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 177,
      "prompt": "A steampunk pocketwatch owl is trapped inside a glass jar buried in sand, surrounded by an hourglass and swirling mist.",
      "image_filenames": [
        "test_177_0.jpg",
        "test_177_1.jpg",
        "test_177_2.jpg",
        "test_177_3.jpg",
        "test_177_4.jpg",
        "test_177_5.jpg",
        "test_177_6.jpg",
        "test_177_7.jpg",
        "test_177_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          3,
          5,
          0,
          4,
          2,
          7,
          6,
          8
        ],
        "order_filenames": [
          "test_177_1.jpg",
          "test_177_3.jpg",
          "test_177_5.jpg",
          "test_177_0.jpg",
          "test_177_4.jpg",
          "test_177_2.jpg",
          "test_177_7.jpg",
          "test_177_6.jpg",
          "test_177_8.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_177_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_177_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1,
            3
          ],
          "winner_filenames": [
            "test_177_1.jpg",
            "test_177_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2315673828125,
            0.2322998046875,
            0.2470703125,
            0.1796875,
            0.1787109375,
            0.2073974609375,
            0.299072265625,
            0.25537109375,
            0.2174072265625
          ],
          "order_indices": [
            6,
            7,
            2,
            1,
            0,
            8,
            5,
            3,
            4
          ],
          "order_filenames": [
            "test_177_6.jpg",
            "test_177_7.jpg",
            "test_177_2.jpg",
            "test_177_1.jpg",
            "test_177_0.jpg",
            "test_177_8.jpg",
            "test_177_5.jpg",
            "test_177_3.jpg",
            "test_177_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.41666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.78125,
            28.546875,
            30.78125,
            27.4375,
            31.28125,
            31.3125,
            39.125,
            42.96875,
            40.15625
          ],
          "order_indices": [
            7,
            8,
            6,
            0,
            5,
            4,
            2,
            1,
            3
          ],
          "order_filenames": [
            "test_177_7.jpg",
            "test_177_8.jpg",
            "test_177_6.jpg",
            "test_177_0.jpg",
            "test_177_5.jpg",
            "test_177_4.jpg",
            "test_177_2.jpg",
            "test_177_1.jpg",
            "test_177_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5555555555555556,
            "spearman_rho": -0.7833333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.4339905381202698,
            -1.3709309101104736,
            -1.5451433658599854,
            -1.807413935661316,
            -0.6689923405647278,
            -1.4510729312896729,
            0.8664660453796387,
            0.6700476408004761,
            0.5358015894889832
          ],
          "order_indices": [
            6,
            7,
            8,
            0,
            4,
            1,
            5,
            2,
            3
          ],
          "order_filenames": [
            "test_177_6.jpg",
            "test_177_7.jpg",
            "test_177_8.jpg",
            "test_177_0.jpg",
            "test_177_4.jpg",
            "test_177_1.jpg",
            "test_177_5.jpg",
            "test_177_2.jpg",
            "test_177_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.7,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 178,
      "prompt": "A pocketwatch hangs from a steam punk hot air balloon amidst a swirling mist.",
      "image_filenames": [
        "test_178_0.jpg",
        "test_178_1.jpg",
        "test_178_2.jpg",
        "test_178_3.jpg",
        "test_178_4.jpg",
        "test_178_5.jpg",
        "test_178_6.jpg",
        "test_178_7.jpg",
        "test_178_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          2,
          3,
          1,
          5,
          6,
          7,
          8,
          0
        ],
        "order_filenames": [
          "test_178_4.jpg",
          "test_178_2.jpg",
          "test_178_3.jpg",
          "test_178_1.jpg",
          "test_178_5.jpg",
          "test_178_6.jpg",
          "test_178_7.jpg",
          "test_178_8.jpg",
          "test_178_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_178_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            2,
            4
          ],
          "winner_filenames": [
            "test_178_2.jpg",
            "test_178_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2,
            4
          ],
          "winner_filenames": [
            "test_178_2.jpg",
            "test_178_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1788330078125,
            0.2200927734375,
            0.2279052734375,
            0.1746826171875,
            0.175048828125,
            0.1741943359375,
            0.2252197265625,
            0.2001953125,
            0.264892578125
          ],
          "order_indices": [
            8,
            2,
            6,
            1,
            7,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_178_8.jpg",
            "test_178_2.jpg",
            "test_178_6.jpg",
            "test_178_1.jpg",
            "test_178_7.jpg",
            "test_178_0.jpg",
            "test_178_4.jpg",
            "test_178_3.jpg",
            "test_178_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.2333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.5625,
            39.0625,
            35.96875,
            35.375,
            29.15625,
            26.921875,
            29.203125,
            41.34375,
            43.78125
          ],
          "order_indices": [
            8,
            7,
            0,
            1,
            2,
            3,
            6,
            4,
            5
          ],
          "order_filenames": [
            "test_178_8.jpg",
            "test_178_7.jpg",
            "test_178_0.jpg",
            "test_178_1.jpg",
            "test_178_2.jpg",
            "test_178_3.jpg",
            "test_178_6.jpg",
            "test_178_4.jpg",
            "test_178_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.6166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.5967077016830444,
            1.0548293590545654,
            -0.040577616542577744,
            -0.3089679479598999,
            -1.241219162940979,
            -2.0292441844940186,
            -1.7215579748153687,
            0.7398009896278381,
            1.7389445304870605
          ],
          "order_indices": [
            8,
            0,
            1,
            7,
            2,
            3,
            4,
            6,
            5
          ],
          "order_filenames": [
            "test_178_8.jpg",
            "test_178_0.jpg",
            "test_178_1.jpg",
            "test_178_7.jpg",
            "test_178_2.jpg",
            "test_178_3.jpg",
            "test_178_4.jpg",
            "test_178_6.jpg",
            "test_178_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.5166666666666666,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 179,
      "prompt": "Small carved figurines of fantasy buildings, miniatures and standalone objects on a table.",
      "image_filenames": [
        "test_179_0.jpg",
        "test_179_1.jpg",
        "test_179_2.jpg",
        "test_179_3.jpg",
        "test_179_4.jpg",
        "test_179_5.jpg",
        "test_179_6.jpg",
        "test_179_7.jpg",
        "test_179_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          3,
          0,
          2,
          1,
          5,
          6,
          8,
          7
        ],
        "order_filenames": [
          "test_179_4.jpg",
          "test_179_3.jpg",
          "test_179_0.jpg",
          "test_179_2.jpg",
          "test_179_1.jpg",
          "test_179_5.jpg",
          "test_179_6.jpg",
          "test_179_8.jpg",
          "test_179_7.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_179_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_179_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_179_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.21044921875,
            0.228271484375,
            0.2476806640625,
            0.1971435546875,
            0.1776123046875,
            0.1822509765625,
            0.231201171875,
            0.2213134765625,
            0.2327880859375
          ],
          "order_indices": [
            2,
            8,
            6,
            1,
            7,
            0,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_179_2.jpg",
            "test_179_8.jpg",
            "test_179_6.jpg",
            "test_179_1.jpg",
            "test_179_7.jpg",
            "test_179_0.jpg",
            "test_179_3.jpg",
            "test_179_5.jpg",
            "test_179_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.5,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            33.15625,
            31.375,
            38.34375,
            28.5625,
            31.515625,
            24.59375,
            31.25,
            38.8125,
            33.28125
          ],
          "order_indices": [
            7,
            2,
            8,
            0,
            4,
            1,
            6,
            3,
            5
          ],
          "order_filenames": [
            "test_179_7.jpg",
            "test_179_2.jpg",
            "test_179_8.jpg",
            "test_179_0.jpg",
            "test_179_4.jpg",
            "test_179_1.jpg",
            "test_179_6.jpg",
            "test_179_3.jpg",
            "test_179_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.30000000000000004,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.1533907651901245,
            -0.24102818965911865,
            1.1654531955718994,
            -0.5073056221008301,
            0.41634222865104675,
            -0.5083187818527222,
            -0.19484978914260864,
            1.4702426195144653,
            0.3457466959953308
          ],
          "order_indices": [
            7,
            2,
            0,
            4,
            8,
            6,
            1,
            3,
            5
          ],
          "order_filenames": [
            "test_179_7.jpg",
            "test_179_2.jpg",
            "test_179_0.jpg",
            "test_179_4.jpg",
            "test_179_8.jpg",
            "test_179_6.jpg",
            "test_179_1.jpg",
            "test_179_3.jpg",
            "test_179_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.1333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 180,
      "prompt": "A full body character of a mouse technomage in cyberpunk armor with a neon background, painted by jorsch.",
      "image_filenames": [
        "test_180_0.jpg",
        "test_180_1.jpg",
        "test_180_2.jpg",
        "test_180_3.jpg",
        "test_180_4.jpg",
        "test_180_5.jpg",
        "test_180_6.jpg",
        "test_180_7.jpg",
        "test_180_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          3,
          6,
          2,
          4,
          7,
          8,
          1,
          0
        ],
        "order_filenames": [
          "test_180_5.jpg",
          "test_180_3.jpg",
          "test_180_6.jpg",
          "test_180_2.jpg",
          "test_180_4.jpg",
          "test_180_7.jpg",
          "test_180_8.jpg",
          "test_180_1.jpg",
          "test_180_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_180_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            2,
            5
          ],
          "winner_filenames": [
            "test_180_2.jpg",
            "test_180_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_180_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.242919921875,
            0.23486328125,
            0.255126953125,
            0.1802978515625,
            0.184326171875,
            0.11285400390625,
            0.2022705078125,
            0.260498046875,
            0.280517578125
          ],
          "order_indices": [
            8,
            7,
            2,
            0,
            1,
            6,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_180_8.jpg",
            "test_180_7.jpg",
            "test_180_2.jpg",
            "test_180_0.jpg",
            "test_180_1.jpg",
            "test_180_6.jpg",
            "test_180_4.jpg",
            "test_180_3.jpg",
            "test_180_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5555555555555556,
            "spearman_rho": -0.6666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            47.71875,
            43.875,
            40.875,
            35.375,
            32.59375,
            23.78125,
            41.09375,
            50.0625,
            48.0
          ],
          "order_indices": [
            7,
            8,
            0,
            1,
            6,
            2,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_180_7.jpg",
            "test_180_8.jpg",
            "test_180_0.jpg",
            "test_180_1.jpg",
            "test_180_6.jpg",
            "test_180_2.jpg",
            "test_180_3.jpg",
            "test_180_4.jpg",
            "test_180_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.7333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.5354241132736206,
            1.5049552917480469,
            1.4011470079421997,
            0.4884675145149231,
            0.6334440112113953,
            -2.112370252609253,
            -0.19488324224948883,
            1.81228506565094,
            1.305620789527893
          ],
          "order_indices": [
            7,
            0,
            1,
            2,
            8,
            4,
            3,
            6,
            5
          ],
          "order_filenames": [
            "test_180_7.jpg",
            "test_180_0.jpg",
            "test_180_1.jpg",
            "test_180_2.jpg",
            "test_180_8.jpg",
            "test_180_4.jpg",
            "test_180_3.jpg",
            "test_180_6.jpg",
            "test_180_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.6666666666666666,
            "spearman_rho": -0.8166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 181,
      "prompt": "A female human barbarian depicted in a traditional Dungeons and Dragons illustration.",
      "image_filenames": [
        "test_181_0.jpg",
        "test_181_1.jpg",
        "test_181_2.jpg",
        "test_181_3.jpg",
        "test_181_4.jpg",
        "test_181_5.jpg",
        "test_181_6.jpg",
        "test_181_7.jpg",
        "test_181_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          0,
          6,
          5,
          3,
          2,
          7,
          8,
          1
        ],
        "order_filenames": [
          "test_181_4.jpg",
          "test_181_0.jpg",
          "test_181_6.jpg",
          "test_181_5.jpg",
          "test_181_3.jpg",
          "test_181_2.jpg",
          "test_181_7.jpg",
          "test_181_8.jpg",
          "test_181_1.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_181_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_181_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_181_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2010498046875,
            0.1812744140625,
            0.23388671875,
            0.1746826171875,
            0.1571044921875,
            0.078369140625,
            0.2166748046875,
            0.21435546875,
            0.1778564453125
          ],
          "order_indices": [
            2,
            6,
            7,
            0,
            1,
            8,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_181_2.jpg",
            "test_181_6.jpg",
            "test_181_7.jpg",
            "test_181_0.jpg",
            "test_181_1.jpg",
            "test_181_8.jpg",
            "test_181_3.jpg",
            "test_181_4.jpg",
            "test_181_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.19999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.5,
            38.78125,
            37.71875,
            28.78125,
            22.28125,
            13.9375,
            39.75,
            38.71875,
            33.03125
          ],
          "order_indices": [
            6,
            1,
            7,
            0,
            2,
            8,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_181_6.jpg",
            "test_181_1.jpg",
            "test_181_7.jpg",
            "test_181_0.jpg",
            "test_181_2.jpg",
            "test_181_8.jpg",
            "test_181_3.jpg",
            "test_181_4.jpg",
            "test_181_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.30000000000000004,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.24056971073150635,
            -1.9203946590423584,
            -0.21820318698883057,
            -0.27570056915283203,
            -0.6955065131187439,
            -2.1286065578460693,
            -0.44826242327690125,
            0.11723194271326065,
            -0.8197910189628601
          ],
          "order_indices": [
            0,
            7,
            2,
            3,
            6,
            4,
            8,
            1,
            5
          ],
          "order_filenames": [
            "test_181_0.jpg",
            "test_181_7.jpg",
            "test_181_2.jpg",
            "test_181_3.jpg",
            "test_181_6.jpg",
            "test_181_4.jpg",
            "test_181_8.jpg",
            "test_181_1.jpg",
            "test_181_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.23333333333333328,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 182,
      "prompt": "Hooded figure standing over a ruined city with red haze and a grin.",
      "image_filenames": [
        "test_182_0.jpg",
        "test_182_1.jpg",
        "test_182_2.jpg",
        "test_182_3.jpg",
        "test_182_4.jpg",
        "test_182_5.jpg",
        "test_182_6.jpg",
        "test_182_7.jpg",
        "test_182_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          7,
          6,
          3,
          5,
          1,
          8,
          2,
          0
        ],
        "order_filenames": [
          "test_182_4.jpg",
          "test_182_7.jpg",
          "test_182_6.jpg",
          "test_182_3.jpg",
          "test_182_5.jpg",
          "test_182_1.jpg",
          "test_182_8.jpg",
          "test_182_2.jpg",
          "test_182_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_182_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_182_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_182_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2008056640625,
            0.2069091796875,
            0.2861328125,
            0.2386474609375,
            0.203369140625,
            0.1507568359375,
            0.275634765625,
            0.2259521484375,
            0.283935546875
          ],
          "order_indices": [
            2,
            8,
            6,
            3,
            7,
            1,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_182_2.jpg",
            "test_182_8.jpg",
            "test_182_6.jpg",
            "test_182_3.jpg",
            "test_182_7.jpg",
            "test_182_1.jpg",
            "test_182_4.jpg",
            "test_182_0.jpg",
            "test_182_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.1333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.75,
            30.453125,
            42.09375,
            38.53125,
            41.5625,
            28.875,
            41.0625,
            39.28125,
            38.1875
          ],
          "order_indices": [
            2,
            4,
            6,
            7,
            3,
            8,
            0,
            1,
            5
          ],
          "order_filenames": [
            "test_182_2.jpg",
            "test_182_4.jpg",
            "test_182_6.jpg",
            "test_182_7.jpg",
            "test_182_3.jpg",
            "test_182_8.jpg",
            "test_182_0.jpg",
            "test_182_1.jpg",
            "test_182_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2777777777777778,
            "spearman_rho": 0.33333333333333337,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.510805606842041,
            0.34440869092941284,
            1.780283808708191,
            0.39436787366867065,
            0.9096354842185974,
            -0.6675435304641724,
            1.1191083192825317,
            1.2425484657287598,
            1.711044192314148
          ],
          "order_indices": [
            2,
            8,
            7,
            6,
            4,
            0,
            3,
            1,
            5
          ],
          "order_filenames": [
            "test_182_2.jpg",
            "test_182_8.jpg",
            "test_182_7.jpg",
            "test_182_6.jpg",
            "test_182_4.jpg",
            "test_182_0.jpg",
            "test_182_3.jpg",
            "test_182_1.jpg",
            "test_182_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.08333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 183,
      "prompt": "A screenshot taken in hl2.",
      "image_filenames": [
        "test_183_0.jpg",
        "test_183_1.jpg",
        "test_183_2.jpg",
        "test_183_3.jpg",
        "test_183_4.jpg",
        "test_183_5.jpg",
        "test_183_6.jpg",
        "test_183_7.jpg",
        "test_183_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          1,
          4,
          5,
          3,
          6,
          7,
          8,
          2
        ],
        "order_filenames": [
          "test_183_0.jpg",
          "test_183_1.jpg",
          "test_183_4.jpg",
          "test_183_5.jpg",
          "test_183_3.jpg",
          "test_183_6.jpg",
          "test_183_7.jpg",
          "test_183_8.jpg",
          "test_183_2.jpg"
        ],
        "condorcet_winner": 1,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_183_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3,
            4
          ],
          "winner_filenames": [
            "test_183_3.jpg",
            "test_183_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_183_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.178466796875,
            0.2056884765625,
            0.237548828125,
            0.1590576171875,
            0.1453857421875,
            0.1568603515625,
            0.1864013671875,
            0.19189453125,
            0.193603515625
          ],
          "order_indices": [
            2,
            1,
            8,
            7,
            6,
            0,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_183_2.jpg",
            "test_183_1.jpg",
            "test_183_8.jpg",
            "test_183_7.jpg",
            "test_183_6.jpg",
            "test_183_0.jpg",
            "test_183_3.jpg",
            "test_183_5.jpg",
            "test_183_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.5,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            29.5,
            34.4375,
            30.78125,
            31.609375,
            22.78125,
            27.78125,
            31.671875,
            28.84375,
            31.109375
          ],
          "order_indices": [
            1,
            6,
            3,
            8,
            2,
            0,
            7,
            5,
            4
          ],
          "order_filenames": [
            "test_183_1.jpg",
            "test_183_6.jpg",
            "test_183_3.jpg",
            "test_183_8.jpg",
            "test_183_2.jpg",
            "test_183_0.jpg",
            "test_183_7.jpg",
            "test_183_5.jpg",
            "test_183_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.08333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 1.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.8632098436355591,
            -0.4469914436340332,
            -0.5271581411361694,
            -0.08900605887174606,
            -0.7712362408638,
            -0.6477999687194824,
            -0.49993598461151123,
            -0.6746331453323364,
            -0.5367671847343445
          ],
          "order_indices": [
            3,
            1,
            6,
            2,
            8,
            5,
            7,
            4,
            0
          ],
          "order_filenames": [
            "test_183_3.jpg",
            "test_183_1.jpg",
            "test_183_6.jpg",
            "test_183_2.jpg",
            "test_183_8.jpg",
            "test_183_5.jpg",
            "test_183_7.jpg",
            "test_183_4.jpg",
            "test_183_0.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.2666666666666666,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 184,
      "prompt": "A digital illustration titled \"The Rise of a Dadaist Government\" by Jeffrey Smith and Tim Biskup.",
      "image_filenames": [
        "test_184_0.jpg",
        "test_184_1.jpg",
        "test_184_2.jpg",
        "test_184_3.jpg",
        "test_184_4.jpg",
        "test_184_5.jpg",
        "test_184_6.jpg",
        "test_184_7.jpg",
        "test_184_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          3,
          1,
          6,
          5,
          2,
          7,
          8,
          0
        ],
        "order_filenames": [
          "test_184_4.jpg",
          "test_184_3.jpg",
          "test_184_1.jpg",
          "test_184_6.jpg",
          "test_184_5.jpg",
          "test_184_2.jpg",
          "test_184_7.jpg",
          "test_184_8.jpg",
          "test_184_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_184_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4,
            6
          ],
          "winner_filenames": [
            "test_184_4.jpg",
            "test_184_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_184_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1622314453125,
            0.1895751953125,
            0.2271728515625,
            0.1773681640625,
            0.1680908203125,
            0.1343994140625,
            0.18603515625,
            0.185302734375,
            0.2359619140625
          ],
          "order_indices": [
            8,
            2,
            1,
            6,
            7,
            3,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_184_8.jpg",
            "test_184_2.jpg",
            "test_184_1.jpg",
            "test_184_6.jpg",
            "test_184_7.jpg",
            "test_184_3.jpg",
            "test_184_4.jpg",
            "test_184_0.jpg",
            "test_184_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.1499999999999999,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            29.90625,
            36.0,
            37.8125,
            28.125,
            18.296875,
            22.734375,
            30.796875,
            34.9375,
            32.03125
          ],
          "order_indices": [
            2,
            1,
            7,
            8,
            6,
            0,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_184_2.jpg",
            "test_184_1.jpg",
            "test_184_7.jpg",
            "test_184_8.jpg",
            "test_184_6.jpg",
            "test_184_0.jpg",
            "test_184_3.jpg",
            "test_184_5.jpg",
            "test_184_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.3833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.3486882448196411,
            -0.5457749962806702,
            0.21454234421253204,
            -0.9198511242866516,
            -1.15619957447052,
            -2.0545167922973633,
            -0.5385339856147766,
            -0.6262303590774536,
            0.6643890142440796
          ],
          "order_indices": [
            8,
            2,
            6,
            1,
            7,
            3,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_184_8.jpg",
            "test_184_2.jpg",
            "test_184_6.jpg",
            "test_184_1.jpg",
            "test_184_7.jpg",
            "test_184_3.jpg",
            "test_184_4.jpg",
            "test_184_0.jpg",
            "test_184_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.16666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 185,
      "prompt": "A lady in a purple dress sitting in a tree - concept art.",
      "image_filenames": [
        "test_185_0.jpg",
        "test_185_1.jpg",
        "test_185_2.jpg",
        "test_185_3.jpg",
        "test_185_4.jpg",
        "test_185_5.jpg",
        "test_185_6.jpg",
        "test_185_7.jpg",
        "test_185_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          4,
          0,
          6,
          1,
          5,
          7,
          2,
          8
        ],
        "order_filenames": [
          "test_185_3.jpg",
          "test_185_4.jpg",
          "test_185_0.jpg",
          "test_185_6.jpg",
          "test_185_1.jpg",
          "test_185_5.jpg",
          "test_185_7.jpg",
          "test_185_2.jpg",
          "test_185_8.jpg"
        ],
        "condorcet_winner": 3,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_185_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_185_3.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_185_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2130126953125,
            0.2442626953125,
            0.304931640625,
            0.243896484375,
            0.233642578125,
            0.1746826171875,
            0.2110595703125,
            0.2357177734375,
            0.304931640625
          ],
          "order_indices": [
            2,
            8,
            1,
            3,
            7,
            4,
            0,
            6,
            5
          ],
          "order_filenames": [
            "test_185_2.jpg",
            "test_185_8.jpg",
            "test_185_1.jpg",
            "test_185_3.jpg",
            "test_185_7.jpg",
            "test_185_4.jpg",
            "test_185_0.jpg",
            "test_185_6.jpg",
            "test_185_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.43333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.28125,
            42.25,
            46.5625,
            35.75,
            36.625,
            32.4375,
            32.59375,
            46.15625,
            44.46875
          ],
          "order_indices": [
            2,
            7,
            8,
            1,
            0,
            4,
            3,
            6,
            5
          ],
          "order_filenames": [
            "test_185_2.jpg",
            "test_185_7.jpg",
            "test_185_8.jpg",
            "test_185_1.jpg",
            "test_185_0.jpg",
            "test_185_4.jpg",
            "test_185_3.jpg",
            "test_185_6.jpg",
            "test_185_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.6000000000000001,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.2030019611120224,
            0.34729912877082825,
            1.0562052726745605,
            0.629174530506134,
            1.4186183214187622,
            -1.9682941436767578,
            -0.4864651560783386,
            -0.207684725522995,
            1.7856929302215576
          ],
          "order_indices": [
            8,
            4,
            2,
            3,
            1,
            0,
            7,
            6,
            5
          ],
          "order_filenames": [
            "test_185_8.jpg",
            "test_185_4.jpg",
            "test_185_2.jpg",
            "test_185_3.jpg",
            "test_185_1.jpg",
            "test_185_0.jpg",
            "test_185_7.jpg",
            "test_185_6.jpg",
            "test_185_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.10000000000000009,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 186,
      "prompt": "A spray painted and analogue collage with canvas texture in a contemporary art style featuring a mathematically correct Tetris design.",
      "image_filenames": [
        "test_186_0.jpg",
        "test_186_1.jpg",
        "test_186_2.jpg",
        "test_186_3.jpg",
        "test_186_4.jpg",
        "test_186_5.jpg",
        "test_186_6.jpg",
        "test_186_7.jpg",
        "test_186_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          1,
          5,
          6,
          2,
          8,
          4,
          7,
          3
        ],
        "order_filenames": [
          "test_186_0.jpg",
          "test_186_1.jpg",
          "test_186_5.jpg",
          "test_186_6.jpg",
          "test_186_2.jpg",
          "test_186_8.jpg",
          "test_186_4.jpg",
          "test_186_7.jpg",
          "test_186_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_186_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_186_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_186_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.20458984375,
            0.22265625,
            0.222900390625,
            0.2205810546875,
            0.1708984375,
            0.1915283203125,
            0.2333984375,
            0.245361328125,
            0.1773681640625
          ],
          "order_indices": [
            7,
            6,
            2,
            1,
            3,
            0,
            5,
            8,
            4
          ],
          "order_filenames": [
            "test_186_7.jpg",
            "test_186_6.jpg",
            "test_186_2.jpg",
            "test_186_1.jpg",
            "test_186_3.jpg",
            "test_186_0.jpg",
            "test_186_5.jpg",
            "test_186_8.jpg",
            "test_186_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.050000000000000044,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.3125,
            36.90625,
            42.375,
            29.359375,
            23.71875,
            31.25,
            41.25,
            42.875,
            38.125
          ],
          "order_indices": [
            7,
            2,
            6,
            8,
            1,
            0,
            5,
            3,
            4
          ],
          "order_filenames": [
            "test_186_7.jpg",
            "test_186_2.jpg",
            "test_186_6.jpg",
            "test_186_8.jpg",
            "test_186_1.jpg",
            "test_186_0.jpg",
            "test_186_5.jpg",
            "test_186_3.jpg",
            "test_186_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": 0.01666666666666672,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.24960944056510925,
            -0.1275593340396881,
            -0.6769181489944458,
            -0.5444703102111816,
            -0.8767622709274292,
            -0.41596850752830505,
            -0.33639487624168396,
            0.5013205409049988,
            -0.5962399840354919
          ],
          "order_indices": [
            7,
            1,
            0,
            6,
            5,
            3,
            8,
            2,
            4
          ],
          "order_filenames": [
            "test_186_7.jpg",
            "test_186_1.jpg",
            "test_186_0.jpg",
            "test_186_6.jpg",
            "test_186_5.jpg",
            "test_186_3.jpg",
            "test_186_8.jpg",
            "test_186_2.jpg",
            "test_186_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2777777777777778,
            "spearman_rho": 0.33333333333333337,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 187,
      "prompt": "The image features a closeup portrait of stone angel statues, created with the Unreal Engine and featuring intricate details by various artists.",
      "image_filenames": [
        "test_187_0.jpg",
        "test_187_1.jpg",
        "test_187_2.jpg",
        "test_187_3.jpg",
        "test_187_4.jpg",
        "test_187_5.jpg",
        "test_187_6.jpg",
        "test_187_7.jpg",
        "test_187_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          4,
          3,
          0,
          6,
          7,
          8,
          1,
          2
        ],
        "order_filenames": [
          "test_187_5.jpg",
          "test_187_4.jpg",
          "test_187_3.jpg",
          "test_187_0.jpg",
          "test_187_6.jpg",
          "test_187_7.jpg",
          "test_187_8.jpg",
          "test_187_1.jpg",
          "test_187_2.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_187_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_187_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_187_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2069091796875,
            0.251220703125,
            0.1900634765625,
            0.2080078125,
            0.170654296875,
            0.138916015625,
            0.250732421875,
            0.287109375,
            0.2193603515625
          ],
          "order_indices": [
            7,
            1,
            6,
            8,
            3,
            0,
            2,
            4,
            5
          ],
          "order_filenames": [
            "test_187_7.jpg",
            "test_187_1.jpg",
            "test_187_6.jpg",
            "test_187_8.jpg",
            "test_187_3.jpg",
            "test_187_0.jpg",
            "test_187_2.jpg",
            "test_187_4.jpg",
            "test_187_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.55,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.4375,
            42.625,
            39.0,
            29.328125,
            29.078125,
            29.34375,
            39.71875,
            45.53125,
            37.6875
          ],
          "order_indices": [
            7,
            1,
            6,
            2,
            8,
            0,
            5,
            3,
            4
          ],
          "order_filenames": [
            "test_187_7.jpg",
            "test_187_1.jpg",
            "test_187_6.jpg",
            "test_187_2.jpg",
            "test_187_8.jpg",
            "test_187_0.jpg",
            "test_187_5.jpg",
            "test_187_3.jpg",
            "test_187_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5555555555555556,
            "spearman_rho": -0.7333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.01710081286728382,
            -0.887944221496582,
            -0.7104954123497009,
            -1.179945468902588,
            -1.7214428186416626,
            -1.6555266380310059,
            -0.09713807702064514,
            1.3533294200897217,
            0.4139380156993866
          ],
          "order_indices": [
            7,
            8,
            0,
            6,
            2,
            1,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_187_7.jpg",
            "test_187_8.jpg",
            "test_187_0.jpg",
            "test_187_6.jpg",
            "test_187_2.jpg",
            "test_187_1.jpg",
            "test_187_3.jpg",
            "test_187_5.jpg",
            "test_187_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.55,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 188,
      "prompt": "A colorful tin toy robot runs a steam engine on a path near a beautiful flower meadow in the Swiss Alps with a mountain panorama in the background, captured in a long shot with motion blur and depth of field.",
      "image_filenames": [
        "test_188_0.jpg",
        "test_188_1.jpg",
        "test_188_2.jpg",
        "test_188_3.jpg",
        "test_188_4.jpg",
        "test_188_5.jpg",
        "test_188_6.jpg",
        "test_188_7.jpg",
        "test_188_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          0,
          5,
          2,
          3,
          1,
          6,
          8,
          7
        ],
        "order_filenames": [
          "test_188_4.jpg",
          "test_188_0.jpg",
          "test_188_5.jpg",
          "test_188_2.jpg",
          "test_188_3.jpg",
          "test_188_1.jpg",
          "test_188_6.jpg",
          "test_188_8.jpg",
          "test_188_7.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_188_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4,
            5
          ],
          "winner_filenames": [
            "test_188_4.jpg",
            "test_188_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_188_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.234375,
            0.31103515625,
            0.272216796875,
            0.2340087890625,
            0.1759033203125,
            0.1973876953125,
            0.288330078125,
            0.246826171875,
            0.26953125
          ],
          "order_indices": [
            1,
            6,
            2,
            8,
            7,
            0,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_188_1.jpg",
            "test_188_6.jpg",
            "test_188_2.jpg",
            "test_188_8.jpg",
            "test_188_7.jpg",
            "test_188_0.jpg",
            "test_188_3.jpg",
            "test_188_5.jpg",
            "test_188_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.6000000000000001,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            46.96875,
            46.96875,
            46.71875,
            30.3125,
            31.921875,
            47.65625,
            42.125,
            46.28125,
            43.5625
          ],
          "order_indices": [
            5,
            0,
            1,
            2,
            7,
            8,
            6,
            4,
            3
          ],
          "order_filenames": [
            "test_188_5.jpg",
            "test_188_0.jpg",
            "test_188_1.jpg",
            "test_188_2.jpg",
            "test_188_7.jpg",
            "test_188_8.jpg",
            "test_188_6.jpg",
            "test_188_4.jpg",
            "test_188_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.2501424551010132,
            1.211869239807129,
            1.2138619422912598,
            0.686294436454773,
            -0.7218490839004517,
            -0.23857775330543518,
            0.9162535071372986,
            0.8462389707565308,
            0.8127149939537048
          ],
          "order_indices": [
            0,
            2,
            1,
            6,
            7,
            8,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_188_0.jpg",
            "test_188_2.jpg",
            "test_188_1.jpg",
            "test_188_6.jpg",
            "test_188_7.jpg",
            "test_188_8.jpg",
            "test_188_3.jpg",
            "test_188_5.jpg",
            "test_188_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.1333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 189,
      "prompt": "Male vampire of clan Banu Haqim with blue braided hair stands in a modern city at night surrounded by neon signs, jewelry, and tattoos.",
      "image_filenames": [
        "test_189_0.jpg",
        "test_189_1.jpg",
        "test_189_2.jpg",
        "test_189_3.jpg",
        "test_189_4.jpg",
        "test_189_5.jpg",
        "test_189_6.jpg",
        "test_189_7.jpg",
        "test_189_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          4,
          1,
          0,
          6,
          5,
          7,
          8,
          3
        ],
        "order_filenames": [
          "test_189_2.jpg",
          "test_189_4.jpg",
          "test_189_1.jpg",
          "test_189_0.jpg",
          "test_189_6.jpg",
          "test_189_5.jpg",
          "test_189_7.jpg",
          "test_189_8.jpg",
          "test_189_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_189_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_189_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_189_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.207275390625,
            0.304443359375,
            0.32275390625,
            0.1788330078125,
            0.1937255859375,
            0.08099365234375,
            0.24560546875,
            0.256591796875,
            0.272705078125
          ],
          "order_indices": [
            2,
            1,
            8,
            7,
            6,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_189_2.jpg",
            "test_189_1.jpg",
            "test_189_8.jpg",
            "test_189_7.jpg",
            "test_189_6.jpg",
            "test_189_0.jpg",
            "test_189_4.jpg",
            "test_189_3.jpg",
            "test_189_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.3833333333333333,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            45.53125,
            43.21875,
            43.75,
            29.21875,
            35.5,
            18.5625,
            44.9375,
            49.78125,
            41.625
          ],
          "order_indices": [
            7,
            0,
            6,
            2,
            1,
            8,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_189_7.jpg",
            "test_189_0.jpg",
            "test_189_6.jpg",
            "test_189_2.jpg",
            "test_189_1.jpg",
            "test_189_8.jpg",
            "test_189_4.jpg",
            "test_189_3.jpg",
            "test_189_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.19999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.517042636871338,
            1.854358434677124,
            1.05447518825531,
            -1.1739815473556519,
            -0.9786427021026611,
            -2.217961311340332,
            0.9236365556716919,
            1.3559412956237793,
            -0.11944584548473358
          ],
          "order_indices": [
            1,
            0,
            7,
            2,
            6,
            8,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_189_1.jpg",
            "test_189_0.jpg",
            "test_189_7.jpg",
            "test_189_2.jpg",
            "test_189_6.jpg",
            "test_189_8.jpg",
            "test_189_4.jpg",
            "test_189_3.jpg",
            "test_189_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.4,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 190,
      "prompt": "The image is a fashion photograph of a humanoid lobster wearing a designer outfit with titanium claws, captured in red color and detailed texture by photographer Jovana Rikalo.",
      "image_filenames": [
        "test_190_0.jpg",
        "test_190_1.jpg",
        "test_190_2.jpg",
        "test_190_3.jpg",
        "test_190_4.jpg",
        "test_190_5.jpg",
        "test_190_6.jpg",
        "test_190_7.jpg",
        "test_190_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          4,
          5,
          2,
          7,
          6,
          8,
          3,
          1
        ],
        "order_filenames": [
          "test_190_0.jpg",
          "test_190_4.jpg",
          "test_190_5.jpg",
          "test_190_2.jpg",
          "test_190_7.jpg",
          "test_190_6.jpg",
          "test_190_8.jpg",
          "test_190_3.jpg",
          "test_190_1.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_190_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            2,
            4,
            5,
            6
          ],
          "winner_filenames": [
            "test_190_2.jpg",
            "test_190_4.jpg",
            "test_190_5.jpg",
            "test_190_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0,
            4
          ],
          "winner_filenames": [
            "test_190_0.jpg",
            "test_190_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2252197265625,
            0.2125244140625,
            0.25341796875,
            0.2109375,
            0.1890869140625,
            0.2001953125,
            0.212646484375,
            0.2222900390625,
            0.25732421875
          ],
          "order_indices": [
            8,
            2,
            0,
            7,
            6,
            1,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_190_8.jpg",
            "test_190_2.jpg",
            "test_190_0.jpg",
            "test_190_7.jpg",
            "test_190_6.jpg",
            "test_190_1.jpg",
            "test_190_3.jpg",
            "test_190_5.jpg",
            "test_190_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.08333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.46875,
            40.96875,
            43.71875,
            35.21875,
            37.09375,
            28.9375,
            41.625,
            45.375,
            47.15625
          ],
          "order_indices": [
            8,
            7,
            2,
            6,
            1,
            4,
            3,
            0,
            5
          ],
          "order_filenames": [
            "test_190_8.jpg",
            "test_190_7.jpg",
            "test_190_2.jpg",
            "test_190_6.jpg",
            "test_190_1.jpg",
            "test_190_4.jpg",
            "test_190_3.jpg",
            "test_190_0.jpg",
            "test_190_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.3999999999999999,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.165602445602417,
            -0.22536538541316986,
            -0.6330411434173584,
            0.06989554315805435,
            0.5266912579536438,
            0.3660396933555603,
            -0.9561464786529541,
            -0.10521961003541946,
            0.2612609267234802
          ],
          "order_indices": [
            0,
            4,
            5,
            8,
            3,
            7,
            1,
            2,
            6
          ],
          "order_filenames": [
            "test_190_0.jpg",
            "test_190_4.jpg",
            "test_190_5.jpg",
            "test_190_8.jpg",
            "test_190_3.jpg",
            "test_190_7.jpg",
            "test_190_1.jpg",
            "test_190_2.jpg",
            "test_190_6.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.5,
            "spearman_rho": 0.6,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 191,
      "prompt": "A giant cosmic tardigrade descending on Tokyo at sunset in a highly detailed concept art.",
      "image_filenames": [
        "test_191_0.jpg",
        "test_191_1.jpg",
        "test_191_2.jpg",
        "test_191_3.jpg",
        "test_191_4.jpg",
        "test_191_5.jpg",
        "test_191_6.jpg",
        "test_191_7.jpg",
        "test_191_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          0,
          1,
          3,
          4,
          8,
          5,
          7,
          6
        ],
        "order_filenames": [
          "test_191_2.jpg",
          "test_191_0.jpg",
          "test_191_1.jpg",
          "test_191_3.jpg",
          "test_191_4.jpg",
          "test_191_8.jpg",
          "test_191_5.jpg",
          "test_191_7.jpg",
          "test_191_6.jpg"
        ],
        "condorcet_winner": 2,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_191_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_191_2.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_191_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1971435546875,
            0.223876953125,
            0.252685546875,
            0.1859130859375,
            0.1318359375,
            0.1859130859375,
            0.2066650390625,
            0.241943359375,
            0.2347412109375
          ],
          "order_indices": [
            2,
            7,
            8,
            1,
            6,
            0,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_191_2.jpg",
            "test_191_7.jpg",
            "test_191_8.jpg",
            "test_191_1.jpg",
            "test_191_6.jpg",
            "test_191_0.jpg",
            "test_191_3.jpg",
            "test_191_5.jpg",
            "test_191_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.1333333333333333,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 1.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            48.59375,
            41.03125,
            44.15625,
            30.6875,
            19.21875,
            29.296875,
            32.875,
            45.25,
            40.28125
          ],
          "order_indices": [
            0,
            7,
            2,
            1,
            8,
            6,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_191_0.jpg",
            "test_191_7.jpg",
            "test_191_2.jpg",
            "test_191_1.jpg",
            "test_191_8.jpg",
            "test_191_6.jpg",
            "test_191_3.jpg",
            "test_191_5.jpg",
            "test_191_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2777777777777778,
            "spearman_rho": 0.35,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.3657035827636719,
            0.7955880165100098,
            0.8855748772621155,
            -0.4716046154499054,
            -0.44927242398262024,
            -1.5487427711486816,
            -0.09457280486822128,
            0.420295387506485,
            1.4223774671554565
          ],
          "order_indices": [
            8,
            0,
            2,
            1,
            7,
            6,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_191_8.jpg",
            "test_191_0.jpg",
            "test_191_2.jpg",
            "test_191_1.jpg",
            "test_191_7.jpg",
            "test_191_6.jpg",
            "test_191_4.jpg",
            "test_191_3.jpg",
            "test_191_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2777777777777778,
            "spearman_rho": 0.4,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 192,
      "prompt": "The image depicts Rengoku as Lucifer morningstar in a detailed digital painting available on ArtStation, featuring smooth render and sharp focus.",
      "image_filenames": [
        "test_192_0.jpg",
        "test_192_1.jpg",
        "test_192_2.jpg",
        "test_192_3.jpg",
        "test_192_4.jpg",
        "test_192_5.jpg",
        "test_192_6.jpg",
        "test_192_7.jpg",
        "test_192_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          1,
          5,
          7,
          3,
          8,
          2,
          0,
          4
        ],
        "order_filenames": [
          "test_192_6.jpg",
          "test_192_1.jpg",
          "test_192_5.jpg",
          "test_192_7.jpg",
          "test_192_3.jpg",
          "test_192_8.jpg",
          "test_192_2.jpg",
          "test_192_0.jpg",
          "test_192_4.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_192_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_192_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1,
            6
          ],
          "winner_filenames": [
            "test_192_1.jpg",
            "test_192_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1898193359375,
            0.259765625,
            0.269775390625,
            0.200927734375,
            0.150634765625,
            0.11541748046875,
            0.2269287109375,
            0.2197265625,
            0.26953125
          ],
          "order_indices": [
            2,
            8,
            1,
            6,
            7,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_192_2.jpg",
            "test_192_8.jpg",
            "test_192_1.jpg",
            "test_192_6.jpg",
            "test_192_7.jpg",
            "test_192_3.jpg",
            "test_192_0.jpg",
            "test_192_4.jpg",
            "test_192_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.15000000000000002,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            31.890625,
            34.40625,
            37.125,
            25.890625,
            26.0625,
            18.453125,
            32.34375,
            41.71875,
            29.390625
          ],
          "order_indices": [
            7,
            2,
            1,
            6,
            0,
            8,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_192_7.jpg",
            "test_192_2.jpg",
            "test_192_1.jpg",
            "test_192_6.jpg",
            "test_192_0.jpg",
            "test_192_8.jpg",
            "test_192_4.jpg",
            "test_192_3.jpg",
            "test_192_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.15000000000000002,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.48841536045074463,
            1.279708981513977,
            1.3035954236984253,
            0.12596824765205383,
            -0.16385343670845032,
            -2.244262456893921,
            1.1089637279510498,
            -0.13681598007678986,
            1.1407361030578613
          ],
          "order_indices": [
            2,
            1,
            8,
            6,
            0,
            3,
            7,
            4,
            5
          ],
          "order_filenames": [
            "test_192_2.jpg",
            "test_192_1.jpg",
            "test_192_8.jpg",
            "test_192_6.jpg",
            "test_192_0.jpg",
            "test_192_3.jpg",
            "test_192_7.jpg",
            "test_192_4.jpg",
            "test_192_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.08333333333333337,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 193,
      "prompt": "An image depicting a fantasy architectural concept with dramatic and cinematic touches through environmental concept art and an infographic-like display of marginalia.",
      "image_filenames": [
        "test_193_0.jpg",
        "test_193_1.jpg",
        "test_193_2.jpg",
        "test_193_3.jpg",
        "test_193_4.jpg",
        "test_193_5.jpg",
        "test_193_6.jpg",
        "test_193_7.jpg",
        "test_193_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          2,
          4,
          0,
          6,
          8,
          7,
          5,
          1
        ],
        "order_filenames": [
          "test_193_3.jpg",
          "test_193_2.jpg",
          "test_193_4.jpg",
          "test_193_0.jpg",
          "test_193_6.jpg",
          "test_193_8.jpg",
          "test_193_7.jpg",
          "test_193_5.jpg",
          "test_193_1.jpg"
        ],
        "condorcet_winner": 3,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_193_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_193_3.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_193_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2021484375,
            0.236328125,
            0.2076416015625,
            0.1689453125,
            0.169677734375,
            0.091064453125,
            0.24951171875,
            0.1800537109375,
            0.1607666015625
          ],
          "order_indices": [
            6,
            1,
            2,
            0,
            7,
            4,
            3,
            8,
            5
          ],
          "order_filenames": [
            "test_193_6.jpg",
            "test_193_1.jpg",
            "test_193_2.jpg",
            "test_193_0.jpg",
            "test_193_7.jpg",
            "test_193_4.jpg",
            "test_193_3.jpg",
            "test_193_8.jpg",
            "test_193_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.0,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.75,
            32.78125,
            42.4375,
            31.234375,
            23.859375,
            22.0625,
            37.5,
            39.03125,
            26.375
          ],
          "order_indices": [
            2,
            7,
            6,
            0,
            1,
            3,
            8,
            4,
            5
          ],
          "order_filenames": [
            "test_193_2.jpg",
            "test_193_7.jpg",
            "test_193_6.jpg",
            "test_193_0.jpg",
            "test_193_1.jpg",
            "test_193_3.jpg",
            "test_193_8.jpg",
            "test_193_4.jpg",
            "test_193_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.4066297709941864,
            0.3625836968421936,
            0.9689751863479614,
            -0.45223867893218994,
            -0.44307881593704224,
            -1.240892767906189,
            1.2855604887008667,
            0.4358691871166229,
            -0.4711810052394867
          ],
          "order_indices": [
            6,
            2,
            7,
            0,
            1,
            4,
            3,
            8,
            5
          ],
          "order_filenames": [
            "test_193_6.jpg",
            "test_193_2.jpg",
            "test_193_7.jpg",
            "test_193_0.jpg",
            "test_193_1.jpg",
            "test_193_4.jpg",
            "test_193_3.jpg",
            "test_193_8.jpg",
            "test_193_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 194,
      "prompt": "\"A samurai warrior made of smoke in Ghibli Studio's mystical and magical style.\"",
      "image_filenames": [
        "test_194_0.jpg",
        "test_194_1.jpg",
        "test_194_2.jpg",
        "test_194_3.jpg",
        "test_194_4.jpg",
        "test_194_5.jpg",
        "test_194_6.jpg",
        "test_194_7.jpg",
        "test_194_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          1,
          2,
          3,
          5,
          0,
          4,
          8,
          7
        ],
        "order_filenames": [
          "test_194_6.jpg",
          "test_194_1.jpg",
          "test_194_2.jpg",
          "test_194_3.jpg",
          "test_194_5.jpg",
          "test_194_0.jpg",
          "test_194_4.jpg",
          "test_194_8.jpg",
          "test_194_7.jpg"
        ],
        "condorcet_winner": 6,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_194_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_194_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_194_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1583251953125,
            0.19482421875,
            0.2529296875,
            0.228515625,
            0.1845703125,
            0.1336669921875,
            0.2374267578125,
            0.22265625,
            0.1990966796875
          ],
          "order_indices": [
            2,
            6,
            3,
            7,
            8,
            1,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_194_2.jpg",
            "test_194_6.jpg",
            "test_194_3.jpg",
            "test_194_7.jpg",
            "test_194_8.jpg",
            "test_194_1.jpg",
            "test_194_4.jpg",
            "test_194_0.jpg",
            "test_194_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.3666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            42.03125,
            34.09375,
            38.65625,
            33.0625,
            23.5625,
            23.375,
            28.671875,
            46.75,
            35.46875
          ],
          "order_indices": [
            7,
            0,
            2,
            8,
            1,
            3,
            6,
            4,
            5
          ],
          "order_filenames": [
            "test_194_7.jpg",
            "test_194_0.jpg",
            "test_194_2.jpg",
            "test_194_8.jpg",
            "test_194_1.jpg",
            "test_194_3.jpg",
            "test_194_6.jpg",
            "test_194_4.jpg",
            "test_194_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.3500000000000001,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.035328593105077744,
            -0.3039979040622711,
            0.7271822094917297,
            0.4571821689605713,
            -0.1357133835554123,
            -2.0022788047790527,
            -0.47817808389663696,
            0.48598915338516235,
            0.0650632232427597
          ],
          "order_indices": [
            2,
            7,
            3,
            8,
            0,
            4,
            1,
            6,
            5
          ],
          "order_filenames": [
            "test_194_2.jpg",
            "test_194_7.jpg",
            "test_194_3.jpg",
            "test_194_8.jpg",
            "test_194_0.jpg",
            "test_194_4.jpg",
            "test_194_1.jpg",
            "test_194_6.jpg",
            "test_194_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.3500000000000001,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 195,
      "prompt": "A brightly painted temple with ornate structures and dramatic lighting inspired by Mayan and Islamic architecture.",
      "image_filenames": [
        "test_195_0.jpg",
        "test_195_1.jpg",
        "test_195_2.jpg",
        "test_195_3.jpg",
        "test_195_4.jpg",
        "test_195_5.jpg",
        "test_195_6.jpg",
        "test_195_7.jpg",
        "test_195_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          0,
          1,
          2,
          3,
          8,
          5,
          7,
          6
        ],
        "order_filenames": [
          "test_195_4.jpg",
          "test_195_0.jpg",
          "test_195_1.jpg",
          "test_195_2.jpg",
          "test_195_3.jpg",
          "test_195_8.jpg",
          "test_195_5.jpg",
          "test_195_7.jpg",
          "test_195_6.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_195_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_195_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1,
            4
          ],
          "winner_filenames": [
            "test_195_1.jpg",
            "test_195_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.261962890625,
            0.309814453125,
            0.31103515625,
            0.264892578125,
            0.25537109375,
            0.196533203125,
            0.31201171875,
            0.25048828125,
            0.2337646484375
          ],
          "order_indices": [
            6,
            2,
            1,
            3,
            0,
            4,
            7,
            8,
            5
          ],
          "order_filenames": [
            "test_195_6.jpg",
            "test_195_2.jpg",
            "test_195_1.jpg",
            "test_195_3.jpg",
            "test_195_0.jpg",
            "test_195_4.jpg",
            "test_195_7.jpg",
            "test_195_8.jpg",
            "test_195_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.625,
            36.59375,
            39.96875,
            36.0,
            34.625,
            29.828125,
            29.71875,
            41.78125,
            35.53125
          ],
          "order_indices": [
            7,
            2,
            0,
            1,
            3,
            8,
            4,
            5,
            6
          ],
          "order_filenames": [
            "test_195_7.jpg",
            "test_195_2.jpg",
            "test_195_0.jpg",
            "test_195_1.jpg",
            "test_195_3.jpg",
            "test_195_8.jpg",
            "test_195_4.jpg",
            "test_195_5.jpg",
            "test_195_6.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.23333333333333328,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.3368957042694092,
            0.7437466979026794,
            0.9337905645370483,
            0.7669703960418701,
            -0.3703264892101288,
            -0.31463000178337097,
            0.40713250637054443,
            0.460262268781662,
            -0.201319620013237
          ],
          "order_indices": [
            0,
            2,
            3,
            1,
            7,
            6,
            8,
            5,
            4
          ],
          "order_filenames": [
            "test_195_0.jpg",
            "test_195_2.jpg",
            "test_195_3.jpg",
            "test_195_1.jpg",
            "test_195_7.jpg",
            "test_195_6.jpg",
            "test_195_8.jpg",
            "test_195_5.jpg",
            "test_195_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.21666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 196,
      "prompt": "Underwater concept art of marine life in Sea of Thieves featuring a wild boar.",
      "image_filenames": [
        "test_196_0.jpg",
        "test_196_1.jpg",
        "test_196_2.jpg",
        "test_196_3.jpg",
        "test_196_4.jpg",
        "test_196_5.jpg",
        "test_196_6.jpg",
        "test_196_7.jpg",
        "test_196_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          6,
          7,
          4,
          5,
          1,
          2,
          8,
          0
        ],
        "order_filenames": [
          "test_196_3.jpg",
          "test_196_6.jpg",
          "test_196_7.jpg",
          "test_196_4.jpg",
          "test_196_5.jpg",
          "test_196_1.jpg",
          "test_196_2.jpg",
          "test_196_8.jpg",
          "test_196_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3,
          6
        ],
        "winner_filenames": [
          "test_196_3.jpg",
          "test_196_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_196_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3,
            6
          ],
          "winner_filenames": [
            "test_196_3.jpg",
            "test_196_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2069091796875,
            0.208984375,
            0.288818359375,
            0.1917724609375,
            0.182861328125,
            0.167724609375,
            0.2098388671875,
            0.22314453125,
            0.25927734375
          ],
          "order_indices": [
            2,
            8,
            7,
            6,
            1,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_196_2.jpg",
            "test_196_8.jpg",
            "test_196_7.jpg",
            "test_196_6.jpg",
            "test_196_1.jpg",
            "test_196_0.jpg",
            "test_196_3.jpg",
            "test_196_4.jpg",
            "test_196_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.28333333333333344,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            42.03125,
            27.8125,
            42.875,
            30.484375,
            23.296875,
            29.0625,
            23.46875,
            45.0625,
            36.15625
          ],
          "order_indices": [
            7,
            2,
            0,
            8,
            3,
            5,
            1,
            6,
            4
          ],
          "order_filenames": [
            "test_196_7.jpg",
            "test_196_2.jpg",
            "test_196_0.jpg",
            "test_196_8.jpg",
            "test_196_3.jpg",
            "test_196_5.jpg",
            "test_196_1.jpg",
            "test_196_6.jpg",
            "test_196_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.33333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.036951739341020584,
            -0.6885055303573608,
            0.9057844281196594,
            -0.48746800422668457,
            -1.8335998058319092,
            -0.8042258620262146,
            -0.2406667023897171,
            -0.33153852820396423,
            0.37138107419013977
          ],
          "order_indices": [
            2,
            8,
            0,
            6,
            7,
            3,
            1,
            5,
            4
          ],
          "order_filenames": [
            "test_196_2.jpg",
            "test_196_8.jpg",
            "test_196_0.jpg",
            "test_196_6.jpg",
            "test_196_7.jpg",
            "test_196_3.jpg",
            "test_196_1.jpg",
            "test_196_5.jpg",
            "test_196_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.46666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 197,
      "prompt": "Side-view blue-ice sneaker inspired by Spiderman created by Weta FX.",
      "image_filenames": [
        "test_197_0.jpg",
        "test_197_1.jpg",
        "test_197_2.jpg",
        "test_197_3.jpg",
        "test_197_4.jpg",
        "test_197_5.jpg",
        "test_197_6.jpg",
        "test_197_7.jpg",
        "test_197_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          2,
          0,
          3,
          5,
          4,
          8,
          7,
          6
        ],
        "order_filenames": [
          "test_197_1.jpg",
          "test_197_2.jpg",
          "test_197_0.jpg",
          "test_197_3.jpg",
          "test_197_5.jpg",
          "test_197_4.jpg",
          "test_197_8.jpg",
          "test_197_7.jpg",
          "test_197_6.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_197_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_197_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_197_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2325439453125,
            0.2247314453125,
            0.2371826171875,
            0.2489013671875,
            0.167724609375,
            0.1976318359375,
            0.206787109375,
            0.227294921875,
            0.2117919921875
          ],
          "order_indices": [
            3,
            2,
            0,
            7,
            1,
            8,
            6,
            5,
            4
          ],
          "order_filenames": [
            "test_197_3.jpg",
            "test_197_2.jpg",
            "test_197_0.jpg",
            "test_197_7.jpg",
            "test_197_1.jpg",
            "test_197_8.jpg",
            "test_197_6.jpg",
            "test_197_5.jpg",
            "test_197_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2777777777777778,
            "spearman_rho": 0.4666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            41.53125,
            33.625,
            39.03125,
            31.015625,
            25.59375,
            36.5625,
            31.84375,
            40.46875,
            35.34375
          ],
          "order_indices": [
            0,
            7,
            2,
            5,
            8,
            1,
            6,
            3,
            4
          ],
          "order_filenames": [
            "test_197_0.jpg",
            "test_197_7.jpg",
            "test_197_2.jpg",
            "test_197_5.jpg",
            "test_197_8.jpg",
            "test_197_1.jpg",
            "test_197_6.jpg",
            "test_197_3.jpg",
            "test_197_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.16666666666666663,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.4636770486831665,
            0.45775306224823,
            0.529018223285675,
            0.7941550016403198,
            -1.3884505033493042,
            -0.18799278140068054,
            0.22841042280197144,
            0.0883922204375267,
            1.2760683298110962
          ],
          "order_indices": [
            0,
            8,
            3,
            2,
            1,
            6,
            7,
            5,
            4
          ],
          "order_filenames": [
            "test_197_0.jpg",
            "test_197_8.jpg",
            "test_197_3.jpg",
            "test_197_2.jpg",
            "test_197_1.jpg",
            "test_197_6.jpg",
            "test_197_7.jpg",
            "test_197_5.jpg",
            "test_197_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.35,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 198,
      "prompt": "The image is a digital art depiction of a female angel warrior with detailed features by artist Magali Villeneuve.",
      "image_filenames": [
        "test_198_0.jpg",
        "test_198_1.jpg",
        "test_198_2.jpg",
        "test_198_3.jpg",
        "test_198_4.jpg",
        "test_198_5.jpg",
        "test_198_6.jpg",
        "test_198_7.jpg",
        "test_198_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          3,
          4,
          6,
          0,
          2,
          1,
          8,
          7
        ],
        "order_filenames": [
          "test_198_5.jpg",
          "test_198_3.jpg",
          "test_198_4.jpg",
          "test_198_6.jpg",
          "test_198_0.jpg",
          "test_198_2.jpg",
          "test_198_1.jpg",
          "test_198_8.jpg",
          "test_198_7.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_198_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_198_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_198_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1806640625,
            0.2939453125,
            0.2486572265625,
            0.19873046875,
            0.169189453125,
            0.11761474609375,
            0.322021484375,
            0.202880859375,
            0.2548828125
          ],
          "order_indices": [
            6,
            1,
            8,
            2,
            7,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_198_6.jpg",
            "test_198_1.jpg",
            "test_198_8.jpg",
            "test_198_2.jpg",
            "test_198_7.jpg",
            "test_198_3.jpg",
            "test_198_0.jpg",
            "test_198_4.jpg",
            "test_198_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.5666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.1875,
            39.8125,
            38.78125,
            34.59375,
            19.375,
            12.203125,
            36.9375,
            35.78125,
            27.4375
          ],
          "order_indices": [
            1,
            2,
            0,
            6,
            7,
            3,
            8,
            4,
            5
          ],
          "order_filenames": [
            "test_198_1.jpg",
            "test_198_2.jpg",
            "test_198_0.jpg",
            "test_198_6.jpg",
            "test_198_7.jpg",
            "test_198_3.jpg",
            "test_198_8.jpg",
            "test_198_4.jpg",
            "test_198_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.4833333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.06493771076202393,
            1.4974809885025024,
            1.2107250690460205,
            -0.20712760090827942,
            -0.1785358190536499,
            -1.6698026657104492,
            1.9142851829528809,
            0.6280866265296936,
            0.08066409826278687
          ],
          "order_indices": [
            6,
            1,
            2,
            7,
            8,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_198_6.jpg",
            "test_198_1.jpg",
            "test_198_2.jpg",
            "test_198_7.jpg",
            "test_198_8.jpg",
            "test_198_0.jpg",
            "test_198_4.jpg",
            "test_198_3.jpg",
            "test_198_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.6166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 199,
      "prompt": "A phantom airship.",
      "image_filenames": [
        "test_199_0.jpg",
        "test_199_1.jpg",
        "test_199_2.jpg",
        "test_199_3.jpg",
        "test_199_4.jpg",
        "test_199_5.jpg",
        "test_199_6.jpg",
        "test_199_7.jpg",
        "test_199_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          2,
          5,
          1,
          3,
          6,
          8,
          0,
          7
        ],
        "order_filenames": [
          "test_199_4.jpg",
          "test_199_2.jpg",
          "test_199_5.jpg",
          "test_199_1.jpg",
          "test_199_3.jpg",
          "test_199_6.jpg",
          "test_199_8.jpg",
          "test_199_0.jpg",
          "test_199_7.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_199_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_199_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_199_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.22412109375,
            0.190673828125,
            0.257080078125,
            0.233154296875,
            0.2384033203125,
            0.1348876953125,
            0.232421875,
            0.26904296875,
            0.255126953125
          ],
          "order_indices": [
            7,
            2,
            8,
            4,
            3,
            6,
            0,
            1,
            5
          ],
          "order_filenames": [
            "test_199_7.jpg",
            "test_199_2.jpg",
            "test_199_8.jpg",
            "test_199_4.jpg",
            "test_199_3.jpg",
            "test_199_6.jpg",
            "test_199_0.jpg",
            "test_199_1.jpg",
            "test_199_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.34375,
            33.40625,
            35.96875,
            35.25,
            25.546875,
            19.796875,
            34.3125,
            36.9375,
            37.8125
          ],
          "order_indices": [
            8,
            0,
            7,
            2,
            3,
            6,
            1,
            4,
            5
          ],
          "order_filenames": [
            "test_199_8.jpg",
            "test_199_0.jpg",
            "test_199_7.jpg",
            "test_199_2.jpg",
            "test_199_3.jpg",
            "test_199_6.jpg",
            "test_199_1.jpg",
            "test_199_4.jpg",
            "test_199_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.7166666666666666,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.8919562101364136,
            -0.4487684369087219,
            1.1101088523864746,
            0.05598645284771919,
            -1.563340187072754,
            -2.2652039527893066,
            0.7027154564857483,
            1.1301722526550293,
            1.129034399986267
          ],
          "order_indices": [
            7,
            8,
            2,
            0,
            6,
            3,
            1,
            4,
            5
          ],
          "order_filenames": [
            "test_199_7.jpg",
            "test_199_8.jpg",
            "test_199_2.jpg",
            "test_199_0.jpg",
            "test_199_6.jpg",
            "test_199_3.jpg",
            "test_199_1.jpg",
            "test_199_4.jpg",
            "test_199_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.6111111111111112,
            "spearman_rho": -0.6833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 200,
      "prompt": "An abstract painting depicting the balance between dark and light in nature with rough brushstrokes and fine details in natural colors.",
      "image_filenames": [
        "test_200_0.jpg",
        "test_200_1.jpg",
        "test_200_2.jpg",
        "test_200_3.jpg",
        "test_200_4.jpg",
        "test_200_5.jpg",
        "test_200_6.jpg",
        "test_200_7.jpg",
        "test_200_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          4,
          5,
          3,
          1,
          6,
          2,
          7,
          8
        ],
        "order_filenames": [
          "test_200_0.jpg",
          "test_200_4.jpg",
          "test_200_5.jpg",
          "test_200_3.jpg",
          "test_200_1.jpg",
          "test_200_6.jpg",
          "test_200_2.jpg",
          "test_200_7.jpg",
          "test_200_8.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_200_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_200_0.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_200_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1915283203125,
            0.189453125,
            0.1805419921875,
            0.169921875,
            0.1845703125,
            0.185546875,
            0.1787109375,
            0.2269287109375,
            0.1881103515625
          ],
          "order_indices": [
            7,
            0,
            1,
            8,
            5,
            4,
            2,
            6,
            3
          ],
          "order_filenames": [
            "test_200_7.jpg",
            "test_200_0.jpg",
            "test_200_1.jpg",
            "test_200_8.jpg",
            "test_200_5.jpg",
            "test_200_4.jpg",
            "test_200_2.jpg",
            "test_200_6.jpg",
            "test_200_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            26.390625,
            35.28125,
            38.625,
            34.375,
            19.5625,
            20.84375,
            28.5,
            28.125,
            35.0
          ],
          "order_indices": [
            2,
            1,
            8,
            3,
            6,
            7,
            0,
            5,
            4
          ],
          "order_filenames": [
            "test_200_2.jpg",
            "test_200_1.jpg",
            "test_200_8.jpg",
            "test_200_3.jpg",
            "test_200_6.jpg",
            "test_200_7.jpg",
            "test_200_0.jpg",
            "test_200_5.jpg",
            "test_200_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.6333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.2673042416572571,
            -1.1420466899871826,
            -0.9498698115348816,
            -0.5560508966445923,
            -1.554558277130127,
            -1.335318684577942,
            -1.7813091278076172,
            -0.8292965888977051,
            -1.2432646751403809
          ],
          "order_indices": [
            0,
            3,
            7,
            2,
            1,
            8,
            5,
            4,
            6
          ],
          "order_filenames": [
            "test_200_0.jpg",
            "test_200_3.jpg",
            "test_200_7.jpg",
            "test_200_2.jpg",
            "test_200_1.jpg",
            "test_200_8.jpg",
            "test_200_5.jpg",
            "test_200_4.jpg",
            "test_200_6.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.09999999999999998,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 201,
      "prompt": "Image of a foothpath in Indian summer with Zugspitze mountain in the background, painted by Sargent, Leyendecker, and Greg Hildebrandt.",
      "image_filenames": [
        "test_201_0.jpg",
        "test_201_1.jpg",
        "test_201_2.jpg",
        "test_201_3.jpg",
        "test_201_4.jpg",
        "test_201_5.jpg",
        "test_201_6.jpg",
        "test_201_7.jpg",
        "test_201_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          1,
          3,
          7,
          4,
          2,
          8,
          6,
          0
        ],
        "order_filenames": [
          "test_201_5.jpg",
          "test_201_1.jpg",
          "test_201_3.jpg",
          "test_201_7.jpg",
          "test_201_4.jpg",
          "test_201_2.jpg",
          "test_201_8.jpg",
          "test_201_6.jpg",
          "test_201_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_201_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_201_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1,
            5
          ],
          "winner_filenames": [
            "test_201_1.jpg",
            "test_201_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1829833984375,
            0.264892578125,
            0.270751953125,
            0.20849609375,
            0.172119140625,
            0.173828125,
            0.2261962890625,
            0.2305908203125,
            0.251220703125
          ],
          "order_indices": [
            2,
            1,
            8,
            7,
            6,
            3,
            0,
            5,
            4
          ],
          "order_filenames": [
            "test_201_2.jpg",
            "test_201_1.jpg",
            "test_201_8.jpg",
            "test_201_7.jpg",
            "test_201_6.jpg",
            "test_201_3.jpg",
            "test_201_0.jpg",
            "test_201_5.jpg",
            "test_201_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.1875,
            43.15625,
            45.59375,
            34.59375,
            33.40625,
            32.375,
            42.78125,
            45.03125,
            39.28125
          ],
          "order_indices": [
            2,
            7,
            1,
            6,
            8,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_201_2.jpg",
            "test_201_7.jpg",
            "test_201_1.jpg",
            "test_201_6.jpg",
            "test_201_8.jpg",
            "test_201_0.jpg",
            "test_201_3.jpg",
            "test_201_4.jpg",
            "test_201_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.2333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.38126635551452637,
            0.7051835656166077,
            0.6582627892494202,
            -0.16635990142822266,
            -0.9735100865364075,
            -0.7757741212844849,
            0.14574217796325684,
            -0.5165428519248962,
            0.4487127959728241
          ],
          "order_indices": [
            1,
            2,
            8,
            6,
            3,
            0,
            7,
            5,
            4
          ],
          "order_filenames": [
            "test_201_1.jpg",
            "test_201_2.jpg",
            "test_201_8.jpg",
            "test_201_6.jpg",
            "test_201_3.jpg",
            "test_201_0.jpg",
            "test_201_7.jpg",
            "test_201_5.jpg",
            "test_201_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.1333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 202,
      "prompt": "A painting featuring two men in a fighting scene wearing black jodhpurs.",
      "image_filenames": [
        "test_202_0.jpg",
        "test_202_1.jpg",
        "test_202_2.jpg",
        "test_202_3.jpg",
        "test_202_4.jpg",
        "test_202_5.jpg",
        "test_202_6.jpg",
        "test_202_7.jpg",
        "test_202_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          5,
          0,
          4,
          2,
          3,
          8,
          6,
          1
        ],
        "order_filenames": [
          "test_202_7.jpg",
          "test_202_5.jpg",
          "test_202_0.jpg",
          "test_202_4.jpg",
          "test_202_2.jpg",
          "test_202_3.jpg",
          "test_202_8.jpg",
          "test_202_6.jpg",
          "test_202_1.jpg"
        ],
        "condorcet_winner": 7,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_202_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_202_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_202_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1705322265625,
            0.19189453125,
            0.23828125,
            0.216064453125,
            0.210693359375,
            0.120849609375,
            0.201416015625,
            0.1966552734375,
            0.264404296875
          ],
          "order_indices": [
            8,
            2,
            3,
            4,
            6,
            7,
            1,
            0,
            5
          ],
          "order_filenames": [
            "test_202_8.jpg",
            "test_202_2.jpg",
            "test_202_3.jpg",
            "test_202_4.jpg",
            "test_202_6.jpg",
            "test_202_7.jpg",
            "test_202_1.jpg",
            "test_202_0.jpg",
            "test_202_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.3833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.3125,
            37.25,
            40.40625,
            35.625,
            38.21875,
            14.9296875,
            40.59375,
            40.21875,
            43.1875
          ],
          "order_indices": [
            8,
            6,
            2,
            7,
            0,
            4,
            1,
            3,
            5
          ],
          "order_filenames": [
            "test_202_8.jpg",
            "test_202_6.jpg",
            "test_202_2.jpg",
            "test_202_7.jpg",
            "test_202_0.jpg",
            "test_202_4.jpg",
            "test_202_1.jpg",
            "test_202_3.jpg",
            "test_202_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.25,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.17044200003147125,
            0.2320878952741623,
            0.6998069882392883,
            0.07733876258134842,
            0.4580341875553131,
            -2.1196541786193848,
            0.42062219977378845,
            -0.6118486523628235,
            0.5325592160224915
          ],
          "order_indices": [
            2,
            8,
            4,
            6,
            1,
            0,
            3,
            7,
            5
          ],
          "order_filenames": [
            "test_202_2.jpg",
            "test_202_8.jpg",
            "test_202_4.jpg",
            "test_202_6.jpg",
            "test_202_1.jpg",
            "test_202_0.jpg",
            "test_202_3.jpg",
            "test_202_7.jpg",
            "test_202_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.5166666666666666,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 203,
      "prompt": "A town of pod homes integrated in a forest area with water and trees, depicted in a detailed watercolor by Lurid.",
      "image_filenames": [
        "test_203_0.jpg",
        "test_203_1.jpg",
        "test_203_2.jpg",
        "test_203_3.jpg",
        "test_203_4.jpg",
        "test_203_5.jpg",
        "test_203_6.jpg",
        "test_203_7.jpg",
        "test_203_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          2,
          5,
          7,
          1,
          0,
          3,
          6,
          8
        ],
        "order_filenames": [
          "test_203_4.jpg",
          "test_203_2.jpg",
          "test_203_5.jpg",
          "test_203_7.jpg",
          "test_203_1.jpg",
          "test_203_0.jpg",
          "test_203_3.jpg",
          "test_203_6.jpg",
          "test_203_8.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_203_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_203_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_203_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.200927734375,
            0.2086181640625,
            0.265869140625,
            0.2176513671875,
            0.194091796875,
            0.17333984375,
            0.204345703125,
            0.2127685546875,
            0.2333984375
          ],
          "order_indices": [
            2,
            8,
            3,
            7,
            1,
            6,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_203_2.jpg",
            "test_203_8.jpg",
            "test_203_3.jpg",
            "test_203_7.jpg",
            "test_203_1.jpg",
            "test_203_6.jpg",
            "test_203_0.jpg",
            "test_203_4.jpg",
            "test_203_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.30000000000000004,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.71875,
            40.625,
            44.4375,
            36.0,
            33.09375,
            29.625,
            42.15625,
            43.8125,
            31.9375
          ],
          "order_indices": [
            2,
            7,
            6,
            0,
            1,
            3,
            4,
            8,
            5
          ],
          "order_filenames": [
            "test_203_2.jpg",
            "test_203_7.jpg",
            "test_203_6.jpg",
            "test_203_0.jpg",
            "test_203_1.jpg",
            "test_203_3.jpg",
            "test_203_4.jpg",
            "test_203_8.jpg",
            "test_203_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.09999999999999998,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.5109514594078064,
            1.1083556413650513,
            1.4927395582199097,
            -1.0647752285003662,
            -0.06745738536119461,
            -1.3155205249786377,
            -0.5019595623016357,
            0.6818185448646545,
            1.0390790700912476
          ],
          "order_indices": [
            2,
            1,
            8,
            7,
            4,
            6,
            0,
            3,
            5
          ],
          "order_filenames": [
            "test_203_2.jpg",
            "test_203_1.jpg",
            "test_203_8.jpg",
            "test_203_7.jpg",
            "test_203_4.jpg",
            "test_203_6.jpg",
            "test_203_0.jpg",
            "test_203_3.jpg",
            "test_203_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.1333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 204,
      "prompt": "The image is a mixed media collage with broken glass and torn paper elements, featuring intricate oil details and a canvas texture, in a contemporary art style.",
      "image_filenames": [
        "test_204_0.jpg",
        "test_204_1.jpg",
        "test_204_2.jpg",
        "test_204_3.jpg",
        "test_204_4.jpg",
        "test_204_5.jpg",
        "test_204_6.jpg",
        "test_204_7.jpg",
        "test_204_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          4,
          5,
          3,
          6,
          1,
          8,
          7,
          2
        ],
        "order_filenames": [
          "test_204_0.jpg",
          "test_204_4.jpg",
          "test_204_5.jpg",
          "test_204_3.jpg",
          "test_204_6.jpg",
          "test_204_1.jpg",
          "test_204_8.jpg",
          "test_204_7.jpg",
          "test_204_2.jpg"
        ],
        "condorcet_winner": 0,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_204_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            1,
            3
          ],
          "winner_filenames": [
            "test_204_1.jpg",
            "test_204_3.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_204_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2109375,
            0.2425537109375,
            0.2149658203125,
            0.21337890625,
            0.1907958984375,
            0.150634765625,
            0.247802734375,
            0.2308349609375,
            0.2052001953125
          ],
          "order_indices": [
            6,
            1,
            7,
            2,
            3,
            0,
            8,
            4,
            5
          ],
          "order_filenames": [
            "test_204_6.jpg",
            "test_204_1.jpg",
            "test_204_7.jpg",
            "test_204_2.jpg",
            "test_204_3.jpg",
            "test_204_0.jpg",
            "test_204_8.jpg",
            "test_204_4.jpg",
            "test_204_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.5,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.9375,
            33.40625,
            38.5625,
            33.375,
            31.90625,
            26.265625,
            37.78125,
            33.46875,
            30.359375
          ],
          "order_indices": [
            2,
            6,
            0,
            7,
            1,
            3,
            4,
            8,
            5
          ],
          "order_filenames": [
            "test_204_2.jpg",
            "test_204_6.jpg",
            "test_204_0.jpg",
            "test_204_7.jpg",
            "test_204_1.jpg",
            "test_204_3.jpg",
            "test_204_4.jpg",
            "test_204_8.jpg",
            "test_204_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.33333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.043449517339468,
            0.794139564037323,
            -0.4500334560871124,
            -0.505935788154602,
            -0.2875950038433075,
            -0.8832058310508728,
            0.2564581036567688,
            -0.17959873378276825,
            -0.6456283330917358
          ],
          "order_indices": [
            1,
            6,
            0,
            7,
            4,
            2,
            3,
            8,
            5
          ],
          "order_filenames": [
            "test_204_1.jpg",
            "test_204_6.jpg",
            "test_204_0.jpg",
            "test_204_7.jpg",
            "test_204_4.jpg",
            "test_204_2.jpg",
            "test_204_3.jpg",
            "test_204_8.jpg",
            "test_204_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.01666666666666672,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 205,
      "prompt": "The Mona Lisa wearing headphones and listening to Lana Del Rey on a phone, depicted with photorealistic high detail.",
      "image_filenames": [
        "test_205_0.jpg",
        "test_205_1.jpg",
        "test_205_2.jpg",
        "test_205_3.jpg",
        "test_205_4.jpg",
        "test_205_5.jpg",
        "test_205_6.jpg",
        "test_205_7.jpg",
        "test_205_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          3,
          4,
          5,
          2,
          1,
          6,
          8,
          0
        ],
        "order_filenames": [
          "test_205_7.jpg",
          "test_205_3.jpg",
          "test_205_4.jpg",
          "test_205_5.jpg",
          "test_205_2.jpg",
          "test_205_1.jpg",
          "test_205_6.jpg",
          "test_205_8.jpg",
          "test_205_0.jpg"
        ],
        "condorcet_winner": 7,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_205_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_205_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_205_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1446533203125,
            0.1715087890625,
            0.264892578125,
            0.1904296875,
            0.1676025390625,
            0.036376953125,
            0.229736328125,
            0.1949462890625,
            0.275390625
          ],
          "order_indices": [
            8,
            2,
            6,
            7,
            3,
            1,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_205_8.jpg",
            "test_205_2.jpg",
            "test_205_6.jpg",
            "test_205_7.jpg",
            "test_205_3.jpg",
            "test_205_1.jpg",
            "test_205_4.jpg",
            "test_205_0.jpg",
            "test_205_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.1166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.4375,
            29.25,
            27.109375,
            27.15625,
            25.15625,
            13.078125,
            29.765625,
            45.8125,
            41.84375
          ],
          "order_indices": [
            7,
            8,
            0,
            6,
            1,
            3,
            2,
            4,
            5
          ],
          "order_filenames": [
            "test_205_7.jpg",
            "test_205_8.jpg",
            "test_205_0.jpg",
            "test_205_6.jpg",
            "test_205_1.jpg",
            "test_205_3.jpg",
            "test_205_2.jpg",
            "test_205_4.jpg",
            "test_205_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.2666666666666666,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 1.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.198991596698761,
            -1.8631802797317505,
            -0.9443531036376953,
            -1.3371963500976562,
            -0.15371808409690857,
            -2.281933546066284,
            -0.6006916165351868,
            0.07985592633485794,
            1.064717173576355
          ],
          "order_indices": [
            8,
            7,
            4,
            0,
            6,
            2,
            3,
            1,
            5
          ],
          "order_filenames": [
            "test_205_8.jpg",
            "test_205_7.jpg",
            "test_205_4.jpg",
            "test_205_0.jpg",
            "test_205_6.jpg",
            "test_205_2.jpg",
            "test_205_3.jpg",
            "test_205_1.jpg",
            "test_205_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.1166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 206,
      "prompt": "\"Albus Dumbledore\" - a portrait of the headmaster of Hogwarts School of Witchcraft and Wizardry from the Harry Potter series.",
      "image_filenames": [
        "test_206_0.jpg",
        "test_206_1.jpg",
        "test_206_2.jpg",
        "test_206_3.jpg",
        "test_206_4.jpg",
        "test_206_5.jpg",
        "test_206_6.jpg",
        "test_206_7.jpg",
        "test_206_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          2,
          6,
          5,
          3,
          7,
          0,
          1,
          8
        ],
        "order_filenames": [
          "test_206_4.jpg",
          "test_206_2.jpg",
          "test_206_6.jpg",
          "test_206_5.jpg",
          "test_206_3.jpg",
          "test_206_7.jpg",
          "test_206_0.jpg",
          "test_206_1.jpg",
          "test_206_8.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_206_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_206_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_206_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.169189453125,
            0.208984375,
            0.268310546875,
            0.1741943359375,
            0.1468505859375,
            0.0946044921875,
            0.257568359375,
            0.195556640625,
            0.28271484375
          ],
          "order_indices": [
            8,
            2,
            6,
            1,
            7,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_206_8.jpg",
            "test_206_2.jpg",
            "test_206_6.jpg",
            "test_206_1.jpg",
            "test_206_7.jpg",
            "test_206_3.jpg",
            "test_206_0.jpg",
            "test_206_4.jpg",
            "test_206_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.30000000000000004,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.90625,
            28.59375,
            40.46875,
            19.984375,
            27.1875,
            5.8671875,
            37.25,
            41.75,
            39.3125
          ],
          "order_indices": [
            7,
            2,
            8,
            6,
            0,
            1,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_206_7.jpg",
            "test_206_2.jpg",
            "test_206_8.jpg",
            "test_206_6.jpg",
            "test_206_0.jpg",
            "test_206_1.jpg",
            "test_206_4.jpg",
            "test_206_3.jpg",
            "test_206_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.16666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.10698714107275009,
            0.5296320915222168,
            0.942101240158081,
            0.33070096373558044,
            -0.7203376293182373,
            -2.2780601978302,
            0.8785736560821533,
            0.5255870819091797,
            1.3612351417541504
          ],
          "order_indices": [
            8,
            2,
            6,
            1,
            7,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_206_8.jpg",
            "test_206_2.jpg",
            "test_206_6.jpg",
            "test_206_1.jpg",
            "test_206_7.jpg",
            "test_206_3.jpg",
            "test_206_0.jpg",
            "test_206_4.jpg",
            "test_206_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.30000000000000004,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 207,
      "prompt": "The image is a Roy Lichtenstein emo portraying a woman with dark brown pixie hair, entirely black eyes, wearing a black tank top, leather jacket, skirt, choker, and boots.",
      "image_filenames": [
        "test_207_0.jpg",
        "test_207_1.jpg",
        "test_207_2.jpg",
        "test_207_3.jpg",
        "test_207_4.jpg",
        "test_207_5.jpg",
        "test_207_6.jpg",
        "test_207_7.jpg",
        "test_207_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          2,
          1,
          3,
          4,
          6,
          8,
          7,
          0
        ],
        "order_filenames": [
          "test_207_5.jpg",
          "test_207_2.jpg",
          "test_207_1.jpg",
          "test_207_3.jpg",
          "test_207_4.jpg",
          "test_207_6.jpg",
          "test_207_8.jpg",
          "test_207_7.jpg",
          "test_207_0.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_207_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_207_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_207_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1328125,
            0.1907958984375,
            0.2049560546875,
            0.138916015625,
            0.186279296875,
            0.09234619140625,
            0.188232421875,
            0.13232421875,
            0.2073974609375
          ],
          "order_indices": [
            8,
            2,
            1,
            6,
            4,
            3,
            0,
            7,
            5
          ],
          "order_filenames": [
            "test_207_8.jpg",
            "test_207_2.jpg",
            "test_207_1.jpg",
            "test_207_6.jpg",
            "test_207_4.jpg",
            "test_207_3.jpg",
            "test_207_0.jpg",
            "test_207_7.jpg",
            "test_207_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.4444444444444444,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.875,
            40.4375,
            43.8125,
            32.9375,
            28.890625,
            15.65625,
            35.0625,
            36.78125,
            47.6875
          ],
          "order_indices": [
            8,
            2,
            1,
            7,
            6,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_207_8.jpg",
            "test_207_2.jpg",
            "test_207_1.jpg",
            "test_207_7.jpg",
            "test_207_6.jpg",
            "test_207_0.jpg",
            "test_207_3.jpg",
            "test_207_4.jpg",
            "test_207_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.19999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -2.263129711151123,
            -1.7866919040679932,
            -1.1778013706207275,
            -2.0758368968963623,
            -1.6372014284133911,
            -2.2791943550109863,
            -1.8314738273620605,
            -1.8983656167984009,
            -0.7023337483406067
          ],
          "order_indices": [
            8,
            2,
            4,
            1,
            6,
            7,
            3,
            0,
            5
          ],
          "order_filenames": [
            "test_207_8.jpg",
            "test_207_2.jpg",
            "test_207_4.jpg",
            "test_207_1.jpg",
            "test_207_6.jpg",
            "test_207_7.jpg",
            "test_207_3.jpg",
            "test_207_0.jpg",
            "test_207_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.0,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 208,
      "prompt": "\"A portrait painting of Batman on Artstation.\"",
      "image_filenames": [
        "test_208_0.jpg",
        "test_208_1.jpg",
        "test_208_2.jpg",
        "test_208_3.jpg",
        "test_208_4.jpg",
        "test_208_5.jpg",
        "test_208_6.jpg",
        "test_208_7.jpg",
        "test_208_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          0,
          5,
          4,
          6,
          7,
          8,
          2,
          3
        ],
        "order_filenames": [
          "test_208_1.jpg",
          "test_208_0.jpg",
          "test_208_5.jpg",
          "test_208_4.jpg",
          "test_208_6.jpg",
          "test_208_7.jpg",
          "test_208_8.jpg",
          "test_208_2.jpg",
          "test_208_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_208_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_208_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_208_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.20458984375,
            0.3046875,
            0.294677734375,
            0.205810546875,
            0.12225341796875,
            0.137939453125,
            0.271728515625,
            0.201416015625,
            0.2359619140625
          ],
          "order_indices": [
            1,
            2,
            6,
            8,
            3,
            0,
            7,
            5,
            4
          ],
          "order_filenames": [
            "test_208_1.jpg",
            "test_208_2.jpg",
            "test_208_6.jpg",
            "test_208_8.jpg",
            "test_208_3.jpg",
            "test_208_0.jpg",
            "test_208_7.jpg",
            "test_208_5.jpg",
            "test_208_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.10000000000000009,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.8125,
            26.140625,
            36.4375,
            37.5625,
            16.265625,
            25.421875,
            27.03125,
            38.40625,
            32.53125
          ],
          "order_indices": [
            7,
            0,
            3,
            2,
            8,
            6,
            1,
            5,
            4
          ],
          "order_filenames": [
            "test_208_7.jpg",
            "test_208_0.jpg",
            "test_208_3.jpg",
            "test_208_2.jpg",
            "test_208_8.jpg",
            "test_208_6.jpg",
            "test_208_1.jpg",
            "test_208_5.jpg",
            "test_208_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.3999999999999999,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.4757155478000641,
            1.654600977897644,
            1.4501210451126099,
            0.6047371029853821,
            -1.303664207458496,
            -1.1475105285644531,
            1.4402481317520142,
            0.7531968355178833,
            -0.7018711566925049
          ],
          "order_indices": [
            1,
            2,
            6,
            7,
            3,
            0,
            8,
            5,
            4
          ],
          "order_filenames": [
            "test_208_1.jpg",
            "test_208_2.jpg",
            "test_208_6.jpg",
            "test_208_7.jpg",
            "test_208_3.jpg",
            "test_208_0.jpg",
            "test_208_8.jpg",
            "test_208_5.jpg",
            "test_208_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.050000000000000044,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 209,
      "prompt": "Elvis Presley performing in a jumpsuit, artwork by Alessandro Pautasso.",
      "image_filenames": [
        "test_209_0.jpg",
        "test_209_1.jpg",
        "test_209_2.jpg",
        "test_209_3.jpg",
        "test_209_4.jpg",
        "test_209_5.jpg",
        "test_209_6.jpg",
        "test_209_7.jpg",
        "test_209_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          1,
          2,
          4,
          6,
          0,
          5,
          8,
          3
        ],
        "order_filenames": [
          "test_209_7.jpg",
          "test_209_1.jpg",
          "test_209_2.jpg",
          "test_209_4.jpg",
          "test_209_6.jpg",
          "test_209_0.jpg",
          "test_209_5.jpg",
          "test_209_8.jpg",
          "test_209_3.jpg"
        ],
        "condorcet_winner": 7,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_209_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_209_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_209_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1510009765625,
            0.2392578125,
            0.248779296875,
            0.189208984375,
            0.181396484375,
            0.09906005859375,
            0.203857421875,
            0.2142333984375,
            0.255859375
          ],
          "order_indices": [
            8,
            2,
            1,
            7,
            6,
            3,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_209_8.jpg",
            "test_209_2.jpg",
            "test_209_1.jpg",
            "test_209_7.jpg",
            "test_209_6.jpg",
            "test_209_3.jpg",
            "test_209_4.jpg",
            "test_209_0.jpg",
            "test_209_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.2833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            32.28125,
            38.34375,
            40.65625,
            36.375,
            23.234375,
            8.0390625,
            36.90625,
            38.5625,
            37.5
          ],
          "order_indices": [
            2,
            7,
            1,
            8,
            6,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_209_2.jpg",
            "test_209_7.jpg",
            "test_209_1.jpg",
            "test_209_8.jpg",
            "test_209_6.jpg",
            "test_209_3.jpg",
            "test_209_0.jpg",
            "test_209_4.jpg",
            "test_209_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3888888888888889,
            "spearman_rho": 0.5666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.8368843793869019,
            1.2523362636566162,
            1.8065664768218994,
            -0.09882305562496185,
            -0.8501250743865967,
            -2.25858998298645,
            0.8453564047813416,
            1.7584199905395508,
            1.2635053396224976
          ],
          "order_indices": [
            2,
            7,
            8,
            1,
            6,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_209_2.jpg",
            "test_209_7.jpg",
            "test_209_8.jpg",
            "test_209_1.jpg",
            "test_209_6.jpg",
            "test_209_3.jpg",
            "test_209_0.jpg",
            "test_209_4.jpg",
            "test_209_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.4666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 210,
      "prompt": "The image depicts a gold filigree tree of life in a detailed fantasy painting.",
      "image_filenames": [
        "test_210_0.jpg",
        "test_210_1.jpg",
        "test_210_2.jpg",
        "test_210_3.jpg",
        "test_210_4.jpg",
        "test_210_5.jpg",
        "test_210_6.jpg",
        "test_210_7.jpg",
        "test_210_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          2,
          0,
          1,
          5,
          3,
          8,
          6,
          7
        ],
        "order_filenames": [
          "test_210_4.jpg",
          "test_210_2.jpg",
          "test_210_0.jpg",
          "test_210_1.jpg",
          "test_210_5.jpg",
          "test_210_3.jpg",
          "test_210_8.jpg",
          "test_210_6.jpg",
          "test_210_7.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_210_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_210_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_210_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.208740234375,
            0.2783203125,
            0.273193359375,
            0.181396484375,
            0.1806640625,
            0.20361328125,
            0.284423828125,
            0.2427978515625,
            0.28564453125
          ],
          "order_indices": [
            8,
            6,
            1,
            2,
            7,
            0,
            5,
            3,
            4
          ],
          "order_filenames": [
            "test_210_8.jpg",
            "test_210_6.jpg",
            "test_210_1.jpg",
            "test_210_2.jpg",
            "test_210_7.jpg",
            "test_210_0.jpg",
            "test_210_5.jpg",
            "test_210_3.jpg",
            "test_210_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.44999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.9375,
            38.40625,
            35.09375,
            29.5,
            30.296875,
            32.09375,
            37.90625,
            40.59375,
            40.46875
          ],
          "order_indices": [
            7,
            8,
            0,
            1,
            6,
            2,
            5,
            4,
            3
          ],
          "order_filenames": [
            "test_210_7.jpg",
            "test_210_8.jpg",
            "test_210_0.jpg",
            "test_210_1.jpg",
            "test_210_6.jpg",
            "test_210_2.jpg",
            "test_210_5.jpg",
            "test_210_4.jpg",
            "test_210_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.46666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.16553840041160583,
            1.4192641973495483,
            1.1977665424346924,
            -1.3085235357284546,
            -1.2198985815048218,
            -0.11445707082748413,
            1.288703203201294,
            0.5186746120452881,
            0.9625974297523499
          ],
          "order_indices": [
            1,
            6,
            2,
            8,
            7,
            5,
            0,
            4,
            3
          ],
          "order_filenames": [
            "test_210_1.jpg",
            "test_210_6.jpg",
            "test_210_2.jpg",
            "test_210_8.jpg",
            "test_210_7.jpg",
            "test_210_5.jpg",
            "test_210_0.jpg",
            "test_210_4.jpg",
            "test_210_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.21666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 211,
      "prompt": "A surreal painting by Ronny Khalil depicting a bestiary of wild emotion monsters repressed in the deep sea of the unconscious psyche, led by Baba Yaga, glowing with dramatic fire light as they prepare to escape in a revolution.",
      "image_filenames": [
        "test_211_0.jpg",
        "test_211_1.jpg",
        "test_211_2.jpg",
        "test_211_3.jpg",
        "test_211_4.jpg",
        "test_211_5.jpg",
        "test_211_6.jpg",
        "test_211_7.jpg",
        "test_211_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          1,
          5,
          6,
          2,
          8,
          7,
          0,
          3
        ],
        "order_filenames": [
          "test_211_4.jpg",
          "test_211_1.jpg",
          "test_211_5.jpg",
          "test_211_6.jpg",
          "test_211_2.jpg",
          "test_211_8.jpg",
          "test_211_7.jpg",
          "test_211_0.jpg",
          "test_211_3.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_211_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_211_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_211_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.209716796875,
            0.212646484375,
            0.27099609375,
            0.17138671875,
            0.1658935546875,
            0.1434326171875,
            0.2095947265625,
            0.251708984375,
            0.287109375
          ],
          "order_indices": [
            8,
            2,
            7,
            1,
            0,
            6,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_211_8.jpg",
            "test_211_2.jpg",
            "test_211_7.jpg",
            "test_211_1.jpg",
            "test_211_0.jpg",
            "test_211_6.jpg",
            "test_211_3.jpg",
            "test_211_4.jpg",
            "test_211_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.30000000000000004,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            41.4375,
            39.09375,
            38.09375,
            30.40625,
            32.96875,
            28.671875,
            35.28125,
            44.34375,
            38.78125
          ],
          "order_indices": [
            7,
            0,
            1,
            8,
            2,
            6,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_211_7.jpg",
            "test_211_0.jpg",
            "test_211_1.jpg",
            "test_211_8.jpg",
            "test_211_2.jpg",
            "test_211_6.jpg",
            "test_211_4.jpg",
            "test_211_3.jpg",
            "test_211_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.28333333333333344,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.485318660736084,
            0.9750926494598389,
            1.0971988439559937,
            -0.15335655212402344,
            -0.2524057924747467,
            -0.7263748049736023,
            0.6733208894729614,
            0.8166671991348267,
            0.7960352301597595
          ],
          "order_indices": [
            2,
            1,
            7,
            8,
            6,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_211_2.jpg",
            "test_211_1.jpg",
            "test_211_7.jpg",
            "test_211_8.jpg",
            "test_211_6.jpg",
            "test_211_0.jpg",
            "test_211_3.jpg",
            "test_211_4.jpg",
            "test_211_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.08333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 212,
      "prompt": "A man wearing a hat performs a magic trick for Jesus in a kitchen painting by Rockwell, Lovell, and Schoonover.",
      "image_filenames": [
        "test_212_0.jpg",
        "test_212_1.jpg",
        "test_212_2.jpg",
        "test_212_3.jpg",
        "test_212_4.jpg",
        "test_212_5.jpg",
        "test_212_6.jpg",
        "test_212_7.jpg",
        "test_212_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          4,
          5,
          6,
          3,
          2,
          1,
          8,
          0
        ],
        "order_filenames": [
          "test_212_7.jpg",
          "test_212_4.jpg",
          "test_212_5.jpg",
          "test_212_6.jpg",
          "test_212_3.jpg",
          "test_212_2.jpg",
          "test_212_1.jpg",
          "test_212_8.jpg",
          "test_212_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_212_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_212_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_212_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1883544921875,
            0.2274169921875,
            0.256103515625,
            0.181640625,
            0.193115234375,
            0.0872802734375,
            0.21484375,
            0.224853515625,
            0.24365234375
          ],
          "order_indices": [
            2,
            8,
            1,
            7,
            6,
            4,
            0,
            3,
            5
          ],
          "order_filenames": [
            "test_212_2.jpg",
            "test_212_8.jpg",
            "test_212_1.jpg",
            "test_212_7.jpg",
            "test_212_6.jpg",
            "test_212_4.jpg",
            "test_212_0.jpg",
            "test_212_3.jpg",
            "test_212_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.2666666666666666,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.71875,
            29.703125,
            32.625,
            33.03125,
            29.125,
            7.76953125,
            29.0625,
            39.5,
            36.6875
          ],
          "order_indices": [
            7,
            8,
            0,
            3,
            2,
            1,
            4,
            6,
            5
          ],
          "order_filenames": [
            "test_212_7.jpg",
            "test_212_8.jpg",
            "test_212_0.jpg",
            "test_212_3.jpg",
            "test_212_2.jpg",
            "test_212_1.jpg",
            "test_212_4.jpg",
            "test_212_6.jpg",
            "test_212_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.2666666666666666,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.21298792958259583,
            -0.5131952166557312,
            -0.13814759254455566,
            -0.37122127413749695,
            -1.1425249576568604,
            -2.2664499282836914,
            -0.22163507342338562,
            1.0342905521392822,
            0.5121012330055237
          ],
          "order_indices": [
            7,
            8,
            0,
            2,
            6,
            3,
            1,
            4,
            5
          ],
          "order_filenames": [
            "test_212_7.jpg",
            "test_212_8.jpg",
            "test_212_0.jpg",
            "test_212_2.jpg",
            "test_212_6.jpg",
            "test_212_3.jpg",
            "test_212_1.jpg",
            "test_212_4.jpg",
            "test_212_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.25,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 213,
      "prompt": "A graveyard at night with a moonlit grave under a sakura tree, rain falling, by Aleksandra Waliszewska.",
      "image_filenames": [
        "test_213_0.jpg",
        "test_213_1.jpg",
        "test_213_2.jpg",
        "test_213_3.jpg",
        "test_213_4.jpg",
        "test_213_5.jpg",
        "test_213_6.jpg",
        "test_213_7.jpg",
        "test_213_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          7,
          1,
          0,
          2,
          4,
          6,
          5,
          8
        ],
        "order_filenames": [
          "test_213_3.jpg",
          "test_213_7.jpg",
          "test_213_1.jpg",
          "test_213_0.jpg",
          "test_213_2.jpg",
          "test_213_4.jpg",
          "test_213_6.jpg",
          "test_213_5.jpg",
          "test_213_8.jpg"
        ],
        "condorcet_winner": 3,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_213_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_213_3.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_213_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2210693359375,
            0.206298828125,
            0.291015625,
            0.197265625,
            0.184814453125,
            0.1854248046875,
            0.1771240234375,
            0.232421875,
            0.28271484375
          ],
          "order_indices": [
            2,
            8,
            7,
            0,
            1,
            3,
            5,
            4,
            6
          ],
          "order_filenames": [
            "test_213_2.jpg",
            "test_213_8.jpg",
            "test_213_7.jpg",
            "test_213_0.jpg",
            "test_213_1.jpg",
            "test_213_3.jpg",
            "test_213_5.jpg",
            "test_213_4.jpg",
            "test_213_6.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.1333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            47.0625,
            37.96875,
            34.125,
            26.359375,
            31.515625,
            36.25,
            35.28125,
            47.34375,
            36.53125
          ],
          "order_indices": [
            7,
            0,
            1,
            8,
            5,
            6,
            2,
            4,
            3
          ],
          "order_filenames": [
            "test_213_7.jpg",
            "test_213_0.jpg",
            "test_213_1.jpg",
            "test_213_8.jpg",
            "test_213_5.jpg",
            "test_213_6.jpg",
            "test_213_2.jpg",
            "test_213_4.jpg",
            "test_213_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.5716886520385742,
            0.159194678068161,
            0.5510267615318298,
            -0.6179011464118958,
            -1.176798939704895,
            0.07314632087945938,
            -0.10961722582578659,
            1.476045846939087,
            1.6604822874069214
          ],
          "order_indices": [
            8,
            0,
            7,
            2,
            1,
            5,
            6,
            3,
            4
          ],
          "order_filenames": [
            "test_213_8.jpg",
            "test_213_0.jpg",
            "test_213_7.jpg",
            "test_213_2.jpg",
            "test_213_1.jpg",
            "test_213_5.jpg",
            "test_213_6.jpg",
            "test_213_3.jpg",
            "test_213_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.1333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 214,
      "prompt": "The image depicts three female figures, known as the muses, playing musical instruments.",
      "image_filenames": [
        "test_214_0.jpg",
        "test_214_1.jpg",
        "test_214_2.jpg",
        "test_214_3.jpg",
        "test_214_4.jpg",
        "test_214_5.jpg",
        "test_214_6.jpg",
        "test_214_7.jpg",
        "test_214_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          2,
          3,
          0,
          6,
          7,
          5,
          8,
          1
        ],
        "order_filenames": [
          "test_214_4.jpg",
          "test_214_2.jpg",
          "test_214_3.jpg",
          "test_214_0.jpg",
          "test_214_6.jpg",
          "test_214_7.jpg",
          "test_214_5.jpg",
          "test_214_8.jpg",
          "test_214_1.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_214_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_214_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_214_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.228515625,
            0.208984375,
            0.26025390625,
            0.17041015625,
            0.180908203125,
            0.06640625,
            0.24609375,
            0.23388671875,
            0.2232666015625
          ],
          "order_indices": [
            2,
            6,
            7,
            0,
            8,
            1,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_214_2.jpg",
            "test_214_6.jpg",
            "test_214_7.jpg",
            "test_214_0.jpg",
            "test_214_8.jpg",
            "test_214_1.jpg",
            "test_214_4.jpg",
            "test_214_3.jpg",
            "test_214_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.15000000000000002,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            42.4375,
            35.96875,
            40.84375,
            22.71875,
            20.421875,
            18.96875,
            36.0625,
            40.5,
            40.90625
          ],
          "order_indices": [
            0,
            8,
            2,
            7,
            6,
            1,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_214_0.jpg",
            "test_214_8.jpg",
            "test_214_2.jpg",
            "test_214_7.jpg",
            "test_214_6.jpg",
            "test_214_1.jpg",
            "test_214_3.jpg",
            "test_214_4.jpg",
            "test_214_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.7160670757293701,
            0.3113194406032562,
            1.6411572694778442,
            1.4287701845169067,
            -0.006037991493940353,
            -2.2833893299102783,
            1.6498754024505615,
            1.7229630947113037,
            1.43561589717865
          ],
          "order_indices": [
            7,
            0,
            6,
            2,
            8,
            3,
            1,
            4,
            5
          ],
          "order_filenames": [
            "test_214_7.jpg",
            "test_214_0.jpg",
            "test_214_6.jpg",
            "test_214_2.jpg",
            "test_214_8.jpg",
            "test_214_3.jpg",
            "test_214_1.jpg",
            "test_214_4.jpg",
            "test_214_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 215,
      "prompt": "A person wearing black and white boots and pants sits in a portrait pose in a detailed fantasy painting by various artists.",
      "image_filenames": [
        "test_215_0.jpg",
        "test_215_1.jpg",
        "test_215_2.jpg",
        "test_215_3.jpg",
        "test_215_4.jpg",
        "test_215_5.jpg",
        "test_215_6.jpg",
        "test_215_7.jpg",
        "test_215_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          3,
          4,
          1,
          2,
          5,
          6,
          7,
          8
        ],
        "order_filenames": [
          "test_215_0.jpg",
          "test_215_3.jpg",
          "test_215_4.jpg",
          "test_215_1.jpg",
          "test_215_2.jpg",
          "test_215_5.jpg",
          "test_215_6.jpg",
          "test_215_7.jpg",
          "test_215_8.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_215_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            2,
            4,
            5
          ],
          "winner_filenames": [
            "test_215_2.jpg",
            "test_215_4.jpg",
            "test_215_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_215_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1851806640625,
            0.216796875,
            0.229736328125,
            0.1729736328125,
            0.1845703125,
            0.1070556640625,
            0.179931640625,
            0.1934814453125,
            0.2022705078125
          ],
          "order_indices": [
            2,
            1,
            8,
            7,
            0,
            4,
            6,
            3,
            5
          ],
          "order_filenames": [
            "test_215_2.jpg",
            "test_215_1.jpg",
            "test_215_8.jpg",
            "test_215_7.jpg",
            "test_215_0.jpg",
            "test_215_4.jpg",
            "test_215_6.jpg",
            "test_215_3.jpg",
            "test_215_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.375,
            37.78125,
            47.40625,
            34.625,
            37.5,
            26.359375,
            37.84375,
            40.59375,
            49.375
          ],
          "order_indices": [
            8,
            2,
            7,
            0,
            6,
            1,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_215_8.jpg",
            "test_215_2.jpg",
            "test_215_7.jpg",
            "test_215_0.jpg",
            "test_215_6.jpg",
            "test_215_1.jpg",
            "test_215_4.jpg",
            "test_215_3.jpg",
            "test_215_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.46666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.7464260458946228,
            0.05400708317756653,
            0.9609135985374451,
            0.01699858531355858,
            -0.6539471745491028,
            -2.2295894622802734,
            -1.912757396697998,
            -0.0341227725148201,
            -1.0362412929534912
          ],
          "order_indices": [
            2,
            0,
            1,
            3,
            7,
            4,
            8,
            6,
            5
          ],
          "order_filenames": [
            "test_215_2.jpg",
            "test_215_0.jpg",
            "test_215_1.jpg",
            "test_215_3.jpg",
            "test_215_7.jpg",
            "test_215_4.jpg",
            "test_215_8.jpg",
            "test_215_6.jpg",
            "test_215_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.55,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 216,
      "prompt": "Female human barbarian in a dungeon, illustrated by Jeff Easley for Dungeons and Dragons.",
      "image_filenames": [
        "test_216_0.jpg",
        "test_216_1.jpg",
        "test_216_2.jpg",
        "test_216_3.jpg",
        "test_216_4.jpg",
        "test_216_5.jpg",
        "test_216_6.jpg",
        "test_216_7.jpg",
        "test_216_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          6,
          7,
          3,
          1,
          2,
          4,
          8,
          5
        ],
        "order_filenames": [
          "test_216_0.jpg",
          "test_216_6.jpg",
          "test_216_7.jpg",
          "test_216_3.jpg",
          "test_216_1.jpg",
          "test_216_2.jpg",
          "test_216_4.jpg",
          "test_216_8.jpg",
          "test_216_5.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0,
          6
        ],
        "winner_filenames": [
          "test_216_0.jpg",
          "test_216_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_216_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_216_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.205810546875,
            0.1942138671875,
            0.259765625,
            0.2071533203125,
            0.148193359375,
            0.0618896484375,
            0.2177734375,
            0.21875,
            0.1802978515625
          ],
          "order_indices": [
            2,
            7,
            6,
            3,
            0,
            1,
            8,
            4,
            5
          ],
          "order_filenames": [
            "test_216_2.jpg",
            "test_216_7.jpg",
            "test_216_6.jpg",
            "test_216_3.jpg",
            "test_216_0.jpg",
            "test_216_1.jpg",
            "test_216_8.jpg",
            "test_216_4.jpg",
            "test_216_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.4444444444444444,
            "spearman_rho": 0.6166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.75,
            37.75,
            35.28125,
            24.0625,
            14.046875,
            11.1953125,
            39.5625,
            40.75,
            25.421875
          ],
          "order_indices": [
            7,
            0,
            6,
            1,
            2,
            8,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_216_7.jpg",
            "test_216_0.jpg",
            "test_216_6.jpg",
            "test_216_1.jpg",
            "test_216_2.jpg",
            "test_216_8.jpg",
            "test_216_3.jpg",
            "test_216_4.jpg",
            "test_216_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.6666666666666666,
            "spearman_rho": 0.8166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.5214884877204895,
            -0.45285168290138245,
            -0.008608311414718628,
            -1.2770488262176514,
            -0.8997966647148132,
            -2.1789331436157227,
            -0.1130792424082756,
            0.01117390114814043,
            -0.8174571394920349
          ],
          "order_indices": [
            7,
            2,
            6,
            1,
            0,
            8,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_216_7.jpg",
            "test_216_2.jpg",
            "test_216_6.jpg",
            "test_216_1.jpg",
            "test_216_0.jpg",
            "test_216_8.jpg",
            "test_216_4.jpg",
            "test_216_3.jpg",
            "test_216_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.5166666666666666,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 217,
      "prompt": "a pointillism ink painting of a Japanese demon with high detail.",
      "image_filenames": [
        "test_217_0.jpg",
        "test_217_1.jpg",
        "test_217_2.jpg",
        "test_217_3.jpg",
        "test_217_4.jpg",
        "test_217_5.jpg",
        "test_217_6.jpg",
        "test_217_7.jpg",
        "test_217_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          5,
          2,
          3,
          6,
          1,
          7,
          8,
          0
        ],
        "order_filenames": [
          "test_217_4.jpg",
          "test_217_5.jpg",
          "test_217_2.jpg",
          "test_217_3.jpg",
          "test_217_6.jpg",
          "test_217_1.jpg",
          "test_217_7.jpg",
          "test_217_8.jpg",
          "test_217_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_217_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4,
            5
          ],
          "winner_filenames": [
            "test_217_4.jpg",
            "test_217_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4,
            5
          ],
          "winner_filenames": [
            "test_217_4.jpg",
            "test_217_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.166748046875,
            0.2061767578125,
            0.164794921875,
            0.1693115234375,
            0.158447265625,
            0.10345458984375,
            0.2147216796875,
            0.209716796875,
            0.21826171875
          ],
          "order_indices": [
            8,
            6,
            7,
            1,
            3,
            0,
            2,
            4,
            5
          ],
          "order_filenames": [
            "test_217_8.jpg",
            "test_217_6.jpg",
            "test_217_7.jpg",
            "test_217_1.jpg",
            "test_217_3.jpg",
            "test_217_0.jpg",
            "test_217_2.jpg",
            "test_217_4.jpg",
            "test_217_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5555555555555556,
            "spearman_rho": -0.6833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.375,
            43.59375,
            37.25,
            34.0625,
            16.609375,
            19.796875,
            41.5,
            42.3125,
            33.3125
          ],
          "order_indices": [
            1,
            7,
            6,
            0,
            2,
            3,
            8,
            5,
            4
          ],
          "order_filenames": [
            "test_217_1.jpg",
            "test_217_7.jpg",
            "test_217_6.jpg",
            "test_217_0.jpg",
            "test_217_2.jpg",
            "test_217_3.jpg",
            "test_217_8.jpg",
            "test_217_5.jpg",
            "test_217_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.5666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.20554915070533752,
            -0.12677741050720215,
            -1.2105474472045898,
            -1.793182373046875,
            -1.6045002937316895,
            -2.2791731357574463,
            0.9788805246353149,
            0.959751307964325,
            0.8178460001945496
          ],
          "order_indices": [
            6,
            7,
            8,
            0,
            1,
            2,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_217_6.jpg",
            "test_217_7.jpg",
            "test_217_8.jpg",
            "test_217_0.jpg",
            "test_217_1.jpg",
            "test_217_2.jpg",
            "test_217_4.jpg",
            "test_217_3.jpg",
            "test_217_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.6833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 218,
      "prompt": "A nebula forms the shape of a face in this detailed artwork.",
      "image_filenames": [
        "test_218_0.jpg",
        "test_218_1.jpg",
        "test_218_2.jpg",
        "test_218_3.jpg",
        "test_218_4.jpg",
        "test_218_5.jpg",
        "test_218_6.jpg",
        "test_218_7.jpg",
        "test_218_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          6,
          2,
          5,
          7,
          8,
          4,
          1,
          0
        ],
        "order_filenames": [
          "test_218_3.jpg",
          "test_218_6.jpg",
          "test_218_2.jpg",
          "test_218_5.jpg",
          "test_218_7.jpg",
          "test_218_8.jpg",
          "test_218_4.jpg",
          "test_218_1.jpg",
          "test_218_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_218_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_218_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3,
            6
          ],
          "winner_filenames": [
            "test_218_3.jpg",
            "test_218_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.193603515625,
            0.231689453125,
            0.2578125,
            0.1751708984375,
            0.158935546875,
            0.1707763671875,
            0.331787109375,
            0.2281494140625,
            0.271240234375
          ],
          "order_indices": [
            6,
            8,
            2,
            1,
            7,
            0,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_218_6.jpg",
            "test_218_8.jpg",
            "test_218_2.jpg",
            "test_218_1.jpg",
            "test_218_7.jpg",
            "test_218_0.jpg",
            "test_218_3.jpg",
            "test_218_5.jpg",
            "test_218_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            41.65625,
            25.671875,
            41.65625,
            27.640625,
            25.34375,
            29.25,
            36.71875,
            37.21875,
            32.84375
          ],
          "order_indices": [
            0,
            2,
            7,
            6,
            8,
            5,
            3,
            1,
            4
          ],
          "order_filenames": [
            "test_218_0.jpg",
            "test_218_2.jpg",
            "test_218_7.jpg",
            "test_218_6.jpg",
            "test_218_8.jpg",
            "test_218_5.jpg",
            "test_218_3.jpg",
            "test_218_1.jpg",
            "test_218_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.01666666666666672,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.09373229742050171,
            -0.9628195762634277,
            -0.2764050364494324,
            -1.0648038387298584,
            -1.7640138864517212,
            -0.9011430740356445,
            0.18441833555698395,
            -1.2747275829315186,
            0.05523400008678436
          ],
          "order_indices": [
            6,
            0,
            8,
            2,
            5,
            1,
            3,
            7,
            4
          ],
          "order_filenames": [
            "test_218_6.jpg",
            "test_218_0.jpg",
            "test_218_8.jpg",
            "test_218_2.jpg",
            "test_218_5.jpg",
            "test_218_1.jpg",
            "test_218_3.jpg",
            "test_218_7.jpg",
            "test_218_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.050000000000000044,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 219,
      "prompt": "The image depicts a Studio Ghibli-style painting of a colossal, ancient ruin with a road winding through the forest, overlooking a sunrise above the cloudy sea.",
      "image_filenames": [
        "test_219_0.jpg",
        "test_219_1.jpg",
        "test_219_2.jpg",
        "test_219_3.jpg",
        "test_219_4.jpg",
        "test_219_5.jpg",
        "test_219_6.jpg",
        "test_219_7.jpg",
        "test_219_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          0,
          4,
          3,
          2,
          8,
          5,
          6,
          1
        ],
        "order_filenames": [
          "test_219_7.jpg",
          "test_219_0.jpg",
          "test_219_4.jpg",
          "test_219_3.jpg",
          "test_219_2.jpg",
          "test_219_8.jpg",
          "test_219_5.jpg",
          "test_219_6.jpg",
          "test_219_1.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_219_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_219_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_219_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.201904296875,
            0.27099609375,
            0.271240234375,
            0.1881103515625,
            0.150634765625,
            0.134765625,
            0.2247314453125,
            0.2335205078125,
            0.263671875
          ],
          "order_indices": [
            2,
            1,
            8,
            7,
            6,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_219_2.jpg",
            "test_219_1.jpg",
            "test_219_8.jpg",
            "test_219_7.jpg",
            "test_219_6.jpg",
            "test_219_0.jpg",
            "test_219_3.jpg",
            "test_219_4.jpg",
            "test_219_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.21666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.375,
            40.71875,
            42.84375,
            35.96875,
            26.671875,
            25.71875,
            34.90625,
            40.625,
            35.625
          ],
          "order_indices": [
            2,
            1,
            7,
            0,
            3,
            8,
            6,
            4,
            5
          ],
          "order_filenames": [
            "test_219_2.jpg",
            "test_219_1.jpg",
            "test_219_7.jpg",
            "test_219_0.jpg",
            "test_219_3.jpg",
            "test_219_8.jpg",
            "test_219_6.jpg",
            "test_219_4.jpg",
            "test_219_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.1333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.27256131172180176,
            -0.1496317833662033,
            1.1035932302474976,
            -0.10203451663255692,
            -1.2868256568908691,
            -1.2662043571472168,
            -0.5755006670951843,
            0.6717619895935059,
            0.9431225061416626
          ],
          "order_indices": [
            2,
            8,
            7,
            3,
            1,
            0,
            6,
            5,
            4
          ],
          "order_filenames": [
            "test_219_2.jpg",
            "test_219_8.jpg",
            "test_219_7.jpg",
            "test_219_3.jpg",
            "test_219_1.jpg",
            "test_219_0.jpg",
            "test_219_6.jpg",
            "test_219_5.jpg",
            "test_219_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.1166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 220,
      "prompt": "Michael Van Gerwen drinking a cup of tea in black and white Warhammer fantasy art.",
      "image_filenames": [
        "test_220_0.jpg",
        "test_220_1.jpg",
        "test_220_2.jpg",
        "test_220_3.jpg",
        "test_220_4.jpg",
        "test_220_5.jpg",
        "test_220_6.jpg",
        "test_220_7.jpg",
        "test_220_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          0,
          6,
          7,
          2,
          4,
          3,
          8,
          1
        ],
        "order_filenames": [
          "test_220_5.jpg",
          "test_220_0.jpg",
          "test_220_6.jpg",
          "test_220_7.jpg",
          "test_220_2.jpg",
          "test_220_4.jpg",
          "test_220_3.jpg",
          "test_220_8.jpg",
          "test_220_1.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_220_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_220_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_220_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.19189453125,
            0.204345703125,
            0.297119140625,
            0.2034912109375,
            0.1802978515625,
            0.1688232421875,
            0.2464599609375,
            0.213134765625,
            0.2354736328125
          ],
          "order_indices": [
            2,
            6,
            8,
            7,
            1,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_220_2.jpg",
            "test_220_6.jpg",
            "test_220_8.jpg",
            "test_220_7.jpg",
            "test_220_1.jpg",
            "test_220_3.jpg",
            "test_220_0.jpg",
            "test_220_4.jpg",
            "test_220_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.2666666666666666,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            45.59375,
            38.8125,
            52.0,
            34.375,
            26.046875,
            24.765625,
            45.5,
            50.28125,
            49.71875
          ],
          "order_indices": [
            2,
            7,
            8,
            0,
            6,
            1,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_220_2.jpg",
            "test_220_7.jpg",
            "test_220_8.jpg",
            "test_220_0.jpg",
            "test_220_6.jpg",
            "test_220_1.jpg",
            "test_220_3.jpg",
            "test_220_4.jpg",
            "test_220_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.08333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.5198673009872437,
            -0.041763484477996826,
            1.809950351715088,
            0.005713157821446657,
            -1.1944608688354492,
            -1.9402486085891724,
            -0.10588452219963074,
            1.0825384855270386,
            1.8899391889572144
          ],
          "order_indices": [
            8,
            2,
            7,
            0,
            3,
            1,
            6,
            4,
            5
          ],
          "order_filenames": [
            "test_220_8.jpg",
            "test_220_2.jpg",
            "test_220_7.jpg",
            "test_220_0.jpg",
            "test_220_3.jpg",
            "test_220_1.jpg",
            "test_220_6.jpg",
            "test_220_4.jpg",
            "test_220_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.33333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 221,
      "prompt": "Portrait of a Victorian gentleman standing on a balcony, richly detailed color illustration with cinematic lighting.",
      "image_filenames": [
        "test_221_0.jpg",
        "test_221_1.jpg",
        "test_221_2.jpg",
        "test_221_3.jpg",
        "test_221_4.jpg",
        "test_221_5.jpg",
        "test_221_6.jpg",
        "test_221_7.jpg",
        "test_221_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          3,
          4,
          7,
          6,
          1,
          8,
          0,
          2
        ],
        "order_filenames": [
          "test_221_5.jpg",
          "test_221_3.jpg",
          "test_221_4.jpg",
          "test_221_7.jpg",
          "test_221_6.jpg",
          "test_221_1.jpg",
          "test_221_8.jpg",
          "test_221_0.jpg",
          "test_221_2.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_221_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_221_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_221_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2095947265625,
            0.22705078125,
            0.25048828125,
            0.11492919921875,
            0.1849365234375,
            0.10064697265625,
            0.2108154296875,
            0.2081298828125,
            0.2744140625
          ],
          "order_indices": [
            8,
            2,
            1,
            6,
            0,
            7,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_221_8.jpg",
            "test_221_2.jpg",
            "test_221_1.jpg",
            "test_221_6.jpg",
            "test_221_0.jpg",
            "test_221_7.jpg",
            "test_221_4.jpg",
            "test_221_3.jpg",
            "test_221_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.7777777777777778,
            "spearman_rho": -0.8666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.125,
            36.375,
            42.03125,
            26.03125,
            32.40625,
            15.40625,
            36.53125,
            39.09375,
            44.3125
          ],
          "order_indices": [
            8,
            2,
            0,
            7,
            6,
            1,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_221_8.jpg",
            "test_221_2.jpg",
            "test_221_0.jpg",
            "test_221_7.jpg",
            "test_221_6.jpg",
            "test_221_1.jpg",
            "test_221_4.jpg",
            "test_221_3.jpg",
            "test_221_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.7222222222222222,
            "spearman_rho": -0.8833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.5433396100997925,
            0.9543928503990173,
            1.2898482084274292,
            -1.6092170476913452,
            0.033532027155160904,
            -2.27236008644104,
            0.6855553984642029,
            0.24694789946079254,
            1.3126544952392578
          ],
          "order_indices": [
            8,
            2,
            1,
            6,
            0,
            7,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_221_8.jpg",
            "test_221_2.jpg",
            "test_221_1.jpg",
            "test_221_6.jpg",
            "test_221_0.jpg",
            "test_221_7.jpg",
            "test_221_4.jpg",
            "test_221_3.jpg",
            "test_221_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.7777777777777778,
            "spearman_rho": -0.8666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 222,
      "prompt": "A painting of a woman by Zinaida Serebriakova wearing a T-shirt with the Supreme brand logo, a sleeveless white blouse, dark brown capris, and black loafers.",
      "image_filenames": [
        "test_222_0.jpg",
        "test_222_1.jpg",
        "test_222_2.jpg",
        "test_222_3.jpg",
        "test_222_4.jpg",
        "test_222_5.jpg",
        "test_222_6.jpg",
        "test_222_7.jpg",
        "test_222_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          2,
          5,
          3,
          1,
          6,
          0,
          7,
          8
        ],
        "order_filenames": [
          "test_222_4.jpg",
          "test_222_2.jpg",
          "test_222_5.jpg",
          "test_222_3.jpg",
          "test_222_1.jpg",
          "test_222_6.jpg",
          "test_222_0.jpg",
          "test_222_7.jpg",
          "test_222_8.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_222_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_222_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2,
            4
          ],
          "winner_filenames": [
            "test_222_2.jpg",
            "test_222_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1953125,
            0.2349853515625,
            0.221435546875,
            0.159423828125,
            0.177001953125,
            0.104736328125,
            0.213623046875,
            0.182373046875,
            0.2437744140625
          ],
          "order_indices": [
            8,
            1,
            2,
            6,
            0,
            7,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_222_8.jpg",
            "test_222_1.jpg",
            "test_222_2.jpg",
            "test_222_6.jpg",
            "test_222_0.jpg",
            "test_222_7.jpg",
            "test_222_4.jpg",
            "test_222_3.jpg",
            "test_222_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.44999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.78125,
            41.5625,
            40.96875,
            34.625,
            27.4375,
            19.15625,
            38.0,
            39.625,
            41.90625
          ],
          "order_indices": [
            8,
            1,
            2,
            0,
            7,
            6,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_222_8.jpg",
            "test_222_1.jpg",
            "test_222_2.jpg",
            "test_222_0.jpg",
            "test_222_7.jpg",
            "test_222_6.jpg",
            "test_222_3.jpg",
            "test_222_4.jpg",
            "test_222_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.55,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.36325061321258545,
            0.5919579863548279,
            -0.07086913287639618,
            -1.1635538339614868,
            -0.8259975910186768,
            -1.905428409576416,
            -0.37973928451538086,
            -0.009782996028661728,
            -0.8922041654586792
          ],
          "order_indices": [
            1,
            0,
            7,
            2,
            6,
            4,
            8,
            3,
            5
          ],
          "order_filenames": [
            "test_222_1.jpg",
            "test_222_0.jpg",
            "test_222_7.jpg",
            "test_222_2.jpg",
            "test_222_6.jpg",
            "test_222_4.jpg",
            "test_222_8.jpg",
            "test_222_3.jpg",
            "test_222_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.2666666666666666,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 223,
      "prompt": "A painting of a starship landing by a temple, created by Hubert Robert.",
      "image_filenames": [
        "test_223_0.jpg",
        "test_223_1.jpg",
        "test_223_2.jpg",
        "test_223_3.jpg",
        "test_223_4.jpg",
        "test_223_5.jpg",
        "test_223_6.jpg",
        "test_223_7.jpg",
        "test_223_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          6,
          5,
          1,
          3,
          7,
          8,
          2,
          0
        ],
        "order_filenames": [
          "test_223_4.jpg",
          "test_223_6.jpg",
          "test_223_5.jpg",
          "test_223_1.jpg",
          "test_223_3.jpg",
          "test_223_7.jpg",
          "test_223_8.jpg",
          "test_223_2.jpg",
          "test_223_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_223_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4,
            5
          ],
          "winner_filenames": [
            "test_223_4.jpg",
            "test_223_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_223_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2099609375,
            0.2427978515625,
            0.167724609375,
            0.2083740234375,
            0.142333984375,
            0.1563720703125,
            0.238525390625,
            0.256591796875,
            0.2294921875
          ],
          "order_indices": [
            7,
            1,
            6,
            8,
            0,
            3,
            2,
            5,
            4
          ],
          "order_filenames": [
            "test_223_7.jpg",
            "test_223_1.jpg",
            "test_223_6.jpg",
            "test_223_8.jpg",
            "test_223_0.jpg",
            "test_223_3.jpg",
            "test_223_2.jpg",
            "test_223_5.jpg",
            "test_223_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.21666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            42.8125,
            35.15625,
            35.84375,
            30.953125,
            24.5,
            21.234375,
            31.203125,
            41.40625,
            27.65625
          ],
          "order_indices": [
            0,
            7,
            2,
            1,
            6,
            3,
            8,
            4,
            5
          ],
          "order_filenames": [
            "test_223_0.jpg",
            "test_223_7.jpg",
            "test_223_2.jpg",
            "test_223_1.jpg",
            "test_223_6.jpg",
            "test_223_3.jpg",
            "test_223_8.jpg",
            "test_223_4.jpg",
            "test_223_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.6666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.4335322380065918,
            -0.07258167117834091,
            -0.7627735733985901,
            0.9923802614212036,
            -0.49683478474617004,
            -0.22297170758247375,
            -0.19581344723701477,
            1.739512324333191,
            1.0452487468719482
          ],
          "order_indices": [
            7,
            0,
            8,
            3,
            1,
            6,
            5,
            4,
            2
          ],
          "order_filenames": [
            "test_223_7.jpg",
            "test_223_0.jpg",
            "test_223_8.jpg",
            "test_223_3.jpg",
            "test_223_1.jpg",
            "test_223_6.jpg",
            "test_223_5.jpg",
            "test_223_4.jpg",
            "test_223_2.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.44999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 224,
      "prompt": "Panorama of Hogwarts.",
      "image_filenames": [
        "test_224_0.jpg",
        "test_224_1.jpg",
        "test_224_2.jpg",
        "test_224_3.jpg",
        "test_224_4.jpg",
        "test_224_5.jpg",
        "test_224_6.jpg",
        "test_224_7.jpg",
        "test_224_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          1,
          3,
          6,
          4,
          5,
          0,
          8,
          7
        ],
        "order_filenames": [
          "test_224_2.jpg",
          "test_224_1.jpg",
          "test_224_3.jpg",
          "test_224_6.jpg",
          "test_224_4.jpg",
          "test_224_5.jpg",
          "test_224_0.jpg",
          "test_224_8.jpg",
          "test_224_7.jpg"
        ],
        "condorcet_winner": 2,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_224_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_224_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_224_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2012939453125,
            0.286376953125,
            0.306396484375,
            0.2392578125,
            0.1962890625,
            0.2288818359375,
            0.27294921875,
            0.218994140625,
            0.2060546875
          ],
          "order_indices": [
            2,
            1,
            6,
            3,
            5,
            7,
            8,
            0,
            4
          ],
          "order_filenames": [
            "test_224_2.jpg",
            "test_224_1.jpg",
            "test_224_6.jpg",
            "test_224_3.jpg",
            "test_224_5.jpg",
            "test_224_7.jpg",
            "test_224_8.jpg",
            "test_224_0.jpg",
            "test_224_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.5555555555555556,
            "spearman_rho": 0.75,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 1.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.375,
            26.875,
            29.859375,
            31.4375,
            24.21875,
            35.0625,
            27.59375,
            36.625,
            35.59375
          ],
          "order_indices": [
            0,
            7,
            8,
            5,
            3,
            2,
            6,
            1,
            4
          ],
          "order_filenames": [
            "test_224_0.jpg",
            "test_224_7.jpg",
            "test_224_8.jpg",
            "test_224_5.jpg",
            "test_224_3.jpg",
            "test_224_2.jpg",
            "test_224_6.jpg",
            "test_224_1.jpg",
            "test_224_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.7,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.17167875170707703,
            0.6362380981445312,
            0.6442990899085999,
            0.3704356551170349,
            -1.4352750778198242,
            -0.03914140164852142,
            -0.40514349937438965,
            -0.9848154783248901,
            0.28262031078338623
          ],
          "order_indices": [
            2,
            1,
            3,
            8,
            0,
            5,
            6,
            7,
            4
          ],
          "order_filenames": [
            "test_224_2.jpg",
            "test_224_1.jpg",
            "test_224_3.jpg",
            "test_224_8.jpg",
            "test_224_0.jpg",
            "test_224_5.jpg",
            "test_224_6.jpg",
            "test_224_7.jpg",
            "test_224_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.4444444444444444,
            "spearman_rho": 0.6166666666666667,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 1.0,
            "exact_position_match": 0.4444444444444444,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 225,
      "prompt": "Close up portrait of a person speaking on the phone in front of a dark, geometrically abstract painting in the style of Sophie Taeuber-Arp, Gary Hume, and Tatsuro Kiuchi.",
      "image_filenames": [
        "test_225_0.jpg",
        "test_225_1.jpg",
        "test_225_2.jpg",
        "test_225_3.jpg",
        "test_225_4.jpg",
        "test_225_5.jpg",
        "test_225_6.jpg",
        "test_225_7.jpg",
        "test_225_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          5,
          2,
          4,
          7,
          1,
          8,
          3,
          6
        ],
        "order_filenames": [
          "test_225_0.jpg",
          "test_225_5.jpg",
          "test_225_2.jpg",
          "test_225_4.jpg",
          "test_225_7.jpg",
          "test_225_1.jpg",
          "test_225_8.jpg",
          "test_225_3.jpg",
          "test_225_6.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0,
          5
        ],
        "winner_filenames": [
          "test_225_0.jpg",
          "test_225_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_225_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0,
            2,
            5
          ],
          "winner_filenames": [
            "test_225_0.jpg",
            "test_225_2.jpg",
            "test_225_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.152587890625,
            0.1912841796875,
            0.2349853515625,
            0.1534423828125,
            0.193115234375,
            0.11376953125,
            0.1544189453125,
            0.21533203125,
            0.222412109375
          ],
          "order_indices": [
            2,
            8,
            7,
            4,
            1,
            6,
            3,
            0,
            5
          ],
          "order_filenames": [
            "test_225_2.jpg",
            "test_225_8.jpg",
            "test_225_7.jpg",
            "test_225_4.jpg",
            "test_225_1.jpg",
            "test_225_6.jpg",
            "test_225_3.jpg",
            "test_225_0.jpg",
            "test_225_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            32.46875,
            38.75,
            34.40625,
            21.859375,
            25.703125,
            16.125,
            37.4375,
            36.53125,
            38.875
          ],
          "order_indices": [
            8,
            1,
            6,
            7,
            2,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_225_8.jpg",
            "test_225_1.jpg",
            "test_225_6.jpg",
            "test_225_7.jpg",
            "test_225_2.jpg",
            "test_225_0.jpg",
            "test_225_4.jpg",
            "test_225_3.jpg",
            "test_225_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.46666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.8864157199859619,
            -0.824709951877594,
            -0.7235914468765259,
            -1.9170633554458618,
            -0.9339643716812134,
            -1.9310587644577026,
            -2.20831561088562,
            -0.3268866539001465,
            -1.9950212240219116
          ],
          "order_indices": [
            7,
            2,
            1,
            0,
            4,
            3,
            5,
            8,
            6
          ],
          "order_filenames": [
            "test_225_7.jpg",
            "test_225_2.jpg",
            "test_225_1.jpg",
            "test_225_0.jpg",
            "test_225_4.jpg",
            "test_225_3.jpg",
            "test_225_5.jpg",
            "test_225_8.jpg",
            "test_225_6.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.44999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 226,
      "prompt": "a shiny metallic renaissance steampunk robot in the style of Jan van Eyck.",
      "image_filenames": [
        "test_226_0.jpg",
        "test_226_1.jpg",
        "test_226_2.jpg",
        "test_226_3.jpg",
        "test_226_4.jpg",
        "test_226_5.jpg",
        "test_226_6.jpg",
        "test_226_7.jpg",
        "test_226_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          4,
          7,
          5,
          8,
          2,
          1,
          6,
          0
        ],
        "order_filenames": [
          "test_226_3.jpg",
          "test_226_4.jpg",
          "test_226_7.jpg",
          "test_226_5.jpg",
          "test_226_8.jpg",
          "test_226_2.jpg",
          "test_226_1.jpg",
          "test_226_6.jpg",
          "test_226_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3,
          4
        ],
        "winner_filenames": [
          "test_226_3.jpg",
          "test_226_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3,
            4
          ],
          "winner_filenames": [
            "test_226_3.jpg",
            "test_226_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3,
            4
          ],
          "winner_filenames": [
            "test_226_3.jpg",
            "test_226_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2152099609375,
            0.262939453125,
            0.27197265625,
            0.2335205078125,
            0.1875,
            0.15625,
            0.29443359375,
            0.2451171875,
            0.2100830078125
          ],
          "order_indices": [
            6,
            2,
            1,
            7,
            3,
            0,
            8,
            4,
            5
          ],
          "order_filenames": [
            "test_226_6.jpg",
            "test_226_2.jpg",
            "test_226_1.jpg",
            "test_226_7.jpg",
            "test_226_3.jpg",
            "test_226_0.jpg",
            "test_226_8.jpg",
            "test_226_4.jpg",
            "test_226_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.43333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.375,
            37.34375,
            37.625,
            39.0625,
            23.125,
            29.53125,
            29.125,
            39.625,
            33.34375
          ],
          "order_indices": [
            7,
            0,
            3,
            2,
            1,
            8,
            5,
            6,
            4
          ],
          "order_filenames": [
            "test_226_7.jpg",
            "test_226_0.jpg",
            "test_226_3.jpg",
            "test_226_2.jpg",
            "test_226_1.jpg",
            "test_226_8.jpg",
            "test_226_5.jpg",
            "test_226_6.jpg",
            "test_226_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.03333333333333344,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.3886905610561371,
            0.28279533982276917,
            0.6676052212715149,
            -0.0036029352340847254,
            -1.6384425163269043,
            -0.8339090943336487,
            0.2709561288356781,
            0.043314073234796524,
            0.18572427332401276
          ],
          "order_indices": [
            2,
            0,
            1,
            6,
            8,
            7,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_226_2.jpg",
            "test_226_0.jpg",
            "test_226_1.jpg",
            "test_226_6.jpg",
            "test_226_8.jpg",
            "test_226_7.jpg",
            "test_226_3.jpg",
            "test_226_5.jpg",
            "test_226_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.6111111111111112,
            "spearman_rho": -0.8,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 227,
      "prompt": "Album art of a hand holding a balloon emerging from the water against a red sky.",
      "image_filenames": [
        "test_227_0.jpg",
        "test_227_1.jpg",
        "test_227_2.jpg",
        "test_227_3.jpg",
        "test_227_4.jpg",
        "test_227_5.jpg",
        "test_227_6.jpg",
        "test_227_7.jpg",
        "test_227_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          3,
          7,
          4,
          6,
          1,
          0,
          8,
          2
        ],
        "order_filenames": [
          "test_227_5.jpg",
          "test_227_3.jpg",
          "test_227_7.jpg",
          "test_227_4.jpg",
          "test_227_6.jpg",
          "test_227_1.jpg",
          "test_227_0.jpg",
          "test_227_8.jpg",
          "test_227_2.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_227_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_227_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_227_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.188720703125,
            0.26025390625,
            0.25244140625,
            0.2030029296875,
            0.1783447265625,
            0.1932373046875,
            0.25048828125,
            0.2408447265625,
            0.277099609375
          ],
          "order_indices": [
            8,
            1,
            2,
            6,
            7,
            3,
            5,
            0,
            4
          ],
          "order_filenames": [
            "test_227_8.jpg",
            "test_227_1.jpg",
            "test_227_2.jpg",
            "test_227_6.jpg",
            "test_227_7.jpg",
            "test_227_3.jpg",
            "test_227_5.jpg",
            "test_227_0.jpg",
            "test_227_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.5333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            32.125,
            35.0625,
            46.125,
            35.0,
            28.9375,
            33.71875,
            41.625,
            42.34375,
            38.625
          ],
          "order_indices": [
            2,
            7,
            6,
            8,
            1,
            3,
            5,
            0,
            4
          ],
          "order_filenames": [
            "test_227_2.jpg",
            "test_227_7.jpg",
            "test_227_6.jpg",
            "test_227_8.jpg",
            "test_227_1.jpg",
            "test_227_3.jpg",
            "test_227_5.jpg",
            "test_227_0.jpg",
            "test_227_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.3666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.9935964345932007,
            -0.3612183928489685,
            1.0447908639907837,
            -0.31018778681755066,
            -1.8264647722244263,
            -1.0873029232025146,
            0.24532410502433777,
            0.3377622961997986,
            1.1835709810256958
          ],
          "order_indices": [
            8,
            2,
            7,
            6,
            3,
            1,
            0,
            5,
            4
          ],
          "order_filenames": [
            "test_227_8.jpg",
            "test_227_2.jpg",
            "test_227_7.jpg",
            "test_227_6.jpg",
            "test_227_3.jpg",
            "test_227_1.jpg",
            "test_227_0.jpg",
            "test_227_5.jpg",
            "test_227_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.5166666666666666,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 228,
      "prompt": "A canvas artwork with art nouveau style depicting an ocean on fire, inspired by artists Reylia Slaby, Peter Gric, and Lexie Liu, featuring intricate and ornate details and volumetric lighting.",
      "image_filenames": [
        "test_228_0.jpg",
        "test_228_1.jpg",
        "test_228_2.jpg",
        "test_228_3.jpg",
        "test_228_4.jpg",
        "test_228_5.jpg",
        "test_228_6.jpg",
        "test_228_7.jpg",
        "test_228_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          3,
          4,
          5,
          6,
          7,
          1,
          8,
          0
        ],
        "order_filenames": [
          "test_228_2.jpg",
          "test_228_3.jpg",
          "test_228_4.jpg",
          "test_228_5.jpg",
          "test_228_6.jpg",
          "test_228_7.jpg",
          "test_228_1.jpg",
          "test_228_8.jpg",
          "test_228_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_228_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            2,
            5,
            6
          ],
          "winner_filenames": [
            "test_228_2.jpg",
            "test_228_5.jpg",
            "test_228_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_228_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2249755859375,
            0.2430419921875,
            0.2259521484375,
            0.187255859375,
            0.1776123046875,
            0.153076171875,
            0.236328125,
            0.229248046875,
            0.226318359375
          ],
          "order_indices": [
            1,
            6,
            7,
            8,
            2,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_228_1.jpg",
            "test_228_6.jpg",
            "test_228_7.jpg",
            "test_228_8.jpg",
            "test_228_2.jpg",
            "test_228_0.jpg",
            "test_228_3.jpg",
            "test_228_4.jpg",
            "test_228_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.41666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.96875,
            34.21875,
            39.28125,
            24.78125,
            32.34375,
            15.0546875,
            33.1875,
            35.09375,
            29.0625
          ],
          "order_indices": [
            0,
            2,
            7,
            1,
            6,
            4,
            8,
            3,
            5
          ],
          "order_filenames": [
            "test_228_0.jpg",
            "test_228_2.jpg",
            "test_228_7.jpg",
            "test_228_1.jpg",
            "test_228_6.jpg",
            "test_228_4.jpg",
            "test_228_8.jpg",
            "test_228_3.jpg",
            "test_228_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.28333333333333344,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.6512976884841919,
            0.19922730326652527,
            -1.010787844657898,
            -0.9492847919464111,
            -0.541979968547821,
            -1.675286054611206,
            -0.3819483816623688,
            0.023181617259979248,
            0.3810453712940216
          ],
          "order_indices": [
            0,
            8,
            1,
            7,
            6,
            4,
            3,
            2,
            5
          ],
          "order_filenames": [
            "test_228_0.jpg",
            "test_228_8.jpg",
            "test_228_1.jpg",
            "test_228_7.jpg",
            "test_228_6.jpg",
            "test_228_4.jpg",
            "test_228_3.jpg",
            "test_228_2.jpg",
            "test_228_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.8333333333333334,
            "spearman_rho": -0.8999999999999999,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 229,
      "prompt": "A painting depicting a foothpath at Indian summer with an epic evening sky at sunset and low thunder clouds.",
      "image_filenames": [
        "test_229_0.jpg",
        "test_229_1.jpg",
        "test_229_2.jpg",
        "test_229_3.jpg",
        "test_229_4.jpg",
        "test_229_5.jpg",
        "test_229_6.jpg",
        "test_229_7.jpg",
        "test_229_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          0,
          1,
          2,
          3,
          5,
          6,
          8,
          7
        ],
        "order_filenames": [
          "test_229_4.jpg",
          "test_229_0.jpg",
          "test_229_1.jpg",
          "test_229_2.jpg",
          "test_229_3.jpg",
          "test_229_5.jpg",
          "test_229_6.jpg",
          "test_229_8.jpg",
          "test_229_7.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_229_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            0,
            1
          ],
          "winner_filenames": [
            "test_229_0.jpg",
            "test_229_1.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_229_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.20166015625,
            0.19287109375,
            0.2337646484375,
            0.189697265625,
            0.1910400390625,
            0.1689453125,
            0.2138671875,
            0.2353515625,
            0.22705078125
          ],
          "order_indices": [
            7,
            2,
            8,
            6,
            0,
            1,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_229_7.jpg",
            "test_229_2.jpg",
            "test_229_8.jpg",
            "test_229_6.jpg",
            "test_229_0.jpg",
            "test_229_1.jpg",
            "test_229_4.jpg",
            "test_229_3.jpg",
            "test_229_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.44999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.625,
            34.59375,
            36.46875,
            37.1875,
            26.046875,
            33.46875,
            36.40625,
            32.03125,
            44.21875
          ],
          "order_indices": [
            8,
            3,
            2,
            6,
            0,
            1,
            5,
            7,
            4
          ],
          "order_filenames": [
            "test_229_8.jpg",
            "test_229_3.jpg",
            "test_229_2.jpg",
            "test_229_6.jpg",
            "test_229_0.jpg",
            "test_229_1.jpg",
            "test_229_5.jpg",
            "test_229_7.jpg",
            "test_229_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.2666666666666666,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.0120266675949097,
            -0.2124132513999939,
            0.008565439842641354,
            -0.391690731048584,
            -0.2421499490737915,
            0.40559080243110657,
            -0.08253956586122513,
            0.6684243083000183,
            0.6636794805526733
          ],
          "order_indices": [
            0,
            7,
            8,
            5,
            2,
            6,
            1,
            4,
            3
          ],
          "order_filenames": [
            "test_229_0.jpg",
            "test_229_7.jpg",
            "test_229_8.jpg",
            "test_229_5.jpg",
            "test_229_2.jpg",
            "test_229_6.jpg",
            "test_229_1.jpg",
            "test_229_4.jpg",
            "test_229_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.3500000000000001,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 230,
      "prompt": "A surreal dark painting featuring mythical creatures, by Ronny Khalil.",
      "image_filenames": [
        "test_230_0.jpg",
        "test_230_1.jpg",
        "test_230_2.jpg",
        "test_230_3.jpg",
        "test_230_4.jpg",
        "test_230_5.jpg",
        "test_230_6.jpg",
        "test_230_7.jpg",
        "test_230_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          3,
          2,
          7,
          4,
          8,
          6,
          1,
          0
        ],
        "order_filenames": [
          "test_230_5.jpg",
          "test_230_3.jpg",
          "test_230_2.jpg",
          "test_230_7.jpg",
          "test_230_4.jpg",
          "test_230_8.jpg",
          "test_230_6.jpg",
          "test_230_1.jpg",
          "test_230_0.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_230_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_230_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_230_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.187744140625,
            0.210693359375,
            0.256103515625,
            0.158935546875,
            0.1783447265625,
            0.1409912109375,
            0.2303466796875,
            0.2376708984375,
            0.2117919921875
          ],
          "order_indices": [
            2,
            7,
            6,
            8,
            1,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_230_2.jpg",
            "test_230_7.jpg",
            "test_230_6.jpg",
            "test_230_8.jpg",
            "test_230_1.jpg",
            "test_230_0.jpg",
            "test_230_4.jpg",
            "test_230_3.jpg",
            "test_230_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.25,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.375,
            31.515625,
            36.53125,
            36.9375,
            31.359375,
            28.703125,
            34.78125,
            43.625,
            30.34375
          ],
          "order_indices": [
            7,
            0,
            3,
            2,
            6,
            1,
            4,
            8,
            5
          ],
          "order_filenames": [
            "test_230_7.jpg",
            "test_230_0.jpg",
            "test_230_3.jpg",
            "test_230_2.jpg",
            "test_230_6.jpg",
            "test_230_1.jpg",
            "test_230_4.jpg",
            "test_230_8.jpg",
            "test_230_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.16666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.16511274874210358,
            0.3859800398349762,
            0.5735281109809875,
            0.10578431189060211,
            -0.6103800535202026,
            -0.9682797789573669,
            0.2956090271472931,
            0.8484009504318237,
            0.1792680323123932
          ],
          "order_indices": [
            7,
            2,
            1,
            6,
            8,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_230_7.jpg",
            "test_230_2.jpg",
            "test_230_1.jpg",
            "test_230_6.jpg",
            "test_230_8.jpg",
            "test_230_0.jpg",
            "test_230_3.jpg",
            "test_230_4.jpg",
            "test_230_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.2666666666666666,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 231,
      "prompt": "A frightened woman with blood on her face, wearing an emerald necklace, crouched in fear in a castle hallway.",
      "image_filenames": [
        "test_231_0.jpg",
        "test_231_1.jpg",
        "test_231_2.jpg",
        "test_231_3.jpg",
        "test_231_4.jpg",
        "test_231_5.jpg",
        "test_231_6.jpg",
        "test_231_7.jpg",
        "test_231_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          0,
          4,
          5,
          6,
          3,
          7,
          8,
          1
        ],
        "order_filenames": [
          "test_231_2.jpg",
          "test_231_0.jpg",
          "test_231_4.jpg",
          "test_231_5.jpg",
          "test_231_6.jpg",
          "test_231_3.jpg",
          "test_231_7.jpg",
          "test_231_8.jpg",
          "test_231_1.jpg"
        ],
        "condorcet_winner": 2,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_231_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_231_2.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_231_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.222900390625,
            0.1558837890625,
            0.263427734375,
            0.1802978515625,
            0.175048828125,
            0.11346435546875,
            0.1492919921875,
            0.2294921875,
            0.250732421875
          ],
          "order_indices": [
            2,
            8,
            7,
            0,
            3,
            4,
            1,
            6,
            5
          ],
          "order_filenames": [
            "test_231_2.jpg",
            "test_231_8.jpg",
            "test_231_7.jpg",
            "test_231_0.jpg",
            "test_231_3.jpg",
            "test_231_4.jpg",
            "test_231_1.jpg",
            "test_231_6.jpg",
            "test_231_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.1333333333333333,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 1.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.625,
            35.625,
            40.125,
            35.125,
            32.9375,
            12.9140625,
            31.09375,
            41.5625,
            38.09375
          ],
          "order_indices": [
            7,
            0,
            2,
            8,
            1,
            3,
            4,
            6,
            5
          ],
          "order_filenames": [
            "test_231_7.jpg",
            "test_231_0.jpg",
            "test_231_2.jpg",
            "test_231_8.jpg",
            "test_231_1.jpg",
            "test_231_3.jpg",
            "test_231_4.jpg",
            "test_231_6.jpg",
            "test_231_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.016666666666666607,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.6174262166023254,
            -1.3922302722930908,
            -0.8158854246139526,
            -1.2090375423431396,
            -1.919904112815857,
            -2.240734338760376,
            -1.354919672012329,
            -0.057885512709617615,
            -0.859023928642273
          ],
          "order_indices": [
            7,
            0,
            2,
            8,
            3,
            6,
            1,
            4,
            5
          ],
          "order_filenames": [
            "test_231_7.jpg",
            "test_231_0.jpg",
            "test_231_2.jpg",
            "test_231_8.jpg",
            "test_231_3.jpg",
            "test_231_6.jpg",
            "test_231_1.jpg",
            "test_231_4.jpg",
            "test_231_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 232,
      "prompt": "Robot painted by Salvador Dali, resembling Wall-E.",
      "image_filenames": [
        "test_232_0.jpg",
        "test_232_1.jpg",
        "test_232_2.jpg",
        "test_232_3.jpg",
        "test_232_4.jpg",
        "test_232_5.jpg",
        "test_232_6.jpg",
        "test_232_7.jpg",
        "test_232_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          4,
          3,
          5,
          1,
          2,
          0,
          7,
          8
        ],
        "order_filenames": [
          "test_232_6.jpg",
          "test_232_4.jpg",
          "test_232_3.jpg",
          "test_232_5.jpg",
          "test_232_1.jpg",
          "test_232_2.jpg",
          "test_232_0.jpg",
          "test_232_7.jpg",
          "test_232_8.jpg"
        ],
        "condorcet_winner": 6,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_232_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_232_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_232_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.195068359375,
            0.2406005859375,
            0.28466796875,
            0.20556640625,
            0.18408203125,
            0.21240234375,
            0.2301025390625,
            0.216552734375,
            0.2470703125
          ],
          "order_indices": [
            2,
            8,
            1,
            6,
            7,
            5,
            3,
            0,
            4
          ],
          "order_filenames": [
            "test_232_2.jpg",
            "test_232_8.jpg",
            "test_232_1.jpg",
            "test_232_6.jpg",
            "test_232_7.jpg",
            "test_232_5.jpg",
            "test_232_3.jpg",
            "test_232_0.jpg",
            "test_232_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.3833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.78125,
            38.96875,
            32.78125,
            37.6875,
            35.71875,
            28.40625,
            30.078125,
            43.5625,
            36.59375
          ],
          "order_indices": [
            7,
            0,
            1,
            3,
            8,
            4,
            2,
            6,
            5
          ],
          "order_filenames": [
            "test_232_7.jpg",
            "test_232_0.jpg",
            "test_232_1.jpg",
            "test_232_3.jpg",
            "test_232_8.jpg",
            "test_232_4.jpg",
            "test_232_2.jpg",
            "test_232_6.jpg",
            "test_232_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.55,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.9776509404182434,
            -0.8242677450180054,
            0.7883769273757935,
            -1.5158390998840332,
            -1.8813644647598267,
            -2.0943338871002197,
            -0.3034191429615021,
            -0.31238511204719543,
            0.8271834850311279
          ],
          "order_indices": [
            8,
            2,
            6,
            7,
            1,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_232_8.jpg",
            "test_232_2.jpg",
            "test_232_6.jpg",
            "test_232_7.jpg",
            "test_232_1.jpg",
            "test_232_0.jpg",
            "test_232_3.jpg",
            "test_232_4.jpg",
            "test_232_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.4833333333333334,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 233,
      "prompt": "The image features a person wearing jodhpurs, knee-high boots, and a leather jacket, painted in a fantasy style by various artists including Greg Manchess, Leyendecker, Greg Rutkowski, Greg Tocchini, James Gilleard, and Joe Fenton.",
      "image_filenames": [
        "test_233_0.jpg",
        "test_233_1.jpg",
        "test_233_2.jpg",
        "test_233_3.jpg",
        "test_233_4.jpg",
        "test_233_5.jpg",
        "test_233_6.jpg",
        "test_233_7.jpg",
        "test_233_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          5,
          2,
          3,
          1,
          4,
          6,
          8,
          0
        ],
        "order_filenames": [
          "test_233_7.jpg",
          "test_233_5.jpg",
          "test_233_2.jpg",
          "test_233_3.jpg",
          "test_233_1.jpg",
          "test_233_4.jpg",
          "test_233_6.jpg",
          "test_233_8.jpg",
          "test_233_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_233_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_233_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5,
            7
          ],
          "winner_filenames": [
            "test_233_5.jpg",
            "test_233_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.15087890625,
            0.2108154296875,
            0.2279052734375,
            0.1802978515625,
            0.183349609375,
            0.1287841796875,
            0.2000732421875,
            0.2178955078125,
            0.26171875
          ],
          "order_indices": [
            8,
            2,
            7,
            1,
            6,
            4,
            3,
            0,
            5
          ],
          "order_filenames": [
            "test_233_8.jpg",
            "test_233_2.jpg",
            "test_233_7.jpg",
            "test_233_1.jpg",
            "test_233_6.jpg",
            "test_233_4.jpg",
            "test_233_3.jpg",
            "test_233_0.jpg",
            "test_233_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.01666666666666672,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.9375,
            38.40625,
            43.6875,
            43.375,
            31.609375,
            19.609375,
            38.34375,
            45.53125,
            31.078125
          ],
          "order_indices": [
            7,
            2,
            3,
            1,
            6,
            0,
            4,
            8,
            5
          ],
          "order_filenames": [
            "test_233_7.jpg",
            "test_233_2.jpg",
            "test_233_3.jpg",
            "test_233_1.jpg",
            "test_233_6.jpg",
            "test_233_0.jpg",
            "test_233_4.jpg",
            "test_233_8.jpg",
            "test_233_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.4444444444444444,
            "spearman_rho": 0.44999999999999996,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.7583574056625366,
            -0.26824820041656494,
            0.3196963667869568,
            0.10532337427139282,
            0.26901087164878845,
            -2.065295457839966,
            0.38088011741638184,
            -0.06936899572610855,
            1.4507017135620117
          ],
          "order_indices": [
            8,
            6,
            2,
            4,
            3,
            7,
            1,
            0,
            5
          ],
          "order_filenames": [
            "test_233_8.jpg",
            "test_233_6.jpg",
            "test_233_2.jpg",
            "test_233_4.jpg",
            "test_233_3.jpg",
            "test_233_7.jpg",
            "test_233_1.jpg",
            "test_233_0.jpg",
            "test_233_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.31666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 234,
      "prompt": "A portrait painting of a male deer in a suit sitting on a sofa near a window by John Singer Sargent.",
      "image_filenames": [
        "test_234_0.jpg",
        "test_234_1.jpg",
        "test_234_2.jpg",
        "test_234_3.jpg",
        "test_234_4.jpg",
        "test_234_5.jpg",
        "test_234_6.jpg",
        "test_234_7.jpg",
        "test_234_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          4,
          8,
          2,
          6,
          7,
          3,
          5,
          0
        ],
        "order_filenames": [
          "test_234_1.jpg",
          "test_234_4.jpg",
          "test_234_8.jpg",
          "test_234_2.jpg",
          "test_234_6.jpg",
          "test_234_7.jpg",
          "test_234_3.jpg",
          "test_234_5.jpg",
          "test_234_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_234_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7,
            8
          ],
          "winner_filenames": [
            "test_234_7.jpg",
            "test_234_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_234_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.138427734375,
            0.2025146484375,
            0.2294921875,
            0.1507568359375,
            0.146484375,
            0.154541015625,
            0.2049560546875,
            0.1993408203125,
            0.25244140625
          ],
          "order_indices": [
            8,
            2,
            6,
            1,
            7,
            5,
            3,
            4,
            0
          ],
          "order_filenames": [
            "test_234_8.jpg",
            "test_234_2.jpg",
            "test_234_6.jpg",
            "test_234_1.jpg",
            "test_234_7.jpg",
            "test_234_5.jpg",
            "test_234_3.jpg",
            "test_234_4.jpg",
            "test_234_0.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.4444444444444444,
            "spearman_rho": 0.4833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.65625,
            41.0625,
            35.09375,
            33.25,
            30.71875,
            28.8125,
            35.9375,
            44.46875,
            47.9375
          ],
          "order_indices": [
            8,
            7,
            1,
            0,
            6,
            2,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_234_8.jpg",
            "test_234_7.jpg",
            "test_234_1.jpg",
            "test_234_0.jpg",
            "test_234_6.jpg",
            "test_234_2.jpg",
            "test_234_3.jpg",
            "test_234_4.jpg",
            "test_234_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.25,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -2.2151660919189453,
            -1.693327784538269,
            -1.1987735033035278,
            -1.366796851158142,
            -0.02789437584578991,
            -1.1139086484909058,
            -1.3403284549713135,
            -0.6450636386871338,
            1.393429160118103
          ],
          "order_indices": [
            8,
            4,
            7,
            5,
            2,
            6,
            3,
            1,
            0
          ],
          "order_filenames": [
            "test_234_8.jpg",
            "test_234_4.jpg",
            "test_234_7.jpg",
            "test_234_5.jpg",
            "test_234_2.jpg",
            "test_234_6.jpg",
            "test_234_3.jpg",
            "test_234_1.jpg",
            "test_234_0.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2777777777777778,
            "spearman_rho": 0.33333333333333337,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 235,
      "prompt": "The image is an ink and wash painting featuring vibrant colors, calligraphy, woodblock and geometric 3D shapes.",
      "image_filenames": [
        "test_235_0.jpg",
        "test_235_1.jpg",
        "test_235_2.jpg",
        "test_235_3.jpg",
        "test_235_4.jpg",
        "test_235_5.jpg",
        "test_235_6.jpg",
        "test_235_7.jpg",
        "test_235_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          6,
          3,
          5,
          0,
          8,
          4,
          2,
          1
        ],
        "order_filenames": [
          "test_235_7.jpg",
          "test_235_6.jpg",
          "test_235_3.jpg",
          "test_235_5.jpg",
          "test_235_0.jpg",
          "test_235_8.jpg",
          "test_235_4.jpg",
          "test_235_2.jpg",
          "test_235_1.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_235_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_235_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3,
            6,
            7
          ],
          "winner_filenames": [
            "test_235_3.jpg",
            "test_235_6.jpg",
            "test_235_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1943359375,
            0.19482421875,
            0.1624755859375,
            0.19189453125,
            0.182373046875,
            0.1353759765625,
            0.17724609375,
            0.2291259765625,
            0.18115234375
          ],
          "order_indices": [
            7,
            1,
            0,
            3,
            4,
            8,
            6,
            2,
            5
          ],
          "order_filenames": [
            "test_235_7.jpg",
            "test_235_1.jpg",
            "test_235_0.jpg",
            "test_235_3.jpg",
            "test_235_4.jpg",
            "test_235_8.jpg",
            "test_235_6.jpg",
            "test_235_2.jpg",
            "test_235_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.09999999999999998,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.9375,
            28.546875,
            31.609375,
            26.796875,
            29.03125,
            27.171875,
            31.328125,
            38.03125,
            35.53125
          ],
          "order_indices": [
            7,
            0,
            8,
            2,
            6,
            4,
            1,
            5,
            3
          ],
          "order_filenames": [
            "test_235_7.jpg",
            "test_235_0.jpg",
            "test_235_8.jpg",
            "test_235_2.jpg",
            "test_235_6.jpg",
            "test_235_4.jpg",
            "test_235_1.jpg",
            "test_235_5.jpg",
            "test_235_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.16666666666666663,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.3824973404407501,
            -0.9944786429405212,
            -1.3815079927444458,
            -1.0196644067764282,
            -1.6038782596588135,
            -1.64470636844635,
            -1.081230878829956,
            0.19007200002670288,
            -1.1327190399169922
          ],
          "order_indices": [
            7,
            0,
            1,
            3,
            6,
            8,
            2,
            4,
            5
          ],
          "order_filenames": [
            "test_235_7.jpg",
            "test_235_0.jpg",
            "test_235_1.jpg",
            "test_235_3.jpg",
            "test_235_6.jpg",
            "test_235_8.jpg",
            "test_235_2.jpg",
            "test_235_4.jpg",
            "test_235_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.31666666666666665,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 236,
      "prompt": "A detailed soft painting of a bat with golden rose flowers and amethyst stained glass in the background.",
      "image_filenames": [
        "test_236_0.jpg",
        "test_236_1.jpg",
        "test_236_2.jpg",
        "test_236_3.jpg",
        "test_236_4.jpg",
        "test_236_5.jpg",
        "test_236_6.jpg",
        "test_236_7.jpg",
        "test_236_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          5,
          4,
          7,
          0,
          1,
          8,
          2,
          3
        ],
        "order_filenames": [
          "test_236_6.jpg",
          "test_236_5.jpg",
          "test_236_4.jpg",
          "test_236_7.jpg",
          "test_236_0.jpg",
          "test_236_1.jpg",
          "test_236_8.jpg",
          "test_236_2.jpg",
          "test_236_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_236_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            2,
            5,
            6,
            7
          ],
          "winner_filenames": [
            "test_236_2.jpg",
            "test_236_5.jpg",
            "test_236_6.jpg",
            "test_236_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_236_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1802978515625,
            0.271484375,
            0.232421875,
            0.182373046875,
            0.181396484375,
            0.1527099609375,
            0.254638671875,
            0.250732421875,
            0.2470703125
          ],
          "order_indices": [
            1,
            6,
            7,
            8,
            2,
            3,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_236_1.jpg",
            "test_236_6.jpg",
            "test_236_7.jpg",
            "test_236_8.jpg",
            "test_236_2.jpg",
            "test_236_3.jpg",
            "test_236_4.jpg",
            "test_236_0.jpg",
            "test_236_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            44.34375,
            46.34375,
            41.25,
            33.71875,
            26.890625,
            38.78125,
            50.3125,
            48.03125,
            47.84375
          ],
          "order_indices": [
            6,
            7,
            8,
            1,
            0,
            2,
            5,
            3,
            4
          ],
          "order_filenames": [
            "test_236_6.jpg",
            "test_236_7.jpg",
            "test_236_8.jpg",
            "test_236_1.jpg",
            "test_236_0.jpg",
            "test_236_2.jpg",
            "test_236_5.jpg",
            "test_236_3.jpg",
            "test_236_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.25,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.5905942916870117,
            1.3439151048660278,
            0.8432531356811523,
            -2.0971460342407227,
            -1.7058452367782593,
            -2.0903820991516113,
            0.9309315085411072,
            0.8133648633956909,
            0.5616995096206665
          ],
          "order_indices": [
            1,
            6,
            2,
            7,
            8,
            0,
            4,
            5,
            3
          ],
          "order_filenames": [
            "test_236_1.jpg",
            "test_236_6.jpg",
            "test_236_2.jpg",
            "test_236_7.jpg",
            "test_236_8.jpg",
            "test_236_0.jpg",
            "test_236_4.jpg",
            "test_236_5.jpg",
            "test_236_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.09999999999999998,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 237,
      "prompt": "The image is a painting by Pierre-Auguste Renoir of an emo with short, messy brown hair, large entirely-black eyes, wearing a black tank top, leather jacket, knee-length skirt, choker, and boots.",
      "image_filenames": [
        "test_237_0.jpg",
        "test_237_1.jpg",
        "test_237_2.jpg",
        "test_237_3.jpg",
        "test_237_4.jpg",
        "test_237_5.jpg",
        "test_237_6.jpg",
        "test_237_7.jpg",
        "test_237_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          5,
          2,
          3,
          1,
          6,
          8,
          0,
          7
        ],
        "order_filenames": [
          "test_237_4.jpg",
          "test_237_5.jpg",
          "test_237_2.jpg",
          "test_237_3.jpg",
          "test_237_1.jpg",
          "test_237_6.jpg",
          "test_237_8.jpg",
          "test_237_0.jpg",
          "test_237_7.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_237_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_237_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_237_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1671142578125,
            0.2022705078125,
            0.2310791015625,
            0.1695556640625,
            0.1785888671875,
            0.07342529296875,
            0.21923828125,
            0.1842041015625,
            0.1822509765625
          ],
          "order_indices": [
            2,
            6,
            1,
            7,
            8,
            4,
            3,
            0,
            5
          ],
          "order_filenames": [
            "test_237_2.jpg",
            "test_237_6.jpg",
            "test_237_1.jpg",
            "test_237_7.jpg",
            "test_237_8.jpg",
            "test_237_4.jpg",
            "test_237_3.jpg",
            "test_237_0.jpg",
            "test_237_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.1333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.9375,
            37.90625,
            42.71875,
            30.609375,
            24.171875,
            11.0546875,
            36.25,
            41.21875,
            33.34375
          ],
          "order_indices": [
            2,
            7,
            1,
            0,
            6,
            8,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_237_2.jpg",
            "test_237_7.jpg",
            "test_237_1.jpg",
            "test_237_0.jpg",
            "test_237_6.jpg",
            "test_237_8.jpg",
            "test_237_3.jpg",
            "test_237_4.jpg",
            "test_237_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.5166666666666666,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.1414055824279785,
            -0.7317931056022644,
            0.4941246807575226,
            -1.0074712038040161,
            -0.631964385509491,
            -2.261477470397949,
            -0.0607498362660408,
            -1.0514776706695557,
            -1.174297571182251
          ],
          "order_indices": [
            2,
            6,
            4,
            1,
            3,
            7,
            0,
            8,
            5
          ],
          "order_filenames": [
            "test_237_2.jpg",
            "test_237_6.jpg",
            "test_237_4.jpg",
            "test_237_1.jpg",
            "test_237_3.jpg",
            "test_237_7.jpg",
            "test_237_0.jpg",
            "test_237_8.jpg",
            "test_237_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.2833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 238,
      "prompt": "Hyper realistic matte painting of the legendary ancient world of Shangrila.",
      "image_filenames": [
        "test_238_0.jpg",
        "test_238_1.jpg",
        "test_238_2.jpg",
        "test_238_3.jpg",
        "test_238_4.jpg",
        "test_238_5.jpg",
        "test_238_6.jpg",
        "test_238_7.jpg",
        "test_238_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          4,
          3,
          6,
          5,
          1,
          7,
          0,
          8
        ],
        "order_filenames": [
          "test_238_2.jpg",
          "test_238_4.jpg",
          "test_238_3.jpg",
          "test_238_6.jpg",
          "test_238_5.jpg",
          "test_238_1.jpg",
          "test_238_7.jpg",
          "test_238_0.jpg",
          "test_238_8.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_238_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_238_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_238_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2020263671875,
            0.2464599609375,
            0.33349609375,
            0.1907958984375,
            0.1900634765625,
            0.1796875,
            0.330078125,
            0.238037109375,
            0.259765625
          ],
          "order_indices": [
            2,
            6,
            8,
            1,
            7,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_238_2.jpg",
            "test_238_6.jpg",
            "test_238_8.jpg",
            "test_238_1.jpg",
            "test_238_7.jpg",
            "test_238_0.jpg",
            "test_238_3.jpg",
            "test_238_4.jpg",
            "test_238_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.0,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.90625,
            35.28125,
            33.46875,
            34.6875,
            29.9375,
            26.5,
            34.4375,
            34.9375,
            33.34375
          ],
          "order_indices": [
            0,
            1,
            7,
            3,
            6,
            2,
            8,
            4,
            5
          ],
          "order_filenames": [
            "test_238_0.jpg",
            "test_238_1.jpg",
            "test_238_7.jpg",
            "test_238_3.jpg",
            "test_238_6.jpg",
            "test_238_2.jpg",
            "test_238_8.jpg",
            "test_238_4.jpg",
            "test_238_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.3666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.8085029721260071,
            0.9628064632415771,
            1.1276942491531372,
            -0.48412951827049255,
            -0.5447391271591187,
            -0.2116537243127823,
            1.3463914394378662,
            0.7824722528457642,
            0.9413992166519165
          ],
          "order_indices": [
            6,
            2,
            1,
            8,
            0,
            7,
            5,
            3,
            4
          ],
          "order_filenames": [
            "test_238_6.jpg",
            "test_238_2.jpg",
            "test_238_1.jpg",
            "test_238_8.jpg",
            "test_238_0.jpg",
            "test_238_7.jpg",
            "test_238_5.jpg",
            "test_238_3.jpg",
            "test_238_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.10000000000000009,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 239,
      "prompt": "Lady Britannia portrayed in crosshatching in 18th century art by William Hogarth.",
      "image_filenames": [
        "test_239_0.jpg",
        "test_239_1.jpg",
        "test_239_2.jpg",
        "test_239_3.jpg",
        "test_239_4.jpg",
        "test_239_5.jpg",
        "test_239_6.jpg",
        "test_239_7.jpg",
        "test_239_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          2,
          0,
          5,
          7,
          6,
          3,
          8,
          1
        ],
        "order_filenames": [
          "test_239_4.jpg",
          "test_239_2.jpg",
          "test_239_0.jpg",
          "test_239_5.jpg",
          "test_239_7.jpg",
          "test_239_6.jpg",
          "test_239_3.jpg",
          "test_239_8.jpg",
          "test_239_1.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_239_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_239_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_239_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1361083984375,
            0.1708984375,
            0.230224609375,
            0.124755859375,
            0.1572265625,
            0.10302734375,
            0.2249755859375,
            0.1658935546875,
            0.1859130859375
          ],
          "order_indices": [
            2,
            6,
            8,
            1,
            7,
            4,
            0,
            3,
            5
          ],
          "order_filenames": [
            "test_239_2.jpg",
            "test_239_6.jpg",
            "test_239_8.jpg",
            "test_239_1.jpg",
            "test_239_7.jpg",
            "test_239_4.jpg",
            "test_239_0.jpg",
            "test_239_3.jpg",
            "test_239_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.1166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.53125,
            29.890625,
            36.75,
            35.3125,
            32.09375,
            9.265625,
            33.34375,
            45.90625,
            30.578125
          ],
          "order_indices": [
            7,
            2,
            0,
            3,
            6,
            4,
            8,
            1,
            5
          ],
          "order_filenames": [
            "test_239_7.jpg",
            "test_239_2.jpg",
            "test_239_0.jpg",
            "test_239_3.jpg",
            "test_239_6.jpg",
            "test_239_4.jpg",
            "test_239_8.jpg",
            "test_239_1.jpg",
            "test_239_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2777777777777778,
            "spearman_rho": 0.35,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.9039581418037415,
            -0.9726232886314392,
            -0.0854446291923523,
            -1.7623865604400635,
            -1.0677897930145264,
            -2.22638201713562,
            -0.13293297588825226,
            -0.555109977722168,
            -0.27271369099617004
          ],
          "order_indices": [
            2,
            6,
            8,
            7,
            0,
            1,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_239_2.jpg",
            "test_239_6.jpg",
            "test_239_8.jpg",
            "test_239_7.jpg",
            "test_239_0.jpg",
            "test_239_1.jpg",
            "test_239_4.jpg",
            "test_239_3.jpg",
            "test_239_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.01666666666666672,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 240,
      "prompt": "The image is an oil on canvas painting of a broken man.",
      "image_filenames": [
        "test_240_0.jpg",
        "test_240_1.jpg",
        "test_240_2.jpg",
        "test_240_3.jpg",
        "test_240_4.jpg",
        "test_240_5.jpg",
        "test_240_6.jpg",
        "test_240_7.jpg",
        "test_240_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          4,
          3,
          6,
          7,
          1,
          2,
          8,
          0
        ],
        "order_filenames": [
          "test_240_5.jpg",
          "test_240_4.jpg",
          "test_240_3.jpg",
          "test_240_6.jpg",
          "test_240_7.jpg",
          "test_240_1.jpg",
          "test_240_2.jpg",
          "test_240_8.jpg",
          "test_240_0.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_240_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_240_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_240_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1973876953125,
            0.1868896484375,
            0.219482421875,
            0.195556640625,
            0.2139892578125,
            0.1531982421875,
            0.254150390625,
            0.2451171875,
            0.26953125
          ],
          "order_indices": [
            8,
            6,
            7,
            2,
            4,
            0,
            3,
            1,
            5
          ],
          "order_filenames": [
            "test_240_8.jpg",
            "test_240_6.jpg",
            "test_240_7.jpg",
            "test_240_2.jpg",
            "test_240_4.jpg",
            "test_240_0.jpg",
            "test_240_3.jpg",
            "test_240_1.jpg",
            "test_240_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.3999999999999999,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.8125,
            34.625,
            38.90625,
            31.3125,
            29.46875,
            29.328125,
            34.0,
            37.71875,
            30.09375
          ],
          "order_indices": [
            2,
            7,
            0,
            1,
            6,
            3,
            8,
            4,
            5
          ],
          "order_filenames": [
            "test_240_2.jpg",
            "test_240_7.jpg",
            "test_240_0.jpg",
            "test_240_1.jpg",
            "test_240_6.jpg",
            "test_240_3.jpg",
            "test_240_8.jpg",
            "test_240_4.jpg",
            "test_240_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5555555555555556,
            "spearman_rho": -0.6333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.14417682588100433,
            -0.6871955394744873,
            -0.812060534954071,
            -1.4395991563796997,
            -0.10097870230674744,
            -1.8109203577041626,
            -0.7693647742271423,
            -0.817037045955658,
            -0.9919513463973999
          ],
          "order_indices": [
            0,
            4,
            1,
            6,
            2,
            7,
            8,
            3,
            5
          ],
          "order_filenames": [
            "test_240_0.jpg",
            "test_240_4.jpg",
            "test_240_1.jpg",
            "test_240_6.jpg",
            "test_240_2.jpg",
            "test_240_7.jpg",
            "test_240_8.jpg",
            "test_240_3.jpg",
            "test_240_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.3999999999999999,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 241,
      "prompt": "A watercolor portrait of a woman by Luke Rueda Studios and David Downton.",
      "image_filenames": [
        "test_241_0.jpg",
        "test_241_1.jpg",
        "test_241_2.jpg",
        "test_241_3.jpg",
        "test_241_4.jpg",
        "test_241_5.jpg",
        "test_241_6.jpg",
        "test_241_7.jpg",
        "test_241_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          6,
          2,
          7,
          1,
          3,
          5,
          8,
          0
        ],
        "order_filenames": [
          "test_241_4.jpg",
          "test_241_6.jpg",
          "test_241_2.jpg",
          "test_241_7.jpg",
          "test_241_1.jpg",
          "test_241_3.jpg",
          "test_241_5.jpg",
          "test_241_8.jpg",
          "test_241_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_241_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_241_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4,
            6
          ],
          "winner_filenames": [
            "test_241_4.jpg",
            "test_241_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1175537109375,
            0.15771484375,
            0.2177734375,
            0.172119140625,
            0.09210205078125,
            0.09515380859375,
            0.18359375,
            0.1488037109375,
            0.1982421875
          ],
          "order_indices": [
            2,
            8,
            6,
            3,
            1,
            7,
            0,
            5,
            4
          ],
          "order_filenames": [
            "test_241_2.jpg",
            "test_241_8.jpg",
            "test_241_6.jpg",
            "test_241_3.jpg",
            "test_241_1.jpg",
            "test_241_7.jpg",
            "test_241_0.jpg",
            "test_241_5.jpg",
            "test_241_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.01666666666666672,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            30.59375,
            36.125,
            37.1875,
            34.53125,
            23.234375,
            28.96875,
            36.46875,
            34.8125,
            37.375
          ],
          "order_indices": [
            8,
            2,
            6,
            1,
            7,
            3,
            0,
            5,
            4
          ],
          "order_filenames": [
            "test_241_8.jpg",
            "test_241_2.jpg",
            "test_241_6.jpg",
            "test_241_1.jpg",
            "test_241_7.jpg",
            "test_241_3.jpg",
            "test_241_0.jpg",
            "test_241_5.jpg",
            "test_241_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": -0.016666666666666607,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -2.111408233642578,
            -1.54893159866333,
            -0.04914706572890282,
            -0.21922394633293152,
            -2.1122500896453857,
            -2.0470900535583496,
            -0.3984983265399933,
            -1.3951406478881836,
            -0.25374922156333923
          ],
          "order_indices": [
            2,
            3,
            8,
            6,
            7,
            1,
            5,
            0,
            4
          ],
          "order_filenames": [
            "test_241_2.jpg",
            "test_241_3.jpg",
            "test_241_8.jpg",
            "test_241_6.jpg",
            "test_241_7.jpg",
            "test_241_1.jpg",
            "test_241_5.jpg",
            "test_241_0.jpg",
            "test_241_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.033333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 242,
      "prompt": "Cyrano de Bergerac holds Roxanne's hand in an illustrated scene by Cs\u00f3k Istv\u00e1n.",
      "image_filenames": [
        "test_242_0.jpg",
        "test_242_1.jpg",
        "test_242_2.jpg",
        "test_242_3.jpg",
        "test_242_4.jpg",
        "test_242_5.jpg",
        "test_242_6.jpg",
        "test_242_7.jpg",
        "test_242_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          3,
          5,
          2,
          1,
          7,
          8,
          0,
          6
        ],
        "order_filenames": [
          "test_242_4.jpg",
          "test_242_3.jpg",
          "test_242_5.jpg",
          "test_242_2.jpg",
          "test_242_1.jpg",
          "test_242_7.jpg",
          "test_242_8.jpg",
          "test_242_0.jpg",
          "test_242_6.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_242_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_242_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_242_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2052001953125,
            0.1968994140625,
            0.2578125,
            0.157958984375,
            0.1505126953125,
            0.1085205078125,
            0.2041015625,
            0.191650390625,
            0.2276611328125
          ],
          "order_indices": [
            2,
            8,
            0,
            6,
            1,
            7,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_242_2.jpg",
            "test_242_8.jpg",
            "test_242_0.jpg",
            "test_242_6.jpg",
            "test_242_1.jpg",
            "test_242_7.jpg",
            "test_242_3.jpg",
            "test_242_4.jpg",
            "test_242_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.6166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.0,
            41.65625,
            41.78125,
            27.84375,
            20.4375,
            17.609375,
            34.25,
            39.71875,
            46.125
          ],
          "order_indices": [
            8,
            2,
            1,
            0,
            7,
            6,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_242_8.jpg",
            "test_242_2.jpg",
            "test_242_1.jpg",
            "test_242_0.jpg",
            "test_242_7.jpg",
            "test_242_6.jpg",
            "test_242_3.jpg",
            "test_242_4.jpg",
            "test_242_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.5,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.2288987636566162,
            0.04828131943941116,
            0.9160504937171936,
            -0.6429682970046997,
            -0.4378681778907776,
            -2.0814461708068848,
            0.7379804253578186,
            0.32385918498039246,
            0.8693480491638184
          ],
          "order_indices": [
            0,
            2,
            8,
            6,
            7,
            1,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_242_0.jpg",
            "test_242_2.jpg",
            "test_242_8.jpg",
            "test_242_6.jpg",
            "test_242_7.jpg",
            "test_242_1.jpg",
            "test_242_4.jpg",
            "test_242_3.jpg",
            "test_242_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.7,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 243,
      "prompt": "Geometric, colorful creature painted with rough brushstrokes on an abstract background by Pavel Lizano (2018).",
      "image_filenames": [
        "test_243_0.jpg",
        "test_243_1.jpg",
        "test_243_2.jpg",
        "test_243_3.jpg",
        "test_243_4.jpg",
        "test_243_5.jpg",
        "test_243_6.jpg",
        "test_243_7.jpg",
        "test_243_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          6,
          4,
          2,
          5,
          7,
          3,
          8,
          0
        ],
        "order_filenames": [
          "test_243_1.jpg",
          "test_243_6.jpg",
          "test_243_4.jpg",
          "test_243_2.jpg",
          "test_243_5.jpg",
          "test_243_7.jpg",
          "test_243_3.jpg",
          "test_243_8.jpg",
          "test_243_0.jpg"
        ],
        "condorcet_winner": 1,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_243_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_243_1.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_243_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1959228515625,
            0.2481689453125,
            0.2437744140625,
            0.1968994140625,
            0.1689453125,
            0.185546875,
            0.1942138671875,
            0.2841796875,
            0.2041015625
          ],
          "order_indices": [
            7,
            1,
            2,
            8,
            3,
            0,
            6,
            5,
            4
          ],
          "order_filenames": [
            "test_243_7.jpg",
            "test_243_1.jpg",
            "test_243_2.jpg",
            "test_243_8.jpg",
            "test_243_3.jpg",
            "test_243_0.jpg",
            "test_243_6.jpg",
            "test_243_5.jpg",
            "test_243_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.050000000000000044,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.5625,
            34.34375,
            34.6875,
            26.375,
            24.3125,
            25.765625,
            30.8125,
            33.78125,
            25.96875
          ],
          "order_indices": [
            0,
            2,
            1,
            7,
            6,
            3,
            8,
            5,
            4
          ],
          "order_filenames": [
            "test_243_0.jpg",
            "test_243_2.jpg",
            "test_243_1.jpg",
            "test_243_7.jpg",
            "test_243_6.jpg",
            "test_243_3.jpg",
            "test_243_8.jpg",
            "test_243_5.jpg",
            "test_243_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.10000000000000009,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.03397750109434128,
            -1.1841522455215454,
            -1.3961806297302246,
            -1.9092602729797363,
            -1.0625725984573364,
            -1.2031939029693604,
            -1.7820359468460083,
            0.21924923360347748,
            -0.8031154274940491
          ],
          "order_indices": [
            7,
            0,
            8,
            4,
            1,
            5,
            2,
            6,
            3
          ],
          "order_filenames": [
            "test_243_7.jpg",
            "test_243_0.jpg",
            "test_243_8.jpg",
            "test_243_4.jpg",
            "test_243_1.jpg",
            "test_243_5.jpg",
            "test_243_2.jpg",
            "test_243_6.jpg",
            "test_243_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.3833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 244,
      "prompt": "Oil portrait of Gearless Joe by Greg Rutowski and Alphonse Mucha.",
      "image_filenames": [
        "test_244_0.jpg",
        "test_244_1.jpg",
        "test_244_2.jpg",
        "test_244_3.jpg",
        "test_244_4.jpg",
        "test_244_5.jpg",
        "test_244_6.jpg",
        "test_244_7.jpg",
        "test_244_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          2,
          1,
          5,
          4,
          3,
          7,
          0,
          8
        ],
        "order_filenames": [
          "test_244_6.jpg",
          "test_244_2.jpg",
          "test_244_1.jpg",
          "test_244_5.jpg",
          "test_244_4.jpg",
          "test_244_3.jpg",
          "test_244_7.jpg",
          "test_244_0.jpg",
          "test_244_8.jpg"
        ],
        "condorcet_winner": 6,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_244_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_244_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_244_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.15673828125,
            0.2027587890625,
            0.2132568359375,
            0.1546630859375,
            0.154296875,
            0.09637451171875,
            0.1829833984375,
            0.194580078125,
            0.22021484375
          ],
          "order_indices": [
            8,
            2,
            1,
            7,
            6,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_244_8.jpg",
            "test_244_2.jpg",
            "test_244_1.jpg",
            "test_244_7.jpg",
            "test_244_6.jpg",
            "test_244_0.jpg",
            "test_244_3.jpg",
            "test_244_4.jpg",
            "test_244_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.25,
            34.5,
            38.0625,
            19.359375,
            30.546875,
            23.125,
            23.375,
            40.4375,
            27.84375
          ],
          "order_indices": [
            7,
            2,
            0,
            1,
            4,
            8,
            6,
            5,
            3
          ],
          "order_filenames": [
            "test_244_7.jpg",
            "test_244_2.jpg",
            "test_244_0.jpg",
            "test_244_1.jpg",
            "test_244_4.jpg",
            "test_244_8.jpg",
            "test_244_6.jpg",
            "test_244_5.jpg",
            "test_244_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.10000000000000009,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.04953530430793762,
            0.8015558123588562,
            1.3323707580566406,
            -0.7722049355506897,
            0.18496748805046082,
            -2.149021625518799,
            -0.4036446809768677,
            0.06765790283679962,
            0.28983360528945923
          ],
          "order_indices": [
            2,
            1,
            8,
            4,
            7,
            0,
            6,
            3,
            5
          ],
          "order_filenames": [
            "test_244_2.jpg",
            "test_244_1.jpg",
            "test_244_8.jpg",
            "test_244_4.jpg",
            "test_244_7.jpg",
            "test_244_0.jpg",
            "test_244_6.jpg",
            "test_244_3.jpg",
            "test_244_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 245,
      "prompt": "A portrait painting of Leighann Vail.",
      "image_filenames": [
        "test_245_0.jpg",
        "test_245_1.jpg",
        "test_245_2.jpg",
        "test_245_3.jpg",
        "test_245_4.jpg",
        "test_245_5.jpg",
        "test_245_6.jpg",
        "test_245_7.jpg",
        "test_245_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          5,
          2,
          3,
          1,
          6,
          8,
          7,
          0
        ],
        "order_filenames": [
          "test_245_4.jpg",
          "test_245_5.jpg",
          "test_245_2.jpg",
          "test_245_3.jpg",
          "test_245_1.jpg",
          "test_245_6.jpg",
          "test_245_8.jpg",
          "test_245_7.jpg",
          "test_245_0.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_245_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_245_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_245_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1964111328125,
            0.1878662109375,
            0.235107421875,
            0.155517578125,
            0.12939453125,
            0.1307373046875,
            0.208251953125,
            0.1715087890625,
            0.235595703125
          ],
          "order_indices": [
            8,
            2,
            6,
            0,
            1,
            7,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_245_8.jpg",
            "test_245_2.jpg",
            "test_245_6.jpg",
            "test_245_0.jpg",
            "test_245_1.jpg",
            "test_245_7.jpg",
            "test_245_3.jpg",
            "test_245_5.jpg",
            "test_245_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.5333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.3125,
            34.96875,
            36.09375,
            31.40625,
            23.234375,
            19.078125,
            34.375,
            30.984375,
            30.796875
          ],
          "order_indices": [
            2,
            1,
            6,
            0,
            3,
            7,
            8,
            4,
            5
          ],
          "order_filenames": [
            "test_245_2.jpg",
            "test_245_1.jpg",
            "test_245_6.jpg",
            "test_245_0.jpg",
            "test_245_3.jpg",
            "test_245_7.jpg",
            "test_245_8.jpg",
            "test_245_4.jpg",
            "test_245_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.25,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.5316471457481384,
            1.3354129791259766,
            1.3510758876800537,
            -0.010090251453220844,
            -0.8358383774757385,
            -1.3576924800872803,
            0.8143723011016846,
            -1.8727161884307861,
            0.36471620202064514
          ],
          "order_indices": [
            2,
            1,
            6,
            0,
            8,
            3,
            4,
            5,
            7
          ],
          "order_filenames": [
            "test_245_2.jpg",
            "test_245_1.jpg",
            "test_245_6.jpg",
            "test_245_0.jpg",
            "test_245_8.jpg",
            "test_245_3.jpg",
            "test_245_4.jpg",
            "test_245_5.jpg",
            "test_245_7.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 246,
      "prompt": "Oil portrait of a skeleton in a Victorian suit.",
      "image_filenames": [
        "test_246_0.jpg",
        "test_246_1.jpg",
        "test_246_2.jpg",
        "test_246_3.jpg",
        "test_246_4.jpg",
        "test_246_5.jpg",
        "test_246_6.jpg",
        "test_246_7.jpg",
        "test_246_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          7,
          5,
          8,
          6,
          1,
          2,
          4,
          3
        ],
        "order_filenames": [
          "test_246_0.jpg",
          "test_246_7.jpg",
          "test_246_5.jpg",
          "test_246_8.jpg",
          "test_246_6.jpg",
          "test_246_1.jpg",
          "test_246_2.jpg",
          "test_246_4.jpg",
          "test_246_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_246_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5,
            7
          ],
          "winner_filenames": [
            "test_246_5.jpg",
            "test_246_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0,
            7
          ],
          "winner_filenames": [
            "test_246_0.jpg",
            "test_246_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.160400390625,
            0.2264404296875,
            0.2568359375,
            0.13232421875,
            0.1553955078125,
            0.11968994140625,
            0.23095703125,
            0.218994140625,
            0.236083984375
          ],
          "order_indices": [
            2,
            8,
            6,
            1,
            7,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_246_2.jpg",
            "test_246_8.jpg",
            "test_246_6.jpg",
            "test_246_1.jpg",
            "test_246_7.jpg",
            "test_246_0.jpg",
            "test_246_4.jpg",
            "test_246_3.jpg",
            "test_246_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.0,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.25,
            41.53125,
            39.40625,
            18.28125,
            24.328125,
            26.65625,
            37.3125,
            44.25,
            37.59375
          ],
          "order_indices": [
            7,
            1,
            0,
            2,
            8,
            6,
            5,
            4,
            3
          ],
          "order_filenames": [
            "test_246_7.jpg",
            "test_246_1.jpg",
            "test_246_0.jpg",
            "test_246_2.jpg",
            "test_246_8.jpg",
            "test_246_6.jpg",
            "test_246_5.jpg",
            "test_246_4.jpg",
            "test_246_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.4444444444444444,
            "spearman_rho": 0.6,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.4485357701778412,
            0.0883185938000679,
            1.5929261445999146,
            -2.2191691398620605,
            -0.49117621779441833,
            -2.110710382461548,
            -0.41781729459762573,
            1.0526986122131348,
            1.017971396446228
          ],
          "order_indices": [
            2,
            7,
            8,
            1,
            6,
            0,
            4,
            5,
            3
          ],
          "order_filenames": [
            "test_246_2.jpg",
            "test_246_7.jpg",
            "test_246_8.jpg",
            "test_246_1.jpg",
            "test_246_6.jpg",
            "test_246_0.jpg",
            "test_246_4.jpg",
            "test_246_5.jpg",
            "test_246_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.23333333333333328,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 247,
      "prompt": "A colorful, detailed painting of a raccoon with a long, flowing mane reminiscent of a lion's, styled in a mohawk.",
      "image_filenames": [
        "test_247_0.jpg",
        "test_247_1.jpg",
        "test_247_2.jpg",
        "test_247_3.jpg",
        "test_247_4.jpg",
        "test_247_5.jpg",
        "test_247_6.jpg",
        "test_247_7.jpg",
        "test_247_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          2,
          7,
          1,
          3,
          5,
          8,
          0,
          6
        ],
        "order_filenames": [
          "test_247_4.jpg",
          "test_247_2.jpg",
          "test_247_7.jpg",
          "test_247_1.jpg",
          "test_247_3.jpg",
          "test_247_5.jpg",
          "test_247_8.jpg",
          "test_247_0.jpg",
          "test_247_6.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_247_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_247_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_247_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1627197265625,
            0.310302734375,
            0.27734375,
            0.2115478515625,
            0.160400390625,
            0.164306640625,
            0.26025390625,
            0.179443359375,
            0.28857421875
          ],
          "order_indices": [
            1,
            8,
            2,
            6,
            3,
            7,
            5,
            0,
            4
          ],
          "order_filenames": [
            "test_247_1.jpg",
            "test_247_8.jpg",
            "test_247_2.jpg",
            "test_247_6.jpg",
            "test_247_3.jpg",
            "test_247_7.jpg",
            "test_247_5.jpg",
            "test_247_0.jpg",
            "test_247_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.1166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            31.359375,
            37.75,
            32.84375,
            33.90625,
            26.78125,
            29.125,
            32.4375,
            36.78125,
            43.625
          ],
          "order_indices": [
            8,
            1,
            7,
            3,
            2,
            6,
            0,
            5,
            4
          ],
          "order_filenames": [
            "test_247_8.jpg",
            "test_247_1.jpg",
            "test_247_7.jpg",
            "test_247_3.jpg",
            "test_247_2.jpg",
            "test_247_6.jpg",
            "test_247_0.jpg",
            "test_247_5.jpg",
            "test_247_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.3761042654514313,
            1.4243180751800537,
            0.6117410063743591,
            0.47260063886642456,
            -1.2599365711212158,
            -1.4174143075942993,
            -0.30582016706466675,
            -0.20318393409252167,
            1.0579537153244019
          ],
          "order_indices": [
            1,
            8,
            2,
            3,
            7,
            6,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_247_1.jpg",
            "test_247_8.jpg",
            "test_247_2.jpg",
            "test_247_3.jpg",
            "test_247_7.jpg",
            "test_247_6.jpg",
            "test_247_0.jpg",
            "test_247_4.jpg",
            "test_247_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.09999999999999998,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 248,
      "prompt": "Two cats, one grey and one black, are wearing steampunk attire and standing in front of a ship in a heavily detailed painting.",
      "image_filenames": [
        "test_248_0.jpg",
        "test_248_1.jpg",
        "test_248_2.jpg",
        "test_248_3.jpg",
        "test_248_4.jpg",
        "test_248_5.jpg",
        "test_248_6.jpg",
        "test_248_7.jpg",
        "test_248_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          2,
          3,
          4,
          5,
          8,
          7,
          0,
          1
        ],
        "order_filenames": [
          "test_248_6.jpg",
          "test_248_2.jpg",
          "test_248_3.jpg",
          "test_248_4.jpg",
          "test_248_5.jpg",
          "test_248_8.jpg",
          "test_248_7.jpg",
          "test_248_0.jpg",
          "test_248_1.jpg"
        ],
        "condorcet_winner": 6,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_248_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_248_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_248_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.23095703125,
            0.259033203125,
            0.36669921875,
            0.2020263671875,
            0.1954345703125,
            0.2247314453125,
            0.321533203125,
            0.270263671875,
            0.32958984375
          ],
          "order_indices": [
            2,
            8,
            6,
            7,
            1,
            0,
            5,
            3,
            4
          ],
          "order_filenames": [
            "test_248_2.jpg",
            "test_248_8.jpg",
            "test_248_6.jpg",
            "test_248_7.jpg",
            "test_248_1.jpg",
            "test_248_0.jpg",
            "test_248_5.jpg",
            "test_248_3.jpg",
            "test_248_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.1333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            42.75,
            44.15625,
            49.90625,
            37.625,
            31.65625,
            25.265625,
            47.09375,
            49.875,
            46.875
          ],
          "order_indices": [
            2,
            7,
            6,
            8,
            1,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_248_2.jpg",
            "test_248_7.jpg",
            "test_248_6.jpg",
            "test_248_8.jpg",
            "test_248_1.jpg",
            "test_248_0.jpg",
            "test_248_3.jpg",
            "test_248_4.jpg",
            "test_248_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.15000000000000002,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.5850951075553894,
            1.579562783241272,
            1.119105339050293,
            -0.5927750468254089,
            -1.5882844924926758,
            -1.4192869663238525,
            1.494882345199585,
            1.634393572807312,
            0.1246277242898941
          ],
          "order_indices": [
            7,
            1,
            6,
            2,
            8,
            0,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_248_7.jpg",
            "test_248_1.jpg",
            "test_248_6.jpg",
            "test_248_2.jpg",
            "test_248_8.jpg",
            "test_248_0.jpg",
            "test_248_3.jpg",
            "test_248_5.jpg",
            "test_248_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.2333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 249,
      "prompt": "Mythical beasts around a fire in a dark, surreal painting by Ronny Khalil.",
      "image_filenames": [
        "test_249_0.jpg",
        "test_249_1.jpg",
        "test_249_2.jpg",
        "test_249_3.jpg",
        "test_249_4.jpg",
        "test_249_5.jpg",
        "test_249_6.jpg",
        "test_249_7.jpg",
        "test_249_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          6,
          5,
          1,
          7,
          4,
          8,
          2,
          3
        ],
        "order_filenames": [
          "test_249_0.jpg",
          "test_249_6.jpg",
          "test_249_5.jpg",
          "test_249_1.jpg",
          "test_249_7.jpg",
          "test_249_4.jpg",
          "test_249_8.jpg",
          "test_249_2.jpg",
          "test_249_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_249_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_249_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1,
            6
          ],
          "winner_filenames": [
            "test_249_1.jpg",
            "test_249_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.187255859375,
            0.2481689453125,
            0.2958984375,
            0.216552734375,
            0.19140625,
            0.1446533203125,
            0.248779296875,
            0.25390625,
            0.2371826171875
          ],
          "order_indices": [
            2,
            7,
            6,
            1,
            8,
            3,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_249_2.jpg",
            "test_249_7.jpg",
            "test_249_6.jpg",
            "test_249_1.jpg",
            "test_249_8.jpg",
            "test_249_3.jpg",
            "test_249_4.jpg",
            "test_249_0.jpg",
            "test_249_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.31666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            44.1875,
            38.875,
            40.3125,
            30.9375,
            26.34375,
            22.71875,
            34.375,
            44.53125,
            37.5
          ],
          "order_indices": [
            7,
            0,
            2,
            1,
            8,
            6,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_249_7.jpg",
            "test_249_0.jpg",
            "test_249_2.jpg",
            "test_249_1.jpg",
            "test_249_8.jpg",
            "test_249_6.jpg",
            "test_249_3.jpg",
            "test_249_4.jpg",
            "test_249_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.1166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.3125137090682983,
            1.512265920639038,
            1.5951776504516602,
            0.6111235618591309,
            -0.6684888005256653,
            -1.240791916847229,
            1.4741827249526978,
            1.6575678586959839,
            1.8835721015930176
          ],
          "order_indices": [
            8,
            7,
            2,
            1,
            6,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_249_8.jpg",
            "test_249_7.jpg",
            "test_249_2.jpg",
            "test_249_1.jpg",
            "test_249_6.jpg",
            "test_249_0.jpg",
            "test_249_3.jpg",
            "test_249_4.jpg",
            "test_249_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.2333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 250,
      "prompt": "Renaissance angel depicted in Gerhard Richter's oil painting.",
      "image_filenames": [
        "test_250_0.jpg",
        "test_250_1.jpg",
        "test_250_2.jpg",
        "test_250_3.jpg",
        "test_250_4.jpg",
        "test_250_5.jpg",
        "test_250_6.jpg",
        "test_250_7.jpg",
        "test_250_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          2,
          4,
          6,
          5,
          3,
          7,
          8,
          0
        ],
        "order_filenames": [
          "test_250_1.jpg",
          "test_250_2.jpg",
          "test_250_4.jpg",
          "test_250_6.jpg",
          "test_250_5.jpg",
          "test_250_3.jpg",
          "test_250_7.jpg",
          "test_250_8.jpg",
          "test_250_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_250_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_250_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1,
            6
          ],
          "winner_filenames": [
            "test_250_1.jpg",
            "test_250_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.15869140625,
            0.217529296875,
            0.224609375,
            0.158203125,
            0.1451416015625,
            0.10113525390625,
            0.21728515625,
            0.2215576171875,
            0.250732421875
          ],
          "order_indices": [
            8,
            2,
            7,
            1,
            6,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_250_8.jpg",
            "test_250_2.jpg",
            "test_250_7.jpg",
            "test_250_1.jpg",
            "test_250_6.jpg",
            "test_250_0.jpg",
            "test_250_3.jpg",
            "test_250_4.jpg",
            "test_250_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.050000000000000044,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            43.28125,
            37.5625,
            39.09375,
            30.859375,
            29.234375,
            21.453125,
            33.84375,
            48.03125,
            33.3125
          ],
          "order_indices": [
            7,
            0,
            2,
            1,
            6,
            8,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_250_7.jpg",
            "test_250_0.jpg",
            "test_250_2.jpg",
            "test_250_1.jpg",
            "test_250_6.jpg",
            "test_250_8.jpg",
            "test_250_3.jpg",
            "test_250_4.jpg",
            "test_250_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.7654203176498413,
            -0.6297122836112976,
            1.1802258491516113,
            -1.248145341873169,
            0.01712418720126152,
            -2.2823307514190674,
            0.13089430332183838,
            1.607528805732727,
            0.08044099062681198
          ],
          "order_indices": [
            7,
            2,
            0,
            6,
            8,
            4,
            1,
            3,
            5
          ],
          "order_filenames": [
            "test_250_7.jpg",
            "test_250_2.jpg",
            "test_250_0.jpg",
            "test_250_6.jpg",
            "test_250_8.jpg",
            "test_250_4.jpg",
            "test_250_1.jpg",
            "test_250_3.jpg",
            "test_250_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.21666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 251,
      "prompt": "Interior of a cathedral with a koi pond and surrounding greenery.",
      "image_filenames": [
        "test_251_0.jpg",
        "test_251_1.jpg",
        "test_251_2.jpg",
        "test_251_3.jpg",
        "test_251_4.jpg",
        "test_251_5.jpg",
        "test_251_6.jpg",
        "test_251_7.jpg",
        "test_251_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          1,
          7,
          2,
          8,
          6,
          3,
          4,
          5
        ],
        "order_filenames": [
          "test_251_0.jpg",
          "test_251_1.jpg",
          "test_251_7.jpg",
          "test_251_2.jpg",
          "test_251_8.jpg",
          "test_251_6.jpg",
          "test_251_3.jpg",
          "test_251_4.jpg",
          "test_251_5.jpg"
        ],
        "condorcet_winner": 0,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_251_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_251_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_251_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2362060546875,
            0.333251953125,
            0.318115234375,
            0.2176513671875,
            0.25634765625,
            0.1728515625,
            0.30419921875,
            0.25537109375,
            0.2353515625
          ],
          "order_indices": [
            1,
            2,
            6,
            4,
            7,
            0,
            8,
            3,
            5
          ],
          "order_filenames": [
            "test_251_1.jpg",
            "test_251_2.jpg",
            "test_251_6.jpg",
            "test_251_4.jpg",
            "test_251_7.jpg",
            "test_251_0.jpg",
            "test_251_8.jpg",
            "test_251_3.jpg",
            "test_251_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3888888888888889,
            "spearman_rho": 0.4666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.84375,
            44.1875,
            44.71875,
            35.9375,
            32.25,
            34.25,
            47.71875,
            32.6875,
            37.5625
          ],
          "order_indices": [
            6,
            2,
            1,
            0,
            8,
            3,
            5,
            7,
            4
          ],
          "order_filenames": [
            "test_251_6.jpg",
            "test_251_2.jpg",
            "test_251_1.jpg",
            "test_251_0.jpg",
            "test_251_8.jpg",
            "test_251_3.jpg",
            "test_251_5.jpg",
            "test_251_7.jpg",
            "test_251_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2777777777777778,
            "spearman_rho": 0.41666666666666663,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.5308328866958618,
            1.632319688796997,
            1.596120834350586,
            -0.5457020401954651,
            -0.7032963037490845,
            -0.5714560747146606,
            1.4401487112045288,
            -0.04822913929820061,
            -1.252132773399353
          ],
          "order_indices": [
            1,
            2,
            6,
            0,
            7,
            3,
            5,
            4,
            8
          ],
          "order_filenames": [
            "test_251_1.jpg",
            "test_251_2.jpg",
            "test_251_6.jpg",
            "test_251_0.jpg",
            "test_251_7.jpg",
            "test_251_3.jpg",
            "test_251_5.jpg",
            "test_251_4.jpg",
            "test_251_8.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.4444444444444444,
            "spearman_rho": 0.6,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 252,
      "prompt": "A silkscreen print of a woman with a short dark brown pixie cut, evil entirely-black eyes, wearing all black clothing.",
      "image_filenames": [
        "test_252_0.jpg",
        "test_252_1.jpg",
        "test_252_2.jpg",
        "test_252_3.jpg",
        "test_252_4.jpg",
        "test_252_5.jpg",
        "test_252_6.jpg",
        "test_252_7.jpg",
        "test_252_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          5,
          4,
          6,
          2,
          7,
          3,
          8,
          0
        ],
        "order_filenames": [
          "test_252_1.jpg",
          "test_252_5.jpg",
          "test_252_4.jpg",
          "test_252_6.jpg",
          "test_252_2.jpg",
          "test_252_7.jpg",
          "test_252_3.jpg",
          "test_252_8.jpg",
          "test_252_0.jpg"
        ],
        "condorcet_winner": 1,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_252_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_252_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_252_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.171142578125,
            0.2215576171875,
            0.1986083984375,
            0.1790771484375,
            0.166259765625,
            0.07757568359375,
            0.1561279296875,
            0.1942138671875,
            0.238037109375
          ],
          "order_indices": [
            8,
            1,
            2,
            7,
            3,
            0,
            4,
            6,
            5
          ],
          "order_filenames": [
            "test_252_8.jpg",
            "test_252_1.jpg",
            "test_252_2.jpg",
            "test_252_7.jpg",
            "test_252_3.jpg",
            "test_252_0.jpg",
            "test_252_4.jpg",
            "test_252_6.jpg",
            "test_252_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.2666666666666666,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            33.59375,
            37.59375,
            42.3125,
            25.203125,
            25.171875,
            17.5,
            38.4375,
            36.6875,
            37.21875
          ],
          "order_indices": [
            2,
            6,
            1,
            8,
            7,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_252_2.jpg",
            "test_252_6.jpg",
            "test_252_1.jpg",
            "test_252_8.jpg",
            "test_252_7.jpg",
            "test_252_0.jpg",
            "test_252_3.jpg",
            "test_252_4.jpg",
            "test_252_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.03333333333333344,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.8766828179359436,
            -0.29443198442459106,
            -1.2287219762802124,
            -2.020592212677002,
            -1.319625735282898,
            -2.2794885635375977,
            -2.182271718978882,
            -1.5343732833862305,
            0.39799290895462036
          ],
          "order_indices": [
            8,
            1,
            0,
            2,
            4,
            7,
            3,
            6,
            5
          ],
          "order_filenames": [
            "test_252_8.jpg",
            "test_252_1.jpg",
            "test_252_0.jpg",
            "test_252_2.jpg",
            "test_252_4.jpg",
            "test_252_7.jpg",
            "test_252_3.jpg",
            "test_252_6.jpg",
            "test_252_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.30000000000000004,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 253,
      "prompt": "The image features a painting of a person wearing white cloth fabric jodhpurs, with elements of fantasy and intricacy.",
      "image_filenames": [
        "test_253_0.jpg",
        "test_253_1.jpg",
        "test_253_2.jpg",
        "test_253_3.jpg",
        "test_253_4.jpg",
        "test_253_5.jpg",
        "test_253_6.jpg",
        "test_253_7.jpg",
        "test_253_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          4,
          1,
          3,
          7,
          5,
          8,
          6,
          0
        ],
        "order_filenames": [
          "test_253_2.jpg",
          "test_253_4.jpg",
          "test_253_1.jpg",
          "test_253_3.jpg",
          "test_253_7.jpg",
          "test_253_5.jpg",
          "test_253_8.jpg",
          "test_253_6.jpg",
          "test_253_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_253_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_253_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_253_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1944580078125,
            0.2265625,
            0.233642578125,
            0.1781005859375,
            0.1864013671875,
            0.10797119140625,
            0.2349853515625,
            0.232177734375,
            0.2020263671875
          ],
          "order_indices": [
            6,
            2,
            7,
            1,
            8,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_253_6.jpg",
            "test_253_2.jpg",
            "test_253_7.jpg",
            "test_253_1.jpg",
            "test_253_8.jpg",
            "test_253_0.jpg",
            "test_253_4.jpg",
            "test_253_3.jpg",
            "test_253_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.01666666666666672,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            42.96875,
            39.96875,
            42.8125,
            31.203125,
            28.84375,
            30.140625,
            31.296875,
            42.625,
            42.0
          ],
          "order_indices": [
            0,
            2,
            7,
            8,
            1,
            6,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_253_0.jpg",
            "test_253_2.jpg",
            "test_253_7.jpg",
            "test_253_8.jpg",
            "test_253_1.jpg",
            "test_253_6.jpg",
            "test_253_3.jpg",
            "test_253_5.jpg",
            "test_253_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.2333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.4198416471481323,
            1.3403915166854858,
            1.4137178659439087,
            -0.171010360121727,
            1.4560341835021973,
            -1.5714962482452393,
            0.047253694385290146,
            1.2343974113464355,
            -2.074256420135498
          ],
          "order_indices": [
            4,
            0,
            2,
            1,
            7,
            6,
            3,
            5,
            8
          ],
          "order_filenames": [
            "test_253_4.jpg",
            "test_253_0.jpg",
            "test_253_2.jpg",
            "test_253_1.jpg",
            "test_253_7.jpg",
            "test_253_6.jpg",
            "test_253_3.jpg",
            "test_253_5.jpg",
            "test_253_8.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.3666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 254,
      "prompt": "Portrait of Steve Buscemi by Ilya Kuvshinov.",
      "image_filenames": [
        "test_254_0.jpg",
        "test_254_1.jpg",
        "test_254_2.jpg",
        "test_254_3.jpg",
        "test_254_4.jpg",
        "test_254_5.jpg",
        "test_254_6.jpg",
        "test_254_7.jpg",
        "test_254_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          5,
          6,
          7,
          1,
          8,
          4,
          2,
          3
        ],
        "order_filenames": [
          "test_254_0.jpg",
          "test_254_5.jpg",
          "test_254_6.jpg",
          "test_254_7.jpg",
          "test_254_1.jpg",
          "test_254_8.jpg",
          "test_254_4.jpg",
          "test_254_2.jpg",
          "test_254_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_254_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_254_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0,
            5
          ],
          "winner_filenames": [
            "test_254_0.jpg",
            "test_254_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.148681640625,
            0.271240234375,
            0.258056640625,
            0.13037109375,
            0.12286376953125,
            0.1517333984375,
            0.2384033203125,
            0.21337890625,
            0.251220703125
          ],
          "order_indices": [
            1,
            2,
            8,
            6,
            7,
            5,
            0,
            3,
            4
          ],
          "order_filenames": [
            "test_254_1.jpg",
            "test_254_2.jpg",
            "test_254_8.jpg",
            "test_254_6.jpg",
            "test_254_7.jpg",
            "test_254_5.jpg",
            "test_254_0.jpg",
            "test_254_3.jpg",
            "test_254_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": 0.0,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.0625,
            40.34375,
            42.25,
            27.953125,
            16.671875,
            13.203125,
            37.375,
            39.34375,
            39.4375
          ],
          "order_indices": [
            2,
            1,
            8,
            7,
            6,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_254_2.jpg",
            "test_254_1.jpg",
            "test_254_8.jpg",
            "test_254_7.jpg",
            "test_254_6.jpg",
            "test_254_0.jpg",
            "test_254_3.jpg",
            "test_254_4.jpg",
            "test_254_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.25,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.1666487455368042,
            1.391656517982483,
            1.5582313537597656,
            -1.0043416023254395,
            -1.4229717254638672,
            -1.62800931930542,
            1.4078806638717651,
            -1.7093324661254883,
            1.6308590173721313
          ],
          "order_indices": [
            8,
            2,
            6,
            1,
            3,
            0,
            4,
            5,
            7
          ],
          "order_filenames": [
            "test_254_8.jpg",
            "test_254_2.jpg",
            "test_254_6.jpg",
            "test_254_1.jpg",
            "test_254_3.jpg",
            "test_254_0.jpg",
            "test_254_4.jpg",
            "test_254_5.jpg",
            "test_254_7.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.3666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 255,
      "prompt": "A portrait of Phoenix Wright, painted in oil by Greg Rutowski and inspired by the art of Alphonse Mucha.",
      "image_filenames": [
        "test_255_0.jpg",
        "test_255_1.jpg",
        "test_255_2.jpg",
        "test_255_3.jpg",
        "test_255_4.jpg",
        "test_255_5.jpg",
        "test_255_6.jpg",
        "test_255_7.jpg",
        "test_255_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          3,
          2,
          1,
          5,
          6,
          7,
          8,
          0
        ],
        "order_filenames": [
          "test_255_4.jpg",
          "test_255_3.jpg",
          "test_255_2.jpg",
          "test_255_1.jpg",
          "test_255_5.jpg",
          "test_255_6.jpg",
          "test_255_7.jpg",
          "test_255_8.jpg",
          "test_255_0.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_255_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_255_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_255_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.220703125,
            0.2296142578125,
            0.22314453125,
            0.144775390625,
            0.1983642578125,
            0.10418701171875,
            0.235107421875,
            0.231201171875,
            0.31103515625
          ],
          "order_indices": [
            8,
            6,
            7,
            1,
            2,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_255_8.jpg",
            "test_255_6.jpg",
            "test_255_7.jpg",
            "test_255_1.jpg",
            "test_255_2.jpg",
            "test_255_0.jpg",
            "test_255_4.jpg",
            "test_255_3.jpg",
            "test_255_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.5166666666666666,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.53125,
            35.09375,
            46.125,
            28.546875,
            34.28125,
            16.84375,
            34.46875,
            42.21875,
            39.75
          ],
          "order_indices": [
            2,
            7,
            8,
            0,
            1,
            6,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_255_2.jpg",
            "test_255_7.jpg",
            "test_255_8.jpg",
            "test_255_0.jpg",
            "test_255_1.jpg",
            "test_255_6.jpg",
            "test_255_4.jpg",
            "test_255_3.jpg",
            "test_255_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.3999999999999999,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.3040701746940613,
            1.0585445165634155,
            1.0801581144332886,
            -1.3174282312393188,
            -0.2098831832408905,
            -2.225801706314087,
            -0.16701510548591614,
            0.20255449414253235,
            1.6230201721191406
          ],
          "order_indices": [
            8,
            2,
            1,
            0,
            7,
            6,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_255_8.jpg",
            "test_255_2.jpg",
            "test_255_1.jpg",
            "test_255_0.jpg",
            "test_255_7.jpg",
            "test_255_6.jpg",
            "test_255_4.jpg",
            "test_255_3.jpg",
            "test_255_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.3999999999999999,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 256,
      "prompt": "An award-winning portrait of a lemon in a muted, space age style reminiscent of the 1930s.",
      "image_filenames": [
        "test_256_0.jpg",
        "test_256_1.jpg",
        "test_256_2.jpg",
        "test_256_3.jpg",
        "test_256_4.jpg",
        "test_256_5.jpg",
        "test_256_6.jpg",
        "test_256_7.jpg",
        "test_256_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          0,
          3,
          2,
          4,
          1,
          6,
          8,
          5
        ],
        "order_filenames": [
          "test_256_7.jpg",
          "test_256_0.jpg",
          "test_256_3.jpg",
          "test_256_2.jpg",
          "test_256_4.jpg",
          "test_256_1.jpg",
          "test_256_6.jpg",
          "test_256_8.jpg",
          "test_256_5.jpg"
        ],
        "condorcet_winner": 7,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_256_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_256_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_256_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1865234375,
            0.2115478515625,
            0.20751953125,
            0.2149658203125,
            0.174560546875,
            0.1893310546875,
            0.2088623046875,
            0.199951171875,
            0.216552734375
          ],
          "order_indices": [
            8,
            3,
            1,
            6,
            2,
            7,
            5,
            0,
            4
          ],
          "order_filenames": [
            "test_256_8.jpg",
            "test_256_3.jpg",
            "test_256_1.jpg",
            "test_256_6.jpg",
            "test_256_2.jpg",
            "test_256_7.jpg",
            "test_256_5.jpg",
            "test_256_0.jpg",
            "test_256_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.25,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            33.1875,
            34.5,
            33.28125,
            32.21875,
            30.203125,
            32.71875,
            35.40625,
            38.09375,
            35.1875
          ],
          "order_indices": [
            7,
            6,
            8,
            1,
            2,
            0,
            5,
            3,
            4
          ],
          "order_filenames": [
            "test_256_7.jpg",
            "test_256_6.jpg",
            "test_256_8.jpg",
            "test_256_1.jpg",
            "test_256_2.jpg",
            "test_256_0.jpg",
            "test_256_5.jpg",
            "test_256_3.jpg",
            "test_256_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.033333333333333326,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 1.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.7261102199554443,
            -1.9362499713897705,
            -1.1433579921722412,
            -1.463476300239563,
            -1.7937657833099365,
            -1.847863793373108,
            -1.361941933631897,
            -1.0795625448226929,
            -1.2418326139450073
          ],
          "order_indices": [
            7,
            2,
            8,
            6,
            3,
            0,
            4,
            5,
            1
          ],
          "order_filenames": [
            "test_256_7.jpg",
            "test_256_2.jpg",
            "test_256_8.jpg",
            "test_256_6.jpg",
            "test_256_3.jpg",
            "test_256_0.jpg",
            "test_256_4.jpg",
            "test_256_5.jpg",
            "test_256_1.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2777777777777778,
            "spearman_rho": 0.4,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 1.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 257,
      "prompt": "A painting by Raffaello Sanzi portraying Kajol and symbiots Riot during the Renaissance era, showcased on Artstation.",
      "image_filenames": [
        "test_257_0.jpg",
        "test_257_1.jpg",
        "test_257_2.jpg",
        "test_257_3.jpg",
        "test_257_4.jpg",
        "test_257_5.jpg",
        "test_257_6.jpg",
        "test_257_7.jpg",
        "test_257_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          6,
          3,
          7,
          4,
          1,
          8,
          0,
          5
        ],
        "order_filenames": [
          "test_257_2.jpg",
          "test_257_6.jpg",
          "test_257_3.jpg",
          "test_257_7.jpg",
          "test_257_4.jpg",
          "test_257_1.jpg",
          "test_257_8.jpg",
          "test_257_0.jpg",
          "test_257_5.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_257_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_257_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_257_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.18017578125,
            0.218017578125,
            0.2376708984375,
            0.1990966796875,
            0.1700439453125,
            0.09814453125,
            0.2164306640625,
            0.218017578125,
            0.2255859375
          ],
          "order_indices": [
            2,
            8,
            1,
            7,
            6,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_257_2.jpg",
            "test_257_8.jpg",
            "test_257_1.jpg",
            "test_257_7.jpg",
            "test_257_6.jpg",
            "test_257_3.jpg",
            "test_257_0.jpg",
            "test_257_4.jpg",
            "test_257_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.4833333333333333,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            41.1875,
            34.03125,
            40.53125,
            35.46875,
            25.546875,
            21.34375,
            41.59375,
            42.4375,
            34.84375
          ],
          "order_indices": [
            7,
            6,
            0,
            2,
            3,
            8,
            1,
            4,
            5
          ],
          "order_filenames": [
            "test_257_7.jpg",
            "test_257_6.jpg",
            "test_257_0.jpg",
            "test_257_2.jpg",
            "test_257_3.jpg",
            "test_257_8.jpg",
            "test_257_1.jpg",
            "test_257_4.jpg",
            "test_257_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.5166666666666666,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.018046285957098007,
            0.6695767045021057,
            0.05154852196574211,
            -0.6475881934165955,
            -1.3147836923599243,
            -1.7450318336486816,
            -1.588012456893921,
            0.5205432176589966,
            -0.11770422011613846
          ],
          "order_indices": [
            1,
            7,
            2,
            0,
            8,
            3,
            4,
            6,
            5
          ],
          "order_filenames": [
            "test_257_1.jpg",
            "test_257_7.jpg",
            "test_257_2.jpg",
            "test_257_0.jpg",
            "test_257_8.jpg",
            "test_257_3.jpg",
            "test_257_4.jpg",
            "test_257_6.jpg",
            "test_257_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.15000000000000002,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 258,
      "prompt": "\"Beeple's painting 'ethos of ego, mythos of id' on canvas features hyperrealistic photorealism.\"",
      "image_filenames": [
        "test_258_0.jpg",
        "test_258_1.jpg",
        "test_258_2.jpg",
        "test_258_3.jpg",
        "test_258_4.jpg",
        "test_258_5.jpg",
        "test_258_6.jpg",
        "test_258_7.jpg",
        "test_258_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          3,
          6,
          5,
          7,
          1,
          8,
          2,
          0
        ],
        "order_filenames": [
          "test_258_4.jpg",
          "test_258_3.jpg",
          "test_258_6.jpg",
          "test_258_5.jpg",
          "test_258_7.jpg",
          "test_258_1.jpg",
          "test_258_8.jpg",
          "test_258_2.jpg",
          "test_258_0.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_258_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_258_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_258_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1280517578125,
            0.162841796875,
            0.2379150390625,
            0.1470947265625,
            0.1192626953125,
            0.10174560546875,
            0.129150390625,
            0.1807861328125,
            0.22802734375
          ],
          "order_indices": [
            2,
            8,
            7,
            1,
            3,
            6,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_258_2.jpg",
            "test_258_8.jpg",
            "test_258_7.jpg",
            "test_258_1.jpg",
            "test_258_3.jpg",
            "test_258_6.jpg",
            "test_258_0.jpg",
            "test_258_4.jpg",
            "test_258_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.4833333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.34375,
            37.3125,
            37.5,
            29.125,
            18.6875,
            16.765625,
            32.75,
            39.09375,
            27.09375
          ],
          "order_indices": [
            7,
            2,
            1,
            0,
            6,
            3,
            8,
            4,
            5
          ],
          "order_filenames": [
            "test_258_7.jpg",
            "test_258_2.jpg",
            "test_258_1.jpg",
            "test_258_0.jpg",
            "test_258_6.jpg",
            "test_258_3.jpg",
            "test_258_8.jpg",
            "test_258_4.jpg",
            "test_258_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.5,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.3039295971393585,
            -1.2988646030426025,
            0.40871545672416687,
            -0.21082694828510284,
            -1.7312630414962769,
            -1.2821037769317627,
            -2.028202533721924,
            -0.21489889919757843,
            0.8238136172294617
          ],
          "order_indices": [
            8,
            2,
            3,
            7,
            0,
            5,
            1,
            4,
            6
          ],
          "order_filenames": [
            "test_258_8.jpg",
            "test_258_2.jpg",
            "test_258_3.jpg",
            "test_258_7.jpg",
            "test_258_0.jpg",
            "test_258_5.jpg",
            "test_258_1.jpg",
            "test_258_4.jpg",
            "test_258_6.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.5,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 259,
      "prompt": "Artwork by Shaun Tan.",
      "image_filenames": [
        "test_259_0.jpg",
        "test_259_1.jpg",
        "test_259_2.jpg",
        "test_259_3.jpg",
        "test_259_4.jpg",
        "test_259_5.jpg",
        "test_259_6.jpg",
        "test_259_7.jpg",
        "test_259_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          4,
          1,
          7,
          6,
          2,
          8,
          0,
          3
        ],
        "order_filenames": [
          "test_259_5.jpg",
          "test_259_4.jpg",
          "test_259_1.jpg",
          "test_259_7.jpg",
          "test_259_6.jpg",
          "test_259_2.jpg",
          "test_259_8.jpg",
          "test_259_0.jpg",
          "test_259_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_259_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4,
            5
          ],
          "winner_filenames": [
            "test_259_4.jpg",
            "test_259_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_259_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.14794921875,
            0.239013671875,
            0.190185546875,
            0.1536865234375,
            0.1544189453125,
            0.1475830078125,
            0.1845703125,
            0.22998046875,
            0.191650390625
          ],
          "order_indices": [
            1,
            7,
            8,
            2,
            6,
            4,
            3,
            0,
            5
          ],
          "order_filenames": [
            "test_259_1.jpg",
            "test_259_7.jpg",
            "test_259_8.jpg",
            "test_259_2.jpg",
            "test_259_6.jpg",
            "test_259_4.jpg",
            "test_259_3.jpg",
            "test_259_0.jpg",
            "test_259_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.4375,
            32.3125,
            38.125,
            29.515625,
            25.3125,
            19.5,
            35.28125,
            37.6875,
            35.4375
          ],
          "order_indices": [
            2,
            7,
            0,
            8,
            6,
            1,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_259_2.jpg",
            "test_259_7.jpg",
            "test_259_0.jpg",
            "test_259_8.jpg",
            "test_259_6.jpg",
            "test_259_1.jpg",
            "test_259_3.jpg",
            "test_259_4.jpg",
            "test_259_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.46666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.7112154960632324,
            0.18167589604854584,
            -0.11074524372816086,
            -0.4811675250530243,
            -0.10097162425518036,
            -0.7680523991584778,
            0.1511373370885849,
            0.3355371654033661,
            0.39473000168800354
          ],
          "order_indices": [
            8,
            7,
            1,
            6,
            4,
            2,
            3,
            0,
            5
          ],
          "order_filenames": [
            "test_259_8.jpg",
            "test_259_7.jpg",
            "test_259_1.jpg",
            "test_259_6.jpg",
            "test_259_4.jpg",
            "test_259_2.jpg",
            "test_259_3.jpg",
            "test_259_0.jpg",
            "test_259_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.01666666666666672,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 260,
      "prompt": "Illustration of a sugar skull day of the dead girl.",
      "image_filenames": [
        "test_260_0.jpg",
        "test_260_1.jpg",
        "test_260_2.jpg",
        "test_260_3.jpg",
        "test_260_4.jpg",
        "test_260_5.jpg",
        "test_260_6.jpg",
        "test_260_7.jpg",
        "test_260_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          6,
          0,
          7,
          2,
          5,
          8,
          4,
          3
        ],
        "order_filenames": [
          "test_260_1.jpg",
          "test_260_6.jpg",
          "test_260_0.jpg",
          "test_260_7.jpg",
          "test_260_2.jpg",
          "test_260_5.jpg",
          "test_260_8.jpg",
          "test_260_4.jpg",
          "test_260_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_260_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_260_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_260_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.15625,
            0.263671875,
            0.26806640625,
            0.1690673828125,
            0.1685791015625,
            0.1370849609375,
            0.20263671875,
            0.2242431640625,
            0.26318359375
          ],
          "order_indices": [
            2,
            1,
            8,
            7,
            6,
            3,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_260_2.jpg",
            "test_260_1.jpg",
            "test_260_8.jpg",
            "test_260_7.jpg",
            "test_260_6.jpg",
            "test_260_3.jpg",
            "test_260_4.jpg",
            "test_260_0.jpg",
            "test_260_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.2833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            28.265625,
            30.71875,
            29.203125,
            22.046875,
            15.953125,
            19.640625,
            32.21875,
            31.59375,
            30.75
          ],
          "order_indices": [
            6,
            7,
            8,
            1,
            2,
            0,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_260_6.jpg",
            "test_260_7.jpg",
            "test_260_8.jpg",
            "test_260_1.jpg",
            "test_260_2.jpg",
            "test_260_0.jpg",
            "test_260_3.jpg",
            "test_260_5.jpg",
            "test_260_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.4444444444444444,
            "spearman_rho": 0.6,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.9121999740600586,
            0.74409019947052,
            1.4070950746536255,
            -1.7833480834960938,
            -1.2709323167800903,
            -2.1538054943084717,
            -1.3077627420425415,
            -0.3285733461380005,
            0.6948175430297852
          ],
          "order_indices": [
            2,
            1,
            8,
            7,
            0,
            4,
            6,
            3,
            5
          ],
          "order_filenames": [
            "test_260_2.jpg",
            "test_260_1.jpg",
            "test_260_8.jpg",
            "test_260_7.jpg",
            "test_260_0.jpg",
            "test_260_4.jpg",
            "test_260_6.jpg",
            "test_260_3.jpg",
            "test_260_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.3666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 261,
      "prompt": "A painting of the TV tower by Zaha Hadid.",
      "image_filenames": [
        "test_261_0.jpg",
        "test_261_1.jpg",
        "test_261_2.jpg",
        "test_261_3.jpg",
        "test_261_4.jpg",
        "test_261_5.jpg",
        "test_261_6.jpg",
        "test_261_7.jpg",
        "test_261_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          8,
          3,
          4,
          6,
          7,
          2,
          5,
          0,
          1
        ],
        "order_filenames": [
          "test_261_8.jpg",
          "test_261_3.jpg",
          "test_261_4.jpg",
          "test_261_6.jpg",
          "test_261_7.jpg",
          "test_261_2.jpg",
          "test_261_5.jpg",
          "test_261_0.jpg",
          "test_261_1.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          8
        ],
        "winner_filenames": [
          "test_261_8.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            8
          ],
          "winner_filenames": [
            "test_261_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            8
          ],
          "winner_filenames": [
            "test_261_8.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1700439453125,
            0.144287109375,
            0.2244873046875,
            0.195068359375,
            0.1676025390625,
            0.1568603515625,
            0.2288818359375,
            0.2081298828125,
            0.216796875
          ],
          "order_indices": [
            6,
            2,
            8,
            7,
            3,
            0,
            4,
            5,
            1
          ],
          "order_filenames": [
            "test_261_6.jpg",
            "test_261_2.jpg",
            "test_261_8.jpg",
            "test_261_7.jpg",
            "test_261_3.jpg",
            "test_261_0.jpg",
            "test_261_4.jpg",
            "test_261_5.jpg",
            "test_261_1.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3888888888888889,
            "spearman_rho": 0.5,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            46.03125,
            33.875,
            47.5625,
            36.875,
            32.09375,
            30.828125,
            36.28125,
            47.1875,
            41.59375
          ],
          "order_indices": [
            2,
            7,
            0,
            8,
            3,
            6,
            1,
            4,
            5
          ],
          "order_filenames": [
            "test_261_2.jpg",
            "test_261_7.jpg",
            "test_261_0.jpg",
            "test_261_8.jpg",
            "test_261_3.jpg",
            "test_261_6.jpg",
            "test_261_1.jpg",
            "test_261_4.jpg",
            "test_261_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.050000000000000044,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.8828540444374084,
            -1.5352660417556763,
            0.16150842607021332,
            -0.21792522072792053,
            -1.043326735496521,
            -0.9232754707336426,
            0.6485567092895508,
            0.7087018489837646,
            0.3466282784938812
          ],
          "order_indices": [
            7,
            6,
            8,
            2,
            3,
            0,
            5,
            4,
            1
          ],
          "order_filenames": [
            "test_261_7.jpg",
            "test_261_6.jpg",
            "test_261_8.jpg",
            "test_261_2.jpg",
            "test_261_3.jpg",
            "test_261_0.jpg",
            "test_261_5.jpg",
            "test_261_4.jpg",
            "test_261_1.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.44999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 262,
      "prompt": "A giant minotaur warrior holding a two handed axe, depicted in a dark fantasy digital painting.",
      "image_filenames": [
        "test_262_0.jpg",
        "test_262_1.jpg",
        "test_262_2.jpg",
        "test_262_3.jpg",
        "test_262_4.jpg",
        "test_262_5.jpg",
        "test_262_6.jpg",
        "test_262_7.jpg",
        "test_262_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          2,
          6,
          1,
          8,
          3,
          7,
          4,
          0
        ],
        "order_filenames": [
          "test_262_5.jpg",
          "test_262_2.jpg",
          "test_262_6.jpg",
          "test_262_1.jpg",
          "test_262_8.jpg",
          "test_262_3.jpg",
          "test_262_7.jpg",
          "test_262_4.jpg",
          "test_262_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_262_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_262_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_262_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.194091796875,
            0.25732421875,
            0.283935546875,
            0.16455078125,
            0.14599609375,
            0.11932373046875,
            0.254150390625,
            0.2119140625,
            0.2734375
          ],
          "order_indices": [
            2,
            8,
            1,
            6,
            7,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_262_2.jpg",
            "test_262_8.jpg",
            "test_262_1.jpg",
            "test_262_6.jpg",
            "test_262_7.jpg",
            "test_262_0.jpg",
            "test_262_3.jpg",
            "test_262_4.jpg",
            "test_262_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.25,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.8125,
            37.625,
            36.65625,
            26.0,
            17.34375,
            17.046875,
            37.03125,
            40.75,
            35.78125
          ],
          "order_indices": [
            7,
            1,
            6,
            0,
            2,
            8,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_262_7.jpg",
            "test_262_1.jpg",
            "test_262_6.jpg",
            "test_262_0.jpg",
            "test_262_2.jpg",
            "test_262_8.jpg",
            "test_262_3.jpg",
            "test_262_4.jpg",
            "test_262_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.16666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.1575319468975067,
            0.4394747316837311,
            1.4530651569366455,
            -0.743378758430481,
            -1.6413360834121704,
            -2.1166269779205322,
            1.1993274688720703,
            0.5314779877662659,
            1.3999603986740112
          ],
          "order_indices": [
            2,
            8,
            6,
            7,
            1,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_262_2.jpg",
            "test_262_8.jpg",
            "test_262_6.jpg",
            "test_262_7.jpg",
            "test_262_1.jpg",
            "test_262_0.jpg",
            "test_262_3.jpg",
            "test_262_4.jpg",
            "test_262_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.21666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 263,
      "prompt": "A Japanese castle landscape painting trending on Artstation.",
      "image_filenames": [
        "test_263_0.jpg",
        "test_263_1.jpg",
        "test_263_2.jpg",
        "test_263_3.jpg",
        "test_263_4.jpg",
        "test_263_5.jpg",
        "test_263_6.jpg",
        "test_263_7.jpg",
        "test_263_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          0,
          8,
          6,
          5,
          1,
          3,
          4,
          2
        ],
        "order_filenames": [
          "test_263_7.jpg",
          "test_263_0.jpg",
          "test_263_8.jpg",
          "test_263_6.jpg",
          "test_263_5.jpg",
          "test_263_1.jpg",
          "test_263_3.jpg",
          "test_263_4.jpg",
          "test_263_2.jpg"
        ],
        "condorcet_winner": 7,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_263_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_263_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_263_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2139892578125,
            0.251220703125,
            0.29248046875,
            0.2353515625,
            0.1781005859375,
            0.271240234375,
            0.292724609375,
            0.253662109375,
            0.29736328125
          ],
          "order_indices": [
            8,
            6,
            2,
            5,
            7,
            1,
            3,
            0,
            4
          ],
          "order_filenames": [
            "test_263_8.jpg",
            "test_263_6.jpg",
            "test_263_2.jpg",
            "test_263_5.jpg",
            "test_263_7.jpg",
            "test_263_1.jpg",
            "test_263_3.jpg",
            "test_263_0.jpg",
            "test_263_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.8125,
            31.6875,
            33.3125,
            31.46875,
            21.15625,
            35.3125,
            32.75,
            36.6875,
            38.09375
          ],
          "order_indices": [
            8,
            7,
            0,
            5,
            2,
            6,
            1,
            3,
            4
          ],
          "order_filenames": [
            "test_263_8.jpg",
            "test_263_7.jpg",
            "test_263_0.jpg",
            "test_263_5.jpg",
            "test_263_2.jpg",
            "test_263_6.jpg",
            "test_263_1.jpg",
            "test_263_3.jpg",
            "test_263_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.6111111111111112,
            "spearman_rho": 0.75,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.316751092672348,
            -0.39556291699409485,
            1.2797296047210693,
            0.15442553162574768,
            -1.841720461845398,
            0.8898826837539673,
            0.8280007243156433,
            1.060226559638977,
            1.2824063301086426
          ],
          "order_indices": [
            8,
            2,
            7,
            5,
            6,
            0,
            3,
            1,
            4
          ],
          "order_filenames": [
            "test_263_8.jpg",
            "test_263_2.jpg",
            "test_263_7.jpg",
            "test_263_5.jpg",
            "test_263_6.jpg",
            "test_263_0.jpg",
            "test_263_3.jpg",
            "test_263_1.jpg",
            "test_263_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2777777777777778,
            "spearman_rho": 0.33333333333333337,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 264,
      "prompt": "A depiction of Boudica, queen and warrior, with a battlefield in the background.",
      "image_filenames": [
        "test_264_0.jpg",
        "test_264_1.jpg",
        "test_264_2.jpg",
        "test_264_3.jpg",
        "test_264_4.jpg",
        "test_264_5.jpg",
        "test_264_6.jpg",
        "test_264_7.jpg",
        "test_264_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          2,
          4,
          5,
          6,
          8,
          3,
          1,
          7
        ],
        "order_filenames": [
          "test_264_0.jpg",
          "test_264_2.jpg",
          "test_264_4.jpg",
          "test_264_5.jpg",
          "test_264_6.jpg",
          "test_264_8.jpg",
          "test_264_3.jpg",
          "test_264_1.jpg",
          "test_264_7.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_264_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            1,
            4,
            5
          ],
          "winner_filenames": [
            "test_264_1.jpg",
            "test_264_4.jpg",
            "test_264_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_264_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2225341796875,
            0.219482421875,
            0.28466796875,
            0.1746826171875,
            0.18017578125,
            0.103515625,
            0.2012939453125,
            0.2359619140625,
            0.2169189453125
          ],
          "order_indices": [
            2,
            7,
            0,
            1,
            8,
            6,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_264_2.jpg",
            "test_264_7.jpg",
            "test_264_0.jpg",
            "test_264_1.jpg",
            "test_264_8.jpg",
            "test_264_6.jpg",
            "test_264_4.jpg",
            "test_264_3.jpg",
            "test_264_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": 0.050000000000000044,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.875,
            30.8125,
            41.84375,
            28.34375,
            34.34375,
            17.09375,
            33.53125,
            44.625,
            33.5
          ],
          "order_indices": [
            7,
            2,
            0,
            4,
            6,
            8,
            1,
            3,
            5
          ],
          "order_filenames": [
            "test_264_7.jpg",
            "test_264_2.jpg",
            "test_264_0.jpg",
            "test_264_4.jpg",
            "test_264_6.jpg",
            "test_264_8.jpg",
            "test_264_1.jpg",
            "test_264_3.jpg",
            "test_264_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.19999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.31507495045661926,
            0.06955235451459885,
            0.052295152097940445,
            -1.1027913093566895,
            -0.11913985759019852,
            -1.832555890083313,
            0.5768337845802307,
            0.561301589012146,
            0.19415925443172455
          ],
          "order_indices": [
            6,
            7,
            0,
            8,
            1,
            2,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_264_6.jpg",
            "test_264_7.jpg",
            "test_264_0.jpg",
            "test_264_8.jpg",
            "test_264_1.jpg",
            "test_264_2.jpg",
            "test_264_4.jpg",
            "test_264_3.jpg",
            "test_264_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.16666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 265,
      "prompt": "Mila Kunis portrayed as a fire elemental in a highly detailed digital painting.",
      "image_filenames": [
        "test_265_0.jpg",
        "test_265_1.jpg",
        "test_265_2.jpg",
        "test_265_3.jpg",
        "test_265_4.jpg",
        "test_265_5.jpg",
        "test_265_6.jpg",
        "test_265_7.jpg",
        "test_265_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          5,
          1,
          3,
          2,
          6,
          7,
          8,
          0
        ],
        "order_filenames": [
          "test_265_4.jpg",
          "test_265_5.jpg",
          "test_265_1.jpg",
          "test_265_3.jpg",
          "test_265_2.jpg",
          "test_265_6.jpg",
          "test_265_7.jpg",
          "test_265_8.jpg",
          "test_265_0.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_265_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_265_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_265_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2064208984375,
            0.285400390625,
            0.296875,
            0.2054443359375,
            0.1793212890625,
            0.1436767578125,
            0.273681640625,
            0.273681640625,
            0.3203125
          ],
          "order_indices": [
            8,
            2,
            1,
            6,
            7,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_265_8.jpg",
            "test_265_2.jpg",
            "test_265_1.jpg",
            "test_265_6.jpg",
            "test_265_7.jpg",
            "test_265_0.jpg",
            "test_265_3.jpg",
            "test_265_4.jpg",
            "test_265_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.5166666666666666,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            46.5,
            47.71875,
            43.09375,
            30.25,
            27.390625,
            23.4375,
            36.0,
            51.21875,
            42.21875
          ],
          "order_indices": [
            7,
            1,
            0,
            2,
            8,
            6,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_265_7.jpg",
            "test_265_1.jpg",
            "test_265_0.jpg",
            "test_265_2.jpg",
            "test_265_8.jpg",
            "test_265_6.jpg",
            "test_265_3.jpg",
            "test_265_4.jpg",
            "test_265_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.5833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.9893127679824829,
            1.4261195659637451,
            1.3506520986557007,
            1.0107618570327759,
            -0.5619251728057861,
            -1.9560232162475586,
            0.0036644814535975456,
            0.08425039798021317,
            1.9180740118026733
          ],
          "order_indices": [
            8,
            1,
            2,
            3,
            0,
            7,
            6,
            4,
            5
          ],
          "order_filenames": [
            "test_265_8.jpg",
            "test_265_1.jpg",
            "test_265_2.jpg",
            "test_265_3.jpg",
            "test_265_0.jpg",
            "test_265_7.jpg",
            "test_265_6.jpg",
            "test_265_4.jpg",
            "test_265_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.41666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 266,
      "prompt": "The image is titled \"Left 4 Dead\" and was painted by John William Waterhouse.",
      "image_filenames": [
        "test_266_0.jpg",
        "test_266_1.jpg",
        "test_266_2.jpg",
        "test_266_3.jpg",
        "test_266_4.jpg",
        "test_266_5.jpg",
        "test_266_6.jpg",
        "test_266_7.jpg",
        "test_266_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          2,
          1,
          6,
          8,
          0,
          4,
          5,
          3
        ],
        "order_filenames": [
          "test_266_7.jpg",
          "test_266_2.jpg",
          "test_266_1.jpg",
          "test_266_6.jpg",
          "test_266_8.jpg",
          "test_266_0.jpg",
          "test_266_4.jpg",
          "test_266_5.jpg",
          "test_266_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_266_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_266_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_266_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1982421875,
            0.26171875,
            0.2381591796875,
            0.1710205078125,
            0.188720703125,
            0.08563232421875,
            0.29833984375,
            0.2314453125,
            0.2210693359375
          ],
          "order_indices": [
            6,
            1,
            2,
            7,
            8,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_266_6.jpg",
            "test_266_1.jpg",
            "test_266_2.jpg",
            "test_266_7.jpg",
            "test_266_8.jpg",
            "test_266_0.jpg",
            "test_266_4.jpg",
            "test_266_3.jpg",
            "test_266_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.6111111111111112,
            "spearman_rho": 0.8166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            33.90625,
            35.375,
            40.96875,
            27.65625,
            30.1875,
            17.703125,
            33.9375,
            41.96875,
            32.96875
          ],
          "order_indices": [
            7,
            2,
            1,
            6,
            0,
            8,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_266_7.jpg",
            "test_266_2.jpg",
            "test_266_1.jpg",
            "test_266_6.jpg",
            "test_266_0.jpg",
            "test_266_8.jpg",
            "test_266_4.jpg",
            "test_266_3.jpg",
            "test_266_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.8888888888888888,
            "spearman_rho": 0.9666666666666667,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.5555555555555556,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.066674828529358,
            -0.535017192363739,
            -0.9148709774017334,
            -0.8653115034103394,
            -1.2493252754211426,
            -2.2072341442108154,
            -0.08699595928192139,
            -0.8468483686447144,
            -0.12980897724628448
          ],
          "order_indices": [
            6,
            8,
            1,
            7,
            3,
            2,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_266_6.jpg",
            "test_266_8.jpg",
            "test_266_1.jpg",
            "test_266_7.jpg",
            "test_266_3.jpg",
            "test_266_2.jpg",
            "test_266_0.jpg",
            "test_266_4.jpg",
            "test_266_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.4833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 267,
      "prompt": "A Proto-Slavic hero is depicted in an intricate and elegant digital painting by multiple artists on ArtStation.",
      "image_filenames": [
        "test_267_0.jpg",
        "test_267_1.jpg",
        "test_267_2.jpg",
        "test_267_3.jpg",
        "test_267_4.jpg",
        "test_267_5.jpg",
        "test_267_6.jpg",
        "test_267_7.jpg",
        "test_267_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          0,
          2,
          6,
          4,
          7,
          1,
          8,
          3
        ],
        "order_filenames": [
          "test_267_5.jpg",
          "test_267_0.jpg",
          "test_267_2.jpg",
          "test_267_6.jpg",
          "test_267_4.jpg",
          "test_267_7.jpg",
          "test_267_1.jpg",
          "test_267_8.jpg",
          "test_267_3.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_267_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_267_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_267_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.18212890625,
            0.28173828125,
            0.2103271484375,
            0.1737060546875,
            0.142333984375,
            0.10528564453125,
            0.1346435546875,
            0.19873046875,
            0.20361328125
          ],
          "order_indices": [
            1,
            2,
            8,
            7,
            0,
            3,
            4,
            6,
            5
          ],
          "order_filenames": [
            "test_267_1.jpg",
            "test_267_2.jpg",
            "test_267_8.jpg",
            "test_267_7.jpg",
            "test_267_0.jpg",
            "test_267_3.jpg",
            "test_267_4.jpg",
            "test_267_6.jpg",
            "test_267_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.3999999999999999,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.0625,
            31.359375,
            38.75,
            31.515625,
            19.71875,
            5.40625,
            34.125,
            37.5625,
            30.578125
          ],
          "order_indices": [
            2,
            7,
            6,
            0,
            3,
            1,
            8,
            4,
            5
          ],
          "order_filenames": [
            "test_267_2.jpg",
            "test_267_7.jpg",
            "test_267_6.jpg",
            "test_267_0.jpg",
            "test_267_3.jpg",
            "test_267_1.jpg",
            "test_267_8.jpg",
            "test_267_4.jpg",
            "test_267_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.033333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.6374896764755249,
            1.5874032974243164,
            0.010693817399442196,
            0.004245637450367212,
            -0.436724454164505,
            -1.6734130382537842,
            -1.1939656734466553,
            -0.009733187966048717,
            0.29698067903518677
          ],
          "order_indices": [
            1,
            0,
            8,
            2,
            3,
            7,
            4,
            6,
            5
          ],
          "order_filenames": [
            "test_267_1.jpg",
            "test_267_0.jpg",
            "test_267_8.jpg",
            "test_267_2.jpg",
            "test_267_3.jpg",
            "test_267_7.jpg",
            "test_267_4.jpg",
            "test_267_6.jpg",
            "test_267_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.3500000000000001,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 268,
      "prompt": "A painting depicting a snowy winter scene featuring a river, a small house on a hill, and a dreamy cloudy sky.",
      "image_filenames": [
        "test_268_0.jpg",
        "test_268_1.jpg",
        "test_268_2.jpg",
        "test_268_3.jpg",
        "test_268_4.jpg",
        "test_268_5.jpg",
        "test_268_6.jpg",
        "test_268_7.jpg",
        "test_268_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          4,
          1,
          5,
          3,
          2,
          6,
          8,
          7
        ],
        "order_filenames": [
          "test_268_0.jpg",
          "test_268_4.jpg",
          "test_268_1.jpg",
          "test_268_5.jpg",
          "test_268_3.jpg",
          "test_268_2.jpg",
          "test_268_6.jpg",
          "test_268_8.jpg",
          "test_268_7.jpg"
        ],
        "condorcet_winner": 0,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_268_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4,
            8
          ],
          "winner_filenames": [
            "test_268_4.jpg",
            "test_268_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_268_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1610107421875,
            0.1856689453125,
            0.2440185546875,
            0.1805419921875,
            0.1727294921875,
            0.203125,
            0.1890869140625,
            0.2178955078125,
            0.1744384765625
          ],
          "order_indices": [
            2,
            7,
            5,
            6,
            1,
            3,
            8,
            4,
            0
          ],
          "order_filenames": [
            "test_268_2.jpg",
            "test_268_7.jpg",
            "test_268_5.jpg",
            "test_268_6.jpg",
            "test_268_1.jpg",
            "test_268_3.jpg",
            "test_268_8.jpg",
            "test_268_4.jpg",
            "test_268_0.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.5833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.5,
            34.0625,
            41.21875,
            29.84375,
            19.78125,
            36.53125,
            35.84375,
            38.96875,
            43.0
          ],
          "order_indices": [
            8,
            2,
            7,
            5,
            6,
            0,
            1,
            3,
            4
          ],
          "order_filenames": [
            "test_268_8.jpg",
            "test_268_2.jpg",
            "test_268_7.jpg",
            "test_268_5.jpg",
            "test_268_6.jpg",
            "test_268_0.jpg",
            "test_268_1.jpg",
            "test_268_3.jpg",
            "test_268_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.7,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.40535306930542,
            -0.8765150904655457,
            1.4041285514831543,
            -1.4890897274017334,
            -1.1355699300765991,
            0.34584346413612366,
            0.015383531339466572,
            0.4377088248729706,
            0.6735586524009705
          ],
          "order_indices": [
            2,
            8,
            7,
            5,
            6,
            1,
            4,
            0,
            3
          ],
          "order_filenames": [
            "test_268_2.jpg",
            "test_268_8.jpg",
            "test_268_7.jpg",
            "test_268_5.jpg",
            "test_268_6.jpg",
            "test_268_1.jpg",
            "test_268_4.jpg",
            "test_268_0.jpg",
            "test_268_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.6666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 269,
      "prompt": "Digital painting with vivid colors and a front view featuring a magical composition.",
      "image_filenames": [
        "test_269_0.jpg",
        "test_269_1.jpg",
        "test_269_2.jpg",
        "test_269_3.jpg",
        "test_269_4.jpg",
        "test_269_5.jpg",
        "test_269_6.jpg",
        "test_269_7.jpg",
        "test_269_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          7,
          1,
          2,
          8,
          0,
          5,
          4,
          6
        ],
        "order_filenames": [
          "test_269_3.jpg",
          "test_269_7.jpg",
          "test_269_1.jpg",
          "test_269_2.jpg",
          "test_269_8.jpg",
          "test_269_0.jpg",
          "test_269_5.jpg",
          "test_269_4.jpg",
          "test_269_6.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_269_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_269_3.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_269_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.17431640625,
            0.2435302734375,
            0.256591796875,
            0.1656494140625,
            0.149658203125,
            0.195068359375,
            0.225830078125,
            0.2149658203125,
            0.168701171875
          ],
          "order_indices": [
            2,
            1,
            6,
            7,
            5,
            0,
            8,
            3,
            4
          ],
          "order_filenames": [
            "test_269_2.jpg",
            "test_269_1.jpg",
            "test_269_6.jpg",
            "test_269_7.jpg",
            "test_269_5.jpg",
            "test_269_0.jpg",
            "test_269_8.jpg",
            "test_269_3.jpg",
            "test_269_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.09999999999999998,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            31.34375,
            30.1875,
            33.15625,
            31.203125,
            25.0625,
            24.515625,
            32.90625,
            35.21875,
            31.765625
          ],
          "order_indices": [
            7,
            2,
            6,
            8,
            0,
            3,
            1,
            4,
            5
          ],
          "order_filenames": [
            "test_269_7.jpg",
            "test_269_2.jpg",
            "test_269_6.jpg",
            "test_269_8.jpg",
            "test_269_0.jpg",
            "test_269_3.jpg",
            "test_269_1.jpg",
            "test_269_4.jpg",
            "test_269_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.2666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.419683814048767,
            -0.4728287160396576,
            0.3416155278682709,
            -1.0139567852020264,
            -1.8470834493637085,
            -0.8998789191246033,
            -0.7245248556137085,
            -1.2024344205856323,
            -1.571021556854248
          ],
          "order_indices": [
            2,
            1,
            6,
            5,
            3,
            7,
            0,
            8,
            4
          ],
          "order_filenames": [
            "test_269_2.jpg",
            "test_269_1.jpg",
            "test_269_6.jpg",
            "test_269_5.jpg",
            "test_269_3.jpg",
            "test_269_7.jpg",
            "test_269_0.jpg",
            "test_269_8.jpg",
            "test_269_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 270,
      "prompt": "The image depicts a portrait of a panda by Petros Afshar.",
      "image_filenames": [
        "test_270_0.jpg",
        "test_270_1.jpg",
        "test_270_2.jpg",
        "test_270_3.jpg",
        "test_270_4.jpg",
        "test_270_5.jpg",
        "test_270_6.jpg",
        "test_270_7.jpg",
        "test_270_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          3,
          2,
          6,
          5,
          7,
          8,
          0,
          1
        ],
        "order_filenames": [
          "test_270_4.jpg",
          "test_270_3.jpg",
          "test_270_2.jpg",
          "test_270_6.jpg",
          "test_270_5.jpg",
          "test_270_7.jpg",
          "test_270_8.jpg",
          "test_270_0.jpg",
          "test_270_1.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_270_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_270_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_270_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2237548828125,
            0.2138671875,
            0.2215576171875,
            0.1929931640625,
            0.2047119140625,
            0.1500244140625,
            0.272705078125,
            0.1824951171875,
            0.2626953125
          ],
          "order_indices": [
            6,
            8,
            0,
            2,
            1,
            4,
            3,
            7,
            5
          ],
          "order_filenames": [
            "test_270_6.jpg",
            "test_270_8.jpg",
            "test_270_0.jpg",
            "test_270_2.jpg",
            "test_270_1.jpg",
            "test_270_4.jpg",
            "test_270_3.jpg",
            "test_270_7.jpg",
            "test_270_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.21666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.9375,
            36.25,
            35.0625,
            35.0625,
            31.3125,
            36.21875,
            32.46875,
            34.375,
            35.1875
          ],
          "order_indices": [
            1,
            5,
            8,
            2,
            3,
            0,
            7,
            6,
            4
          ],
          "order_filenames": [
            "test_270_1.jpg",
            "test_270_5.jpg",
            "test_270_8.jpg",
            "test_270_2.jpg",
            "test_270_3.jpg",
            "test_270_0.jpg",
            "test_270_7.jpg",
            "test_270_6.jpg",
            "test_270_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.5333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.90896075963974,
            0.29546669125556946,
            -1.5348706245422363,
            0.11201190203428268,
            -0.6035702228546143,
            -1.7998192310333252,
            0.6234917640686035,
            -0.9182161688804626,
            1.2952501773834229
          ],
          "order_indices": [
            8,
            0,
            6,
            1,
            3,
            4,
            7,
            2,
            5
          ],
          "order_filenames": [
            "test_270_8.jpg",
            "test_270_0.jpg",
            "test_270_6.jpg",
            "test_270_1.jpg",
            "test_270_3.jpg",
            "test_270_4.jpg",
            "test_270_7.jpg",
            "test_270_2.jpg",
            "test_270_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.44999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 271,
      "prompt": "An androgynous glam rocker poses outside CBGB in the style of Phil Hale.",
      "image_filenames": [
        "test_271_0.jpg",
        "test_271_1.jpg",
        "test_271_2.jpg",
        "test_271_3.jpg",
        "test_271_4.jpg",
        "test_271_5.jpg",
        "test_271_6.jpg",
        "test_271_7.jpg",
        "test_271_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          4,
          1,
          5,
          6,
          7,
          8,
          0,
          2
        ],
        "order_filenames": [
          "test_271_3.jpg",
          "test_271_4.jpg",
          "test_271_1.jpg",
          "test_271_5.jpg",
          "test_271_6.jpg",
          "test_271_7.jpg",
          "test_271_8.jpg",
          "test_271_0.jpg",
          "test_271_2.jpg"
        ],
        "condorcet_winner": 3,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_271_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_271_3.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_271_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.15380859375,
            0.155517578125,
            0.2003173828125,
            0.1451416015625,
            0.1767578125,
            0.08892822265625,
            0.1507568359375,
            0.16845703125,
            0.2376708984375
          ],
          "order_indices": [
            8,
            2,
            4,
            7,
            1,
            0,
            6,
            3,
            5
          ],
          "order_filenames": [
            "test_271_8.jpg",
            "test_271_2.jpg",
            "test_271_4.jpg",
            "test_271_7.jpg",
            "test_271_1.jpg",
            "test_271_0.jpg",
            "test_271_6.jpg",
            "test_271_3.jpg",
            "test_271_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.46666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.1875,
            27.0625,
            47.09375,
            35.8125,
            30.984375,
            4.5078125,
            28.0625,
            41.875,
            36.21875
          ],
          "order_indices": [
            2,
            7,
            0,
            8,
            3,
            4,
            6,
            1,
            5
          ],
          "order_filenames": [
            "test_271_2.jpg",
            "test_271_7.jpg",
            "test_271_0.jpg",
            "test_271_8.jpg",
            "test_271_3.jpg",
            "test_271_4.jpg",
            "test_271_6.jpg",
            "test_271_1.jpg",
            "test_271_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.6666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.29493385553359985,
            -2.2172670364379883,
            0.6133305430412292,
            -1.2806100845336914,
            -1.2818684577941895,
            -1.7265506982803345,
            -2.270967483520508,
            -0.31094226241111755,
            0.5637450814247131
          ],
          "order_indices": [
            2,
            8,
            0,
            7,
            3,
            4,
            5,
            1,
            6
          ],
          "order_filenames": [
            "test_271_2.jpg",
            "test_271_8.jpg",
            "test_271_0.jpg",
            "test_271_7.jpg",
            "test_271_3.jpg",
            "test_271_4.jpg",
            "test_271_5.jpg",
            "test_271_1.jpg",
            "test_271_6.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.6666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 272,
      "prompt": "A digital painting of a symmetric fantasy depiction of a Shinigami Japanese figure with highly detailed and realistic intricate port.",
      "image_filenames": [
        "test_272_0.jpg",
        "test_272_1.jpg",
        "test_272_2.jpg",
        "test_272_3.jpg",
        "test_272_4.jpg",
        "test_272_5.jpg",
        "test_272_6.jpg",
        "test_272_7.jpg",
        "test_272_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          6,
          4,
          3,
          7,
          2,
          8,
          1,
          0
        ],
        "order_filenames": [
          "test_272_5.jpg",
          "test_272_6.jpg",
          "test_272_4.jpg",
          "test_272_3.jpg",
          "test_272_7.jpg",
          "test_272_2.jpg",
          "test_272_8.jpg",
          "test_272_1.jpg",
          "test_272_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_272_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_272_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5,
            6
          ],
          "winner_filenames": [
            "test_272_5.jpg",
            "test_272_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.169921875,
            0.1549072265625,
            0.17724609375,
            0.176025390625,
            0.1475830078125,
            0.17919921875,
            0.181884765625,
            0.2000732421875,
            0.24755859375
          ],
          "order_indices": [
            8,
            7,
            6,
            5,
            2,
            3,
            0,
            1,
            4
          ],
          "order_filenames": [
            "test_272_8.jpg",
            "test_272_7.jpg",
            "test_272_6.jpg",
            "test_272_5.jpg",
            "test_272_2.jpg",
            "test_272_3.jpg",
            "test_272_0.jpg",
            "test_272_1.jpg",
            "test_272_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.16666666666666663,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            33.125,
            32.9375,
            41.3125,
            31.765625,
            26.65625,
            26.9375,
            32.125,
            40.40625,
            23.4375
          ],
          "order_indices": [
            2,
            7,
            0,
            1,
            6,
            3,
            5,
            4,
            8
          ],
          "order_filenames": [
            "test_272_2.jpg",
            "test_272_7.jpg",
            "test_272_0.jpg",
            "test_272_1.jpg",
            "test_272_6.jpg",
            "test_272_3.jpg",
            "test_272_5.jpg",
            "test_272_4.jpg",
            "test_272_8.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.3666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.008984453044831753,
            -1.6443753242492676,
            0.012453797273337841,
            -0.7678984999656677,
            -0.28455543518066406,
            -1.7666120529174805,
            -1.662992000579834,
            -0.02261766605079174,
            0.5718991756439209
          ],
          "order_indices": [
            8,
            2,
            0,
            7,
            4,
            3,
            1,
            6,
            5
          ],
          "order_filenames": [
            "test_272_8.jpg",
            "test_272_2.jpg",
            "test_272_0.jpg",
            "test_272_7.jpg",
            "test_272_4.jpg",
            "test_272_3.jpg",
            "test_272_1.jpg",
            "test_272_6.jpg",
            "test_272_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5555555555555556,
            "spearman_rho": -0.6499999999999999,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 273,
      "prompt": "A magical hand reaching up on a dark-violet background, depicted through a digital painting.",
      "image_filenames": [
        "test_273_0.jpg",
        "test_273_1.jpg",
        "test_273_2.jpg",
        "test_273_3.jpg",
        "test_273_4.jpg",
        "test_273_5.jpg",
        "test_273_6.jpg",
        "test_273_7.jpg",
        "test_273_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          3,
          5,
          2,
          8,
          6,
          4,
          7,
          0
        ],
        "order_filenames": [
          "test_273_1.jpg",
          "test_273_3.jpg",
          "test_273_5.jpg",
          "test_273_2.jpg",
          "test_273_8.jpg",
          "test_273_6.jpg",
          "test_273_4.jpg",
          "test_273_7.jpg",
          "test_273_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_273_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_273_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_273_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.202880859375,
            0.241455078125,
            0.249755859375,
            0.19140625,
            0.168212890625,
            0.177734375,
            0.2120361328125,
            0.246826171875,
            0.225341796875
          ],
          "order_indices": [
            2,
            7,
            1,
            8,
            6,
            0,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_273_2.jpg",
            "test_273_7.jpg",
            "test_273_1.jpg",
            "test_273_8.jpg",
            "test_273_6.jpg",
            "test_273_0.jpg",
            "test_273_3.jpg",
            "test_273_5.jpg",
            "test_273_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.050000000000000044,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            44.375,
            35.875,
            41.15625,
            37.5,
            21.65625,
            31.34375,
            42.59375,
            45.40625,
            46.59375
          ],
          "order_indices": [
            8,
            7,
            0,
            6,
            2,
            3,
            1,
            5,
            4
          ],
          "order_filenames": [
            "test_273_8.jpg",
            "test_273_7.jpg",
            "test_273_0.jpg",
            "test_273_6.jpg",
            "test_273_2.jpg",
            "test_273_3.jpg",
            "test_273_1.jpg",
            "test_273_5.jpg",
            "test_273_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.44999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.5534708499908447,
            -0.2578236758708954,
            -1.0823216438293457,
            -1.5590503215789795,
            -1.72129487991333,
            -0.9131853580474854,
            -1.353789210319519,
            -0.6000245809555054,
            -0.6480796933174133
          ],
          "order_indices": [
            1,
            7,
            8,
            5,
            2,
            6,
            0,
            3,
            4
          ],
          "order_filenames": [
            "test_273_1.jpg",
            "test_273_7.jpg",
            "test_273_8.jpg",
            "test_273_5.jpg",
            "test_273_2.jpg",
            "test_273_6.jpg",
            "test_273_0.jpg",
            "test_273_3.jpg",
            "test_273_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.2833333333333333,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 274,
      "prompt": "An oil painting portrait of a beautiful dryad wearing an ombre velvet gown, with long hair and a tiara, adorned with dozens of jeweled necklaces, and illuminated with dramatic cinematic lighting.",
      "image_filenames": [
        "test_274_0.jpg",
        "test_274_1.jpg",
        "test_274_2.jpg",
        "test_274_3.jpg",
        "test_274_4.jpg",
        "test_274_5.jpg",
        "test_274_6.jpg",
        "test_274_7.jpg",
        "test_274_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          2,
          3,
          5,
          1,
          7,
          8,
          6,
          0
        ],
        "order_filenames": [
          "test_274_4.jpg",
          "test_274_2.jpg",
          "test_274_3.jpg",
          "test_274_5.jpg",
          "test_274_1.jpg",
          "test_274_7.jpg",
          "test_274_8.jpg",
          "test_274_6.jpg",
          "test_274_0.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_274_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_274_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_274_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1962890625,
            0.223388671875,
            0.2156982421875,
            0.1685791015625,
            0.1546630859375,
            0.07952880859375,
            0.1983642578125,
            0.198974609375,
            0.27880859375
          ],
          "order_indices": [
            8,
            1,
            2,
            7,
            6,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_274_8.jpg",
            "test_274_1.jpg",
            "test_274_2.jpg",
            "test_274_7.jpg",
            "test_274_6.jpg",
            "test_274_0.jpg",
            "test_274_3.jpg",
            "test_274_4.jpg",
            "test_274_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.31666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.71875,
            40.90625,
            40.71875,
            31.640625,
            32.4375,
            17.34375,
            38.46875,
            38.21875,
            39.0625
          ],
          "order_indices": [
            1,
            2,
            8,
            6,
            7,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_274_1.jpg",
            "test_274_2.jpg",
            "test_274_8.jpg",
            "test_274_6.jpg",
            "test_274_7.jpg",
            "test_274_0.jpg",
            "test_274_4.jpg",
            "test_274_3.jpg",
            "test_274_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.19999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.195022702217102,
            1.0778651237487793,
            1.4736778736114502,
            0.6986785531044006,
            0.054675959050655365,
            -1.7933472394943237,
            0.4699227511882782,
            0.04745800420641899,
            0.8659840226173401
          ],
          "order_indices": [
            2,
            0,
            1,
            8,
            3,
            6,
            4,
            7,
            5
          ],
          "order_filenames": [
            "test_274_2.jpg",
            "test_274_0.jpg",
            "test_274_1.jpg",
            "test_274_8.jpg",
            "test_274_3.jpg",
            "test_274_6.jpg",
            "test_274_4.jpg",
            "test_274_7.jpg",
            "test_274_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.1333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 275,
      "prompt": "Michal Karcz has painted a beautiful landscape, featuring purple trees with intricate and elegant details.",
      "image_filenames": [
        "test_275_0.jpg",
        "test_275_1.jpg",
        "test_275_2.jpg",
        "test_275_3.jpg",
        "test_275_4.jpg",
        "test_275_5.jpg",
        "test_275_6.jpg",
        "test_275_7.jpg",
        "test_275_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          3,
          8,
          6,
          2,
          0,
          5,
          4,
          1
        ],
        "order_filenames": [
          "test_275_7.jpg",
          "test_275_3.jpg",
          "test_275_8.jpg",
          "test_275_6.jpg",
          "test_275_2.jpg",
          "test_275_0.jpg",
          "test_275_5.jpg",
          "test_275_4.jpg",
          "test_275_1.jpg"
        ],
        "condorcet_winner": 7,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_275_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_275_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_275_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1715087890625,
            0.274169921875,
            0.218017578125,
            0.2396240234375,
            0.14111328125,
            0.1744384765625,
            0.263671875,
            0.2041015625,
            0.267578125
          ],
          "order_indices": [
            1,
            8,
            6,
            3,
            2,
            7,
            5,
            0,
            4
          ],
          "order_filenames": [
            "test_275_1.jpg",
            "test_275_8.jpg",
            "test_275_6.jpg",
            "test_275_3.jpg",
            "test_275_2.jpg",
            "test_275_7.jpg",
            "test_275_5.jpg",
            "test_275_0.jpg",
            "test_275_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.16666666666666663,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            33.9375,
            31.9375,
            38.28125,
            24.671875,
            25.65625,
            29.5625,
            35.8125,
            33.28125,
            24.703125
          ],
          "order_indices": [
            2,
            6,
            0,
            7,
            1,
            5,
            4,
            8,
            3
          ],
          "order_filenames": [
            "test_275_2.jpg",
            "test_275_6.jpg",
            "test_275_0.jpg",
            "test_275_7.jpg",
            "test_275_1.jpg",
            "test_275_5.jpg",
            "test_275_4.jpg",
            "test_275_8.jpg",
            "test_275_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.08333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.3676096796989441,
            1.4953811168670654,
            0.913497269153595,
            0.377202570438385,
            -1.9406217336654663,
            0.37404221296310425,
            1.6622072458267212,
            0.20744848251342773,
            1.4883010387420654
          ],
          "order_indices": [
            6,
            1,
            8,
            2,
            3,
            5,
            7,
            0,
            4
          ],
          "order_filenames": [
            "test_275_6.jpg",
            "test_275_1.jpg",
            "test_275_8.jpg",
            "test_275_2.jpg",
            "test_275_3.jpg",
            "test_275_5.jpg",
            "test_275_7.jpg",
            "test_275_0.jpg",
            "test_275_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.08333333333333337,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 276,
      "prompt": "Portrait of a black man with open mouth, viewed from below, in the style of Lucian Freud.",
      "image_filenames": [
        "test_276_0.jpg",
        "test_276_1.jpg",
        "test_276_2.jpg",
        "test_276_3.jpg",
        "test_276_4.jpg",
        "test_276_5.jpg",
        "test_276_6.jpg",
        "test_276_7.jpg",
        "test_276_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          4,
          0,
          5,
          6,
          3,
          2,
          1,
          8
        ],
        "order_filenames": [
          "test_276_7.jpg",
          "test_276_4.jpg",
          "test_276_0.jpg",
          "test_276_5.jpg",
          "test_276_6.jpg",
          "test_276_3.jpg",
          "test_276_2.jpg",
          "test_276_1.jpg",
          "test_276_8.jpg"
        ],
        "condorcet_winner": 7,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_276_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_276_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_276_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.14208984375,
            0.26611328125,
            0.250244140625,
            0.192138671875,
            0.1568603515625,
            0.1070556640625,
            0.237060546875,
            0.2060546875,
            0.270263671875
          ],
          "order_indices": [
            8,
            1,
            2,
            6,
            7,
            3,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_276_8.jpg",
            "test_276_1.jpg",
            "test_276_2.jpg",
            "test_276_6.jpg",
            "test_276_7.jpg",
            "test_276_3.jpg",
            "test_276_4.jpg",
            "test_276_0.jpg",
            "test_276_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5555555555555556,
            "spearman_rho": -0.7333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.75,
            34.5,
            39.625,
            27.921875,
            25.578125,
            19.453125,
            43.34375,
            42.09375,
            42.15625
          ],
          "order_indices": [
            6,
            8,
            7,
            0,
            2,
            1,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_276_6.jpg",
            "test_276_8.jpg",
            "test_276_7.jpg",
            "test_276_0.jpg",
            "test_276_2.jpg",
            "test_276_1.jpg",
            "test_276_3.jpg",
            "test_276_4.jpg",
            "test_276_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.16666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.7678393125534058,
            0.9123111367225647,
            1.5714033842086792,
            0.13212747871875763,
            -1.7236649990081787,
            -2.2804036140441895,
            1.6593488454818726,
            -0.08845467120409012,
            1.61301851272583
          ],
          "order_indices": [
            6,
            8,
            2,
            1,
            3,
            7,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_276_6.jpg",
            "test_276_8.jpg",
            "test_276_2.jpg",
            "test_276_1.jpg",
            "test_276_3.jpg",
            "test_276_7.jpg",
            "test_276_4.jpg",
            "test_276_0.jpg",
            "test_276_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.6499999999999999,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 277,
      "prompt": "Whimsical creatures in a dark, surreal painting by Ronny Khalil.",
      "image_filenames": [
        "test_277_0.jpg",
        "test_277_1.jpg",
        "test_277_2.jpg",
        "test_277_3.jpg",
        "test_277_4.jpg",
        "test_277_5.jpg",
        "test_277_6.jpg",
        "test_277_7.jpg",
        "test_277_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          0,
          5,
          3,
          7,
          6,
          8,
          1,
          2
        ],
        "order_filenames": [
          "test_277_4.jpg",
          "test_277_0.jpg",
          "test_277_5.jpg",
          "test_277_3.jpg",
          "test_277_7.jpg",
          "test_277_6.jpg",
          "test_277_8.jpg",
          "test_277_1.jpg",
          "test_277_2.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_277_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_277_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_277_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.206787109375,
            0.23486328125,
            0.2205810546875,
            0.15234375,
            0.1920166015625,
            0.1151123046875,
            0.2449951171875,
            0.2481689453125,
            0.218505859375
          ],
          "order_indices": [
            7,
            6,
            1,
            2,
            8,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_277_7.jpg",
            "test_277_6.jpg",
            "test_277_1.jpg",
            "test_277_2.jpg",
            "test_277_8.jpg",
            "test_277_0.jpg",
            "test_277_4.jpg",
            "test_277_3.jpg",
            "test_277_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.5833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.09375,
            35.875,
            35.90625,
            30.171875,
            25.125,
            12.3046875,
            39.8125,
            40.4375,
            41.71875
          ],
          "order_indices": [
            8,
            7,
            6,
            0,
            2,
            1,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_277_8.jpg",
            "test_277_7.jpg",
            "test_277_6.jpg",
            "test_277_0.jpg",
            "test_277_2.jpg",
            "test_277_1.jpg",
            "test_277_3.jpg",
            "test_277_4.jpg",
            "test_277_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.43333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.3783535063266754,
            0.20038941502571106,
            -0.9454952478408813,
            -0.330789178609848,
            0.01408930029720068,
            -1.7596460580825806,
            0.7376956343650818,
            0.9097527265548706,
            0.2902369797229767
          ],
          "order_indices": [
            7,
            6,
            0,
            8,
            1,
            4,
            3,
            2,
            5
          ],
          "order_filenames": [
            "test_277_7.jpg",
            "test_277_6.jpg",
            "test_277_0.jpg",
            "test_277_8.jpg",
            "test_277_1.jpg",
            "test_277_4.jpg",
            "test_277_3.jpg",
            "test_277_2.jpg",
            "test_277_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": -0.016666666666666607,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 278,
      "prompt": "A falcon in flight, depicted in a highly detailed painting by Ilya Repin, Phil Hale, and Kent Williams.",
      "image_filenames": [
        "test_278_0.jpg",
        "test_278_1.jpg",
        "test_278_2.jpg",
        "test_278_3.jpg",
        "test_278_4.jpg",
        "test_278_5.jpg",
        "test_278_6.jpg",
        "test_278_7.jpg",
        "test_278_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          3,
          6,
          2,
          7,
          1,
          4,
          8,
          0
        ],
        "order_filenames": [
          "test_278_5.jpg",
          "test_278_3.jpg",
          "test_278_6.jpg",
          "test_278_2.jpg",
          "test_278_7.jpg",
          "test_278_1.jpg",
          "test_278_4.jpg",
          "test_278_8.jpg",
          "test_278_0.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_278_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5,
            6
          ],
          "winner_filenames": [
            "test_278_5.jpg",
            "test_278_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_278_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.190673828125,
            0.2347412109375,
            0.221435546875,
            0.155517578125,
            0.163818359375,
            0.1982421875,
            0.257080078125,
            0.19775390625,
            0.261962890625
          ],
          "order_indices": [
            8,
            6,
            1,
            2,
            5,
            7,
            0,
            4,
            3
          ],
          "order_filenames": [
            "test_278_8.jpg",
            "test_278_6.jpg",
            "test_278_1.jpg",
            "test_278_2.jpg",
            "test_278_5.jpg",
            "test_278_7.jpg",
            "test_278_0.jpg",
            "test_278_4.jpg",
            "test_278_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.08333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            45.5625,
            36.5,
            42.59375,
            32.75,
            33.8125,
            31.296875,
            34.40625,
            44.4375,
            32.625
          ],
          "order_indices": [
            0,
            7,
            2,
            1,
            6,
            4,
            3,
            8,
            5
          ],
          "order_filenames": [
            "test_278_0.jpg",
            "test_278_7.jpg",
            "test_278_2.jpg",
            "test_278_1.jpg",
            "test_278_6.jpg",
            "test_278_4.jpg",
            "test_278_3.jpg",
            "test_278_8.jpg",
            "test_278_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.43333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.05895603075623512,
            1.51563560962677,
            1.3961162567138672,
            -1.441977858543396,
            -0.3307432532310486,
            -0.3664742410182953,
            1.265058159828186,
            -0.2917698323726654,
            1.360770583152771
          ],
          "order_indices": [
            1,
            2,
            8,
            6,
            0,
            7,
            4,
            5,
            3
          ],
          "order_filenames": [
            "test_278_1.jpg",
            "test_278_2.jpg",
            "test_278_8.jpg",
            "test_278_6.jpg",
            "test_278_0.jpg",
            "test_278_7.jpg",
            "test_278_4.jpg",
            "test_278_5.jpg",
            "test_278_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.41666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 279,
      "prompt": "A portrait painting of Lashaundra Garrette.",
      "image_filenames": [
        "test_279_0.jpg",
        "test_279_1.jpg",
        "test_279_2.jpg",
        "test_279_3.jpg",
        "test_279_4.jpg",
        "test_279_5.jpg",
        "test_279_6.jpg",
        "test_279_7.jpg",
        "test_279_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          4,
          0,
          1,
          6,
          3,
          7,
          8,
          2
        ],
        "order_filenames": [
          "test_279_5.jpg",
          "test_279_4.jpg",
          "test_279_0.jpg",
          "test_279_1.jpg",
          "test_279_6.jpg",
          "test_279_3.jpg",
          "test_279_7.jpg",
          "test_279_8.jpg",
          "test_279_2.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_279_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_279_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_279_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.143798828125,
            0.2083740234375,
            0.242919921875,
            0.14501953125,
            0.1392822265625,
            0.10357666015625,
            0.1871337890625,
            0.1771240234375,
            0.21728515625
          ],
          "order_indices": [
            2,
            8,
            1,
            6,
            7,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_279_2.jpg",
            "test_279_8.jpg",
            "test_279_1.jpg",
            "test_279_6.jpg",
            "test_279_7.jpg",
            "test_279_3.jpg",
            "test_279_0.jpg",
            "test_279_4.jpg",
            "test_279_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.7222222222222222,
            "spearman_rho": -0.8500000000000001,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.53125,
            35.59375,
            37.6875,
            32.4375,
            21.703125,
            15.78125,
            36.90625,
            37.5625,
            35.25
          ],
          "order_indices": [
            2,
            7,
            6,
            1,
            0,
            8,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_279_2.jpg",
            "test_279_7.jpg",
            "test_279_6.jpg",
            "test_279_1.jpg",
            "test_279_0.jpg",
            "test_279_8.jpg",
            "test_279_3.jpg",
            "test_279_4.jpg",
            "test_279_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.6111111111111112,
            "spearman_rho": -0.6833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.1913217306137085,
            0.9499658942222595,
            1.428210973739624,
            0.33510079979896545,
            -0.7204010486602783,
            -2.1254470348358154,
            1.0550185441970825,
            -0.9777514338493347,
            0.863606870174408
          ],
          "order_indices": [
            2,
            6,
            1,
            8,
            3,
            4,
            7,
            0,
            5
          ],
          "order_filenames": [
            "test_279_2.jpg",
            "test_279_6.jpg",
            "test_279_1.jpg",
            "test_279_8.jpg",
            "test_279_3.jpg",
            "test_279_4.jpg",
            "test_279_7.jpg",
            "test_279_0.jpg",
            "test_279_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.6333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 280,
      "prompt": "A polar expedition unloads from a ship in the 19th century in an intricate and elegant fantasy illustration.",
      "image_filenames": [
        "test_280_0.jpg",
        "test_280_1.jpg",
        "test_280_2.jpg",
        "test_280_3.jpg",
        "test_280_4.jpg",
        "test_280_5.jpg",
        "test_280_6.jpg",
        "test_280_7.jpg",
        "test_280_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          1,
          8,
          5,
          2,
          4,
          3,
          6,
          0
        ],
        "order_filenames": [
          "test_280_7.jpg",
          "test_280_1.jpg",
          "test_280_8.jpg",
          "test_280_5.jpg",
          "test_280_2.jpg",
          "test_280_4.jpg",
          "test_280_3.jpg",
          "test_280_6.jpg",
          "test_280_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_280_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            8
          ],
          "winner_filenames": [
            "test_280_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_280_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.153076171875,
            0.2373046875,
            0.2071533203125,
            0.203125,
            0.177001953125,
            0.1351318359375,
            0.205810546875,
            0.21337890625,
            0.2239990234375
          ],
          "order_indices": [
            1,
            8,
            7,
            2,
            6,
            3,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_280_1.jpg",
            "test_280_8.jpg",
            "test_280_7.jpg",
            "test_280_2.jpg",
            "test_280_6.jpg",
            "test_280_3.jpg",
            "test_280_4.jpg",
            "test_280_0.jpg",
            "test_280_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.4444444444444444,
            "spearman_rho": 0.6333333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.40625,
            36.25,
            40.5625,
            37.28125,
            26.09375,
            28.53125,
            36.40625,
            37.71875,
            33.625
          ],
          "order_indices": [
            2,
            7,
            0,
            3,
            6,
            1,
            8,
            5,
            4
          ],
          "order_filenames": [
            "test_280_2.jpg",
            "test_280_7.jpg",
            "test_280_0.jpg",
            "test_280_3.jpg",
            "test_280_6.jpg",
            "test_280_1.jpg",
            "test_280_8.jpg",
            "test_280_5.jpg",
            "test_280_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.3846244215965271,
            -0.2718835771083832,
            -0.026607947424054146,
            -0.05613576993346214,
            -0.2004215568304062,
            -1.1381679773330688,
            -0.31626904010772705,
            0.43684273958206177,
            0.5294797420501709
          ],
          "order_indices": [
            8,
            7,
            2,
            3,
            4,
            1,
            6,
            0,
            5
          ],
          "order_filenames": [
            "test_280_8.jpg",
            "test_280_7.jpg",
            "test_280_2.jpg",
            "test_280_3.jpg",
            "test_280_4.jpg",
            "test_280_1.jpg",
            "test_280_6.jpg",
            "test_280_0.jpg",
            "test_280_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3888888888888889,
            "spearman_rho": 0.4833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 281,
      "prompt": "Close-up view of ancient Greek ruins set against a colourful, starry night sky creating a mystical atmosphere.",
      "image_filenames": [
        "test_281_0.jpg",
        "test_281_1.jpg",
        "test_281_2.jpg",
        "test_281_3.jpg",
        "test_281_4.jpg",
        "test_281_5.jpg",
        "test_281_6.jpg",
        "test_281_7.jpg",
        "test_281_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          6,
          1,
          3,
          0,
          2,
          5,
          8,
          7
        ],
        "order_filenames": [
          "test_281_4.jpg",
          "test_281_6.jpg",
          "test_281_1.jpg",
          "test_281_3.jpg",
          "test_281_0.jpg",
          "test_281_2.jpg",
          "test_281_5.jpg",
          "test_281_8.jpg",
          "test_281_7.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_281_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_281_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_281_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2314453125,
            0.2384033203125,
            0.294677734375,
            0.2149658203125,
            0.1717529296875,
            0.22412109375,
            0.307861328125,
            0.245849609375,
            0.20947265625
          ],
          "order_indices": [
            6,
            2,
            7,
            1,
            0,
            5,
            3,
            8,
            4
          ],
          "order_filenames": [
            "test_281_6.jpg",
            "test_281_2.jpg",
            "test_281_7.jpg",
            "test_281_1.jpg",
            "test_281_0.jpg",
            "test_281_5.jpg",
            "test_281_3.jpg",
            "test_281_8.jpg",
            "test_281_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.96875,
            34.90625,
            40.71875,
            36.09375,
            26.125,
            37.40625,
            36.53125,
            42.40625,
            43.4375
          ],
          "order_indices": [
            8,
            7,
            0,
            2,
            5,
            6,
            3,
            1,
            4
          ],
          "order_filenames": [
            "test_281_8.jpg",
            "test_281_7.jpg",
            "test_281_0.jpg",
            "test_281_2.jpg",
            "test_281_5.jpg",
            "test_281_6.jpg",
            "test_281_3.jpg",
            "test_281_1.jpg",
            "test_281_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.6666666666666666,
            "spearman_rho": -0.8666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.3347259759902954,
            1.5514228343963623,
            1.6459217071533203,
            0.9704282879829407,
            -1.130892276763916,
            0.5630200505256653,
            1.8395081758499146,
            0.5628584027290344,
            -0.39795202016830444
          ],
          "order_indices": [
            6,
            2,
            1,
            0,
            3,
            5,
            7,
            8,
            4
          ],
          "order_filenames": [
            "test_281_6.jpg",
            "test_281_2.jpg",
            "test_281_1.jpg",
            "test_281_0.jpg",
            "test_281_3.jpg",
            "test_281_5.jpg",
            "test_281_7.jpg",
            "test_281_8.jpg",
            "test_281_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2777777777777778,
            "spearman_rho": 0.2666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 282,
      "prompt": "A Monet portrait.",
      "image_filenames": [
        "test_282_0.jpg",
        "test_282_1.jpg",
        "test_282_2.jpg",
        "test_282_3.jpg",
        "test_282_4.jpg",
        "test_282_5.jpg",
        "test_282_6.jpg",
        "test_282_7.jpg",
        "test_282_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          4,
          1,
          2,
          0,
          7,
          8,
          5,
          6
        ],
        "order_filenames": [
          "test_282_3.jpg",
          "test_282_4.jpg",
          "test_282_1.jpg",
          "test_282_2.jpg",
          "test_282_0.jpg",
          "test_282_7.jpg",
          "test_282_8.jpg",
          "test_282_5.jpg",
          "test_282_6.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_282_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_282_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3,
            4
          ],
          "winner_filenames": [
            "test_282_3.jpg",
            "test_282_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.17529296875,
            0.2176513671875,
            0.281005859375,
            0.1890869140625,
            0.12017822265625,
            0.1337890625,
            0.2724609375,
            0.2281494140625,
            0.179443359375
          ],
          "order_indices": [
            2,
            6,
            7,
            1,
            3,
            8,
            0,
            5,
            4
          ],
          "order_filenames": [
            "test_282_2.jpg",
            "test_282_6.jpg",
            "test_282_7.jpg",
            "test_282_1.jpg",
            "test_282_3.jpg",
            "test_282_8.jpg",
            "test_282_0.jpg",
            "test_282_5.jpg",
            "test_282_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.1499999999999999,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.21875,
            30.515625,
            38.46875,
            27.625,
            26.46875,
            11.0390625,
            33.9375,
            37.96875,
            32.1875
          ],
          "order_indices": [
            0,
            2,
            7,
            6,
            8,
            1,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_282_0.jpg",
            "test_282_2.jpg",
            "test_282_7.jpg",
            "test_282_6.jpg",
            "test_282_8.jpg",
            "test_282_1.jpg",
            "test_282_3.jpg",
            "test_282_4.jpg",
            "test_282_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.16666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.14367066323757172,
            -1.429796814918518,
            1.5067214965820312,
            -0.0290901567786932,
            -2.268721103668213,
            -2.1902873516082764,
            0.7119569182395935,
            0.5524320006370544,
            -1.7754085063934326
          ],
          "order_indices": [
            2,
            6,
            7,
            0,
            3,
            1,
            8,
            5,
            4
          ],
          "order_filenames": [
            "test_282_2.jpg",
            "test_282_6.jpg",
            "test_282_7.jpg",
            "test_282_0.jpg",
            "test_282_3.jpg",
            "test_282_1.jpg",
            "test_282_8.jpg",
            "test_282_5.jpg",
            "test_282_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.18333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 283,
      "prompt": "A portrait painting of Roxie Kownacki.",
      "image_filenames": [
        "test_283_0.jpg",
        "test_283_1.jpg",
        "test_283_2.jpg",
        "test_283_3.jpg",
        "test_283_4.jpg",
        "test_283_5.jpg",
        "test_283_6.jpg",
        "test_283_7.jpg",
        "test_283_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          8,
          2,
          3,
          5,
          7,
          6,
          4,
          1,
          0
        ],
        "order_filenames": [
          "test_283_8.jpg",
          "test_283_2.jpg",
          "test_283_3.jpg",
          "test_283_5.jpg",
          "test_283_7.jpg",
          "test_283_6.jpg",
          "test_283_4.jpg",
          "test_283_1.jpg",
          "test_283_0.jpg"
        ],
        "condorcet_winner": 8,
        "winner_indices": [
          8
        ],
        "winner_filenames": [
          "test_283_8.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            8
          ],
          "winner_filenames": [
            "test_283_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            8
          ],
          "winner_filenames": [
            "test_283_8.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.16357421875,
            0.1937255859375,
            0.1982421875,
            0.1357421875,
            0.12469482421875,
            0.1212158203125,
            0.20263671875,
            0.1890869140625,
            0.2529296875
          ],
          "order_indices": [
            8,
            6,
            2,
            1,
            7,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_283_8.jpg",
            "test_283_6.jpg",
            "test_283_2.jpg",
            "test_283_1.jpg",
            "test_283_7.jpg",
            "test_283_0.jpg",
            "test_283_3.jpg",
            "test_283_4.jpg",
            "test_283_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.30000000000000004,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 1.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            30.265625,
            37.6875,
            35.0625,
            24.8125,
            24.59375,
            20.59375,
            36.78125,
            34.8125,
            33.65625
          ],
          "order_indices": [
            1,
            6,
            2,
            7,
            8,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_283_1.jpg",
            "test_283_6.jpg",
            "test_283_2.jpg",
            "test_283_7.jpg",
            "test_283_8.jpg",
            "test_283_0.jpg",
            "test_283_3.jpg",
            "test_283_4.jpg",
            "test_283_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.1166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.0536165237426758,
            1.6109856367111206,
            0.8644990921020508,
            0.07601658254861832,
            -0.10809865593910217,
            -1.5806699991226196,
            1.4310550689697266,
            0.5342665314674377,
            1.8267991542816162
          ],
          "order_indices": [
            8,
            1,
            6,
            2,
            7,
            3,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_283_8.jpg",
            "test_283_1.jpg",
            "test_283_6.jpg",
            "test_283_2.jpg",
            "test_283_7.jpg",
            "test_283_3.jpg",
            "test_283_4.jpg",
            "test_283_0.jpg",
            "test_283_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.30000000000000004,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 1.0,
            "exact_position_match": 0.3333333333333333,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 284,
      "prompt": "A cave painting of a Stone Age party.",
      "image_filenames": [
        "test_284_0.jpg",
        "test_284_1.jpg",
        "test_284_2.jpg",
        "test_284_3.jpg",
        "test_284_4.jpg",
        "test_284_5.jpg",
        "test_284_6.jpg",
        "test_284_7.jpg",
        "test_284_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          2,
          3,
          4,
          7,
          5,
          6,
          8,
          1
        ],
        "order_filenames": [
          "test_284_0.jpg",
          "test_284_2.jpg",
          "test_284_3.jpg",
          "test_284_4.jpg",
          "test_284_7.jpg",
          "test_284_5.jpg",
          "test_284_6.jpg",
          "test_284_8.jpg",
          "test_284_1.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_284_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_284_3.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_284_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1990966796875,
            0.19091796875,
            0.2213134765625,
            0.2030029296875,
            0.20751953125,
            0.1444091796875,
            0.20849609375,
            0.2200927734375,
            0.1964111328125
          ],
          "order_indices": [
            2,
            7,
            6,
            4,
            3,
            0,
            8,
            1,
            5
          ],
          "order_filenames": [
            "test_284_2.jpg",
            "test_284_7.jpg",
            "test_284_6.jpg",
            "test_284_4.jpg",
            "test_284_3.jpg",
            "test_284_0.jpg",
            "test_284_8.jpg",
            "test_284_1.jpg",
            "test_284_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2777777777777778,
            "spearman_rho": 0.44999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.78125,
            34.25,
            35.28125,
            29.546875,
            31.53125,
            31.875,
            35.53125,
            41.1875,
            35.5625
          ],
          "order_indices": [
            7,
            0,
            8,
            6,
            2,
            1,
            5,
            4,
            3
          ],
          "order_filenames": [
            "test_284_7.jpg",
            "test_284_0.jpg",
            "test_284_8.jpg",
            "test_284_6.jpg",
            "test_284_2.jpg",
            "test_284_1.jpg",
            "test_284_5.jpg",
            "test_284_4.jpg",
            "test_284_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.016666666666666607,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.1070312112569809,
            0.4142630398273468,
            0.5450802445411682,
            -0.2065146565437317,
            0.4029902219772339,
            -0.8400627374649048,
            0.4079878032207489,
            0.7775260806083679,
            1.173852562904358
          ],
          "order_indices": [
            8,
            7,
            2,
            1,
            6,
            4,
            0,
            3,
            5
          ],
          "order_filenames": [
            "test_284_8.jpg",
            "test_284_7.jpg",
            "test_284_2.jpg",
            "test_284_1.jpg",
            "test_284_6.jpg",
            "test_284_4.jpg",
            "test_284_0.jpg",
            "test_284_3.jpg",
            "test_284_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.3500000000000001,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 285,
      "prompt": "An oil on canvas painting depicting a surreal cognitive illusion of a key, by artists Oleg Shupliak and Jeffrey Smith, with nods to Afrofuturism and surrealism.",
      "image_filenames": [
        "test_285_0.jpg",
        "test_285_1.jpg",
        "test_285_2.jpg",
        "test_285_3.jpg",
        "test_285_4.jpg",
        "test_285_5.jpg",
        "test_285_6.jpg",
        "test_285_7.jpg",
        "test_285_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          2,
          5,
          6,
          4,
          3,
          7,
          8,
          0
        ],
        "order_filenames": [
          "test_285_1.jpg",
          "test_285_2.jpg",
          "test_285_5.jpg",
          "test_285_6.jpg",
          "test_285_4.jpg",
          "test_285_3.jpg",
          "test_285_7.jpg",
          "test_285_8.jpg",
          "test_285_0.jpg"
        ],
        "condorcet_winner": 1,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_285_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_285_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_285_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.207763671875,
            0.1683349609375,
            0.1795654296875,
            0.18603515625,
            0.160400390625,
            0.1302490234375,
            0.17626953125,
            0.236572265625,
            0.25048828125
          ],
          "order_indices": [
            8,
            7,
            0,
            3,
            2,
            6,
            1,
            4,
            5
          ],
          "order_filenames": [
            "test_285_8.jpg",
            "test_285_7.jpg",
            "test_285_0.jpg",
            "test_285_3.jpg",
            "test_285_2.jpg",
            "test_285_6.jpg",
            "test_285_1.jpg",
            "test_285_4.jpg",
            "test_285_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5555555555555556,
            "spearman_rho": -0.7333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.84375,
            30.40625,
            41.96875,
            28.765625,
            14.90625,
            23.3125,
            33.40625,
            40.40625,
            44.28125
          ],
          "order_indices": [
            8,
            2,
            7,
            0,
            6,
            1,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_285_8.jpg",
            "test_285_2.jpg",
            "test_285_7.jpg",
            "test_285_0.jpg",
            "test_285_6.jpg",
            "test_285_1.jpg",
            "test_285_3.jpg",
            "test_285_5.jpg",
            "test_285_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.31666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.45531970262527466,
            -0.20899425446987152,
            0.7772791385650635,
            -0.7257676720619202,
            0.051605597138404846,
            -0.6119162440299988,
            0.039383795112371445,
            1.5319291353225708,
            1.2304660081863403
          ],
          "order_indices": [
            7,
            8,
            2,
            0,
            4,
            6,
            1,
            5,
            3
          ],
          "order_filenames": [
            "test_285_7.jpg",
            "test_285_8.jpg",
            "test_285_2.jpg",
            "test_285_0.jpg",
            "test_285_4.jpg",
            "test_285_6.jpg",
            "test_285_1.jpg",
            "test_285_5.jpg",
            "test_285_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.43333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 286,
      "prompt": "A Weezer album painted by Hieronymus Bosch.",
      "image_filenames": [
        "test_286_0.jpg",
        "test_286_1.jpg",
        "test_286_2.jpg",
        "test_286_3.jpg",
        "test_286_4.jpg",
        "test_286_5.jpg",
        "test_286_6.jpg",
        "test_286_7.jpg",
        "test_286_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          3,
          0,
          5,
          2,
          4,
          1,
          8,
          7
        ],
        "order_filenames": [
          "test_286_6.jpg",
          "test_286_3.jpg",
          "test_286_0.jpg",
          "test_286_5.jpg",
          "test_286_2.jpg",
          "test_286_4.jpg",
          "test_286_1.jpg",
          "test_286_8.jpg",
          "test_286_7.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_286_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_286_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_286_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1573486328125,
            0.230224609375,
            0.1944580078125,
            0.1866455078125,
            0.1533203125,
            0.12646484375,
            0.212890625,
            0.192138671875,
            0.193359375
          ],
          "order_indices": [
            1,
            6,
            2,
            8,
            7,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_286_1.jpg",
            "test_286_6.jpg",
            "test_286_2.jpg",
            "test_286_8.jpg",
            "test_286_7.jpg",
            "test_286_3.jpg",
            "test_286_0.jpg",
            "test_286_4.jpg",
            "test_286_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.1166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.875,
            30.828125,
            38.03125,
            29.484375,
            31.140625,
            22.515625,
            28.15625,
            39.4375,
            34.3125
          ],
          "order_indices": [
            7,
            2,
            0,
            8,
            4,
            1,
            3,
            6,
            5
          ],
          "order_filenames": [
            "test_286_7.jpg",
            "test_286_2.jpg",
            "test_286_0.jpg",
            "test_286_8.jpg",
            "test_286_4.jpg",
            "test_286_1.jpg",
            "test_286_3.jpg",
            "test_286_6.jpg",
            "test_286_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.5833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.6225634217262268,
            0.32521915435791016,
            -0.3158320486545563,
            -1.0260215997695923,
            -1.3272377252578735,
            -2.0911412239074707,
            0.11931490898132324,
            0.9887485504150391,
            0.06342083215713501
          ],
          "order_indices": [
            7,
            1,
            6,
            8,
            2,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_286_7.jpg",
            "test_286_1.jpg",
            "test_286_6.jpg",
            "test_286_8.jpg",
            "test_286_2.jpg",
            "test_286_0.jpg",
            "test_286_3.jpg",
            "test_286_4.jpg",
            "test_286_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.43333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 287,
      "prompt": "A painting by Ludek Marold of cattle grazing in a field, done in oil on canvas.",
      "image_filenames": [
        "test_287_0.jpg",
        "test_287_1.jpg",
        "test_287_2.jpg",
        "test_287_3.jpg",
        "test_287_4.jpg",
        "test_287_5.jpg",
        "test_287_6.jpg",
        "test_287_7.jpg",
        "test_287_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          1,
          2,
          5,
          3,
          7,
          6,
          8,
          0
        ],
        "order_filenames": [
          "test_287_4.jpg",
          "test_287_1.jpg",
          "test_287_2.jpg",
          "test_287_5.jpg",
          "test_287_3.jpg",
          "test_287_7.jpg",
          "test_287_6.jpg",
          "test_287_8.jpg",
          "test_287_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_287_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_287_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_287_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.195556640625,
            0.2269287109375,
            0.209228515625,
            0.1884765625,
            0.2100830078125,
            0.1771240234375,
            0.197998046875,
            0.1962890625,
            0.25146484375
          ],
          "order_indices": [
            8,
            1,
            4,
            2,
            6,
            7,
            0,
            3,
            5
          ],
          "order_filenames": [
            "test_287_8.jpg",
            "test_287_1.jpg",
            "test_287_4.jpg",
            "test_287_2.jpg",
            "test_287_6.jpg",
            "test_287_7.jpg",
            "test_287_0.jpg",
            "test_287_3.jpg",
            "test_287_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.19999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.90625,
            30.28125,
            33.90625,
            31.984375,
            30.203125,
            36.9375,
            35.09375,
            37.53125,
            37.25
          ],
          "order_indices": [
            7,
            8,
            5,
            0,
            6,
            2,
            3,
            1,
            4
          ],
          "order_filenames": [
            "test_287_7.jpg",
            "test_287_8.jpg",
            "test_287_5.jpg",
            "test_287_0.jpg",
            "test_287_6.jpg",
            "test_287_2.jpg",
            "test_287_3.jpg",
            "test_287_1.jpg",
            "test_287_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5555555555555556,
            "spearman_rho": -0.7,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.8872179985046387,
            0.06092972308397293,
            0.7679110169410706,
            -0.7016283869743347,
            0.71662837266922,
            0.002172201406210661,
            0.292863130569458,
            0.6898586750030518,
            0.8592736124992371
          ],
          "order_indices": [
            0,
            8,
            2,
            4,
            7,
            6,
            1,
            5,
            3
          ],
          "order_filenames": [
            "test_287_0.jpg",
            "test_287_8.jpg",
            "test_287_2.jpg",
            "test_287_4.jpg",
            "test_287_7.jpg",
            "test_287_6.jpg",
            "test_287_1.jpg",
            "test_287_5.jpg",
            "test_287_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.3999999999999999,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 288,
      "prompt": "The image depicts a Sri Lankan king, created by artist Nizovtsev, Victor.",
      "image_filenames": [
        "test_288_0.jpg",
        "test_288_1.jpg",
        "test_288_2.jpg",
        "test_288_3.jpg",
        "test_288_4.jpg",
        "test_288_5.jpg",
        "test_288_6.jpg",
        "test_288_7.jpg",
        "test_288_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          4,
          2,
          1,
          0,
          7,
          8,
          6,
          3
        ],
        "order_filenames": [
          "test_288_5.jpg",
          "test_288_4.jpg",
          "test_288_2.jpg",
          "test_288_1.jpg",
          "test_288_0.jpg",
          "test_288_7.jpg",
          "test_288_8.jpg",
          "test_288_6.jpg",
          "test_288_3.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_288_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_288_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_288_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.19775390625,
            0.288330078125,
            0.311767578125,
            0.2060546875,
            0.146728515625,
            0.088623046875,
            0.309814453125,
            0.21240234375,
            0.308349609375
          ],
          "order_indices": [
            2,
            6,
            8,
            1,
            7,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_288_2.jpg",
            "test_288_6.jpg",
            "test_288_8.jpg",
            "test_288_1.jpg",
            "test_288_7.jpg",
            "test_288_3.jpg",
            "test_288_0.jpg",
            "test_288_4.jpg",
            "test_288_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.41666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.25,
            36.59375,
            35.375,
            39.3125,
            27.28125,
            18.796875,
            35.96875,
            39.03125,
            40.21875
          ],
          "order_indices": [
            8,
            3,
            0,
            7,
            1,
            6,
            2,
            4,
            5
          ],
          "order_filenames": [
            "test_288_8.jpg",
            "test_288_3.jpg",
            "test_288_0.jpg",
            "test_288_7.jpg",
            "test_288_1.jpg",
            "test_288_6.jpg",
            "test_288_2.jpg",
            "test_288_4.jpg",
            "test_288_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.6666666666666666,
            "spearman_rho": -0.7833333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.495872974395752,
            1.514029860496521,
            1.6183667182922363,
            0.6852317452430725,
            -1.754852294921875,
            -2.2765238285064697,
            1.702847957611084,
            1.023780345916748,
            1.182300090789795
          ],
          "order_indices": [
            6,
            2,
            1,
            0,
            8,
            7,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_288_6.jpg",
            "test_288_2.jpg",
            "test_288_1.jpg",
            "test_288_0.jpg",
            "test_288_8.jpg",
            "test_288_7.jpg",
            "test_288_3.jpg",
            "test_288_4.jpg",
            "test_288_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.33333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 289,
      "prompt": "A semirealistic digital painting of a Japanese schoolgirl in a gentle grayish color palette, by Chinese artists on ArtStation.",
      "image_filenames": [
        "test_289_0.jpg",
        "test_289_1.jpg",
        "test_289_2.jpg",
        "test_289_3.jpg",
        "test_289_4.jpg",
        "test_289_5.jpg",
        "test_289_6.jpg",
        "test_289_7.jpg",
        "test_289_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          4,
          2,
          6,
          5,
          8,
          1,
          7,
          0
        ],
        "order_filenames": [
          "test_289_3.jpg",
          "test_289_4.jpg",
          "test_289_2.jpg",
          "test_289_6.jpg",
          "test_289_5.jpg",
          "test_289_8.jpg",
          "test_289_1.jpg",
          "test_289_7.jpg",
          "test_289_0.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_289_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_289_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_289_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1673583984375,
            0.204833984375,
            0.24072265625,
            0.1505126953125,
            0.1409912109375,
            0.09771728515625,
            0.279052734375,
            0.2100830078125,
            0.283447265625
          ],
          "order_indices": [
            8,
            6,
            2,
            7,
            1,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_289_8.jpg",
            "test_289_6.jpg",
            "test_289_2.jpg",
            "test_289_7.jpg",
            "test_289_1.jpg",
            "test_289_0.jpg",
            "test_289_3.jpg",
            "test_289_4.jpg",
            "test_289_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.21666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.28125,
            43.3125,
            41.8125,
            37.5625,
            30.140625,
            10.2734375,
            40.15625,
            40.09375,
            42.53125
          ],
          "order_indices": [
            1,
            8,
            2,
            6,
            7,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_289_1.jpg",
            "test_289_8.jpg",
            "test_289_2.jpg",
            "test_289_6.jpg",
            "test_289_7.jpg",
            "test_289_0.jpg",
            "test_289_3.jpg",
            "test_289_4.jpg",
            "test_289_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.16666666666666666,
            "spearman_rho": -0.31666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.8337198495864868,
            0.004963181912899017,
            0.9057692289352417,
            -0.574969470500946,
            -1.1109777688980103,
            -2.191427707672119,
            1.385015606880188,
            0.6714979410171509,
            1.8105467557907104
          ],
          "order_indices": [
            8,
            6,
            2,
            7,
            1,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_289_8.jpg",
            "test_289_6.jpg",
            "test_289_2.jpg",
            "test_289_7.jpg",
            "test_289_1.jpg",
            "test_289_3.jpg",
            "test_289_0.jpg",
            "test_289_4.jpg",
            "test_289_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.08333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 290,
      "prompt": "A portrait of Frank Zappa smoking, with vivid neon colors, by various artists.",
      "image_filenames": [
        "test_290_0.jpg",
        "test_290_1.jpg",
        "test_290_2.jpg",
        "test_290_3.jpg",
        "test_290_4.jpg",
        "test_290_5.jpg",
        "test_290_6.jpg",
        "test_290_7.jpg",
        "test_290_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          4,
          3,
          1,
          5,
          0,
          2,
          6,
          8
        ],
        "order_filenames": [
          "test_290_7.jpg",
          "test_290_4.jpg",
          "test_290_3.jpg",
          "test_290_1.jpg",
          "test_290_5.jpg",
          "test_290_0.jpg",
          "test_290_2.jpg",
          "test_290_6.jpg",
          "test_290_8.jpg"
        ],
        "condorcet_winner": 7,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_290_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_290_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_290_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.177978515625,
            0.3466796875,
            0.279541015625,
            0.2120361328125,
            0.167724609375,
            0.135498046875,
            0.28125,
            0.26318359375,
            0.317138671875
          ],
          "order_indices": [
            1,
            8,
            6,
            2,
            7,
            3,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_290_1.jpg",
            "test_290_8.jpg",
            "test_290_6.jpg",
            "test_290_2.jpg",
            "test_290_7.jpg",
            "test_290_3.jpg",
            "test_290_0.jpg",
            "test_290_4.jpg",
            "test_290_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.41666666666666674,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            41.21875,
            37.75,
            36.4375,
            30.1875,
            22.53125,
            28.109375,
            37.78125,
            48.375,
            38.9375
          ],
          "order_indices": [
            7,
            0,
            8,
            6,
            1,
            2,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_290_7.jpg",
            "test_290_0.jpg",
            "test_290_8.jpg",
            "test_290_6.jpg",
            "test_290_1.jpg",
            "test_290_2.jpg",
            "test_290_3.jpg",
            "test_290_5.jpg",
            "test_290_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.19999999999999996,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 1.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.2576007843017578,
            1.7337772846221924,
            0.4644770622253418,
            0.9573530554771423,
            -0.18769054114818573,
            -1.6687384843826294,
            0.7538560032844543,
            1.249420404434204,
            1.8770701885223389
          ],
          "order_indices": [
            8,
            1,
            7,
            3,
            6,
            2,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_290_8.jpg",
            "test_290_1.jpg",
            "test_290_7.jpg",
            "test_290_3.jpg",
            "test_290_6.jpg",
            "test_290_2.jpg",
            "test_290_4.jpg",
            "test_290_0.jpg",
            "test_290_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 291,
      "prompt": "A portrait of Larry David playing poker by Sandra Chevrier, featured on Artstation.",
      "image_filenames": [
        "test_291_0.jpg",
        "test_291_1.jpg",
        "test_291_2.jpg",
        "test_291_3.jpg",
        "test_291_4.jpg",
        "test_291_5.jpg",
        "test_291_6.jpg",
        "test_291_7.jpg",
        "test_291_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          6,
          4,
          7,
          5,
          2,
          0,
          8,
          3
        ],
        "order_filenames": [
          "test_291_1.jpg",
          "test_291_6.jpg",
          "test_291_4.jpg",
          "test_291_7.jpg",
          "test_291_5.jpg",
          "test_291_2.jpg",
          "test_291_0.jpg",
          "test_291_8.jpg",
          "test_291_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_291_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_291_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_291_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.153564453125,
            0.2724609375,
            0.33740234375,
            0.2105712890625,
            0.152099609375,
            0.08355712890625,
            0.28955078125,
            0.205810546875,
            0.2568359375
          ],
          "order_indices": [
            2,
            6,
            1,
            8,
            3,
            7,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_291_2.jpg",
            "test_291_6.jpg",
            "test_291_1.jpg",
            "test_291_8.jpg",
            "test_291_3.jpg",
            "test_291_7.jpg",
            "test_291_0.jpg",
            "test_291_4.jpg",
            "test_291_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.1166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            33.4375,
            39.3125,
            42.5,
            27.40625,
            29.203125,
            5.6015625,
            42.34375,
            44.25,
            39.65625
          ],
          "order_indices": [
            7,
            2,
            6,
            8,
            1,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_291_7.jpg",
            "test_291_2.jpg",
            "test_291_6.jpg",
            "test_291_8.jpg",
            "test_291_1.jpg",
            "test_291_0.jpg",
            "test_291_4.jpg",
            "test_291_3.jpg",
            "test_291_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.23333333333333328,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.134350061416626,
            0.7179909944534302,
            1.5024844408035278,
            0.3015068769454956,
            0.12852881848812103,
            -2.274827241897583,
            1.3901182413101196,
            0.305148720741272,
            0.9881683588027954
          ],
          "order_indices": [
            2,
            6,
            8,
            1,
            7,
            3,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_291_2.jpg",
            "test_291_6.jpg",
            "test_291_8.jpg",
            "test_291_1.jpg",
            "test_291_7.jpg",
            "test_291_3.jpg",
            "test_291_4.jpg",
            "test_291_0.jpg",
            "test_291_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.15000000000000002,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 292,
      "prompt": "A digital painting of a small universe with intricate details and ornate features, featuring the styles of Claude Monet and Vincent van Gogh.",
      "image_filenames": [
        "test_292_0.jpg",
        "test_292_1.jpg",
        "test_292_2.jpg",
        "test_292_3.jpg",
        "test_292_4.jpg",
        "test_292_5.jpg",
        "test_292_6.jpg",
        "test_292_7.jpg",
        "test_292_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          4,
          3,
          8,
          0,
          1,
          5,
          7,
          6
        ],
        "order_filenames": [
          "test_292_2.jpg",
          "test_292_4.jpg",
          "test_292_3.jpg",
          "test_292_8.jpg",
          "test_292_0.jpg",
          "test_292_1.jpg",
          "test_292_5.jpg",
          "test_292_7.jpg",
          "test_292_6.jpg"
        ],
        "condorcet_winner": 2,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_292_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_292_1.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_292_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2369384765625,
            0.197998046875,
            0.2239990234375,
            0.1785888671875,
            0.1939697265625,
            0.175048828125,
            0.1656494140625,
            0.2086181640625,
            0.226318359375
          ],
          "order_indices": [
            0,
            8,
            2,
            7,
            1,
            4,
            3,
            5,
            6
          ],
          "order_filenames": [
            "test_292_0.jpg",
            "test_292_8.jpg",
            "test_292_2.jpg",
            "test_292_7.jpg",
            "test_292_1.jpg",
            "test_292_4.jpg",
            "test_292_3.jpg",
            "test_292_5.jpg",
            "test_292_6.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2777777777777778,
            "spearman_rho": 0.3833333333333333,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.28125,
            29.015625,
            37.8125,
            36.0,
            27.390625,
            29.90625,
            34.40625,
            40.03125,
            40.34375
          ],
          "order_indices": [
            8,
            7,
            0,
            2,
            3,
            6,
            5,
            1,
            4
          ],
          "order_filenames": [
            "test_292_8.jpg",
            "test_292_7.jpg",
            "test_292_0.jpg",
            "test_292_2.jpg",
            "test_292_3.jpg",
            "test_292_6.jpg",
            "test_292_5.jpg",
            "test_292_1.jpg",
            "test_292_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.03333333333333344,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.27369678020477295,
            -1.1091727018356323,
            -0.5579907894134521,
            -1.6403619050979614,
            -1.811208963394165,
            -1.8395894765853882,
            -1.1704334020614624,
            -0.49326199293136597,
            -0.4033169150352478
          ],
          "order_indices": [
            0,
            8,
            7,
            2,
            1,
            6,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_292_0.jpg",
            "test_292_8.jpg",
            "test_292_7.jpg",
            "test_292_2.jpg",
            "test_292_1.jpg",
            "test_292_6.jpg",
            "test_292_3.jpg",
            "test_292_4.jpg",
            "test_292_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.0,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 293,
      "prompt": "A white Persian cat wearing a peacock feather headdress and surrounded by flowers, in a magical realism painting.",
      "image_filenames": [
        "test_293_0.jpg",
        "test_293_1.jpg",
        "test_293_2.jpg",
        "test_293_3.jpg",
        "test_293_4.jpg",
        "test_293_5.jpg",
        "test_293_6.jpg",
        "test_293_7.jpg",
        "test_293_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          4,
          8,
          7,
          3,
          5,
          2,
          1,
          6
        ],
        "order_filenames": [
          "test_293_0.jpg",
          "test_293_4.jpg",
          "test_293_8.jpg",
          "test_293_7.jpg",
          "test_293_3.jpg",
          "test_293_5.jpg",
          "test_293_2.jpg",
          "test_293_1.jpg",
          "test_293_6.jpg"
        ],
        "condorcet_winner": 0,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_293_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            8
          ],
          "winner_filenames": [
            "test_293_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_293_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1754150390625,
            0.28173828125,
            0.3310546875,
            0.231201171875,
            0.2061767578125,
            0.1995849609375,
            0.3017578125,
            0.212890625,
            0.264404296875
          ],
          "order_indices": [
            2,
            6,
            1,
            8,
            3,
            7,
            4,
            5,
            0
          ],
          "order_filenames": [
            "test_293_2.jpg",
            "test_293_6.jpg",
            "test_293_1.jpg",
            "test_293_8.jpg",
            "test_293_3.jpg",
            "test_293_7.jpg",
            "test_293_4.jpg",
            "test_293_5.jpg",
            "test_293_0.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5555555555555556,
            "spearman_rho": -0.7333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.28125,
            40.6875,
            42.65625,
            37.625,
            30.59375,
            30.765625,
            45.375,
            36.03125,
            43.96875
          ],
          "order_indices": [
            6,
            8,
            2,
            1,
            3,
            0,
            7,
            5,
            4
          ],
          "order_filenames": [
            "test_293_6.jpg",
            "test_293_8.jpg",
            "test_293_2.jpg",
            "test_293_1.jpg",
            "test_293_3.jpg",
            "test_293_0.jpg",
            "test_293_7.jpg",
            "test_293_5.jpg",
            "test_293_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3888888888888889,
            "spearman_rho": -0.5333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.9251521825790405,
            1.7000776529312134,
            1.9079617261886597,
            1.4414628744125366,
            0.055260661989450455,
            -1.147022008895874,
            1.86940598487854,
            0.2121872901916504,
            1.6674240827560425
          ],
          "order_indices": [
            2,
            6,
            1,
            8,
            3,
            7,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_293_2.jpg",
            "test_293_6.jpg",
            "test_293_1.jpg",
            "test_293_8.jpg",
            "test_293_3.jpg",
            "test_293_7.jpg",
            "test_293_4.jpg",
            "test_293_0.jpg",
            "test_293_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5,
            "spearman_rho": -0.6499999999999999,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 294,
      "prompt": "A purple and black generative art, with repeating biomorphic patterns by Patrick Heron.",
      "image_filenames": [
        "test_294_0.jpg",
        "test_294_1.jpg",
        "test_294_2.jpg",
        "test_294_3.jpg",
        "test_294_4.jpg",
        "test_294_5.jpg",
        "test_294_6.jpg",
        "test_294_7.jpg",
        "test_294_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          4,
          8,
          0,
          6,
          2,
          5,
          7,
          3
        ],
        "order_filenames": [
          "test_294_1.jpg",
          "test_294_4.jpg",
          "test_294_8.jpg",
          "test_294_0.jpg",
          "test_294_6.jpg",
          "test_294_2.jpg",
          "test_294_5.jpg",
          "test_294_7.jpg",
          "test_294_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_294_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            2,
            3,
            4
          ],
          "winner_filenames": [
            "test_294_2.jpg",
            "test_294_3.jpg",
            "test_294_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_294_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.20947265625,
            0.2388916015625,
            0.22900390625,
            0.1739501953125,
            0.1763916015625,
            0.1788330078125,
            0.2200927734375,
            0.230712890625,
            0.2203369140625
          ],
          "order_indices": [
            1,
            7,
            2,
            8,
            6,
            0,
            5,
            4,
            3
          ],
          "order_filenames": [
            "test_294_1.jpg",
            "test_294_7.jpg",
            "test_294_2.jpg",
            "test_294_8.jpg",
            "test_294_6.jpg",
            "test_294_0.jpg",
            "test_294_5.jpg",
            "test_294_4.jpg",
            "test_294_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.2833333333333333,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.4444444444444444,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.65625,
            39.8125,
            40.03125,
            22.890625,
            20.71875,
            22.09375,
            37.34375,
            39.34375,
            44.03125
          ],
          "order_indices": [
            8,
            0,
            2,
            1,
            7,
            6,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_294_8.jpg",
            "test_294_0.jpg",
            "test_294_2.jpg",
            "test_294_1.jpg",
            "test_294_7.jpg",
            "test_294_6.jpg",
            "test_294_3.jpg",
            "test_294_5.jpg",
            "test_294_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2222222222222222,
            "spearman_rho": 0.25,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.4656617045402527,
            0.09718551486730576,
            -0.004147651139646769,
            -0.6689386963844299,
            -1.9380569458007812,
            -1.3377187252044678,
            -0.2721098065376282,
            -0.8898122906684875,
            -0.34736794233322144
          ],
          "order_indices": [
            1,
            2,
            6,
            8,
            0,
            3,
            7,
            5,
            4
          ],
          "order_filenames": [
            "test_294_1.jpg",
            "test_294_2.jpg",
            "test_294_6.jpg",
            "test_294_8.jpg",
            "test_294_0.jpg",
            "test_294_3.jpg",
            "test_294_7.jpg",
            "test_294_5.jpg",
            "test_294_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.16666666666666666,
            "spearman_rho": 0.31666666666666665,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 295,
      "prompt": "The Magician by Ren\u00e9 Magritte.",
      "image_filenames": [
        "test_295_0.jpg",
        "test_295_1.jpg",
        "test_295_2.jpg",
        "test_295_3.jpg",
        "test_295_4.jpg",
        "test_295_5.jpg",
        "test_295_6.jpg",
        "test_295_7.jpg",
        "test_295_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          0,
          4,
          5,
          8,
          7,
          6,
          2,
          1
        ],
        "order_filenames": [
          "test_295_3.jpg",
          "test_295_0.jpg",
          "test_295_4.jpg",
          "test_295_5.jpg",
          "test_295_8.jpg",
          "test_295_7.jpg",
          "test_295_6.jpg",
          "test_295_2.jpg",
          "test_295_1.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_295_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3,
            4
          ],
          "winner_filenames": [
            "test_295_3.jpg",
            "test_295_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_295_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.155029296875,
            0.2568359375,
            0.191162109375,
            0.110595703125,
            0.115478515625,
            0.143310546875,
            0.201171875,
            0.1524658203125,
            0.21435546875
          ],
          "order_indices": [
            1,
            8,
            6,
            2,
            0,
            7,
            5,
            4,
            3
          ],
          "order_filenames": [
            "test_295_1.jpg",
            "test_295_8.jpg",
            "test_295_6.jpg",
            "test_295_2.jpg",
            "test_295_0.jpg",
            "test_295_7.jpg",
            "test_295_5.jpg",
            "test_295_4.jpg",
            "test_295_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.6111111111111112,
            "spearman_rho": -0.7666666666666666,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            33.40625,
            35.84375,
            37.0,
            19.03125,
            21.5,
            23.578125,
            36.375,
            32.5,
            36.53125
          ],
          "order_indices": [
            2,
            8,
            6,
            1,
            0,
            7,
            5,
            4,
            3
          ],
          "order_filenames": [
            "test_295_2.jpg",
            "test_295_8.jpg",
            "test_295_6.jpg",
            "test_295_1.jpg",
            "test_295_0.jpg",
            "test_295_7.jpg",
            "test_295_5.jpg",
            "test_295_4.jpg",
            "test_295_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5555555555555556,
            "spearman_rho": -0.7166666666666666,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.5771641135215759,
            1.7321618795394897,
            -0.2251802533864975,
            -2.2555761337280273,
            -1.7362990379333496,
            -1.612892746925354,
            -0.7907254695892334,
            -1.0797430276870728,
            0.7279948592185974
          ],
          "order_indices": [
            1,
            8,
            0,
            2,
            6,
            7,
            5,
            4,
            3
          ],
          "order_filenames": [
            "test_295_1.jpg",
            "test_295_8.jpg",
            "test_295_0.jpg",
            "test_295_2.jpg",
            "test_295_6.jpg",
            "test_295_7.jpg",
            "test_295_5.jpg",
            "test_295_4.jpg",
            "test_295_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5555555555555556,
            "spearman_rho": -0.6000000000000001,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 296,
      "prompt": "Digital painting of a lush natural scene on an alien planet with colourful, weird vegetation, cliffs, and water by Gerald Brom.",
      "image_filenames": [
        "test_296_0.jpg",
        "test_296_1.jpg",
        "test_296_2.jpg",
        "test_296_3.jpg",
        "test_296_4.jpg",
        "test_296_5.jpg",
        "test_296_6.jpg",
        "test_296_7.jpg",
        "test_296_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          4,
          1,
          3,
          0,
          5,
          6,
          7,
          8
        ],
        "order_filenames": [
          "test_296_2.jpg",
          "test_296_4.jpg",
          "test_296_1.jpg",
          "test_296_3.jpg",
          "test_296_0.jpg",
          "test_296_5.jpg",
          "test_296_6.jpg",
          "test_296_7.jpg",
          "test_296_8.jpg"
        ],
        "condorcet_winner": 2,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_296_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_296_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_296_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1932373046875,
            0.246337890625,
            0.25390625,
            0.22802734375,
            0.1900634765625,
            0.216064453125,
            0.24267578125,
            0.22314453125,
            0.237548828125
          ],
          "order_indices": [
            2,
            1,
            6,
            8,
            3,
            7,
            5,
            0,
            4
          ],
          "order_filenames": [
            "test_296_2.jpg",
            "test_296_1.jpg",
            "test_296_6.jpg",
            "test_296_8.jpg",
            "test_296_3.jpg",
            "test_296_7.jpg",
            "test_296_5.jpg",
            "test_296_0.jpg",
            "test_296_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.05555555555555555,
            "spearman_rho": 0.1166666666666667,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 1.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            29.5625,
            34.6875,
            37.875,
            23.65625,
            28.203125,
            28.03125,
            32.65625,
            41.46875,
            34.46875
          ],
          "order_indices": [
            7,
            2,
            1,
            8,
            6,
            0,
            4,
            5,
            3
          ],
          "order_filenames": [
            "test_296_7.jpg",
            "test_296_2.jpg",
            "test_296_1.jpg",
            "test_296_8.jpg",
            "test_296_6.jpg",
            "test_296_0.jpg",
            "test_296_4.jpg",
            "test_296_5.jpg",
            "test_296_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.1166666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.0828064680099487,
            0.4941577911376953,
            0.4394248425960541,
            0.18950186669826508,
            -1.272215723991394,
            -0.20837752521038055,
            0.2401052564382553,
            -1.3745605945587158,
            0.9037407636642456
          ],
          "order_indices": [
            8,
            1,
            2,
            6,
            3,
            5,
            0,
            4,
            7
          ],
          "order_filenames": [
            "test_296_8.jpg",
            "test_296_1.jpg",
            "test_296_2.jpg",
            "test_296_6.jpg",
            "test_296_3.jpg",
            "test_296_5.jpg",
            "test_296_0.jpg",
            "test_296_4.jpg",
            "test_296_7.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": 0.0,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 297,
      "prompt": "Plankton creatures gathered around a fire geyser in a surreal, dark painting by Ronny Khalil.",
      "image_filenames": [
        "test_297_0.jpg",
        "test_297_1.jpg",
        "test_297_2.jpg",
        "test_297_3.jpg",
        "test_297_4.jpg",
        "test_297_5.jpg",
        "test_297_6.jpg",
        "test_297_7.jpg",
        "test_297_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          5,
          7,
          1,
          4,
          8,
          6,
          2,
          0
        ],
        "order_filenames": [
          "test_297_3.jpg",
          "test_297_5.jpg",
          "test_297_7.jpg",
          "test_297_1.jpg",
          "test_297_4.jpg",
          "test_297_8.jpg",
          "test_297_6.jpg",
          "test_297_2.jpg",
          "test_297_0.jpg"
        ],
        "condorcet_winner": 3,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_297_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_297_3.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_297_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1845703125,
            0.174560546875,
            0.2498779296875,
            0.1668701171875,
            0.17822265625,
            0.1533203125,
            0.2294921875,
            0.26171875,
            0.2076416015625
          ],
          "order_indices": [
            7,
            2,
            6,
            8,
            0,
            4,
            1,
            3,
            5
          ],
          "order_filenames": [
            "test_297_7.jpg",
            "test_297_2.jpg",
            "test_297_6.jpg",
            "test_297_8.jpg",
            "test_297_0.jpg",
            "test_297_4.jpg",
            "test_297_1.jpg",
            "test_297_3.jpg",
            "test_297_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.5333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            44.53125,
            33.90625,
            44.25,
            33.125,
            26.203125,
            24.53125,
            35.0625,
            47.5625,
            38.15625
          ],
          "order_indices": [
            7,
            0,
            2,
            8,
            6,
            1,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_297_7.jpg",
            "test_297_0.jpg",
            "test_297_2.jpg",
            "test_297_8.jpg",
            "test_297_6.jpg",
            "test_297_1.jpg",
            "test_297_3.jpg",
            "test_297_4.jpg",
            "test_297_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4444444444444444,
            "spearman_rho": -0.5333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.9932056069374084,
            -0.1714828461408615,
            1.3395130634307861,
            -0.5652136206626892,
            -0.2715032398700714,
            -1.444587230682373,
            -0.6696395874023438,
            1.452734351158142,
            1.4926186800003052
          ],
          "order_indices": [
            8,
            7,
            2,
            0,
            1,
            4,
            3,
            6,
            5
          ],
          "order_filenames": [
            "test_297_8.jpg",
            "test_297_7.jpg",
            "test_297_2.jpg",
            "test_297_0.jpg",
            "test_297_1.jpg",
            "test_297_4.jpg",
            "test_297_3.jpg",
            "test_297_6.jpg",
            "test_297_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2222222222222222,
            "spearman_rho": -0.3666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 298,
      "prompt": "Oil painting portrait of demon king with gazing eyes, art by John Howe, Keith Parkinson, and Larry Elmore, featured on ArtStation and CGSociety.",
      "image_filenames": [
        "test_298_0.jpg",
        "test_298_1.jpg",
        "test_298_2.jpg",
        "test_298_3.jpg",
        "test_298_4.jpg",
        "test_298_5.jpg",
        "test_298_6.jpg",
        "test_298_7.jpg",
        "test_298_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          2,
          3,
          5,
          7,
          4,
          1,
          8,
          0
        ],
        "order_filenames": [
          "test_298_6.jpg",
          "test_298_2.jpg",
          "test_298_3.jpg",
          "test_298_5.jpg",
          "test_298_7.jpg",
          "test_298_4.jpg",
          "test_298_1.jpg",
          "test_298_8.jpg",
          "test_298_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_298_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4,
            5,
            6
          ],
          "winner_filenames": [
            "test_298_4.jpg",
            "test_298_5.jpg",
            "test_298_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_298_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1724853515625,
            0.1890869140625,
            0.227783203125,
            0.167724609375,
            0.1304931640625,
            0.1102294921875,
            0.1866455078125,
            0.2103271484375,
            0.257080078125
          ],
          "order_indices": [
            8,
            2,
            7,
            1,
            6,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_298_8.jpg",
            "test_298_2.jpg",
            "test_298_7.jpg",
            "test_298_1.jpg",
            "test_298_6.jpg",
            "test_298_0.jpg",
            "test_298_3.jpg",
            "test_298_4.jpg",
            "test_298_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.10000000000000009,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1111111111111111,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.09375,
            31.640625,
            34.375,
            26.75,
            13.984375,
            18.8125,
            28.609375,
            36.0,
            34.90625
          ],
          "order_indices": [
            0,
            7,
            8,
            2,
            1,
            6,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_298_0.jpg",
            "test_298_7.jpg",
            "test_298_8.jpg",
            "test_298_2.jpg",
            "test_298_1.jpg",
            "test_298_6.jpg",
            "test_298_3.jpg",
            "test_298_5.jpg",
            "test_298_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2777777777777778,
            "spearman_rho": -0.43333333333333335,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.15532413125038147,
            1.5163626670837402,
            1.7144300937652588,
            -0.1659773588180542,
            -0.9305188655853271,
            -2.0969393253326416,
            1.2129818201065063,
            -0.058404602110385895,
            1.7118922472000122
          ],
          "order_indices": [
            2,
            8,
            1,
            6,
            0,
            7,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_298_2.jpg",
            "test_298_8.jpg",
            "test_298_1.jpg",
            "test_298_6.jpg",
            "test_298_0.jpg",
            "test_298_7.jpg",
            "test_298_3.jpg",
            "test_298_4.jpg",
            "test_298_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.03333333333333344,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 299,
      "prompt": "\"Hyperrealistic acrylic painting on canvas by Junji Ito depicting the mythos of ego and ethos of id.\"",
      "image_filenames": [
        "test_299_0.jpg",
        "test_299_1.jpg",
        "test_299_2.jpg",
        "test_299_3.jpg",
        "test_299_4.jpg",
        "test_299_5.jpg",
        "test_299_6.jpg",
        "test_299_7.jpg",
        "test_299_8.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          5,
          7,
          0,
          3,
          4,
          8,
          1,
          2
        ],
        "order_filenames": [
          "test_299_6.jpg",
          "test_299_5.jpg",
          "test_299_7.jpg",
          "test_299_0.jpg",
          "test_299_3.jpg",
          "test_299_4.jpg",
          "test_299_8.jpg",
          "test_299_1.jpg",
          "test_299_2.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_299_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_299_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_299_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1480712890625,
            0.10760498046875,
            0.1929931640625,
            0.1461181640625,
            0.1070556640625,
            0.10711669921875,
            0.183837890625,
            0.20556640625,
            0.222900390625
          ],
          "order_indices": [
            8,
            7,
            2,
            6,
            0,
            3,
            1,
            5,
            4
          ],
          "order_filenames": [
            "test_299_8.jpg",
            "test_299_7.jpg",
            "test_299_2.jpg",
            "test_299_6.jpg",
            "test_299_0.jpg",
            "test_299_3.jpg",
            "test_299_1.jpg",
            "test_299_5.jpg",
            "test_299_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.08333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.9375,
            30.15625,
            42.84375,
            22.875,
            21.0,
            18.15625,
            39.53125,
            37.6875,
            30.5625
          ],
          "order_indices": [
            2,
            6,
            0,
            7,
            8,
            1,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_299_2.jpg",
            "test_299_6.jpg",
            "test_299_0.jpg",
            "test_299_7.jpg",
            "test_299_8.jpg",
            "test_299_1.jpg",
            "test_299_3.jpg",
            "test_299_4.jpg",
            "test_299_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.05555555555555555,
            "spearman_rho": -0.10000000000000009,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.4980311691761017,
            -1.4728120565414429,
            -0.1443176567554474,
            -1.0911463499069214,
            -1.5778013467788696,
            -1.2124154567718506,
            -0.3351045250892639,
            -0.27464422583580017,
            0.2771817445755005
          ],
          "order_indices": [
            8,
            2,
            7,
            6,
            0,
            3,
            5,
            1,
            4
          ],
          "order_filenames": [
            "test_299_8.jpg",
            "test_299_2.jpg",
            "test_299_7.jpg",
            "test_299_6.jpg",
            "test_299_0.jpg",
            "test_299_3.jpg",
            "test_299_5.jpg",
            "test_299_1.jpg",
            "test_299_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.0,
            "spearman_rho": -0.08333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2222222222222222,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 300,
      "prompt": "A train is moving along the track in the countryside.",
      "image_filenames": [
        "test_300_0.jpg",
        "test_300_1.jpg",
        "test_300_2.jpg",
        "test_300_3.jpg",
        "test_300_4.jpg",
        "test_300_5.jpg",
        "test_300_6.jpg",
        "test_300_7.jpg",
        "test_300_8.jpg",
        "test_300_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          2,
          8,
          3,
          4,
          0,
          9,
          6,
          5,
          7
        ],
        "order_filenames": [
          "test_300_1.jpg",
          "test_300_2.jpg",
          "test_300_8.jpg",
          "test_300_3.jpg",
          "test_300_4.jpg",
          "test_300_0.jpg",
          "test_300_9.jpg",
          "test_300_6.jpg",
          "test_300_5.jpg",
          "test_300_7.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1,
          2,
          8
        ],
        "winner_filenames": [
          "test_300_1.jpg",
          "test_300_2.jpg",
          "test_300_8.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6,
            8
          ],
          "winner_filenames": [
            "test_300_6.jpg",
            "test_300_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            8
          ],
          "winner_filenames": [
            "test_300_8.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2318115234375,
            0.2646484375,
            0.28173828125,
            0.1884765625,
            0.2626953125,
            0.1763916015625,
            0.2587890625,
            0.2147216796875,
            0.26220703125,
            0.2298583984375
          ],
          "order_indices": [
            2,
            1,
            4,
            8,
            6,
            0,
            9,
            7,
            3,
            5
          ],
          "order_filenames": [
            "test_300_2.jpg",
            "test_300_1.jpg",
            "test_300_4.jpg",
            "test_300_8.jpg",
            "test_300_6.jpg",
            "test_300_0.jpg",
            "test_300_9.jpg",
            "test_300_7.jpg",
            "test_300_3.jpg",
            "test_300_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.5555555555555556,
            "spearman_rho": 0.7212121212121212,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            29.4375,
            30.3125,
            30.5,
            28.515625,
            30.890625,
            24.75,
            29.875,
            27.609375,
            27.625,
            26.0625
          ],
          "order_indices": [
            4,
            2,
            1,
            6,
            0,
            3,
            8,
            7,
            9,
            5
          ],
          "order_filenames": [
            "test_300_4.jpg",
            "test_300_2.jpg",
            "test_300_1.jpg",
            "test_300_6.jpg",
            "test_300_0.jpg",
            "test_300_3.jpg",
            "test_300_8.jpg",
            "test_300_7.jpg",
            "test_300_9.jpg",
            "test_300_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.37777777777777777,
            "spearman_rho": 0.6,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.55999356508255,
            0.9485049247741699,
            1.0019067525863647,
            -1.174273133277893,
            0.45900917053222656,
            -1.8244751691818237,
            1.0788509845733643,
            0.8768542408943176,
            0.9582772254943848,
            0.20846334099769592
          ],
          "order_indices": [
            6,
            2,
            8,
            1,
            7,
            0,
            4,
            9,
            3,
            5
          ],
          "order_filenames": [
            "test_300_6.jpg",
            "test_300_2.jpg",
            "test_300_8.jpg",
            "test_300_1.jpg",
            "test_300_7.jpg",
            "test_300_0.jpg",
            "test_300_4.jpg",
            "test_300_9.jpg",
            "test_300_3.jpg",
            "test_300_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2,
            "spearman_rho": 0.3090909090909091,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 301,
      "prompt": "a castle is in the middle of a eurpean city ",
      "image_filenames": [
        "test_301_0.jpg",
        "test_301_1.jpg",
        "test_301_2.jpg",
        "test_301_3.jpg",
        "test_301_4.jpg",
        "test_301_5.jpg",
        "test_301_6.jpg",
        "test_301_7.jpg",
        "test_301_8.jpg",
        "test_301_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          6,
          2,
          3,
          1,
          5,
          0,
          8,
          7,
          9
        ],
        "order_filenames": [
          "test_301_4.jpg",
          "test_301_6.jpg",
          "test_301_2.jpg",
          "test_301_3.jpg",
          "test_301_1.jpg",
          "test_301_5.jpg",
          "test_301_0.jpg",
          "test_301_8.jpg",
          "test_301_7.jpg",
          "test_301_9.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_301_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_301_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_301_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2032470703125,
            0.2607421875,
            0.287841796875,
            0.2432861328125,
            0.1856689453125,
            0.2027587890625,
            0.290771484375,
            0.18505859375,
            0.1875,
            0.215087890625
          ],
          "order_indices": [
            6,
            2,
            1,
            3,
            9,
            0,
            5,
            8,
            4,
            7
          ],
          "order_filenames": [
            "test_301_6.jpg",
            "test_301_2.jpg",
            "test_301_1.jpg",
            "test_301_3.jpg",
            "test_301_9.jpg",
            "test_301_0.jpg",
            "test_301_5.jpg",
            "test_301_8.jpg",
            "test_301_4.jpg",
            "test_301_7.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.37777777777777777,
            "spearman_rho": 0.406060606060606,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            32.25,
            26.328125,
            30.09375,
            25.875,
            20.484375,
            23.203125,
            32.53125,
            31.359375,
            29.6875,
            22.109375
          ],
          "order_indices": [
            6,
            0,
            7,
            2,
            8,
            1,
            3,
            5,
            9,
            4
          ],
          "order_filenames": [
            "test_301_6.jpg",
            "test_301_0.jpg",
            "test_301_7.jpg",
            "test_301_2.jpg",
            "test_301_8.jpg",
            "test_301_1.jpg",
            "test_301_3.jpg",
            "test_301_5.jpg",
            "test_301_9.jpg",
            "test_301_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.022222222222222223,
            "spearman_rho": -0.018181818181818077,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.0310641527175903,
            -0.03862779214978218,
            0.5538498759269714,
            0.14941176772117615,
            -1.572378158569336,
            -0.4412681460380554,
            0.7219094038009644,
            -0.7267417907714844,
            -0.24987028539180756,
            -0.7424085736274719
          ],
          "order_indices": [
            0,
            6,
            2,
            3,
            1,
            8,
            5,
            7,
            9,
            4
          ],
          "order_filenames": [
            "test_301_0.jpg",
            "test_301_6.jpg",
            "test_301_2.jpg",
            "test_301_3.jpg",
            "test_301_1.jpg",
            "test_301_8.jpg",
            "test_301_5.jpg",
            "test_301_7.jpg",
            "test_301_9.jpg",
            "test_301_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.24848484848484853,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.4,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 302,
      "prompt": "A lot of building on each side of the road, with a very curvy road in the middle.",
      "image_filenames": [
        "test_302_0.jpg",
        "test_302_1.jpg",
        "test_302_2.jpg",
        "test_302_3.jpg",
        "test_302_4.jpg",
        "test_302_5.jpg",
        "test_302_6.jpg",
        "test_302_7.jpg",
        "test_302_8.jpg",
        "test_302_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          7,
          6,
          5,
          8,
          2,
          3,
          9,
          1,
          0
        ],
        "order_filenames": [
          "test_302_4.jpg",
          "test_302_7.jpg",
          "test_302_6.jpg",
          "test_302_5.jpg",
          "test_302_8.jpg",
          "test_302_2.jpg",
          "test_302_3.jpg",
          "test_302_9.jpg",
          "test_302_1.jpg",
          "test_302_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_302_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_302_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4,
            6
          ],
          "winner_filenames": [
            "test_302_4.jpg",
            "test_302_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.179443359375,
            0.2386474609375,
            0.172607421875,
            0.2357177734375,
            0.193359375,
            0.171875,
            0.23046875,
            0.1737060546875,
            0.2266845703125,
            0.2301025390625
          ],
          "order_indices": [
            1,
            3,
            6,
            9,
            8,
            4,
            0,
            7,
            2,
            5
          ],
          "order_filenames": [
            "test_302_1.jpg",
            "test_302_3.jpg",
            "test_302_6.jpg",
            "test_302_9.jpg",
            "test_302_8.jpg",
            "test_302_4.jpg",
            "test_302_0.jpg",
            "test_302_7.jpg",
            "test_302_2.jpg",
            "test_302_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.24444444444444444,
            "spearman_rho": -0.33333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            31.296875,
            30.796875,
            28.3125,
            24.453125,
            24.796875,
            26.9375,
            30.640625,
            31.9375,
            25.75,
            27.15625
          ],
          "order_indices": [
            7,
            0,
            1,
            6,
            2,
            9,
            5,
            8,
            4,
            3
          ],
          "order_filenames": [
            "test_302_7.jpg",
            "test_302_0.jpg",
            "test_302_1.jpg",
            "test_302_6.jpg",
            "test_302_2.jpg",
            "test_302_9.jpg",
            "test_302_5.jpg",
            "test_302_8.jpg",
            "test_302_4.jpg",
            "test_302_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.15555555555555556,
            "spearman_rho": -0.19999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.1148356199264526,
            -0.335029274225235,
            -1.9835084676742554,
            -0.25143951177597046,
            -0.8723640441894531,
            -2.1720104217529297,
            -0.02284989133477211,
            -1.2002536058425903,
            -0.6195571422576904,
            0.18988698720932007
          ],
          "order_indices": [
            9,
            6,
            3,
            1,
            8,
            4,
            0,
            7,
            2,
            5
          ],
          "order_filenames": [
            "test_302_9.jpg",
            "test_302_6.jpg",
            "test_302_3.jpg",
            "test_302_1.jpg",
            "test_302_8.jpg",
            "test_302_4.jpg",
            "test_302_0.jpg",
            "test_302_7.jpg",
            "test_302_2.jpg",
            "test_302_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.15555555555555556,
            "spearman_rho": -0.24848484848484853,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 303,
      "prompt": "People standing in the grass playing with a frisbee.",
      "image_filenames": [
        "test_303_0.jpg",
        "test_303_1.jpg",
        "test_303_2.jpg",
        "test_303_3.jpg",
        "test_303_4.jpg",
        "test_303_5.jpg",
        "test_303_6.jpg",
        "test_303_7.jpg",
        "test_303_8.jpg",
        "test_303_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          4,
          3,
          6,
          7,
          8,
          2,
          9,
          0,
          1
        ],
        "order_filenames": [
          "test_303_5.jpg",
          "test_303_4.jpg",
          "test_303_3.jpg",
          "test_303_6.jpg",
          "test_303_7.jpg",
          "test_303_8.jpg",
          "test_303_2.jpg",
          "test_303_9.jpg",
          "test_303_0.jpg",
          "test_303_1.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_303_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_303_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_303_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.22021484375,
            0.2276611328125,
            0.280517578125,
            0.1912841796875,
            0.2239990234375,
            0.1190185546875,
            0.2181396484375,
            0.22265625,
            0.2391357421875,
            0.2484130859375
          ],
          "order_indices": [
            2,
            9,
            8,
            1,
            4,
            7,
            0,
            6,
            3,
            5
          ],
          "order_filenames": [
            "test_303_2.jpg",
            "test_303_9.jpg",
            "test_303_8.jpg",
            "test_303_1.jpg",
            "test_303_4.jpg",
            "test_303_7.jpg",
            "test_303_0.jpg",
            "test_303_6.jpg",
            "test_303_3.jpg",
            "test_303_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4666666666666667,
            "spearman_rho": -0.6000000000000001,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.28125,
            35.84375,
            41.0,
            31.359375,
            37.75,
            13.8203125,
            32.75,
            31.578125,
            35.8125,
            31.109375
          ],
          "order_indices": [
            2,
            4,
            0,
            1,
            8,
            6,
            7,
            3,
            9,
            5
          ],
          "order_filenames": [
            "test_303_2.jpg",
            "test_303_4.jpg",
            "test_303_0.jpg",
            "test_303_1.jpg",
            "test_303_8.jpg",
            "test_303_6.jpg",
            "test_303_7.jpg",
            "test_303_3.jpg",
            "test_303_9.jpg",
            "test_303_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.28888888888888886,
            "spearman_rho": -0.35757575757575766,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.0994727686047554,
            -0.01600395329296589,
            0.4199562668800354,
            -1.397020936012268,
            -0.11086338758468628,
            -2.2042059898376465,
            -0.4640006422996521,
            0.1358620822429657,
            0.39577794075012207,
            0.15998722612857819
          ],
          "order_indices": [
            2,
            8,
            9,
            7,
            1,
            0,
            4,
            6,
            3,
            5
          ],
          "order_filenames": [
            "test_303_2.jpg",
            "test_303_8.jpg",
            "test_303_9.jpg",
            "test_303_7.jpg",
            "test_303_1.jpg",
            "test_303_0.jpg",
            "test_303_4.jpg",
            "test_303_6.jpg",
            "test_303_3.jpg",
            "test_303_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4666666666666667,
            "spearman_rho": -0.6363636363636365,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 304,
      "prompt": "A street light and other road signs. ",
      "image_filenames": [
        "test_304_0.jpg",
        "test_304_1.jpg",
        "test_304_2.jpg",
        "test_304_3.jpg",
        "test_304_4.jpg",
        "test_304_5.jpg",
        "test_304_6.jpg",
        "test_304_7.jpg",
        "test_304_8.jpg",
        "test_304_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          3,
          6,
          4,
          5,
          1,
          8,
          9,
          0,
          2
        ],
        "order_filenames": [
          "test_304_7.jpg",
          "test_304_3.jpg",
          "test_304_6.jpg",
          "test_304_4.jpg",
          "test_304_5.jpg",
          "test_304_1.jpg",
          "test_304_8.jpg",
          "test_304_9.jpg",
          "test_304_0.jpg",
          "test_304_2.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_304_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            1,
            6
          ],
          "winner_filenames": [
            "test_304_1.jpg",
            "test_304_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_304_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.244140625,
            0.2359619140625,
            0.26123046875,
            0.19287109375,
            0.2137451171875,
            0.2425537109375,
            0.261474609375,
            0.188720703125,
            0.1380615234375,
            0.280517578125
          ],
          "order_indices": [
            9,
            6,
            2,
            0,
            5,
            1,
            4,
            3,
            7,
            8
          ],
          "order_filenames": [
            "test_304_9.jpg",
            "test_304_6.jpg",
            "test_304_2.jpg",
            "test_304_0.jpg",
            "test_304_5.jpg",
            "test_304_1.jpg",
            "test_304_4.jpg",
            "test_304_3.jpg",
            "test_304_7.jpg",
            "test_304_8.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.37777777777777777,
            "spearman_rho": -0.46666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.75,
            29.859375,
            32.3125,
            28.671875,
            33.4375,
            35.09375,
            35.71875,
            34.1875,
            32.1875,
            30.15625
          ],
          "order_indices": [
            0,
            6,
            5,
            7,
            4,
            2,
            8,
            9,
            1,
            3
          ],
          "order_filenames": [
            "test_304_0.jpg",
            "test_304_6.jpg",
            "test_304_5.jpg",
            "test_304_7.jpg",
            "test_304_4.jpg",
            "test_304_2.jpg",
            "test_304_8.jpg",
            "test_304_9.jpg",
            "test_304_1.jpg",
            "test_304_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.022222222222222223,
            "spearman_rho": -0.018181818181818077,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.08363713324069977,
            -0.8930031061172485,
            -1.4676486253738403,
            -1.6395407915115356,
            -0.9791128635406494,
            -0.0025846248026937246,
            0.6381585001945496,
            0.4040224850177765,
            -0.6327940821647644,
            0.6480677127838135
          ],
          "order_indices": [
            9,
            6,
            7,
            5,
            0,
            8,
            1,
            4,
            2,
            3
          ],
          "order_filenames": [
            "test_304_9.jpg",
            "test_304_6.jpg",
            "test_304_7.jpg",
            "test_304_5.jpg",
            "test_304_0.jpg",
            "test_304_8.jpg",
            "test_304_1.jpg",
            "test_304_4.jpg",
            "test_304_2.jpg",
            "test_304_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.022222222222222223,
            "spearman_rho": 0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 305,
      "prompt": "Two men sitting in a green living room talking to a girl seen in the mirror.",
      "image_filenames": [
        "test_305_0.jpg",
        "test_305_1.jpg",
        "test_305_2.jpg",
        "test_305_3.jpg",
        "test_305_4.jpg",
        "test_305_5.jpg",
        "test_305_6.jpg",
        "test_305_7.jpg",
        "test_305_8.jpg",
        "test_305_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          8,
          3,
          6,
          4,
          7,
          2,
          9,
          5,
          0
        ],
        "order_filenames": [
          "test_305_1.jpg",
          "test_305_8.jpg",
          "test_305_3.jpg",
          "test_305_6.jpg",
          "test_305_4.jpg",
          "test_305_7.jpg",
          "test_305_2.jpg",
          "test_305_9.jpg",
          "test_305_5.jpg",
          "test_305_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_305_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            1,
            3,
            5,
            6
          ],
          "winner_filenames": [
            "test_305_1.jpg",
            "test_305_3.jpg",
            "test_305_5.jpg",
            "test_305_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_305_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2159423828125,
            0.258056640625,
            0.307861328125,
            0.18408203125,
            0.20947265625,
            0.1365966796875,
            0.2349853515625,
            0.250732421875,
            0.261962890625,
            0.2900390625
          ],
          "order_indices": [
            2,
            9,
            8,
            1,
            7,
            6,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_305_2.jpg",
            "test_305_9.jpg",
            "test_305_8.jpg",
            "test_305_1.jpg",
            "test_305_7.jpg",
            "test_305_6.jpg",
            "test_305_0.jpg",
            "test_305_4.jpg",
            "test_305_3.jpg",
            "test_305_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.06666666666666667,
            "spearman_rho": 0.1393939393939394,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.125,
            37.5625,
            47.40625,
            31.65625,
            31.171875,
            21.5625,
            36.75,
            43.03125,
            45.25,
            40.40625
          ],
          "order_indices": [
            2,
            8,
            7,
            9,
            1,
            6,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_305_2.jpg",
            "test_305_8.jpg",
            "test_305_7.jpg",
            "test_305_9.jpg",
            "test_305_1.jpg",
            "test_305_6.jpg",
            "test_305_0.jpg",
            "test_305_3.jpg",
            "test_305_4.jpg",
            "test_305_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.15555555555555556,
            "spearman_rho": 0.19999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.022009873762726784,
            -0.2970215678215027,
            0.5536348819732666,
            -0.15750162303447723,
            -0.5260909795761108,
            -2.250091075897217,
            -0.6908787488937378,
            0.3480057120323181,
            0.4788365960121155,
            0.5242902040481567
          ],
          "order_indices": [
            2,
            9,
            8,
            7,
            0,
            3,
            1,
            4,
            6,
            5
          ],
          "order_filenames": [
            "test_305_2.jpg",
            "test_305_9.jpg",
            "test_305_8.jpg",
            "test_305_7.jpg",
            "test_305_0.jpg",
            "test_305_3.jpg",
            "test_305_1.jpg",
            "test_305_4.jpg",
            "test_305_6.jpg",
            "test_305_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.06666666666666667,
            "spearman_rho": -0.10303030303030303,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 306,
      "prompt": "Empty double decker London bus in rural area.",
      "image_filenames": [
        "test_306_0.jpg",
        "test_306_1.jpg",
        "test_306_2.jpg",
        "test_306_3.jpg",
        "test_306_4.jpg",
        "test_306_5.jpg",
        "test_306_6.jpg",
        "test_306_7.jpg",
        "test_306_8.jpg",
        "test_306_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          8,
          3,
          2,
          6,
          9,
          0,
          4,
          5,
          1
        ],
        "order_filenames": [
          "test_306_7.jpg",
          "test_306_8.jpg",
          "test_306_3.jpg",
          "test_306_2.jpg",
          "test_306_6.jpg",
          "test_306_9.jpg",
          "test_306_0.jpg",
          "test_306_4.jpg",
          "test_306_5.jpg",
          "test_306_1.jpg"
        ],
        "condorcet_winner": 7,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_306_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_306_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_306_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2113037109375,
            0.251708984375,
            0.292236328125,
            0.2200927734375,
            0.239990234375,
            0.21435546875,
            0.2939453125,
            0.187744140625,
            0.258056640625,
            0.281494140625
          ],
          "order_indices": [
            6,
            2,
            9,
            8,
            1,
            4,
            3,
            5,
            0,
            7
          ],
          "order_filenames": [
            "test_306_6.jpg",
            "test_306_2.jpg",
            "test_306_9.jpg",
            "test_306_8.jpg",
            "test_306_1.jpg",
            "test_306_4.jpg",
            "test_306_3.jpg",
            "test_306_5.jpg",
            "test_306_0.jpg",
            "test_306_7.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.022222222222222223,
            "spearman_rho": 0.0060606060606061,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.53125,
            23.1875,
            35.375,
            20.0625,
            33.0625,
            28.96875,
            28.703125,
            36.40625,
            33.59375,
            30.109375
          ],
          "order_indices": [
            7,
            0,
            2,
            8,
            4,
            9,
            5,
            6,
            1,
            3
          ],
          "order_filenames": [
            "test_306_7.jpg",
            "test_306_0.jpg",
            "test_306_2.jpg",
            "test_306_8.jpg",
            "test_306_4.jpg",
            "test_306_9.jpg",
            "test_306_5.jpg",
            "test_306_6.jpg",
            "test_306_1.jpg",
            "test_306_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.28888888888888886,
            "spearman_rho": 0.38181818181818183,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 1.0,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.19944338500499725,
            -0.19890901446342468,
            0.6752825379371643,
            -1.6796592473983765,
            0.3163212835788727,
            -1.7870655059814453,
            0.31015801429748535,
            0.03194713965058327,
            0.5132893323898315,
            0.27186623215675354
          ],
          "order_indices": [
            2,
            8,
            4,
            6,
            9,
            7,
            1,
            0,
            3,
            5
          ],
          "order_filenames": [
            "test_306_2.jpg",
            "test_306_8.jpg",
            "test_306_4.jpg",
            "test_306_6.jpg",
            "test_306_9.jpg",
            "test_306_7.jpg",
            "test_306_1.jpg",
            "test_306_0.jpg",
            "test_306_3.jpg",
            "test_306_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.24444444444444444,
            "spearman_rho": 0.34545454545454546,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 307,
      "prompt": "A plate topped with lots of different kinds of fruit.",
      "image_filenames": [
        "test_307_0.jpg",
        "test_307_1.jpg",
        "test_307_2.jpg",
        "test_307_3.jpg",
        "test_307_4.jpg",
        "test_307_5.jpg",
        "test_307_6.jpg",
        "test_307_7.jpg",
        "test_307_8.jpg",
        "test_307_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          1,
          3,
          8,
          9,
          6,
          7,
          5,
          2,
          4
        ],
        "order_filenames": [
          "test_307_0.jpg",
          "test_307_1.jpg",
          "test_307_3.jpg",
          "test_307_8.jpg",
          "test_307_9.jpg",
          "test_307_6.jpg",
          "test_307_7.jpg",
          "test_307_5.jpg",
          "test_307_2.jpg",
          "test_307_4.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_307_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3,
            8
          ],
          "winner_filenames": [
            "test_307_3.jpg",
            "test_307_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_307_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.229736328125,
            0.292724609375,
            0.319580078125,
            0.27197265625,
            0.218994140625,
            0.22265625,
            0.29931640625,
            0.25048828125,
            0.275146484375,
            0.256591796875
          ],
          "order_indices": [
            2,
            6,
            1,
            8,
            3,
            9,
            7,
            0,
            5,
            4
          ],
          "order_filenames": [
            "test_307_2.jpg",
            "test_307_6.jpg",
            "test_307_1.jpg",
            "test_307_8.jpg",
            "test_307_3.jpg",
            "test_307_9.jpg",
            "test_307_7.jpg",
            "test_307_0.jpg",
            "test_307_5.jpg",
            "test_307_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.15555555555555556,
            "spearman_rho": 0.17575757575757578,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.5,
            33.78125,
            34.375,
            32.3125,
            36.53125,
            35.34375,
            30.953125,
            35.78125,
            34.96875,
            33.65625
          ],
          "order_indices": [
            0,
            4,
            7,
            5,
            8,
            2,
            1,
            9,
            3,
            6
          ],
          "order_filenames": [
            "test_307_0.jpg",
            "test_307_4.jpg",
            "test_307_7.jpg",
            "test_307_5.jpg",
            "test_307_8.jpg",
            "test_307_2.jpg",
            "test_307_1.jpg",
            "test_307_9.jpg",
            "test_307_3.jpg",
            "test_307_6.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.16363636363636358,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.1637721061706543,
            1.225800633430481,
            1.2370848655700684,
            0.9749131798744202,
            0.7006540894508362,
            0.4315529763698578,
            1.1314613819122314,
            0.6623527407646179,
            1.3295308351516724,
            1.1912293434143066
          ],
          "order_indices": [
            8,
            2,
            1,
            9,
            0,
            6,
            3,
            4,
            7,
            5
          ],
          "order_filenames": [
            "test_307_8.jpg",
            "test_307_2.jpg",
            "test_307_1.jpg",
            "test_307_9.jpg",
            "test_307_0.jpg",
            "test_307_6.jpg",
            "test_307_3.jpg",
            "test_307_4.jpg",
            "test_307_7.jpg",
            "test_307_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.28888888888888886,
            "spearman_rho": 0.36969696969696975,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 308,
      "prompt": "an empty bench next to a busy street.",
      "image_filenames": [
        "test_308_0.jpg",
        "test_308_1.jpg",
        "test_308_2.jpg",
        "test_308_3.jpg",
        "test_308_4.jpg",
        "test_308_5.jpg",
        "test_308_6.jpg",
        "test_308_7.jpg",
        "test_308_8.jpg",
        "test_308_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          7,
          8,
          9,
          0,
          5,
          4,
          6,
          2,
          3
        ],
        "order_filenames": [
          "test_308_1.jpg",
          "test_308_7.jpg",
          "test_308_8.jpg",
          "test_308_9.jpg",
          "test_308_0.jpg",
          "test_308_5.jpg",
          "test_308_4.jpg",
          "test_308_6.jpg",
          "test_308_2.jpg",
          "test_308_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_308_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5,
            7,
            8
          ],
          "winner_filenames": [
            "test_308_5.jpg",
            "test_308_7.jpg",
            "test_308_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_308_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1700439453125,
            0.219970703125,
            0.244140625,
            0.1851806640625,
            0.19287109375,
            0.1998291015625,
            0.201171875,
            0.2059326171875,
            0.2130126953125,
            0.2149658203125
          ],
          "order_indices": [
            2,
            1,
            9,
            8,
            7,
            6,
            5,
            4,
            3,
            0
          ],
          "order_filenames": [
            "test_308_2.jpg",
            "test_308_1.jpg",
            "test_308_9.jpg",
            "test_308_8.jpg",
            "test_308_7.jpg",
            "test_308_6.jpg",
            "test_308_5.jpg",
            "test_308_4.jpg",
            "test_308_3.jpg",
            "test_308_0.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.24444444444444444,
            "spearman_rho": 0.34545454545454546,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            33.3125,
            40.71875,
            41.78125,
            33.1875,
            36.4375,
            31.671875,
            30.6875,
            32.75,
            39.8125,
            31.25
          ],
          "order_indices": [
            2,
            1,
            8,
            4,
            0,
            3,
            7,
            5,
            9,
            6
          ],
          "order_filenames": [
            "test_308_2.jpg",
            "test_308_1.jpg",
            "test_308_8.jpg",
            "test_308_4.jpg",
            "test_308_0.jpg",
            "test_308_3.jpg",
            "test_308_7.jpg",
            "test_308_5.jpg",
            "test_308_9.jpg",
            "test_308_6.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.10303030303030303,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.39786219596862793,
            0.2704538106918335,
            -0.2713853120803833,
            -1.3807711601257324,
            -0.5074343681335449,
            -1.3044382333755493,
            -1.4292980432510376,
            -0.5800105333328247,
            1.1098254919052124,
            -0.42553386092185974
          ],
          "order_indices": [
            8,
            1,
            2,
            0,
            9,
            4,
            7,
            5,
            3,
            6
          ],
          "order_filenames": [
            "test_308_8.jpg",
            "test_308_1.jpg",
            "test_308_2.jpg",
            "test_308_0.jpg",
            "test_308_9.jpg",
            "test_308_4.jpg",
            "test_308_7.jpg",
            "test_308_5.jpg",
            "test_308_3.jpg",
            "test_308_6.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.37777777777777777,
            "spearman_rho": 0.5272727272727273,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 309,
      "prompt": "A person holding a remote while playing a game",
      "image_filenames": [
        "test_309_0.jpg",
        "test_309_1.jpg",
        "test_309_2.jpg",
        "test_309_3.jpg",
        "test_309_4.jpg",
        "test_309_5.jpg",
        "test_309_6.jpg",
        "test_309_7.jpg",
        "test_309_8.jpg",
        "test_309_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          7,
          2,
          4,
          5,
          6,
          9,
          8,
          1,
          0
        ],
        "order_filenames": [
          "test_309_3.jpg",
          "test_309_7.jpg",
          "test_309_2.jpg",
          "test_309_4.jpg",
          "test_309_5.jpg",
          "test_309_6.jpg",
          "test_309_9.jpg",
          "test_309_8.jpg",
          "test_309_1.jpg",
          "test_309_0.jpg"
        ],
        "condorcet_winner": 7,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_309_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_309_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_309_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.184326171875,
            0.19775390625,
            0.234375,
            0.185791015625,
            0.18115234375,
            0.1279296875,
            0.22119140625,
            0.185302734375,
            0.229736328125,
            0.151611328125
          ],
          "order_indices": [
            2,
            8,
            6,
            1,
            3,
            7,
            0,
            4,
            9,
            5
          ],
          "order_filenames": [
            "test_309_2.jpg",
            "test_309_8.jpg",
            "test_309_6.jpg",
            "test_309_1.jpg",
            "test_309_3.jpg",
            "test_309_7.jpg",
            "test_309_0.jpg",
            "test_309_4.jpg",
            "test_309_9.jpg",
            "test_309_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.06666666666666667,
            "spearman_rho": 0.030303030303030276,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.21875,
            30.125,
            38.28125,
            38.09375,
            30.328125,
            19.328125,
            35.1875,
            29.078125,
            30.65625,
            21.453125
          ],
          "order_indices": [
            2,
            3,
            0,
            6,
            8,
            4,
            1,
            7,
            9,
            5
          ],
          "order_filenames": [
            "test_309_2.jpg",
            "test_309_3.jpg",
            "test_309_0.jpg",
            "test_309_6.jpg",
            "test_309_8.jpg",
            "test_309_4.jpg",
            "test_309_1.jpg",
            "test_309_7.jpg",
            "test_309_9.jpg",
            "test_309_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.06666666666666667,
            "spearman_rho": 0.1515151515151515,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.02944869175553322,
            -1.0279532670974731,
            -0.9630162119865417,
            -1.1576734781265259,
            0.1679358035326004,
            -2.0752601623535156,
            -0.4120745062828064,
            -0.212743878364563,
            -0.4420431852340698,
            -0.5717944502830505
          ],
          "order_indices": [
            4,
            0,
            7,
            6,
            8,
            9,
            2,
            1,
            3,
            5
          ],
          "order_filenames": [
            "test_309_4.jpg",
            "test_309_0.jpg",
            "test_309_7.jpg",
            "test_309_6.jpg",
            "test_309_8.jpg",
            "test_309_9.jpg",
            "test_309_2.jpg",
            "test_309_1.jpg",
            "test_309_3.jpg",
            "test_309_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.17575757575757578,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 310,
      "prompt": "Racing horse being guided by an asian man. ",
      "image_filenames": [
        "test_310_0.jpg",
        "test_310_1.jpg",
        "test_310_2.jpg",
        "test_310_3.jpg",
        "test_310_4.jpg",
        "test_310_5.jpg",
        "test_310_6.jpg",
        "test_310_7.jpg",
        "test_310_8.jpg",
        "test_310_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          6,
          5,
          8,
          2,
          4,
          9,
          1,
          0,
          3
        ],
        "order_filenames": [
          "test_310_7.jpg",
          "test_310_6.jpg",
          "test_310_5.jpg",
          "test_310_8.jpg",
          "test_310_2.jpg",
          "test_310_4.jpg",
          "test_310_9.jpg",
          "test_310_1.jpg",
          "test_310_0.jpg",
          "test_310_3.jpg"
        ],
        "condorcet_winner": 7,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_310_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_310_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_310_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1678466796875,
            0.267333984375,
            0.294921875,
            0.1737060546875,
            0.1849365234375,
            0.1317138671875,
            0.270263671875,
            0.1734619140625,
            0.26123046875,
            0.282470703125
          ],
          "order_indices": [
            2,
            9,
            6,
            1,
            8,
            4,
            3,
            7,
            0,
            5
          ],
          "order_filenames": [
            "test_310_2.jpg",
            "test_310_9.jpg",
            "test_310_6.jpg",
            "test_310_1.jpg",
            "test_310_8.jpg",
            "test_310_4.jpg",
            "test_310_3.jpg",
            "test_310_7.jpg",
            "test_310_0.jpg",
            "test_310_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.022222222222222223,
            "spearman_rho": -0.0060606060606061,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.46875,
            33.03125,
            37.8125,
            24.59375,
            30.453125,
            17.953125,
            34.4375,
            32.25,
            33.9375,
            33.84375
          ],
          "order_indices": [
            2,
            0,
            6,
            8,
            9,
            1,
            7,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_310_2.jpg",
            "test_310_0.jpg",
            "test_310_6.jpg",
            "test_310_8.jpg",
            "test_310_9.jpg",
            "test_310_1.jpg",
            "test_310_7.jpg",
            "test_310_4.jpg",
            "test_310_3.jpg",
            "test_310_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.022222222222222223,
            "spearman_rho": 0.0060606060606061,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.05209074169397354,
            -0.032210804522037506,
            0.06314226984977722,
            -1.3133052587509155,
            -0.24773702025413513,
            -1.2834924459457397,
            0.3049718737602234,
            -0.8573024868965149,
            0.7353478670120239,
            1.1801483631134033
          ],
          "order_indices": [
            9,
            8,
            6,
            2,
            0,
            1,
            4,
            7,
            5,
            3
          ],
          "order_filenames": [
            "test_310_9.jpg",
            "test_310_8.jpg",
            "test_310_6.jpg",
            "test_310_2.jpg",
            "test_310_0.jpg",
            "test_310_1.jpg",
            "test_310_4.jpg",
            "test_310_7.jpg",
            "test_310_5.jpg",
            "test_310_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.06666666666666667,
            "spearman_rho": 0.10303030303030303,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 311,
      "prompt": "there is a old rusted train sitting on the ground",
      "image_filenames": [
        "test_311_0.jpg",
        "test_311_1.jpg",
        "test_311_2.jpg",
        "test_311_3.jpg",
        "test_311_4.jpg",
        "test_311_5.jpg",
        "test_311_6.jpg",
        "test_311_7.jpg",
        "test_311_8.jpg",
        "test_311_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          5,
          4,
          3,
          8,
          7,
          6,
          1,
          9,
          0
        ],
        "order_filenames": [
          "test_311_2.jpg",
          "test_311_5.jpg",
          "test_311_4.jpg",
          "test_311_3.jpg",
          "test_311_8.jpg",
          "test_311_7.jpg",
          "test_311_6.jpg",
          "test_311_1.jpg",
          "test_311_9.jpg",
          "test_311_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_311_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4,
            5,
            6
          ],
          "winner_filenames": [
            "test_311_4.jpg",
            "test_311_5.jpg",
            "test_311_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_311_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.208740234375,
            0.245361328125,
            0.29443359375,
            0.249755859375,
            0.277587890625,
            0.2283935546875,
            0.2017822265625,
            0.20849609375,
            0.265380859375,
            0.276123046875
          ],
          "order_indices": [
            2,
            4,
            9,
            8,
            3,
            1,
            5,
            0,
            7,
            6
          ],
          "order_filenames": [
            "test_311_2.jpg",
            "test_311_4.jpg",
            "test_311_9.jpg",
            "test_311_8.jpg",
            "test_311_3.jpg",
            "test_311_1.jpg",
            "test_311_5.jpg",
            "test_311_0.jpg",
            "test_311_7.jpg",
            "test_311_6.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.4545454545454546,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.78125,
            36.6875,
            36.9375,
            34.09375,
            34.5,
            33.6875,
            27.890625,
            32.28125,
            36.9375,
            30.328125
          ],
          "order_indices": [
            2,
            8,
            1,
            0,
            4,
            3,
            5,
            7,
            9,
            6
          ],
          "order_filenames": [
            "test_311_2.jpg",
            "test_311_8.jpg",
            "test_311_1.jpg",
            "test_311_0.jpg",
            "test_311_4.jpg",
            "test_311_3.jpg",
            "test_311_5.jpg",
            "test_311_7.jpg",
            "test_311_9.jpg",
            "test_311_6.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.24444444444444444,
            "spearman_rho": 0.296969696969697,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.6250684261322021,
            1.04164719581604,
            1.3675487041473389,
            0.7891556620597839,
            1.118956446647644,
            0.22877831757068634,
            -1.2031241655349731,
            -0.42060407996177673,
            1.0654551982879639,
            1.1313444375991821
          ],
          "order_indices": [
            2,
            9,
            4,
            8,
            1,
            3,
            0,
            5,
            7,
            6
          ],
          "order_filenames": [
            "test_311_2.jpg",
            "test_311_9.jpg",
            "test_311_4.jpg",
            "test_311_8.jpg",
            "test_311_1.jpg",
            "test_311_3.jpg",
            "test_311_0.jpg",
            "test_311_5.jpg",
            "test_311_7.jpg",
            "test_311_6.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2,
            "spearman_rho": 0.23636363636363633,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 312,
      "prompt": "baseball player swinging metal bat at home plate.",
      "image_filenames": [
        "test_312_0.jpg",
        "test_312_1.jpg",
        "test_312_2.jpg",
        "test_312_3.jpg",
        "test_312_4.jpg",
        "test_312_5.jpg",
        "test_312_6.jpg",
        "test_312_7.jpg",
        "test_312_8.jpg",
        "test_312_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          7,
          6,
          4,
          1,
          2,
          9,
          0,
          3,
          8
        ],
        "order_filenames": [
          "test_312_5.jpg",
          "test_312_7.jpg",
          "test_312_6.jpg",
          "test_312_4.jpg",
          "test_312_1.jpg",
          "test_312_2.jpg",
          "test_312_9.jpg",
          "test_312_0.jpg",
          "test_312_3.jpg",
          "test_312_8.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_312_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_312_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_312_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1610107421875,
            0.2127685546875,
            0.236328125,
            0.18115234375,
            0.2130126953125,
            0.0582275390625,
            0.224853515625,
            0.1575927734375,
            0.25830078125,
            0.232666015625
          ],
          "order_indices": [
            8,
            2,
            9,
            6,
            4,
            1,
            3,
            0,
            7,
            5
          ],
          "order_filenames": [
            "test_312_8.jpg",
            "test_312_2.jpg",
            "test_312_9.jpg",
            "test_312_6.jpg",
            "test_312_4.jpg",
            "test_312_1.jpg",
            "test_312_3.jpg",
            "test_312_0.jpg",
            "test_312_7.jpg",
            "test_312_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.37777777777777777,
            "spearman_rho": -0.5151515151515151,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            28.5,
            29.28125,
            31.78125,
            33.15625,
            30.421875,
            4.97265625,
            30.265625,
            29.109375,
            28.0,
            29.140625
          ],
          "order_indices": [
            3,
            2,
            4,
            6,
            1,
            9,
            7,
            0,
            8,
            5
          ],
          "order_filenames": [
            "test_312_3.jpg",
            "test_312_2.jpg",
            "test_312_4.jpg",
            "test_312_6.jpg",
            "test_312_1.jpg",
            "test_312_9.jpg",
            "test_312_7.jpg",
            "test_312_0.jpg",
            "test_312_8.jpg",
            "test_312_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.1515151515151516,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.0796646997332573,
            0.754077136516571,
            0.2000911980867386,
            0.09524034708738327,
            0.815567135810852,
            -2.2776808738708496,
            -0.8075188398361206,
            0.2658226490020752,
            1.1036254167556763,
            1.0670145750045776
          ],
          "order_indices": [
            8,
            9,
            4,
            1,
            7,
            2,
            3,
            0,
            6,
            5
          ],
          "order_filenames": [
            "test_312_8.jpg",
            "test_312_9.jpg",
            "test_312_4.jpg",
            "test_312_1.jpg",
            "test_312_7.jpg",
            "test_312_2.jpg",
            "test_312_3.jpg",
            "test_312_0.jpg",
            "test_312_6.jpg",
            "test_312_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.4424242424242424,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 313,
      "prompt": "Room full of people playing video games and having a party.",
      "image_filenames": [
        "test_313_0.jpg",
        "test_313_1.jpg",
        "test_313_2.jpg",
        "test_313_3.jpg",
        "test_313_4.jpg",
        "test_313_5.jpg",
        "test_313_6.jpg",
        "test_313_7.jpg",
        "test_313_8.jpg",
        "test_313_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          6,
          0,
          5,
          8,
          7,
          4,
          9,
          2,
          3
        ],
        "order_filenames": [
          "test_313_1.jpg",
          "test_313_6.jpg",
          "test_313_0.jpg",
          "test_313_5.jpg",
          "test_313_8.jpg",
          "test_313_7.jpg",
          "test_313_4.jpg",
          "test_313_9.jpg",
          "test_313_2.jpg",
          "test_313_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_313_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            8
          ],
          "winner_filenames": [
            "test_313_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_313_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1978759765625,
            0.277587890625,
            0.256103515625,
            0.2012939453125,
            0.19384765625,
            0.09002685546875,
            0.2333984375,
            0.184814453125,
            0.2529296875,
            0.215576171875
          ],
          "order_indices": [
            1,
            2,
            8,
            6,
            9,
            3,
            0,
            4,
            7,
            5
          ],
          "order_filenames": [
            "test_313_1.jpg",
            "test_313_2.jpg",
            "test_313_8.jpg",
            "test_313_6.jpg",
            "test_313_9.jpg",
            "test_313_3.jpg",
            "test_313_0.jpg",
            "test_313_4.jpg",
            "test_313_7.jpg",
            "test_313_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.06666666666666667,
            "spearman_rho": 0.12727272727272732,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.625,
            37.4375,
            35.53125,
            37.78125,
            31.40625,
            11.4921875,
            36.34375,
            36.4375,
            37.40625,
            24.5625
          ],
          "order_indices": [
            3,
            0,
            1,
            8,
            7,
            6,
            2,
            4,
            9,
            5
          ],
          "order_filenames": [
            "test_313_3.jpg",
            "test_313_0.jpg",
            "test_313_1.jpg",
            "test_313_8.jpg",
            "test_313_7.jpg",
            "test_313_6.jpg",
            "test_313_2.jpg",
            "test_313_4.jpg",
            "test_313_9.jpg",
            "test_313_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.11515151515151512,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.015745759010315,
            1.2080163955688477,
            -0.16936075687408447,
            -1.0121889114379883,
            0.441845178604126,
            -2.2553510665893555,
            0.20576666295528412,
            0.28640016913414,
            -0.6880710124969482,
            -1.86346435546875
          ],
          "order_indices": [
            1,
            0,
            4,
            7,
            6,
            2,
            8,
            3,
            9,
            5
          ],
          "order_filenames": [
            "test_313_1.jpg",
            "test_313_0.jpg",
            "test_313_4.jpg",
            "test_313_7.jpg",
            "test_313_6.jpg",
            "test_313_2.jpg",
            "test_313_8.jpg",
            "test_313_3.jpg",
            "test_313_9.jpg",
            "test_313_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.49090909090909096,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 314,
      "prompt": "An airplane is flying with a white line in the sky above it.",
      "image_filenames": [
        "test_314_0.jpg",
        "test_314_1.jpg",
        "test_314_2.jpg",
        "test_314_3.jpg",
        "test_314_4.jpg",
        "test_314_5.jpg",
        "test_314_6.jpg",
        "test_314_7.jpg",
        "test_314_8.jpg",
        "test_314_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          2,
          3,
          7,
          5,
          6,
          1,
          8,
          0,
          9
        ],
        "order_filenames": [
          "test_314_4.jpg",
          "test_314_2.jpg",
          "test_314_3.jpg",
          "test_314_7.jpg",
          "test_314_5.jpg",
          "test_314_6.jpg",
          "test_314_1.jpg",
          "test_314_8.jpg",
          "test_314_0.jpg",
          "test_314_9.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_314_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_314_2.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_314_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1998291015625,
            0.25146484375,
            0.23779296875,
            0.2003173828125,
            0.2200927734375,
            0.192138671875,
            0.197998046875,
            0.2010498046875,
            0.1861572265625,
            0.271240234375
          ],
          "order_indices": [
            9,
            1,
            2,
            4,
            7,
            3,
            0,
            6,
            5,
            8
          ],
          "order_filenames": [
            "test_314_9.jpg",
            "test_314_1.jpg",
            "test_314_2.jpg",
            "test_314_4.jpg",
            "test_314_7.jpg",
            "test_314_3.jpg",
            "test_314_0.jpg",
            "test_314_6.jpg",
            "test_314_5.jpg",
            "test_314_8.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.06666666666666667,
            "spearman_rho": 0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.84375,
            30.265625,
            29.09375,
            31.578125,
            31.46875,
            29.078125,
            28.296875,
            33.6875,
            38.78125,
            28.3125
          ],
          "order_indices": [
            8,
            0,
            7,
            3,
            4,
            1,
            2,
            5,
            9,
            6
          ],
          "order_filenames": [
            "test_314_8.jpg",
            "test_314_0.jpg",
            "test_314_7.jpg",
            "test_314_3.jpg",
            "test_314_4.jpg",
            "test_314_1.jpg",
            "test_314_2.jpg",
            "test_314_5.jpg",
            "test_314_9.jpg",
            "test_314_6.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.022222222222222223,
            "spearman_rho": -0.018181818181818077,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.14928866922855377,
            0.654782235622406,
            1.0727407932281494,
            -0.9254619479179382,
            0.011673596687614918,
            0.432724267244339,
            0.6303392648696899,
            0.2791052758693695,
            -0.2688126266002655,
            1.246300458908081
          ],
          "order_indices": [
            9,
            2,
            1,
            6,
            5,
            7,
            0,
            4,
            8,
            3
          ],
          "order_filenames": [
            "test_314_9.jpg",
            "test_314_2.jpg",
            "test_314_1.jpg",
            "test_314_6.jpg",
            "test_314_5.jpg",
            "test_314_7.jpg",
            "test_314_0.jpg",
            "test_314_4.jpg",
            "test_314_8.jpg",
            "test_314_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.24444444444444444,
            "spearman_rho": -0.2606060606060605,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 315,
      "prompt": "Three zebras crowd around each other in a painting. ",
      "image_filenames": [
        "test_315_0.jpg",
        "test_315_1.jpg",
        "test_315_2.jpg",
        "test_315_3.jpg",
        "test_315_4.jpg",
        "test_315_5.jpg",
        "test_315_6.jpg",
        "test_315_7.jpg",
        "test_315_8.jpg",
        "test_315_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          4,
          7,
          2,
          8,
          3,
          9,
          5,
          6,
          0
        ],
        "order_filenames": [
          "test_315_1.jpg",
          "test_315_4.jpg",
          "test_315_7.jpg",
          "test_315_2.jpg",
          "test_315_8.jpg",
          "test_315_3.jpg",
          "test_315_9.jpg",
          "test_315_5.jpg",
          "test_315_6.jpg",
          "test_315_0.jpg"
        ],
        "condorcet_winner": 1,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_315_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_315_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_315_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1854248046875,
            0.252197265625,
            0.24658203125,
            0.2257080078125,
            0.1983642578125,
            0.2161865234375,
            0.2174072265625,
            0.197998046875,
            0.2044677734375,
            0.291259765625
          ],
          "order_indices": [
            9,
            1,
            2,
            3,
            6,
            5,
            8,
            4,
            7,
            0
          ],
          "order_filenames": [
            "test_315_9.jpg",
            "test_315_1.jpg",
            "test_315_2.jpg",
            "test_315_3.jpg",
            "test_315_6.jpg",
            "test_315_5.jpg",
            "test_315_8.jpg",
            "test_315_4.jpg",
            "test_315_7.jpg",
            "test_315_0.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.1636363636363637,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.65625,
            35.84375,
            38.28125,
            36.53125,
            28.703125,
            35.75,
            31.59375,
            37.59375,
            32.5625,
            30.546875
          ],
          "order_indices": [
            2,
            7,
            3,
            1,
            5,
            0,
            8,
            6,
            9,
            4
          ],
          "order_filenames": [
            "test_315_2.jpg",
            "test_315_7.jpg",
            "test_315_3.jpg",
            "test_315_1.jpg",
            "test_315_5.jpg",
            "test_315_0.jpg",
            "test_315_8.jpg",
            "test_315_6.jpg",
            "test_315_9.jpg",
            "test_315_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.15555555555555556,
            "spearman_rho": 0.23636363636363633,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.08951551467180252,
            0.5175753831863403,
            0.24557386338710785,
            1.096725583076477,
            0.0445796363055706,
            0.5436647534370422,
            -0.4368946850299835,
            0.1859351396560669,
            -0.41486236453056335,
            0.9302685260772705
          ],
          "order_indices": [
            3,
            9,
            5,
            1,
            2,
            7,
            0,
            4,
            8,
            6
          ],
          "order_filenames": [
            "test_315_3.jpg",
            "test_315_9.jpg",
            "test_315_5.jpg",
            "test_315_1.jpg",
            "test_315_2.jpg",
            "test_315_7.jpg",
            "test_315_0.jpg",
            "test_315_4.jpg",
            "test_315_8.jpg",
            "test_315_6.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.06666666666666667,
            "spearman_rho": 0.054545454545454564,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 316,
      "prompt": "a plate that has some kind of food on it",
      "image_filenames": [
        "test_316_0.jpg",
        "test_316_1.jpg",
        "test_316_2.jpg",
        "test_316_3.jpg",
        "test_316_4.jpg",
        "test_316_5.jpg",
        "test_316_6.jpg",
        "test_316_7.jpg",
        "test_316_8.jpg",
        "test_316_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          8,
          1,
          2,
          4,
          3,
          9,
          5,
          7,
          6
        ],
        "order_filenames": [
          "test_316_0.jpg",
          "test_316_8.jpg",
          "test_316_1.jpg",
          "test_316_2.jpg",
          "test_316_4.jpg",
          "test_316_3.jpg",
          "test_316_9.jpg",
          "test_316_5.jpg",
          "test_316_7.jpg",
          "test_316_6.jpg"
        ],
        "condorcet_winner": 8,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_316_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            8
          ],
          "winner_filenames": [
            "test_316_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            8
          ],
          "winner_filenames": [
            "test_316_8.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1898193359375,
            0.296630859375,
            0.257568359375,
            0.261962890625,
            0.21728515625,
            0.1539306640625,
            0.24853515625,
            0.21337890625,
            0.189453125,
            0.21044921875
          ],
          "order_indices": [
            1,
            3,
            2,
            6,
            4,
            7,
            9,
            0,
            8,
            5
          ],
          "order_filenames": [
            "test_316_1.jpg",
            "test_316_3.jpg",
            "test_316_2.jpg",
            "test_316_6.jpg",
            "test_316_4.jpg",
            "test_316_7.jpg",
            "test_316_9.jpg",
            "test_316_0.jpg",
            "test_316_8.jpg",
            "test_316_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.022222222222222223,
            "spearman_rho": -0.018181818181818077,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            29.140625,
            28.421875,
            31.375,
            29.171875,
            30.515625,
            24.203125,
            28.15625,
            38.9375,
            28.671875,
            23.734375
          ],
          "order_indices": [
            7,
            2,
            4,
            3,
            0,
            8,
            1,
            6,
            5,
            9
          ],
          "order_filenames": [
            "test_316_7.jpg",
            "test_316_2.jpg",
            "test_316_4.jpg",
            "test_316_3.jpg",
            "test_316_0.jpg",
            "test_316_8.jpg",
            "test_316_1.jpg",
            "test_316_6.jpg",
            "test_316_5.jpg",
            "test_316_9.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.1636363636363637,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.16959041357040405,
            0.2746393382549286,
            0.5704670548439026,
            0.32308799028396606,
            0.37604889273643494,
            -2.2703182697296143,
            0.3321271538734436,
            -0.2420712411403656,
            -0.06153449788689613,
            0.2694850265979767
          ],
          "order_indices": [
            2,
            4,
            6,
            3,
            1,
            9,
            8,
            0,
            7,
            5
          ],
          "order_filenames": [
            "test_316_2.jpg",
            "test_316_4.jpg",
            "test_316_6.jpg",
            "test_316_3.jpg",
            "test_316_1.jpg",
            "test_316_9.jpg",
            "test_316_8.jpg",
            "test_316_0.jpg",
            "test_316_7.jpg",
            "test_316_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.022222222222222223,
            "spearman_rho": 0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 317,
      "prompt": "a  vehicle with many people even on top",
      "image_filenames": [
        "test_317_0.jpg",
        "test_317_1.jpg",
        "test_317_2.jpg",
        "test_317_3.jpg",
        "test_317_4.jpg",
        "test_317_5.jpg",
        "test_317_6.jpg",
        "test_317_7.jpg",
        "test_317_8.jpg",
        "test_317_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          5,
          1,
          0,
          2,
          6,
          7,
          3,
          8,
          9
        ],
        "order_filenames": [
          "test_317_4.jpg",
          "test_317_5.jpg",
          "test_317_1.jpg",
          "test_317_0.jpg",
          "test_317_2.jpg",
          "test_317_6.jpg",
          "test_317_7.jpg",
          "test_317_3.jpg",
          "test_317_8.jpg",
          "test_317_9.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_317_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_317_2.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_317_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.243896484375,
            0.2783203125,
            0.25927734375,
            0.2060546875,
            0.2705078125,
            0.198974609375,
            0.252685546875,
            0.261962890625,
            0.239990234375,
            0.204833984375
          ],
          "order_indices": [
            1,
            4,
            7,
            2,
            6,
            0,
            8,
            3,
            9,
            5
          ],
          "order_filenames": [
            "test_317_1.jpg",
            "test_317_4.jpg",
            "test_317_7.jpg",
            "test_317_2.jpg",
            "test_317_6.jpg",
            "test_317_0.jpg",
            "test_317_8.jpg",
            "test_317_3.jpg",
            "test_317_9.jpg",
            "test_317_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.4181818181818182,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            41.5,
            33.96875,
            31.75,
            19.6875,
            38.9375,
            28.90625,
            26.3125,
            41.03125,
            39.03125,
            25.359375
          ],
          "order_indices": [
            0,
            7,
            8,
            4,
            1,
            2,
            5,
            6,
            9,
            3
          ],
          "order_filenames": [
            "test_317_0.jpg",
            "test_317_7.jpg",
            "test_317_8.jpg",
            "test_317_4.jpg",
            "test_317_1.jpg",
            "test_317_2.jpg",
            "test_317_5.jpg",
            "test_317_6.jpg",
            "test_317_9.jpg",
            "test_317_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.24444444444444444,
            "spearman_rho": 0.2848484848484848,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.4051439762115479,
            -0.04881562665104866,
            0.8022965788841248,
            -0.3643018305301666,
            1.7027833461761475,
            -0.7957947850227356,
            -1.0582724809646606,
            1.5661829710006714,
            1.0902937650680542,
            1.0562173128128052
          ],
          "order_indices": [
            4,
            7,
            0,
            8,
            9,
            2,
            1,
            3,
            5,
            6
          ],
          "order_filenames": [
            "test_317_4.jpg",
            "test_317_7.jpg",
            "test_317_0.jpg",
            "test_317_8.jpg",
            "test_317_9.jpg",
            "test_317_2.jpg",
            "test_317_1.jpg",
            "test_317_3.jpg",
            "test_317_5.jpg",
            "test_317_6.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.022222222222222223,
            "spearman_rho": 0.042424242424242475,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 1.0,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 318,
      "prompt": "The skater is riding very low on his board.",
      "image_filenames": [
        "test_318_0.jpg",
        "test_318_1.jpg",
        "test_318_2.jpg",
        "test_318_3.jpg",
        "test_318_4.jpg",
        "test_318_5.jpg",
        "test_318_6.jpg",
        "test_318_7.jpg",
        "test_318_8.jpg",
        "test_318_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          6,
          3,
          5,
          2,
          1,
          9,
          7,
          8,
          0
        ],
        "order_filenames": [
          "test_318_4.jpg",
          "test_318_6.jpg",
          "test_318_3.jpg",
          "test_318_5.jpg",
          "test_318_2.jpg",
          "test_318_1.jpg",
          "test_318_9.jpg",
          "test_318_7.jpg",
          "test_318_8.jpg",
          "test_318_0.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_318_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4,
            5,
            6
          ],
          "winner_filenames": [
            "test_318_4.jpg",
            "test_318_5.jpg",
            "test_318_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_318_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.196044921875,
            0.2283935546875,
            0.2354736328125,
            0.178955078125,
            0.198974609375,
            0.1326904296875,
            0.235107421875,
            0.1783447265625,
            0.180419921875,
            0.278076171875
          ],
          "order_indices": [
            9,
            2,
            6,
            1,
            4,
            0,
            8,
            3,
            7,
            5
          ],
          "order_filenames": [
            "test_318_9.jpg",
            "test_318_2.jpg",
            "test_318_6.jpg",
            "test_318_1.jpg",
            "test_318_4.jpg",
            "test_318_0.jpg",
            "test_318_8.jpg",
            "test_318_3.jpg",
            "test_318_7.jpg",
            "test_318_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.022222222222222223,
            "spearman_rho": 0.10303030303030303,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.875,
            33.6875,
            33.3125,
            33.0,
            31.3125,
            17.8125,
            31.890625,
            33.4375,
            31.65625,
            31.1875
          ],
          "order_indices": [
            0,
            1,
            7,
            2,
            3,
            6,
            8,
            4,
            9,
            5
          ],
          "order_filenames": [
            "test_318_0.jpg",
            "test_318_1.jpg",
            "test_318_7.jpg",
            "test_318_2.jpg",
            "test_318_3.jpg",
            "test_318_6.jpg",
            "test_318_8.jpg",
            "test_318_4.jpg",
            "test_318_9.jpg",
            "test_318_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.37777777777777777,
            "spearman_rho": -0.4303030303030304,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.44577667117118835,
            1.010060429573059,
            0.7438691258430481,
            0.38382482528686523,
            0.07655838131904602,
            -2.2591822147369385,
            0.23585839569568634,
            -0.2715456485748291,
            0.3864142596721649,
            1.7433006763458252
          ],
          "order_indices": [
            9,
            1,
            2,
            0,
            8,
            3,
            6,
            4,
            7,
            5
          ],
          "order_filenames": [
            "test_318_9.jpg",
            "test_318_1.jpg",
            "test_318_2.jpg",
            "test_318_0.jpg",
            "test_318_8.jpg",
            "test_318_3.jpg",
            "test_318_6.jpg",
            "test_318_4.jpg",
            "test_318_7.jpg",
            "test_318_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.38181818181818183,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 319,
      "prompt": "Snow boarder falling down in almost white out conditions of snow.",
      "image_filenames": [
        "test_319_0.jpg",
        "test_319_1.jpg",
        "test_319_2.jpg",
        "test_319_3.jpg",
        "test_319_4.jpg",
        "test_319_5.jpg",
        "test_319_6.jpg",
        "test_319_7.jpg",
        "test_319_8.jpg",
        "test_319_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          5,
          7,
          1,
          6,
          3,
          2,
          8,
          9,
          0
        ],
        "order_filenames": [
          "test_319_4.jpg",
          "test_319_5.jpg",
          "test_319_7.jpg",
          "test_319_1.jpg",
          "test_319_6.jpg",
          "test_319_3.jpg",
          "test_319_2.jpg",
          "test_319_8.jpg",
          "test_319_9.jpg",
          "test_319_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_319_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_319_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_319_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.19287109375,
            0.249755859375,
            0.3037109375,
            0.188720703125,
            0.197509765625,
            0.1409912109375,
            0.247314453125,
            0.1883544921875,
            0.2366943359375,
            0.213623046875
          ],
          "order_indices": [
            2,
            1,
            6,
            8,
            9,
            4,
            0,
            3,
            7,
            5
          ],
          "order_filenames": [
            "test_319_2.jpg",
            "test_319_1.jpg",
            "test_319_6.jpg",
            "test_319_8.jpg",
            "test_319_9.jpg",
            "test_319_4.jpg",
            "test_319_0.jpg",
            "test_319_3.jpg",
            "test_319_7.jpg",
            "test_319_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.15555555555555556,
            "spearman_rho": -0.2969696969696969,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.84375,
            32.53125,
            34.5625,
            28.3125,
            32.0625,
            26.25,
            31.21875,
            34.625,
            41.875,
            32.34375
          ],
          "order_indices": [
            8,
            0,
            7,
            2,
            1,
            9,
            4,
            6,
            3,
            5
          ],
          "order_filenames": [
            "test_319_8.jpg",
            "test_319_0.jpg",
            "test_319_7.jpg",
            "test_319_2.jpg",
            "test_319_1.jpg",
            "test_319_9.jpg",
            "test_319_4.jpg",
            "test_319_6.jpg",
            "test_319_3.jpg",
            "test_319_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.5151515151515151,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.8682684898376465,
            1.043361783027649,
            0.7875230312347412,
            0.3681144416332245,
            -0.3814491033554077,
            -2.248725652694702,
            0.8214132785797119,
            -1.3928569555282593,
            1.0430729389190674,
            1.031821608543396
          ],
          "order_indices": [
            1,
            8,
            9,
            0,
            6,
            2,
            3,
            4,
            7,
            5
          ],
          "order_filenames": [
            "test_319_1.jpg",
            "test_319_8.jpg",
            "test_319_9.jpg",
            "test_319_0.jpg",
            "test_319_6.jpg",
            "test_319_2.jpg",
            "test_319_3.jpg",
            "test_319_4.jpg",
            "test_319_7.jpg",
            "test_319_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4222222222222222,
            "spearman_rho": -0.6242424242424243,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 320,
      "prompt": "A brown and black dog sticking its head out a window.",
      "image_filenames": [
        "test_320_0.jpg",
        "test_320_1.jpg",
        "test_320_2.jpg",
        "test_320_3.jpg",
        "test_320_4.jpg",
        "test_320_5.jpg",
        "test_320_6.jpg",
        "test_320_7.jpg",
        "test_320_8.jpg",
        "test_320_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          4,
          5,
          8,
          7,
          6,
          9,
          2,
          0,
          1
        ],
        "order_filenames": [
          "test_320_3.jpg",
          "test_320_4.jpg",
          "test_320_5.jpg",
          "test_320_8.jpg",
          "test_320_7.jpg",
          "test_320_6.jpg",
          "test_320_9.jpg",
          "test_320_2.jpg",
          "test_320_0.jpg",
          "test_320_1.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_320_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5,
            8
          ],
          "winner_filenames": [
            "test_320_5.jpg",
            "test_320_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_320_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1998291015625,
            0.2413330078125,
            0.3115234375,
            0.2208251953125,
            0.201904296875,
            0.174072265625,
            0.261962890625,
            0.184326171875,
            0.30126953125,
            0.28955078125
          ],
          "order_indices": [
            2,
            8,
            9,
            6,
            1,
            3,
            4,
            0,
            7,
            5
          ],
          "order_filenames": [
            "test_320_2.jpg",
            "test_320_8.jpg",
            "test_320_9.jpg",
            "test_320_6.jpg",
            "test_320_1.jpg",
            "test_320_3.jpg",
            "test_320_4.jpg",
            "test_320_0.jpg",
            "test_320_7.jpg",
            "test_320_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2,
            "spearman_rho": -0.2969696969696969,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.21875,
            38.1875,
            35.875,
            29.671875,
            35.9375,
            21.96875,
            35.90625,
            33.21875,
            33.625,
            33.09375
          ],
          "order_indices": [
            0,
            1,
            4,
            6,
            2,
            8,
            7,
            9,
            3,
            5
          ],
          "order_filenames": [
            "test_320_0.jpg",
            "test_320_1.jpg",
            "test_320_4.jpg",
            "test_320_6.jpg",
            "test_320_2.jpg",
            "test_320_8.jpg",
            "test_320_7.jpg",
            "test_320_9.jpg",
            "test_320_3.jpg",
            "test_320_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4222222222222222,
            "spearman_rho": -0.6000000000000001,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.3803809881210327,
            -0.20731496810913086,
            0.6908225417137146,
            -1.3034231662750244,
            -1.6346856355667114,
            -1.3610421419143677,
            -0.3565748333930969,
            -1.9744658470153809,
            0.9127638936042786,
            1.3807306289672852
          ],
          "order_indices": [
            9,
            8,
            2,
            1,
            6,
            3,
            5,
            0,
            4,
            7
          ],
          "order_filenames": [
            "test_320_9.jpg",
            "test_320_8.jpg",
            "test_320_2.jpg",
            "test_320_1.jpg",
            "test_320_6.jpg",
            "test_320_3.jpg",
            "test_320_5.jpg",
            "test_320_0.jpg",
            "test_320_4.jpg",
            "test_320_7.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2,
            "spearman_rho": -0.3212121212121213,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 321,
      "prompt": "A train is coming along near some unusual looking tracks.",
      "image_filenames": [
        "test_321_0.jpg",
        "test_321_1.jpg",
        "test_321_2.jpg",
        "test_321_3.jpg",
        "test_321_4.jpg",
        "test_321_5.jpg",
        "test_321_6.jpg",
        "test_321_7.jpg",
        "test_321_8.jpg",
        "test_321_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          6,
          3,
          5,
          2,
          0,
          7,
          8,
          1,
          9
        ],
        "order_filenames": [
          "test_321_4.jpg",
          "test_321_6.jpg",
          "test_321_3.jpg",
          "test_321_5.jpg",
          "test_321_2.jpg",
          "test_321_0.jpg",
          "test_321_7.jpg",
          "test_321_8.jpg",
          "test_321_1.jpg",
          "test_321_9.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_321_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4,
            6
          ],
          "winner_filenames": [
            "test_321_4.jpg",
            "test_321_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4,
            6
          ],
          "winner_filenames": [
            "test_321_4.jpg",
            "test_321_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2259521484375,
            0.27880859375,
            0.2205810546875,
            0.2244873046875,
            0.251708984375,
            0.186767578125,
            0.275146484375,
            0.15283203125,
            0.221435546875,
            0.25146484375
          ],
          "order_indices": [
            1,
            6,
            4,
            9,
            0,
            3,
            8,
            2,
            5,
            7
          ],
          "order_filenames": [
            "test_321_1.jpg",
            "test_321_6.jpg",
            "test_321_4.jpg",
            "test_321_9.jpg",
            "test_321_0.jpg",
            "test_321_3.jpg",
            "test_321_8.jpg",
            "test_321_2.jpg",
            "test_321_5.jpg",
            "test_321_7.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.022222222222222223,
            "spearman_rho": 0.042424242424242475,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.96875,
            21.96875,
            32.46875,
            31.625,
            25.890625,
            24.15625,
            27.984375,
            39.8125,
            25.078125,
            26.765625
          ],
          "order_indices": [
            7,
            0,
            2,
            3,
            6,
            9,
            4,
            8,
            5,
            1
          ],
          "order_filenames": [
            "test_321_7.jpg",
            "test_321_0.jpg",
            "test_321_2.jpg",
            "test_321_3.jpg",
            "test_321_6.jpg",
            "test_321_9.jpg",
            "test_321_4.jpg",
            "test_321_8.jpg",
            "test_321_5.jpg",
            "test_321_1.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.022222222222222223,
            "spearman_rho": 0.12727272727272732,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.45465710759162903,
            0.4515489935874939,
            -1.1795120239257812,
            0.1357385814189911,
            0.2647768259048462,
            -1.8327099084854126,
            0.4513181447982788,
            -1.2404649257659912,
            0.5456870794296265,
            0.589977502822876
          ],
          "order_indices": [
            9,
            8,
            0,
            1,
            6,
            4,
            3,
            2,
            7,
            5
          ],
          "order_filenames": [
            "test_321_9.jpg",
            "test_321_8.jpg",
            "test_321_0.jpg",
            "test_321_1.jpg",
            "test_321_6.jpg",
            "test_321_4.jpg",
            "test_321_3.jpg",
            "test_321_2.jpg",
            "test_321_7.jpg",
            "test_321_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.5151515151515151,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 322,
      "prompt": "A group of four friends commemorating a ski trip in the snow.",
      "image_filenames": [
        "test_322_0.jpg",
        "test_322_1.jpg",
        "test_322_2.jpg",
        "test_322_3.jpg",
        "test_322_4.jpg",
        "test_322_5.jpg",
        "test_322_6.jpg",
        "test_322_7.jpg",
        "test_322_8.jpg",
        "test_322_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          5,
          7,
          3,
          2,
          8,
          9,
          4,
          1,
          0
        ],
        "order_filenames": [
          "test_322_6.jpg",
          "test_322_5.jpg",
          "test_322_7.jpg",
          "test_322_3.jpg",
          "test_322_2.jpg",
          "test_322_8.jpg",
          "test_322_9.jpg",
          "test_322_4.jpg",
          "test_322_1.jpg",
          "test_322_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_322_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_322_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_322_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.205078125,
            0.292724609375,
            0.306396484375,
            0.23046875,
            0.2415771484375,
            0.1767578125,
            0.28955078125,
            0.1920166015625,
            0.29248046875,
            0.255126953125
          ],
          "order_indices": [
            2,
            1,
            8,
            6,
            9,
            4,
            3,
            0,
            7,
            5
          ],
          "order_filenames": [
            "test_322_2.jpg",
            "test_322_1.jpg",
            "test_322_8.jpg",
            "test_322_6.jpg",
            "test_322_9.jpg",
            "test_322_4.jpg",
            "test_322_3.jpg",
            "test_322_0.jpg",
            "test_322_7.jpg",
            "test_322_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.15555555555555556,
            "spearman_rho": -0.23636363636363633,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            31.59375,
            35.6875,
            36.21875,
            28.890625,
            30.65625,
            22.640625,
            33.25,
            27.578125,
            35.5,
            32.71875
          ],
          "order_indices": [
            2,
            1,
            8,
            6,
            9,
            0,
            4,
            3,
            7,
            5
          ],
          "order_filenames": [
            "test_322_2.jpg",
            "test_322_1.jpg",
            "test_322_8.jpg",
            "test_322_6.jpg",
            "test_322_9.jpg",
            "test_322_0.jpg",
            "test_322_4.jpg",
            "test_322_3.jpg",
            "test_322_7.jpg",
            "test_322_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.24444444444444444,
            "spearman_rho": -0.33333333333333326,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.6537699699401855,
            1.1159451007843018,
            0.8379870057106018,
            -1.5839236974716187,
            -0.09499165415763855,
            -2.048126697540283,
            0.8105509281158447,
            -1.991168737411499,
            0.9504833817481995,
            0.5093830823898315
          ],
          "order_indices": [
            1,
            8,
            2,
            6,
            9,
            4,
            0,
            3,
            7,
            5
          ],
          "order_filenames": [
            "test_322_1.jpg",
            "test_322_8.jpg",
            "test_322_2.jpg",
            "test_322_6.jpg",
            "test_322_9.jpg",
            "test_322_4.jpg",
            "test_322_0.jpg",
            "test_322_3.jpg",
            "test_322_7.jpg",
            "test_322_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.28888888888888886,
            "spearman_rho": -0.36969696969696964,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 323,
      "prompt": "Very ornate bedroom with a chandelier over the bed.",
      "image_filenames": [
        "test_323_0.jpg",
        "test_323_1.jpg",
        "test_323_2.jpg",
        "test_323_3.jpg",
        "test_323_4.jpg",
        "test_323_5.jpg",
        "test_323_6.jpg",
        "test_323_7.jpg",
        "test_323_8.jpg",
        "test_323_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          2,
          4,
          5,
          8,
          3,
          0,
          1,
          9,
          6
        ],
        "order_filenames": [
          "test_323_7.jpg",
          "test_323_2.jpg",
          "test_323_4.jpg",
          "test_323_5.jpg",
          "test_323_8.jpg",
          "test_323_3.jpg",
          "test_323_0.jpg",
          "test_323_1.jpg",
          "test_323_9.jpg",
          "test_323_6.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_323_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_323_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_323_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2191162109375,
            0.28173828125,
            0.29443359375,
            0.272216796875,
            0.2099609375,
            0.185302734375,
            0.298583984375,
            0.238037109375,
            0.264892578125,
            0.2802734375
          ],
          "order_indices": [
            6,
            2,
            1,
            9,
            3,
            8,
            7,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_323_6.jpg",
            "test_323_2.jpg",
            "test_323_1.jpg",
            "test_323_9.jpg",
            "test_323_3.jpg",
            "test_323_8.jpg",
            "test_323_7.jpg",
            "test_323_0.jpg",
            "test_323_4.jpg",
            "test_323_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.37777777777777777,
            "spearman_rho": -0.46666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            30.3125,
            32.96875,
            32.65625,
            36.40625,
            28.453125,
            24.578125,
            36.78125,
            32.4375,
            31.5625,
            33.5
          ],
          "order_indices": [
            6,
            3,
            9,
            1,
            2,
            7,
            8,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_323_6.jpg",
            "test_323_3.jpg",
            "test_323_9.jpg",
            "test_323_1.jpg",
            "test_323_2.jpg",
            "test_323_7.jpg",
            "test_323_8.jpg",
            "test_323_0.jpg",
            "test_323_4.jpg",
            "test_323_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4222222222222222,
            "spearman_rho": -0.5757575757575757,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.0067394571378827095,
            1.0537335872650146,
            1.31309974193573,
            0.8550934195518494,
            -0.5133787989616394,
            -0.5843843221664429,
            0.9708032011985779,
            0.6135237812995911,
            0.8781759738922119,
            0.6246142387390137
          ],
          "order_indices": [
            2,
            1,
            6,
            8,
            3,
            9,
            7,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_323_2.jpg",
            "test_323_1.jpg",
            "test_323_6.jpg",
            "test_323_8.jpg",
            "test_323_3.jpg",
            "test_323_9.jpg",
            "test_323_7.jpg",
            "test_323_0.jpg",
            "test_323_4.jpg",
            "test_323_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.15555555555555556,
            "spearman_rho": -0.24848484848484853,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 324,
      "prompt": "A mother bear and her cub crossing a two lane road.",
      "image_filenames": [
        "test_324_0.jpg",
        "test_324_1.jpg",
        "test_324_2.jpg",
        "test_324_3.jpg",
        "test_324_4.jpg",
        "test_324_5.jpg",
        "test_324_6.jpg",
        "test_324_7.jpg",
        "test_324_8.jpg",
        "test_324_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          6,
          4,
          7,
          8,
          1,
          0,
          3,
          9,
          2
        ],
        "order_filenames": [
          "test_324_5.jpg",
          "test_324_6.jpg",
          "test_324_4.jpg",
          "test_324_7.jpg",
          "test_324_8.jpg",
          "test_324_1.jpg",
          "test_324_0.jpg",
          "test_324_3.jpg",
          "test_324_9.jpg",
          "test_324_2.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_324_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4,
            5,
            6
          ],
          "winner_filenames": [
            "test_324_4.jpg",
            "test_324_5.jpg",
            "test_324_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4,
            5
          ],
          "winner_filenames": [
            "test_324_4.jpg",
            "test_324_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.217041015625,
            0.2247314453125,
            0.290771484375,
            0.214111328125,
            0.18994140625,
            0.1640625,
            0.268798828125,
            0.1693115234375,
            0.266845703125,
            0.305908203125
          ],
          "order_indices": [
            9,
            2,
            6,
            8,
            1,
            0,
            3,
            4,
            7,
            5
          ],
          "order_filenames": [
            "test_324_9.jpg",
            "test_324_2.jpg",
            "test_324_6.jpg",
            "test_324_8.jpg",
            "test_324_1.jpg",
            "test_324_0.jpg",
            "test_324_3.jpg",
            "test_324_4.jpg",
            "test_324_7.jpg",
            "test_324_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.37777777777777777,
            "spearman_rho": -0.6000000000000001,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.6875,
            30.6875,
            38.96875,
            35.0625,
            35.125,
            33.59375,
            38.8125,
            36.59375,
            39.90625,
            31.65625
          ],
          "order_indices": [
            8,
            2,
            6,
            0,
            7,
            4,
            3,
            5,
            9,
            1
          ],
          "order_filenames": [
            "test_324_8.jpg",
            "test_324_2.jpg",
            "test_324_6.jpg",
            "test_324_0.jpg",
            "test_324_7.jpg",
            "test_324_4.jpg",
            "test_324_3.jpg",
            "test_324_5.jpg",
            "test_324_9.jpg",
            "test_324_1.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.022222222222222223,
            "spearman_rho": -0.0060606060606061,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.11370693147182465,
            0.5874390602111816,
            1.6897962093353271,
            0.6016820073127747,
            0.3029783368110657,
            -0.20665250718593597,
            1.5642732381820679,
            -0.639279305934906,
            1.278543472290039,
            0.8736123442649841
          ],
          "order_indices": [
            2,
            6,
            8,
            9,
            3,
            1,
            4,
            0,
            5,
            7
          ],
          "order_filenames": [
            "test_324_2.jpg",
            "test_324_6.jpg",
            "test_324_8.jpg",
            "test_324_9.jpg",
            "test_324_3.jpg",
            "test_324_1.jpg",
            "test_324_4.jpg",
            "test_324_0.jpg",
            "test_324_5.jpg",
            "test_324_7.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.4303030303030304,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 325,
      "prompt": "Two little dogs looking a large pizza sitting on a table.",
      "image_filenames": [
        "test_325_0.jpg",
        "test_325_1.jpg",
        "test_325_2.jpg",
        "test_325_3.jpg",
        "test_325_4.jpg",
        "test_325_5.jpg",
        "test_325_6.jpg",
        "test_325_7.jpg",
        "test_325_8.jpg",
        "test_325_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          9,
          0,
          6,
          8,
          1,
          4,
          7,
          5,
          3,
          2
        ],
        "order_filenames": [
          "test_325_9.jpg",
          "test_325_0.jpg",
          "test_325_6.jpg",
          "test_325_8.jpg",
          "test_325_1.jpg",
          "test_325_4.jpg",
          "test_325_7.jpg",
          "test_325_5.jpg",
          "test_325_3.jpg",
          "test_325_2.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          9
        ],
        "winner_filenames": [
          "test_325_9.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            9
          ],
          "winner_filenames": [
            "test_325_9.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            9
          ],
          "winner_filenames": [
            "test_325_9.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2086181640625,
            0.299072265625,
            0.300048828125,
            0.2255859375,
            0.199951171875,
            0.2587890625,
            0.310791015625,
            0.226318359375,
            0.279296875,
            0.3017578125
          ],
          "order_indices": [
            6,
            9,
            2,
            1,
            8,
            5,
            7,
            3,
            0,
            4
          ],
          "order_filenames": [
            "test_325_6.jpg",
            "test_325_9.jpg",
            "test_325_2.jpg",
            "test_325_1.jpg",
            "test_325_8.jpg",
            "test_325_5.jpg",
            "test_325_7.jpg",
            "test_325_3.jpg",
            "test_325_0.jpg",
            "test_325_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.15555555555555556,
            "spearman_rho": 0.23636363636363633,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.84375,
            38.15625,
            39.875,
            26.234375,
            37.28125,
            36.4375,
            37.71875,
            39.78125,
            41.28125,
            40.03125
          ],
          "order_indices": [
            8,
            9,
            2,
            7,
            0,
            1,
            6,
            4,
            5,
            3
          ],
          "order_filenames": [
            "test_325_8.jpg",
            "test_325_9.jpg",
            "test_325_2.jpg",
            "test_325_7.jpg",
            "test_325_0.jpg",
            "test_325_1.jpg",
            "test_325_6.jpg",
            "test_325_4.jpg",
            "test_325_5.jpg",
            "test_325_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.3939393939393939,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.8764110803604126,
            1.245910406112671,
            0.5762348771095276,
            -0.944728672504425,
            0.5300217866897583,
            -0.03989563137292862,
            1.5220997333526611,
            -0.8112006783485413,
            1.7249197959899902,
            0.9249191284179688
          ],
          "order_indices": [
            8,
            6,
            1,
            9,
            2,
            4,
            5,
            7,
            0,
            3
          ],
          "order_filenames": [
            "test_325_8.jpg",
            "test_325_6.jpg",
            "test_325_1.jpg",
            "test_325_9.jpg",
            "test_325_2.jpg",
            "test_325_4.jpg",
            "test_325_5.jpg",
            "test_325_7.jpg",
            "test_325_0.jpg",
            "test_325_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.28888888888888886,
            "spearman_rho": 0.3939393939393939,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 326,
      "prompt": "an image of a messy counter in a bathroom",
      "image_filenames": [
        "test_326_0.jpg",
        "test_326_1.jpg",
        "test_326_2.jpg",
        "test_326_3.jpg",
        "test_326_4.jpg",
        "test_326_5.jpg",
        "test_326_6.jpg",
        "test_326_7.jpg",
        "test_326_8.jpg",
        "test_326_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          3,
          6,
          8,
          4,
          5,
          9,
          2,
          1,
          0
        ],
        "order_filenames": [
          "test_326_7.jpg",
          "test_326_3.jpg",
          "test_326_6.jpg",
          "test_326_8.jpg",
          "test_326_4.jpg",
          "test_326_5.jpg",
          "test_326_9.jpg",
          "test_326_2.jpg",
          "test_326_1.jpg",
          "test_326_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_326_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_326_3.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7,
            8
          ],
          "winner_filenames": [
            "test_326_7.jpg",
            "test_326_8.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2064208984375,
            0.2254638671875,
            0.22265625,
            0.220458984375,
            0.201416015625,
            0.2119140625,
            0.2357177734375,
            0.263427734375,
            0.270263671875,
            0.24658203125
          ],
          "order_indices": [
            8,
            7,
            9,
            6,
            1,
            2,
            3,
            5,
            0,
            4
          ],
          "order_filenames": [
            "test_326_8.jpg",
            "test_326_7.jpg",
            "test_326_9.jpg",
            "test_326_6.jpg",
            "test_326_1.jpg",
            "test_326_2.jpg",
            "test_326_3.jpg",
            "test_326_5.jpg",
            "test_326_0.jpg",
            "test_326_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.24444444444444444,
            "spearman_rho": 0.38181818181818183,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.28125,
            29.015625,
            31.25,
            27.40625,
            29.640625,
            34.59375,
            25.734375,
            42.21875,
            36.3125,
            31.921875
          ],
          "order_indices": [
            7,
            8,
            0,
            5,
            9,
            2,
            4,
            1,
            3,
            6
          ],
          "order_filenames": [
            "test_326_7.jpg",
            "test_326_8.jpg",
            "test_326_0.jpg",
            "test_326_5.jpg",
            "test_326_9.jpg",
            "test_326_2.jpg",
            "test_326_4.jpg",
            "test_326_1.jpg",
            "test_326_3.jpg",
            "test_326_6.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.022222222222222223,
            "spearman_rho": -0.018181818181818077,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.5184364914894104,
            -1.7987456321716309,
            -0.10332343727350235,
            -0.9242067933082581,
            -0.37733736634254456,
            1.0692998170852661,
            -1.7145588397979736,
            1.1705131530761719,
            0.6332419514656067,
            0.8490836024284363
          ],
          "order_indices": [
            7,
            5,
            9,
            8,
            2,
            4,
            0,
            3,
            6,
            1
          ],
          "order_filenames": [
            "test_326_7.jpg",
            "test_326_5.jpg",
            "test_326_9.jpg",
            "test_326_8.jpg",
            "test_326_2.jpg",
            "test_326_4.jpg",
            "test_326_0.jpg",
            "test_326_3.jpg",
            "test_326_6.jpg",
            "test_326_1.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2,
            "spearman_rho": 0.24848484848484853,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 327,
      "prompt": "The bus is parked beside of the shopping center.",
      "image_filenames": [
        "test_327_0.jpg",
        "test_327_1.jpg",
        "test_327_2.jpg",
        "test_327_3.jpg",
        "test_327_4.jpg",
        "test_327_5.jpg",
        "test_327_6.jpg",
        "test_327_7.jpg",
        "test_327_8.jpg",
        "test_327_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          5,
          6,
          8,
          1,
          3,
          4,
          9,
          2,
          0
        ],
        "order_filenames": [
          "test_327_7.jpg",
          "test_327_5.jpg",
          "test_327_6.jpg",
          "test_327_8.jpg",
          "test_327_1.jpg",
          "test_327_3.jpg",
          "test_327_4.jpg",
          "test_327_9.jpg",
          "test_327_2.jpg",
          "test_327_0.jpg"
        ],
        "condorcet_winner": 7,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_327_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5,
            7
          ],
          "winner_filenames": [
            "test_327_5.jpg",
            "test_327_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_327_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.19189453125,
            0.27587890625,
            0.27783203125,
            0.2122802734375,
            0.19921875,
            0.214111328125,
            0.25830078125,
            0.2066650390625,
            0.22119140625,
            0.26806640625
          ],
          "order_indices": [
            2,
            1,
            9,
            6,
            8,
            5,
            3,
            7,
            4,
            0
          ],
          "order_filenames": [
            "test_327_2.jpg",
            "test_327_1.jpg",
            "test_327_9.jpg",
            "test_327_6.jpg",
            "test_327_8.jpg",
            "test_327_5.jpg",
            "test_327_3.jpg",
            "test_327_7.jpg",
            "test_327_4.jpg",
            "test_327_0.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.06666666666666667,
            "spearman_rho": -0.030303030303030276,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.25,
            25.328125,
            34.28125,
            25.859375,
            31.625,
            34.09375,
            26.359375,
            34.6875,
            33.625,
            25.4375
          ],
          "order_indices": [
            0,
            7,
            2,
            5,
            8,
            4,
            6,
            3,
            9,
            1
          ],
          "order_filenames": [
            "test_327_0.jpg",
            "test_327_7.jpg",
            "test_327_2.jpg",
            "test_327_5.jpg",
            "test_327_8.jpg",
            "test_327_4.jpg",
            "test_327_6.jpg",
            "test_327_3.jpg",
            "test_327_9.jpg",
            "test_327_1.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.022222222222222223,
            "spearman_rho": -0.030303030303030276,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.6189302206039429,
            -0.9630694389343262,
            0.7748493552207947,
            -0.7621867656707764,
            -1.2998491525650024,
            -0.7714598774909973,
            -0.44918859004974365,
            -0.7097071409225464,
            -0.7135390639305115,
            -0.20033049583435059
          ],
          "order_indices": [
            2,
            9,
            6,
            0,
            7,
            8,
            3,
            5,
            1,
            4
          ],
          "order_filenames": [
            "test_327_2.jpg",
            "test_327_9.jpg",
            "test_327_6.jpg",
            "test_327_0.jpg",
            "test_327_7.jpg",
            "test_327_8.jpg",
            "test_327_3.jpg",
            "test_327_5.jpg",
            "test_327_1.jpg",
            "test_327_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.15555555555555556,
            "spearman_rho": -0.3212121212121213,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 328,
      "prompt": "Side of a street, where there is a fire hydrant and a mirror showing the street.",
      "image_filenames": [
        "test_328_0.jpg",
        "test_328_1.jpg",
        "test_328_2.jpg",
        "test_328_3.jpg",
        "test_328_4.jpg",
        "test_328_5.jpg",
        "test_328_6.jpg",
        "test_328_7.jpg",
        "test_328_8.jpg",
        "test_328_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          8,
          3,
          2,
          6,
          9,
          5,
          7,
          1,
          0
        ],
        "order_filenames": [
          "test_328_4.jpg",
          "test_328_8.jpg",
          "test_328_3.jpg",
          "test_328_2.jpg",
          "test_328_6.jpg",
          "test_328_9.jpg",
          "test_328_5.jpg",
          "test_328_7.jpg",
          "test_328_1.jpg",
          "test_328_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4,
          8
        ],
        "winner_filenames": [
          "test_328_4.jpg",
          "test_328_8.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            9
          ],
          "winner_filenames": [
            "test_328_9.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4,
            8
          ],
          "winner_filenames": [
            "test_328_4.jpg",
            "test_328_8.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.19140625,
            0.1702880859375,
            0.222412109375,
            0.19775390625,
            0.191162109375,
            0.2005615234375,
            0.2119140625,
            0.2252197265625,
            0.2095947265625,
            0.2003173828125
          ],
          "order_indices": [
            7,
            2,
            6,
            8,
            5,
            9,
            3,
            0,
            4,
            1
          ],
          "order_filenames": [
            "test_328_7.jpg",
            "test_328_2.jpg",
            "test_328_6.jpg",
            "test_328_8.jpg",
            "test_328_5.jpg",
            "test_328_9.jpg",
            "test_328_3.jpg",
            "test_328_0.jpg",
            "test_328_4.jpg",
            "test_328_1.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.022222222222222223,
            "spearman_rho": 0.09090909090909094,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.65625,
            27.890625,
            35.75,
            34.78125,
            40.9375,
            37.875,
            34.78125,
            44.09375,
            36.53125,
            41.34375
          ],
          "order_indices": [
            7,
            9,
            4,
            5,
            0,
            8,
            2,
            3,
            6,
            1
          ],
          "order_filenames": [
            "test_328_7.jpg",
            "test_328_9.jpg",
            "test_328_4.jpg",
            "test_328_5.jpg",
            "test_328_0.jpg",
            "test_328_8.jpg",
            "test_328_2.jpg",
            "test_328_3.jpg",
            "test_328_6.jpg",
            "test_328_1.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.022222222222222223,
            "spearman_rho": -0.030303030303030276,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.0020805743988603354,
            -2.1665964126586914,
            -1.0605642795562744,
            -1.3443760871887207,
            -0.6125054359436035,
            -1.1730573177337646,
            -1.3684096336364746,
            0.8228398561477661,
            0.01771455816924572,
            -0.5446279048919678
          ],
          "order_indices": [
            7,
            8,
            0,
            9,
            4,
            2,
            5,
            3,
            6,
            1
          ],
          "order_filenames": [
            "test_328_7.jpg",
            "test_328_8.jpg",
            "test_328_0.jpg",
            "test_328_9.jpg",
            "test_328_4.jpg",
            "test_328_2.jpg",
            "test_328_5.jpg",
            "test_328_3.jpg",
            "test_328_6.jpg",
            "test_328_1.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.022222222222222223,
            "spearman_rho": 0.0060606060606061,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 329,
      "prompt": "Two young ladies seated with several other people at a dinner table.",
      "image_filenames": [
        "test_329_0.jpg",
        "test_329_1.jpg",
        "test_329_2.jpg",
        "test_329_3.jpg",
        "test_329_4.jpg",
        "test_329_5.jpg",
        "test_329_6.jpg",
        "test_329_7.jpg",
        "test_329_8.jpg",
        "test_329_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          5,
          2,
          3,
          6,
          7,
          9,
          8,
          1,
          0
        ],
        "order_filenames": [
          "test_329_4.jpg",
          "test_329_5.jpg",
          "test_329_2.jpg",
          "test_329_3.jpg",
          "test_329_6.jpg",
          "test_329_7.jpg",
          "test_329_9.jpg",
          "test_329_8.jpg",
          "test_329_1.jpg",
          "test_329_0.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_329_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_329_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_329_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.195556640625,
            0.16015625,
            0.187255859375,
            0.201171875,
            0.197021484375,
            0.07720947265625,
            0.17333984375,
            0.1962890625,
            0.277587890625,
            0.24169921875
          ],
          "order_indices": [
            8,
            9,
            3,
            4,
            7,
            0,
            2,
            6,
            1,
            5
          ],
          "order_filenames": [
            "test_329_8.jpg",
            "test_329_9.jpg",
            "test_329_3.jpg",
            "test_329_4.jpg",
            "test_329_7.jpg",
            "test_329_0.jpg",
            "test_329_2.jpg",
            "test_329_6.jpg",
            "test_329_1.jpg",
            "test_329_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.15555555555555556,
            "spearman_rho": -0.1515151515151516,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.4375,
            32.875,
            39.21875,
            32.1875,
            34.125,
            5.60546875,
            36.28125,
            36.875,
            37.6875,
            32.84375
          ],
          "order_indices": [
            2,
            8,
            7,
            6,
            0,
            4,
            1,
            9,
            3,
            5
          ],
          "order_filenames": [
            "test_329_2.jpg",
            "test_329_8.jpg",
            "test_329_7.jpg",
            "test_329_6.jpg",
            "test_329_0.jpg",
            "test_329_4.jpg",
            "test_329_1.jpg",
            "test_329_9.jpg",
            "test_329_3.jpg",
            "test_329_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.15555555555555556,
            "spearman_rho": -0.17575757575757578,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.25235745310783386,
            -0.8082070350646973,
            -0.643903374671936,
            -0.3253473937511444,
            -0.34283527731895447,
            -2.2798831462860107,
            -1.064156413078308,
            -0.6004084944725037,
            0.3701198101043701,
            -0.961672842502594
          ],
          "order_indices": [
            8,
            0,
            3,
            4,
            7,
            2,
            1,
            9,
            6,
            5
          ],
          "order_filenames": [
            "test_329_8.jpg",
            "test_329_0.jpg",
            "test_329_3.jpg",
            "test_329_4.jpg",
            "test_329_7.jpg",
            "test_329_2.jpg",
            "test_329_1.jpg",
            "test_329_9.jpg",
            "test_329_6.jpg",
            "test_329_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.24444444444444444,
            "spearman_rho": -0.3212121212121213,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 330,
      "prompt": "A great room with the living area in the foreground, dining table behind it and kitchen in the very back. ",
      "image_filenames": [
        "test_330_0.jpg",
        "test_330_1.jpg",
        "test_330_2.jpg",
        "test_330_3.jpg",
        "test_330_4.jpg",
        "test_330_5.jpg",
        "test_330_6.jpg",
        "test_330_7.jpg",
        "test_330_8.jpg",
        "test_330_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          6,
          4,
          5,
          2,
          7,
          8,
          1,
          9,
          0
        ],
        "order_filenames": [
          "test_330_3.jpg",
          "test_330_6.jpg",
          "test_330_4.jpg",
          "test_330_5.jpg",
          "test_330_2.jpg",
          "test_330_7.jpg",
          "test_330_8.jpg",
          "test_330_1.jpg",
          "test_330_9.jpg",
          "test_330_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_330_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_330_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_330_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1634521484375,
            0.197265625,
            0.213623046875,
            0.1785888671875,
            0.146484375,
            0.1527099609375,
            0.2034912109375,
            0.16650390625,
            0.2313232421875,
            0.231201171875
          ],
          "order_indices": [
            8,
            9,
            2,
            6,
            1,
            3,
            7,
            0,
            5,
            4
          ],
          "order_filenames": [
            "test_330_8.jpg",
            "test_330_9.jpg",
            "test_330_2.jpg",
            "test_330_6.jpg",
            "test_330_1.jpg",
            "test_330_3.jpg",
            "test_330_7.jpg",
            "test_330_0.jpg",
            "test_330_5.jpg",
            "test_330_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2,
            "spearman_rho": -0.24848484848484853,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            30.78125,
            29.84375,
            31.109375,
            26.90625,
            25.40625,
            22.46875,
            27.28125,
            24.953125,
            28.125,
            26.1875
          ],
          "order_indices": [
            2,
            0,
            1,
            8,
            6,
            3,
            9,
            4,
            7,
            5
          ],
          "order_filenames": [
            "test_330_2.jpg",
            "test_330_0.jpg",
            "test_330_1.jpg",
            "test_330_8.jpg",
            "test_330_6.jpg",
            "test_330_3.jpg",
            "test_330_9.jpg",
            "test_330_4.jpg",
            "test_330_7.jpg",
            "test_330_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.24444444444444444,
            "spearman_rho": -0.34545454545454546,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.788704514503479,
            0.2775328755378723,
            -0.2770569622516632,
            -1.0058221817016602,
            -1.2895087003707886,
            -1.5548912286758423,
            -1.104989767074585,
            -0.9924877882003784,
            0.12220100313425064,
            -0.23758523166179657
          ],
          "order_indices": [
            1,
            8,
            9,
            2,
            0,
            7,
            3,
            6,
            4,
            5
          ],
          "order_filenames": [
            "test_330_1.jpg",
            "test_330_8.jpg",
            "test_330_9.jpg",
            "test_330_2.jpg",
            "test_330_0.jpg",
            "test_330_7.jpg",
            "test_330_3.jpg",
            "test_330_6.jpg",
            "test_330_4.jpg",
            "test_330_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4222222222222222,
            "spearman_rho": -0.696969696969697,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 331,
      "prompt": "The shadow of a person across an asphalt street next to a street sign.",
      "image_filenames": [
        "test_331_0.jpg",
        "test_331_1.jpg",
        "test_331_2.jpg",
        "test_331_3.jpg",
        "test_331_4.jpg",
        "test_331_5.jpg",
        "test_331_6.jpg",
        "test_331_7.jpg",
        "test_331_8.jpg",
        "test_331_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          9,
          5,
          6,
          7,
          3,
          2,
          8,
          1,
          0
        ],
        "order_filenames": [
          "test_331_4.jpg",
          "test_331_9.jpg",
          "test_331_5.jpg",
          "test_331_6.jpg",
          "test_331_7.jpg",
          "test_331_3.jpg",
          "test_331_2.jpg",
          "test_331_8.jpg",
          "test_331_1.jpg",
          "test_331_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_331_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4,
            5
          ],
          "winner_filenames": [
            "test_331_4.jpg",
            "test_331_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_331_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.19873046875,
            0.1905517578125,
            0.1583251953125,
            0.1676025390625,
            0.1943359375,
            0.14990234375,
            0.1697998046875,
            0.1925048828125,
            0.2314453125,
            0.25341796875
          ],
          "order_indices": [
            9,
            8,
            0,
            4,
            7,
            1,
            6,
            3,
            2,
            5
          ],
          "order_filenames": [
            "test_331_9.jpg",
            "test_331_8.jpg",
            "test_331_0.jpg",
            "test_331_4.jpg",
            "test_331_7.jpg",
            "test_331_1.jpg",
            "test_331_6.jpg",
            "test_331_3.jpg",
            "test_331_2.jpg",
            "test_331_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.022222222222222223,
            "spearman_rho": -0.030303030303030276,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.78125,
            30.921875,
            25.625,
            24.890625,
            30.5,
            29.171875,
            25.5625,
            39.09375,
            39.25,
            36.0625
          ],
          "order_indices": [
            8,
            7,
            0,
            9,
            1,
            4,
            5,
            2,
            6,
            3
          ],
          "order_filenames": [
            "test_331_8.jpg",
            "test_331_7.jpg",
            "test_331_0.jpg",
            "test_331_9.jpg",
            "test_331_1.jpg",
            "test_331_4.jpg",
            "test_331_5.jpg",
            "test_331_2.jpg",
            "test_331_6.jpg",
            "test_331_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.15555555555555556,
            "spearman_rho": -0.2727272727272727,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.936730146408081,
            -2.1061370372772217,
            -1.9733942747116089,
            -0.5129863619804382,
            -0.689185619354248,
            -1.2050695419311523,
            -1.735977053642273,
            0.13681232929229736,
            -0.10843255370855331,
            0.768921971321106
          ],
          "order_indices": [
            9,
            7,
            8,
            3,
            4,
            0,
            5,
            6,
            2,
            1
          ],
          "order_filenames": [
            "test_331_9.jpg",
            "test_331_7.jpg",
            "test_331_8.jpg",
            "test_331_3.jpg",
            "test_331_4.jpg",
            "test_331_0.jpg",
            "test_331_5.jpg",
            "test_331_6.jpg",
            "test_331_2.jpg",
            "test_331_1.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.28888888888888886,
            "spearman_rho": 0.34545454545454546,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 332,
      "prompt": "There is a bicycle parked next to a car.",
      "image_filenames": [
        "test_332_0.jpg",
        "test_332_1.jpg",
        "test_332_2.jpg",
        "test_332_3.jpg",
        "test_332_4.jpg",
        "test_332_5.jpg",
        "test_332_6.jpg",
        "test_332_7.jpg",
        "test_332_8.jpg",
        "test_332_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          5,
          8,
          7,
          3,
          6,
          2,
          9,
          1,
          0
        ],
        "order_filenames": [
          "test_332_4.jpg",
          "test_332_5.jpg",
          "test_332_8.jpg",
          "test_332_7.jpg",
          "test_332_3.jpg",
          "test_332_6.jpg",
          "test_332_2.jpg",
          "test_332_9.jpg",
          "test_332_1.jpg",
          "test_332_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_332_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_332_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            8
          ],
          "winner_filenames": [
            "test_332_8.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.20556640625,
            0.1904296875,
            0.21923828125,
            0.210693359375,
            0.2177734375,
            0.2156982421875,
            0.2406005859375,
            0.1815185546875,
            0.27587890625,
            0.25927734375
          ],
          "order_indices": [
            8,
            9,
            6,
            2,
            4,
            5,
            3,
            0,
            1,
            7
          ],
          "order_filenames": [
            "test_332_8.jpg",
            "test_332_9.jpg",
            "test_332_6.jpg",
            "test_332_2.jpg",
            "test_332_4.jpg",
            "test_332_5.jpg",
            "test_332_3.jpg",
            "test_332_0.jpg",
            "test_332_1.jpg",
            "test_332_7.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.18787878787878787,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.78125,
            24.421875,
            24.75,
            33.40625,
            29.8125,
            36.5625,
            27.609375,
            33.875,
            37.875,
            21.265625
          ],
          "order_indices": [
            8,
            0,
            5,
            7,
            3,
            4,
            6,
            2,
            1,
            9
          ],
          "order_filenames": [
            "test_332_8.jpg",
            "test_332_0.jpg",
            "test_332_5.jpg",
            "test_332_7.jpg",
            "test_332_3.jpg",
            "test_332_4.jpg",
            "test_332_6.jpg",
            "test_332_2.jpg",
            "test_332_1.jpg",
            "test_332_9.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.37777777777777777,
            "spearman_rho": 0.3939393939393939,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.669518232345581,
            -2.182493209838867,
            -1.2549840211868286,
            1.1909247636795044,
            0.38474681973457336,
            1.166436791419983,
            -2.0361928939819336,
            -0.7860640287399292,
            1.4299277067184448,
            1.3551219701766968
          ],
          "order_indices": [
            8,
            9,
            3,
            5,
            0,
            4,
            7,
            2,
            6,
            1
          ],
          "order_filenames": [
            "test_332_8.jpg",
            "test_332_9.jpg",
            "test_332_3.jpg",
            "test_332_5.jpg",
            "test_332_0.jpg",
            "test_332_4.jpg",
            "test_332_7.jpg",
            "test_332_2.jpg",
            "test_332_6.jpg",
            "test_332_1.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2,
            "spearman_rho": 0.2848484848484848,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 333,
      "prompt": "A man walking on the bea with his surfboard.",
      "image_filenames": [
        "test_333_0.jpg",
        "test_333_1.jpg",
        "test_333_2.jpg",
        "test_333_3.jpg",
        "test_333_4.jpg",
        "test_333_5.jpg",
        "test_333_6.jpg",
        "test_333_7.jpg",
        "test_333_8.jpg",
        "test_333_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          4,
          6,
          7,
          1,
          3,
          9,
          8,
          2,
          0
        ],
        "order_filenames": [
          "test_333_5.jpg",
          "test_333_4.jpg",
          "test_333_6.jpg",
          "test_333_7.jpg",
          "test_333_1.jpg",
          "test_333_3.jpg",
          "test_333_9.jpg",
          "test_333_8.jpg",
          "test_333_2.jpg",
          "test_333_0.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_333_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_333_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_333_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2115478515625,
            0.2049560546875,
            0.28955078125,
            0.181396484375,
            0.1947021484375,
            0.123291015625,
            0.255859375,
            0.1761474609375,
            0.272216796875,
            0.29541015625
          ],
          "order_indices": [
            9,
            2,
            8,
            6,
            0,
            1,
            4,
            3,
            7,
            5
          ],
          "order_filenames": [
            "test_333_9.jpg",
            "test_333_2.jpg",
            "test_333_8.jpg",
            "test_333_6.jpg",
            "test_333_0.jpg",
            "test_333_1.jpg",
            "test_333_4.jpg",
            "test_333_3.jpg",
            "test_333_7.jpg",
            "test_333_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4666666666666667,
            "spearman_rho": -0.6484848484848484,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.03125,
            34.0,
            34.875,
            27.484375,
            33.21875,
            20.265625,
            34.0625,
            30.65625,
            35.0,
            32.65625
          ],
          "order_indices": [
            0,
            8,
            2,
            6,
            1,
            4,
            9,
            7,
            3,
            5
          ],
          "order_filenames": [
            "test_333_0.jpg",
            "test_333_8.jpg",
            "test_333_2.jpg",
            "test_333_6.jpg",
            "test_333_1.jpg",
            "test_333_4.jpg",
            "test_333_9.jpg",
            "test_333_7.jpg",
            "test_333_3.jpg",
            "test_333_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5111111111111111,
            "spearman_rho": -0.6727272727272726,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.6029001474380493,
            0.9876077175140381,
            1.4303652048110962,
            -1.7845313549041748,
            0.463212788105011,
            -2.0458664894104004,
            0.9832285046577454,
            0.508999228477478,
            1.1471216678619385,
            1.2148267030715942
          ],
          "order_indices": [
            2,
            9,
            8,
            1,
            6,
            7,
            4,
            0,
            3,
            5
          ],
          "order_filenames": [
            "test_333_2.jpg",
            "test_333_9.jpg",
            "test_333_8.jpg",
            "test_333_1.jpg",
            "test_333_6.jpg",
            "test_333_7.jpg",
            "test_333_4.jpg",
            "test_333_0.jpg",
            "test_333_3.jpg",
            "test_333_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4222222222222222,
            "spearman_rho": -0.46666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 334,
      "prompt": "A lighted birthday cake with chunks of walnuts.",
      "image_filenames": [
        "test_334_0.jpg",
        "test_334_1.jpg",
        "test_334_2.jpg",
        "test_334_3.jpg",
        "test_334_4.jpg",
        "test_334_5.jpg",
        "test_334_6.jpg",
        "test_334_7.jpg",
        "test_334_8.jpg",
        "test_334_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          7,
          8,
          9,
          4,
          3,
          5,
          2,
          0,
          1
        ],
        "order_filenames": [
          "test_334_6.jpg",
          "test_334_7.jpg",
          "test_334_8.jpg",
          "test_334_9.jpg",
          "test_334_4.jpg",
          "test_334_3.jpg",
          "test_334_5.jpg",
          "test_334_2.jpg",
          "test_334_0.jpg",
          "test_334_1.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_334_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_334_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_334_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.23388671875,
            0.24658203125,
            0.2529296875,
            0.23828125,
            0.2122802734375,
            0.27294921875,
            0.3017578125,
            0.26318359375,
            0.24560546875,
            0.272216796875
          ],
          "order_indices": [
            6,
            5,
            9,
            7,
            2,
            1,
            8,
            3,
            0,
            4
          ],
          "order_filenames": [
            "test_334_6.jpg",
            "test_334_5.jpg",
            "test_334_9.jpg",
            "test_334_7.jpg",
            "test_334_2.jpg",
            "test_334_1.jpg",
            "test_334_8.jpg",
            "test_334_3.jpg",
            "test_334_0.jpg",
            "test_334_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.28888888888888886,
            "spearman_rho": 0.3939393939393939,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.0625,
            32.5,
            33.59375,
            35.3125,
            34.28125,
            41.75,
            42.78125,
            42.8125,
            38.96875,
            42.1875
          ],
          "order_indices": [
            7,
            6,
            9,
            5,
            0,
            8,
            3,
            4,
            2,
            1
          ],
          "order_filenames": [
            "test_334_7.jpg",
            "test_334_6.jpg",
            "test_334_9.jpg",
            "test_334_5.jpg",
            "test_334_0.jpg",
            "test_334_8.jpg",
            "test_334_3.jpg",
            "test_334_4.jpg",
            "test_334_2.jpg",
            "test_334_1.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.5555555555555556,
            "spearman_rho": 0.7090909090909091,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.4108529090881348,
            0.8690305352210999,
            -0.6987609267234802,
            -0.5886212587356567,
            -0.0546986348927021,
            1.477258324623108,
            1.5765591859817505,
            1.4756892919540405,
            1.3107852935791016,
            1.6028416156768799
          ],
          "order_indices": [
            9,
            6,
            5,
            7,
            0,
            8,
            1,
            4,
            3,
            2
          ],
          "order_filenames": [
            "test_334_9.jpg",
            "test_334_6.jpg",
            "test_334_5.jpg",
            "test_334_7.jpg",
            "test_334_0.jpg",
            "test_334_8.jpg",
            "test_334_1.jpg",
            "test_334_4.jpg",
            "test_334_3.jpg",
            "test_334_2.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.37777777777777777,
            "spearman_rho": 0.47878787878787876,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 335,
      "prompt": "A woman wearing a bridal veil and suitcase poses with a man in a yellow tie.",
      "image_filenames": [
        "test_335_0.jpg",
        "test_335_1.jpg",
        "test_335_2.jpg",
        "test_335_3.jpg",
        "test_335_4.jpg",
        "test_335_5.jpg",
        "test_335_6.jpg",
        "test_335_7.jpg",
        "test_335_8.jpg",
        "test_335_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          4,
          7,
          5,
          8,
          9,
          3,
          2,
          1,
          0
        ],
        "order_filenames": [
          "test_335_6.jpg",
          "test_335_4.jpg",
          "test_335_7.jpg",
          "test_335_5.jpg",
          "test_335_8.jpg",
          "test_335_9.jpg",
          "test_335_3.jpg",
          "test_335_2.jpg",
          "test_335_1.jpg",
          "test_335_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_335_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6,
            7
          ],
          "winner_filenames": [
            "test_335_6.jpg",
            "test_335_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_335_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2073974609375,
            0.21337890625,
            0.29296875,
            0.2164306640625,
            0.201171875,
            0.12298583984375,
            0.2105712890625,
            0.252685546875,
            0.2802734375,
            0.213134765625
          ],
          "order_indices": [
            2,
            8,
            7,
            3,
            1,
            9,
            6,
            0,
            4,
            5
          ],
          "order_filenames": [
            "test_335_2.jpg",
            "test_335_8.jpg",
            "test_335_7.jpg",
            "test_335_3.jpg",
            "test_335_1.jpg",
            "test_335_9.jpg",
            "test_335_6.jpg",
            "test_335_0.jpg",
            "test_335_4.jpg",
            "test_335_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.15555555555555556,
            "spearman_rho": -0.2606060606060605,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.40625,
            33.09375,
            42.8125,
            28.71875,
            33.28125,
            19.359375,
            34.875,
            45.3125,
            40.28125,
            21.0625
          ],
          "order_indices": [
            7,
            2,
            0,
            8,
            6,
            4,
            1,
            3,
            9,
            5
          ],
          "order_filenames": [
            "test_335_7.jpg",
            "test_335_2.jpg",
            "test_335_0.jpg",
            "test_335_8.jpg",
            "test_335_6.jpg",
            "test_335_4.jpg",
            "test_335_1.jpg",
            "test_335_3.jpg",
            "test_335_9.jpg",
            "test_335_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.06666666666666667,
            "spearman_rho": -0.042424242424242475,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.7520917654037476,
            -1.954404592514038,
            1.319464087486267,
            -1.834374189376831,
            -0.6641485095024109,
            -2.2864487171173096,
            -1.3892836570739746,
            -0.3981197774410248,
            0.4075585901737213,
            -1.2770594358444214
          ],
          "order_indices": [
            2,
            8,
            7,
            4,
            0,
            9,
            6,
            3,
            1,
            5
          ],
          "order_filenames": [
            "test_335_2.jpg",
            "test_335_8.jpg",
            "test_335_7.jpg",
            "test_335_4.jpg",
            "test_335_0.jpg",
            "test_335_9.jpg",
            "test_335_6.jpg",
            "test_335_3.jpg",
            "test_335_1.jpg",
            "test_335_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.022222222222222223,
            "spearman_rho": 0.030303030303030276,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 336,
      "prompt": "a man walking alone down the street in a velvet jacket",
      "image_filenames": [
        "test_336_0.jpg",
        "test_336_1.jpg",
        "test_336_2.jpg",
        "test_336_3.jpg",
        "test_336_4.jpg",
        "test_336_5.jpg",
        "test_336_6.jpg",
        "test_336_7.jpg",
        "test_336_8.jpg",
        "test_336_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          6,
          4,
          8,
          5,
          3,
          9,
          2,
          1,
          0
        ],
        "order_filenames": [
          "test_336_7.jpg",
          "test_336_6.jpg",
          "test_336_4.jpg",
          "test_336_8.jpg",
          "test_336_5.jpg",
          "test_336_3.jpg",
          "test_336_9.jpg",
          "test_336_2.jpg",
          "test_336_1.jpg",
          "test_336_0.jpg"
        ],
        "condorcet_winner": 7,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_336_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7,
            8
          ],
          "winner_filenames": [
            "test_336_7.jpg",
            "test_336_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_336_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1947021484375,
            0.2010498046875,
            0.248046875,
            0.220947265625,
            0.2042236328125,
            0.072998046875,
            0.265380859375,
            0.208740234375,
            0.277587890625,
            0.26953125
          ],
          "order_indices": [
            8,
            9,
            6,
            2,
            3,
            7,
            4,
            1,
            0,
            5
          ],
          "order_filenames": [
            "test_336_8.jpg",
            "test_336_9.jpg",
            "test_336_6.jpg",
            "test_336_2.jpg",
            "test_336_3.jpg",
            "test_336_7.jpg",
            "test_336_4.jpg",
            "test_336_1.jpg",
            "test_336_0.jpg",
            "test_336_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2,
            "spearman_rho": 0.2727272727272727,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.03125,
            30.09375,
            34.78125,
            31.234375,
            32.03125,
            9.2578125,
            39.46875,
            30.609375,
            41.625,
            30.078125
          ],
          "order_indices": [
            8,
            6,
            0,
            2,
            4,
            3,
            7,
            1,
            9,
            5
          ],
          "order_filenames": [
            "test_336_8.jpg",
            "test_336_6.jpg",
            "test_336_0.jpg",
            "test_336_2.jpg",
            "test_336_4.jpg",
            "test_336_3.jpg",
            "test_336_7.jpg",
            "test_336_1.jpg",
            "test_336_9.jpg",
            "test_336_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.022222222222222223,
            "spearman_rho": 0.12727272727272732,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.9394664168357849,
            0.9769922494888306,
            0.09981928765773773,
            -1.1907352209091187,
            -1.1989885568618774,
            -2.2819879055023193,
            1.9042640924453735,
            0.6033077836036682,
            1.8519400358200073,
            0.6729727983474731
          ],
          "order_indices": [
            6,
            8,
            1,
            0,
            9,
            7,
            2,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_336_6.jpg",
            "test_336_8.jpg",
            "test_336_1.jpg",
            "test_336_0.jpg",
            "test_336_9.jpg",
            "test_336_7.jpg",
            "test_336_2.jpg",
            "test_336_3.jpg",
            "test_336_4.jpg",
            "test_336_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.06666666666666667,
            "spearman_rho": -0.042424242424242475,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 337,
      "prompt": "A person holding a very small slice on pizza between their fingers.",
      "image_filenames": [
        "test_337_0.jpg",
        "test_337_1.jpg",
        "test_337_2.jpg",
        "test_337_3.jpg",
        "test_337_4.jpg",
        "test_337_5.jpg",
        "test_337_6.jpg",
        "test_337_7.jpg",
        "test_337_8.jpg",
        "test_337_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          3,
          7,
          6,
          5,
          8,
          4,
          9,
          1,
          0
        ],
        "order_filenames": [
          "test_337_2.jpg",
          "test_337_3.jpg",
          "test_337_7.jpg",
          "test_337_6.jpg",
          "test_337_5.jpg",
          "test_337_8.jpg",
          "test_337_4.jpg",
          "test_337_9.jpg",
          "test_337_1.jpg",
          "test_337_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_337_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_337_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_337_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1695556640625,
            0.2283935546875,
            0.2529296875,
            0.19384765625,
            0.180419921875,
            0.1414794921875,
            0.2081298828125,
            0.194091796875,
            0.2059326171875,
            0.244873046875
          ],
          "order_indices": [
            2,
            9,
            1,
            6,
            8,
            7,
            3,
            4,
            0,
            5
          ],
          "order_filenames": [
            "test_337_2.jpg",
            "test_337_9.jpg",
            "test_337_1.jpg",
            "test_337_6.jpg",
            "test_337_8.jpg",
            "test_337_7.jpg",
            "test_337_3.jpg",
            "test_337_4.jpg",
            "test_337_0.jpg",
            "test_337_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.18787878787878787,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.28125,
            37.3125,
            29.609375,
            33.71875,
            33.9375,
            21.8125,
            33.53125,
            36.21875,
            37.34375,
            29.21875
          ],
          "order_indices": [
            8,
            1,
            0,
            7,
            4,
            3,
            6,
            2,
            9,
            5
          ],
          "order_filenames": [
            "test_337_8.jpg",
            "test_337_1.jpg",
            "test_337_0.jpg",
            "test_337_7.jpg",
            "test_337_4.jpg",
            "test_337_3.jpg",
            "test_337_6.jpg",
            "test_337_2.jpg",
            "test_337_9.jpg",
            "test_337_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.24444444444444444,
            "spearman_rho": -0.38181818181818183,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.03162473067641258,
            0.45611193776130676,
            0.24431265890598297,
            0.05013149976730347,
            -0.25849461555480957,
            -2.1621150970458984,
            0.011172747239470482,
            0.11896737664937973,
            0.5283202528953552,
            0.8066548705101013
          ],
          "order_indices": [
            9,
            8,
            1,
            2,
            7,
            3,
            0,
            6,
            4,
            5
          ],
          "order_filenames": [
            "test_337_9.jpg",
            "test_337_8.jpg",
            "test_337_1.jpg",
            "test_337_2.jpg",
            "test_337_7.jpg",
            "test_337_3.jpg",
            "test_337_0.jpg",
            "test_337_6.jpg",
            "test_337_4.jpg",
            "test_337_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.022222222222222223,
            "spearman_rho": -0.11515151515151523,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 338,
      "prompt": "A person flying a kite while standing in the grass.",
      "image_filenames": [
        "test_338_0.jpg",
        "test_338_1.jpg",
        "test_338_2.jpg",
        "test_338_3.jpg",
        "test_338_4.jpg",
        "test_338_5.jpg",
        "test_338_6.jpg",
        "test_338_7.jpg",
        "test_338_8.jpg",
        "test_338_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          5,
          0,
          8,
          4,
          6,
          3,
          9,
          1,
          2
        ],
        "order_filenames": [
          "test_338_7.jpg",
          "test_338_5.jpg",
          "test_338_0.jpg",
          "test_338_8.jpg",
          "test_338_4.jpg",
          "test_338_6.jpg",
          "test_338_3.jpg",
          "test_338_9.jpg",
          "test_338_1.jpg",
          "test_338_2.jpg"
        ],
        "condorcet_winner": 7,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_338_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5,
            7
          ],
          "winner_filenames": [
            "test_338_5.jpg",
            "test_338_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_338_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.202392578125,
            0.21142578125,
            0.266357421875,
            0.2186279296875,
            0.208251953125,
            0.1778564453125,
            0.248779296875,
            0.197998046875,
            0.2239990234375,
            0.2098388671875
          ],
          "order_indices": [
            2,
            6,
            8,
            3,
            1,
            9,
            4,
            0,
            7,
            5
          ],
          "order_filenames": [
            "test_338_2.jpg",
            "test_338_6.jpg",
            "test_338_8.jpg",
            "test_338_3.jpg",
            "test_338_1.jpg",
            "test_338_9.jpg",
            "test_338_4.jpg",
            "test_338_0.jpg",
            "test_338_7.jpg",
            "test_338_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5555555555555556,
            "spearman_rho": -0.7212121212121212,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.71875,
            37.65625,
            37.875,
            35.1875,
            34.71875,
            34.0,
            35.65625,
            33.03125,
            37.75,
            26.890625
          ],
          "order_indices": [
            2,
            8,
            1,
            6,
            3,
            0,
            4,
            5,
            7,
            9
          ],
          "order_filenames": [
            "test_338_2.jpg",
            "test_338_8.jpg",
            "test_338_1.jpg",
            "test_338_6.jpg",
            "test_338_3.jpg",
            "test_338_0.jpg",
            "test_338_4.jpg",
            "test_338_5.jpg",
            "test_338_7.jpg",
            "test_338_9.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4222222222222222,
            "spearman_rho": -0.49090909090909096,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.8396165370941162,
            0.32288458943367004,
            0.968097984790802,
            0.14234237372875214,
            1.0442583560943604,
            -0.07150685042142868,
            0.9757682085037231,
            0.469944566488266,
            1.0044161081314087,
            1.0981909036636353
          ],
          "order_indices": [
            9,
            4,
            8,
            6,
            2,
            0,
            7,
            1,
            3,
            5
          ],
          "order_filenames": [
            "test_338_9.jpg",
            "test_338_4.jpg",
            "test_338_8.jpg",
            "test_338_6.jpg",
            "test_338_2.jpg",
            "test_338_0.jpg",
            "test_338_7.jpg",
            "test_338_1.jpg",
            "test_338_3.jpg",
            "test_338_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2,
            "spearman_rho": -0.22424242424242413,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 339,
      "prompt": "A man stands in front of a bus and a car that have collided.",
      "image_filenames": [
        "test_339_0.jpg",
        "test_339_1.jpg",
        "test_339_2.jpg",
        "test_339_3.jpg",
        "test_339_4.jpg",
        "test_339_5.jpg",
        "test_339_6.jpg",
        "test_339_7.jpg",
        "test_339_8.jpg",
        "test_339_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          2,
          4,
          8,
          1,
          3,
          7,
          9,
          6,
          0
        ],
        "order_filenames": [
          "test_339_5.jpg",
          "test_339_2.jpg",
          "test_339_4.jpg",
          "test_339_8.jpg",
          "test_339_1.jpg",
          "test_339_3.jpg",
          "test_339_7.jpg",
          "test_339_9.jpg",
          "test_339_6.jpg",
          "test_339_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_339_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_339_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2,
            5
          ],
          "winner_filenames": [
            "test_339_2.jpg",
            "test_339_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2154541015625,
            0.2386474609375,
            0.22900390625,
            0.2012939453125,
            0.1689453125,
            0.1832275390625,
            0.268310546875,
            0.20849609375,
            0.25927734375,
            0.29931640625
          ],
          "order_indices": [
            9,
            6,
            8,
            1,
            2,
            0,
            7,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_339_9.jpg",
            "test_339_6.jpg",
            "test_339_8.jpg",
            "test_339_1.jpg",
            "test_339_2.jpg",
            "test_339_0.jpg",
            "test_339_7.jpg",
            "test_339_3.jpg",
            "test_339_5.jpg",
            "test_339_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.46666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.625,
            38.875,
            35.125,
            28.59375,
            25.328125,
            22.34375,
            37.15625,
            37.78125,
            38.875,
            33.40625
          ],
          "order_indices": [
            1,
            8,
            7,
            6,
            2,
            0,
            9,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_339_1.jpg",
            "test_339_8.jpg",
            "test_339_7.jpg",
            "test_339_6.jpg",
            "test_339_2.jpg",
            "test_339_0.jpg",
            "test_339_9.jpg",
            "test_339_3.jpg",
            "test_339_4.jpg",
            "test_339_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2,
            "spearman_rho": -0.2606060606060605,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.7692384719848633,
            1.6718392372131348,
            0.6482199430465698,
            -0.8679082989692688,
            -0.7432652711868286,
            -0.9984249472618103,
            1.4865020513534546,
            1.6686567068099976,
            1.5489883422851562,
            1.759507179260254
          ],
          "order_indices": [
            0,
            9,
            1,
            7,
            8,
            6,
            2,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_339_0.jpg",
            "test_339_9.jpg",
            "test_339_1.jpg",
            "test_339_7.jpg",
            "test_339_8.jpg",
            "test_339_6.jpg",
            "test_339_2.jpg",
            "test_339_4.jpg",
            "test_339_3.jpg",
            "test_339_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5555555555555556,
            "spearman_rho": -0.696969696969697,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 340,
      "prompt": "An airplane is flying down above a tree.",
      "image_filenames": [
        "test_340_0.jpg",
        "test_340_1.jpg",
        "test_340_2.jpg",
        "test_340_3.jpg",
        "test_340_4.jpg",
        "test_340_5.jpg",
        "test_340_6.jpg",
        "test_340_7.jpg",
        "test_340_8.jpg",
        "test_340_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          6,
          7,
          1,
          3,
          2,
          4,
          8,
          9,
          0
        ],
        "order_filenames": [
          "test_340_5.jpg",
          "test_340_6.jpg",
          "test_340_7.jpg",
          "test_340_1.jpg",
          "test_340_3.jpg",
          "test_340_2.jpg",
          "test_340_4.jpg",
          "test_340_8.jpg",
          "test_340_9.jpg",
          "test_340_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5,
          6
        ],
        "winner_filenames": [
          "test_340_5.jpg",
          "test_340_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_340_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_340_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.228515625,
            0.30029296875,
            0.31884765625,
            0.1707763671875,
            0.24462890625,
            0.20263671875,
            0.277099609375,
            0.25927734375,
            0.30224609375,
            0.2308349609375
          ],
          "order_indices": [
            2,
            8,
            1,
            6,
            7,
            4,
            9,
            0,
            5,
            3
          ],
          "order_filenames": [
            "test_340_2.jpg",
            "test_340_8.jpg",
            "test_340_1.jpg",
            "test_340_6.jpg",
            "test_340_7.jpg",
            "test_340_4.jpg",
            "test_340_9.jpg",
            "test_340_0.jpg",
            "test_340_5.jpg",
            "test_340_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.022222222222222223,
            "spearman_rho": -0.018181818181818077,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.84375,
            43.90625,
            42.15625,
            15.328125,
            37.15625,
            33.1875,
            34.40625,
            41.53125,
            41.90625,
            30.1875
          ],
          "order_indices": [
            1,
            2,
            8,
            7,
            4,
            0,
            6,
            5,
            9,
            3
          ],
          "order_filenames": [
            "test_340_1.jpg",
            "test_340_2.jpg",
            "test_340_8.jpg",
            "test_340_7.jpg",
            "test_340_4.jpg",
            "test_340_0.jpg",
            "test_340_6.jpg",
            "test_340_5.jpg",
            "test_340_9.jpg",
            "test_340_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.022222222222222223,
            "spearman_rho": -0.030303030303030276,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.39082103967666626,
            1.5116325616836548,
            1.6989363431930542,
            -1.6500284671783447,
            0.6451319456100464,
            1.0340063571929932,
            1.5182204246520996,
            1.2485939264297485,
            1.608705759048462,
            -1.1926066875457764
          ],
          "order_indices": [
            2,
            8,
            6,
            1,
            7,
            5,
            4,
            0,
            9,
            3
          ],
          "order_filenames": [
            "test_340_2.jpg",
            "test_340_8.jpg",
            "test_340_6.jpg",
            "test_340_1.jpg",
            "test_340_7.jpg",
            "test_340_5.jpg",
            "test_340_4.jpg",
            "test_340_0.jpg",
            "test_340_9.jpg",
            "test_340_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.15555555555555556,
            "spearman_rho": 0.2727272727272727,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 341,
      "prompt": "A woman riding skis across snow covered ground.",
      "image_filenames": [
        "test_341_0.jpg",
        "test_341_1.jpg",
        "test_341_2.jpg",
        "test_341_3.jpg",
        "test_341_4.jpg",
        "test_341_5.jpg",
        "test_341_6.jpg",
        "test_341_7.jpg",
        "test_341_8.jpg",
        "test_341_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          7,
          6,
          5,
          8,
          9,
          2,
          1,
          3,
          4
        ],
        "order_filenames": [
          "test_341_0.jpg",
          "test_341_7.jpg",
          "test_341_6.jpg",
          "test_341_5.jpg",
          "test_341_8.jpg",
          "test_341_9.jpg",
          "test_341_2.jpg",
          "test_341_1.jpg",
          "test_341_3.jpg",
          "test_341_4.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_341_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_341_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0,
            7
          ],
          "winner_filenames": [
            "test_341_0.jpg",
            "test_341_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1943359375,
            0.284912109375,
            0.253662109375,
            0.1781005859375,
            0.205322265625,
            0.1187744140625,
            0.28857421875,
            0.195068359375,
            0.259521484375,
            0.251708984375
          ],
          "order_indices": [
            6,
            1,
            8,
            2,
            9,
            4,
            7,
            0,
            3,
            5
          ],
          "order_filenames": [
            "test_341_6.jpg",
            "test_341_1.jpg",
            "test_341_8.jpg",
            "test_341_2.jpg",
            "test_341_9.jpg",
            "test_341_4.jpg",
            "test_341_7.jpg",
            "test_341_0.jpg",
            "test_341_3.jpg",
            "test_341_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.06666666666666667,
            "spearman_rho": -0.09090909090909083,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.40625,
            32.25,
            36.1875,
            28.484375,
            34.1875,
            29.9375,
            34.65625,
            32.625,
            33.875,
            28.484375
          ],
          "order_indices": [
            2,
            6,
            0,
            4,
            8,
            7,
            1,
            5,
            3,
            9
          ],
          "order_filenames": [
            "test_341_2.jpg",
            "test_341_6.jpg",
            "test_341_0.jpg",
            "test_341_4.jpg",
            "test_341_8.jpg",
            "test_341_7.jpg",
            "test_341_1.jpg",
            "test_341_5.jpg",
            "test_341_3.jpg",
            "test_341_9.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.15555555555555556,
            "spearman_rho": 0.23636363636363633,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.548959493637085,
            0.2936681807041168,
            -0.034873541444540024,
            -1.6718913316726685,
            0.17003829777240753,
            -2.1677963733673096,
            0.29854506254196167,
            -1.5341713428497314,
            -0.48186519742012024,
            -0.784082293510437
          ],
          "order_indices": [
            6,
            1,
            4,
            2,
            8,
            0,
            9,
            7,
            3,
            5
          ],
          "order_filenames": [
            "test_341_6.jpg",
            "test_341_1.jpg",
            "test_341_4.jpg",
            "test_341_2.jpg",
            "test_341_8.jpg",
            "test_341_0.jpg",
            "test_341_9.jpg",
            "test_341_7.jpg",
            "test_341_3.jpg",
            "test_341_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.15555555555555556,
            "spearman_rho": -0.18787878787878798,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 342,
      "prompt": "A bunch of people waiting in line by a rail.",
      "image_filenames": [
        "test_342_0.jpg",
        "test_342_1.jpg",
        "test_342_2.jpg",
        "test_342_3.jpg",
        "test_342_4.jpg",
        "test_342_5.jpg",
        "test_342_6.jpg",
        "test_342_7.jpg",
        "test_342_8.jpg",
        "test_342_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          2,
          5,
          6,
          4,
          9,
          7,
          0,
          1,
          8
        ],
        "order_filenames": [
          "test_342_3.jpg",
          "test_342_2.jpg",
          "test_342_5.jpg",
          "test_342_6.jpg",
          "test_342_4.jpg",
          "test_342_9.jpg",
          "test_342_7.jpg",
          "test_342_0.jpg",
          "test_342_1.jpg",
          "test_342_8.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_342_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4,
            5,
            6,
            7
          ],
          "winner_filenames": [
            "test_342_4.jpg",
            "test_342_5.jpg",
            "test_342_6.jpg",
            "test_342_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_342_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1942138671875,
            0.2396240234375,
            0.2509765625,
            0.2015380859375,
            0.21875,
            0.15478515625,
            0.2313232421875,
            0.1951904296875,
            0.2484130859375,
            0.2154541015625
          ],
          "order_indices": [
            2,
            8,
            1,
            6,
            4,
            9,
            3,
            7,
            0,
            5
          ],
          "order_filenames": [
            "test_342_2.jpg",
            "test_342_8.jpg",
            "test_342_1.jpg",
            "test_342_6.jpg",
            "test_342_4.jpg",
            "test_342_9.jpg",
            "test_342_3.jpg",
            "test_342_7.jpg",
            "test_342_0.jpg",
            "test_342_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.06666666666666667,
            "spearman_rho": -0.1393939393939394,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.28125,
            40.96875,
            38.125,
            33.09375,
            27.5625,
            21.21875,
            39.6875,
            27.25,
            35.90625,
            31.5625
          ],
          "order_indices": [
            1,
            6,
            2,
            0,
            8,
            3,
            9,
            4,
            7,
            5
          ],
          "order_filenames": [
            "test_342_1.jpg",
            "test_342_6.jpg",
            "test_342_2.jpg",
            "test_342_0.jpg",
            "test_342_8.jpg",
            "test_342_3.jpg",
            "test_342_9.jpg",
            "test_342_4.jpg",
            "test_342_7.jpg",
            "test_342_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.15555555555555556,
            "spearman_rho": -0.19999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.4756273031234741,
            1.0680495500564575,
            1.1283931732177734,
            0.36466890573501587,
            0.5997036695480347,
            -1.9405179023742676,
            1.030829668045044,
            0.5872765779495239,
            0.2557738721370697,
            -0.19760099053382874
          ],
          "order_indices": [
            0,
            2,
            1,
            6,
            4,
            7,
            3,
            8,
            9,
            5
          ],
          "order_filenames": [
            "test_342_0.jpg",
            "test_342_2.jpg",
            "test_342_1.jpg",
            "test_342_6.jpg",
            "test_342_4.jpg",
            "test_342_7.jpg",
            "test_342_3.jpg",
            "test_342_8.jpg",
            "test_342_9.jpg",
            "test_342_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.06666666666666667,
            "spearman_rho": -0.11515151515151523,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 343,
      "prompt": "A man playing with a tennis racquet, on a court.",
      "image_filenames": [
        "test_343_0.jpg",
        "test_343_1.jpg",
        "test_343_2.jpg",
        "test_343_3.jpg",
        "test_343_4.jpg",
        "test_343_5.jpg",
        "test_343_6.jpg",
        "test_343_7.jpg",
        "test_343_8.jpg",
        "test_343_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          6,
          1,
          8,
          0,
          9,
          3,
          4,
          2,
          7
        ],
        "order_filenames": [
          "test_343_5.jpg",
          "test_343_6.jpg",
          "test_343_1.jpg",
          "test_343_8.jpg",
          "test_343_0.jpg",
          "test_343_9.jpg",
          "test_343_3.jpg",
          "test_343_4.jpg",
          "test_343_2.jpg",
          "test_343_7.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_343_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_343_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_343_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.18115234375,
            0.2447509765625,
            0.2093505859375,
            0.152587890625,
            0.167724609375,
            0.09259033203125,
            0.22216796875,
            0.1748046875,
            0.24072265625,
            0.21435546875
          ],
          "order_indices": [
            1,
            8,
            6,
            9,
            2,
            0,
            7,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_343_1.jpg",
            "test_343_8.jpg",
            "test_343_6.jpg",
            "test_343_9.jpg",
            "test_343_2.jpg",
            "test_343_0.jpg",
            "test_343_7.jpg",
            "test_343_4.jpg",
            "test_343_3.jpg",
            "test_343_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2,
            "spearman_rho": 0.24848484848484853,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            32.03125,
            33.3125,
            31.8125,
            26.71875,
            31.015625,
            25.078125,
            32.625,
            28.546875,
            29.671875,
            29.1875
          ],
          "order_indices": [
            1,
            6,
            0,
            2,
            4,
            8,
            9,
            7,
            3,
            5
          ],
          "order_filenames": [
            "test_343_1.jpg",
            "test_343_6.jpg",
            "test_343_0.jpg",
            "test_343_2.jpg",
            "test_343_4.jpg",
            "test_343_8.jpg",
            "test_343_9.jpg",
            "test_343_7.jpg",
            "test_343_3.jpg",
            "test_343_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.15555555555555556,
            "spearman_rho": 0.17575757575757578,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.2643669843673706,
            0.4721633493900299,
            -0.15428759157657623,
            -1.322615146636963,
            0.4547986090183258,
            -2.0965561866760254,
            0.6462693214416504,
            0.27769625186920166,
            0.7557493448257446,
            1.4245985746383667
          ],
          "order_indices": [
            9,
            0,
            8,
            6,
            1,
            4,
            7,
            2,
            3,
            5
          ],
          "order_filenames": [
            "test_343_9.jpg",
            "test_343_0.jpg",
            "test_343_8.jpg",
            "test_343_6.jpg",
            "test_343_1.jpg",
            "test_343_4.jpg",
            "test_343_7.jpg",
            "test_343_2.jpg",
            "test_343_3.jpg",
            "test_343_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.022222222222222223,
            "spearman_rho": 0.1393939393939394,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 344,
      "prompt": "A small dog looking at a white plate holding donuts.",
      "image_filenames": [
        "test_344_0.jpg",
        "test_344_1.jpg",
        "test_344_2.jpg",
        "test_344_3.jpg",
        "test_344_4.jpg",
        "test_344_5.jpg",
        "test_344_6.jpg",
        "test_344_7.jpg",
        "test_344_8.jpg",
        "test_344_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          2,
          8,
          0,
          3,
          5,
          7,
          9,
          1,
          4
        ],
        "order_filenames": [
          "test_344_6.jpg",
          "test_344_2.jpg",
          "test_344_8.jpg",
          "test_344_0.jpg",
          "test_344_3.jpg",
          "test_344_5.jpg",
          "test_344_7.jpg",
          "test_344_9.jpg",
          "test_344_1.jpg",
          "test_344_4.jpg"
        ],
        "condorcet_winner": 6,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_344_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_344_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_344_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1971435546875,
            0.28076171875,
            0.32177734375,
            0.2476806640625,
            0.1995849609375,
            0.1812744140625,
            0.292724609375,
            0.1810302734375,
            0.308349609375,
            0.2646484375
          ],
          "order_indices": [
            2,
            8,
            6,
            1,
            9,
            3,
            4,
            0,
            5,
            7
          ],
          "order_filenames": [
            "test_344_2.jpg",
            "test_344_8.jpg",
            "test_344_6.jpg",
            "test_344_1.jpg",
            "test_344_9.jpg",
            "test_344_3.jpg",
            "test_344_4.jpg",
            "test_344_0.jpg",
            "test_344_5.jpg",
            "test_344_7.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.49090909090909096,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            33.53125,
            41.125,
            37.375,
            33.15625,
            33.3125,
            27.875,
            41.8125,
            37.6875,
            40.0,
            35.125
          ],
          "order_indices": [
            6,
            1,
            8,
            7,
            2,
            9,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_344_6.jpg",
            "test_344_1.jpg",
            "test_344_8.jpg",
            "test_344_7.jpg",
            "test_344_2.jpg",
            "test_344_9.jpg",
            "test_344_0.jpg",
            "test_344_4.jpg",
            "test_344_3.jpg",
            "test_344_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.24444444444444444,
            "spearman_rho": 0.296969696969697,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 1.0,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.872293472290039,
            1.025664210319519,
            0.7564199566841125,
            1.0701770782470703,
            0.7327481508255005,
            -2.117920398712158,
            1.6530119180679321,
            -0.3242267370223999,
            1.3268436193466187,
            1.118770718574524
          ],
          "order_indices": [
            6,
            8,
            9,
            3,
            1,
            2,
            4,
            7,
            0,
            5
          ],
          "order_filenames": [
            "test_344_6.jpg",
            "test_344_8.jpg",
            "test_344_9.jpg",
            "test_344_3.jpg",
            "test_344_1.jpg",
            "test_344_2.jpg",
            "test_344_4.jpg",
            "test_344_7.jpg",
            "test_344_0.jpg",
            "test_344_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.24444444444444444,
            "spearman_rho": 0.33333333333333337,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 1.0,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 345,
      "prompt": "A couple of men are standing outside their car watching sheep cross a road. ",
      "image_filenames": [
        "test_345_0.jpg",
        "test_345_1.jpg",
        "test_345_2.jpg",
        "test_345_3.jpg",
        "test_345_4.jpg",
        "test_345_5.jpg",
        "test_345_6.jpg",
        "test_345_7.jpg",
        "test_345_8.jpg",
        "test_345_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          3,
          2,
          8,
          9,
          7,
          4,
          5,
          1,
          0
        ],
        "order_filenames": [
          "test_345_6.jpg",
          "test_345_3.jpg",
          "test_345_2.jpg",
          "test_345_8.jpg",
          "test_345_9.jpg",
          "test_345_7.jpg",
          "test_345_4.jpg",
          "test_345_5.jpg",
          "test_345_1.jpg",
          "test_345_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_345_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_345_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_345_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1719970703125,
            0.2420654296875,
            0.248291015625,
            0.11541748046875,
            0.19140625,
            0.188720703125,
            0.2225341796875,
            0.1995849609375,
            0.3134765625,
            0.29296875
          ],
          "order_indices": [
            8,
            9,
            2,
            1,
            6,
            7,
            4,
            5,
            0,
            3
          ],
          "order_filenames": [
            "test_345_8.jpg",
            "test_345_9.jpg",
            "test_345_2.jpg",
            "test_345_1.jpg",
            "test_345_6.jpg",
            "test_345_7.jpg",
            "test_345_4.jpg",
            "test_345_5.jpg",
            "test_345_0.jpg",
            "test_345_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.24444444444444444,
            "spearman_rho": 0.24848484848484853,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.4,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.71875,
            32.78125,
            39.21875,
            22.96875,
            38.28125,
            35.28125,
            38.46875,
            42.875,
            47.53125,
            36.84375
          ],
          "order_indices": [
            8,
            7,
            2,
            0,
            6,
            4,
            9,
            5,
            1,
            3
          ],
          "order_filenames": [
            "test_345_8.jpg",
            "test_345_7.jpg",
            "test_345_2.jpg",
            "test_345_0.jpg",
            "test_345_6.jpg",
            "test_345_4.jpg",
            "test_345_9.jpg",
            "test_345_5.jpg",
            "test_345_1.jpg",
            "test_345_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.11515151515151512,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.0251234769821167,
            -1.217048168182373,
            0.4902803301811218,
            -1.6102378368377686,
            -0.38587620854377747,
            0.06402738392353058,
            0.9858396649360657,
            0.3472983241081238,
            1.2099909782409668,
            0.5976330041885376
          ],
          "order_indices": [
            8,
            6,
            9,
            2,
            7,
            5,
            4,
            0,
            1,
            3
          ],
          "order_filenames": [
            "test_345_8.jpg",
            "test_345_6.jpg",
            "test_345_9.jpg",
            "test_345_2.jpg",
            "test_345_7.jpg",
            "test_345_5.jpg",
            "test_345_4.jpg",
            "test_345_0.jpg",
            "test_345_1.jpg",
            "test_345_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.4222222222222222,
            "spearman_rho": 0.4666666666666667,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 346,
      "prompt": "People rafting on a river while others ride on top of elephants.",
      "image_filenames": [
        "test_346_0.jpg",
        "test_346_1.jpg",
        "test_346_2.jpg",
        "test_346_3.jpg",
        "test_346_4.jpg",
        "test_346_5.jpg",
        "test_346_6.jpg",
        "test_346_7.jpg",
        "test_346_8.jpg",
        "test_346_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          5,
          1,
          6,
          3,
          2,
          7,
          0,
          9,
          8
        ],
        "order_filenames": [
          "test_346_4.jpg",
          "test_346_5.jpg",
          "test_346_1.jpg",
          "test_346_6.jpg",
          "test_346_3.jpg",
          "test_346_2.jpg",
          "test_346_7.jpg",
          "test_346_0.jpg",
          "test_346_9.jpg",
          "test_346_8.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_346_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_346_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_346_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.253173828125,
            0.255615234375,
            0.2900390625,
            0.236328125,
            0.24169921875,
            0.1646728515625,
            0.2666015625,
            0.2337646484375,
            0.227783203125,
            0.275146484375
          ],
          "order_indices": [
            2,
            9,
            6,
            1,
            0,
            4,
            3,
            7,
            8,
            5
          ],
          "order_filenames": [
            "test_346_2.jpg",
            "test_346_9.jpg",
            "test_346_6.jpg",
            "test_346_1.jpg",
            "test_346_0.jpg",
            "test_346_4.jpg",
            "test_346_3.jpg",
            "test_346_7.jpg",
            "test_346_8.jpg",
            "test_346_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.06666666666666667,
            "spearman_rho": -0.09090909090909083,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.5,
            26.203125,
            33.8125,
            28.921875,
            33.9375,
            27.984375,
            26.65625,
            38.0625,
            37.3125,
            32.96875
          ],
          "order_indices": [
            7,
            8,
            0,
            4,
            2,
            9,
            3,
            5,
            6,
            1
          ],
          "order_filenames": [
            "test_346_7.jpg",
            "test_346_8.jpg",
            "test_346_0.jpg",
            "test_346_4.jpg",
            "test_346_2.jpg",
            "test_346_9.jpg",
            "test_346_3.jpg",
            "test_346_5.jpg",
            "test_346_6.jpg",
            "test_346_1.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4222222222222222,
            "spearman_rho": -0.5636363636363637,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.6975382566452026,
            -1.1920127868652344,
            1.5636228322982788,
            0.49915000796318054,
            0.5905584692955017,
            -1.9853003025054932,
            -0.7955846190452576,
            0.7881200313568115,
            0.819930374622345,
            0.33674386143684387
          ],
          "order_indices": [
            0,
            2,
            8,
            7,
            4,
            3,
            9,
            6,
            1,
            5
          ],
          "order_filenames": [
            "test_346_0.jpg",
            "test_346_2.jpg",
            "test_346_8.jpg",
            "test_346_7.jpg",
            "test_346_4.jpg",
            "test_346_3.jpg",
            "test_346_9.jpg",
            "test_346_6.jpg",
            "test_346_1.jpg",
            "test_346_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4666666666666667,
            "spearman_rho": -0.5757575757575757,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 347,
      "prompt": "A motorcycle that is sitting in the dirt.",
      "image_filenames": [
        "test_347_0.jpg",
        "test_347_1.jpg",
        "test_347_2.jpg",
        "test_347_3.jpg",
        "test_347_4.jpg",
        "test_347_5.jpg",
        "test_347_6.jpg",
        "test_347_7.jpg",
        "test_347_8.jpg",
        "test_347_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          7,
          8,
          5,
          6,
          4,
          3,
          1,
          2,
          9
        ],
        "order_filenames": [
          "test_347_0.jpg",
          "test_347_7.jpg",
          "test_347_8.jpg",
          "test_347_5.jpg",
          "test_347_6.jpg",
          "test_347_4.jpg",
          "test_347_3.jpg",
          "test_347_1.jpg",
          "test_347_2.jpg",
          "test_347_9.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_347_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            8
          ],
          "winner_filenames": [
            "test_347_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_347_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1942138671875,
            0.2208251953125,
            0.274169921875,
            0.2269287109375,
            0.250244140625,
            0.2105712890625,
            0.2410888671875,
            0.21337890625,
            0.2249755859375,
            0.245849609375
          ],
          "order_indices": [
            2,
            4,
            9,
            6,
            3,
            8,
            1,
            7,
            5,
            0
          ],
          "order_filenames": [
            "test_347_2.jpg",
            "test_347_4.jpg",
            "test_347_9.jpg",
            "test_347_6.jpg",
            "test_347_3.jpg",
            "test_347_8.jpg",
            "test_347_1.jpg",
            "test_347_7.jpg",
            "test_347_5.jpg",
            "test_347_0.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5555555555555556,
            "spearman_rho": -0.7333333333333334,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.90625,
            34.15625,
            36.09375,
            38.9375,
            36.15625,
            34.75,
            34.4375,
            33.40625,
            34.59375,
            24.734375
          ],
          "order_indices": [
            3,
            4,
            2,
            0,
            5,
            8,
            6,
            1,
            7,
            9
          ],
          "order_filenames": [
            "test_347_3.jpg",
            "test_347_4.jpg",
            "test_347_2.jpg",
            "test_347_0.jpg",
            "test_347_5.jpg",
            "test_347_8.jpg",
            "test_347_6.jpg",
            "test_347_1.jpg",
            "test_347_7.jpg",
            "test_347_9.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.022222222222222223,
            "spearman_rho": 0.030303030303030276,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.2900996506214142,
            0.7188712358474731,
            0.7024096846580505,
            0.6170017123222351,
            0.7087302207946777,
            -0.20002293586730957,
            0.7836791276931763,
            0.4968942105770111,
            0.5413205027580261,
            1.1727302074432373
          ],
          "order_indices": [
            9,
            6,
            1,
            4,
            2,
            3,
            8,
            7,
            0,
            5
          ],
          "order_filenames": [
            "test_347_9.jpg",
            "test_347_6.jpg",
            "test_347_1.jpg",
            "test_347_4.jpg",
            "test_347_2.jpg",
            "test_347_3.jpg",
            "test_347_8.jpg",
            "test_347_7.jpg",
            "test_347_0.jpg",
            "test_347_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5555555555555556,
            "spearman_rho": -0.7454545454545454,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 348,
      "prompt": "A blue vase filled with yellow flowers on a window sill.",
      "image_filenames": [
        "test_348_0.jpg",
        "test_348_1.jpg",
        "test_348_2.jpg",
        "test_348_3.jpg",
        "test_348_4.jpg",
        "test_348_5.jpg",
        "test_348_6.jpg",
        "test_348_7.jpg",
        "test_348_8.jpg",
        "test_348_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          8,
          6,
          7,
          4,
          5,
          9,
          3,
          0,
          1,
          2
        ],
        "order_filenames": [
          "test_348_8.jpg",
          "test_348_6.jpg",
          "test_348_7.jpg",
          "test_348_4.jpg",
          "test_348_5.jpg",
          "test_348_9.jpg",
          "test_348_3.jpg",
          "test_348_0.jpg",
          "test_348_1.jpg",
          "test_348_2.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          8
        ],
        "winner_filenames": [
          "test_348_8.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7,
            8
          ],
          "winner_filenames": [
            "test_348_7.jpg",
            "test_348_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            8
          ],
          "winner_filenames": [
            "test_348_8.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.21240234375,
            0.29150390625,
            0.3251953125,
            0.300537109375,
            0.283203125,
            0.253662109375,
            0.33984375,
            0.26025390625,
            0.32373046875,
            0.328857421875
          ],
          "order_indices": [
            6,
            9,
            2,
            8,
            3,
            1,
            4,
            7,
            5,
            0
          ],
          "order_filenames": [
            "test_348_6.jpg",
            "test_348_9.jpg",
            "test_348_2.jpg",
            "test_348_8.jpg",
            "test_348_3.jpg",
            "test_348_1.jpg",
            "test_348_4.jpg",
            "test_348_7.jpg",
            "test_348_5.jpg",
            "test_348_0.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.1393939393939394,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            41.625,
            41.65625,
            44.5,
            35.65625,
            40.4375,
            33.46875,
            42.03125,
            41.46875,
            41.4375,
            40.1875
          ],
          "order_indices": [
            2,
            6,
            1,
            0,
            7,
            8,
            4,
            9,
            3,
            5
          ],
          "order_filenames": [
            "test_348_2.jpg",
            "test_348_6.jpg",
            "test_348_1.jpg",
            "test_348_0.jpg",
            "test_348_7.jpg",
            "test_348_8.jpg",
            "test_348_4.jpg",
            "test_348_9.jpg",
            "test_348_3.jpg",
            "test_348_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.15555555555555556,
            "spearman_rho": -0.23636363636363633,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.181408166885376,
            -1.081520915031433,
            1.845897912979126,
            1.5962473154067993,
            1.841821551322937,
            -0.20579791069030762,
            1.8942829370498657,
            1.1178371906280518,
            1.8821978569030762,
            1.9206163883209229
          ],
          "order_indices": [
            9,
            6,
            8,
            2,
            4,
            3,
            0,
            7,
            5,
            1
          ],
          "order_filenames": [
            "test_348_9.jpg",
            "test_348_6.jpg",
            "test_348_8.jpg",
            "test_348_2.jpg",
            "test_348_4.jpg",
            "test_348_3.jpg",
            "test_348_0.jpg",
            "test_348_7.jpg",
            "test_348_5.jpg",
            "test_348_1.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.24444444444444444,
            "spearman_rho": 0.33333333333333337,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 349,
      "prompt": "A giraffe walking through the grass towards a wall.",
      "image_filenames": [
        "test_349_0.jpg",
        "test_349_1.jpg",
        "test_349_2.jpg",
        "test_349_3.jpg",
        "test_349_4.jpg",
        "test_349_5.jpg",
        "test_349_6.jpg",
        "test_349_7.jpg",
        "test_349_8.jpg",
        "test_349_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          8,
          3,
          7,
          4,
          2,
          6,
          5,
          9,
          1,
          0
        ],
        "order_filenames": [
          "test_349_8.jpg",
          "test_349_3.jpg",
          "test_349_7.jpg",
          "test_349_4.jpg",
          "test_349_2.jpg",
          "test_349_6.jpg",
          "test_349_5.jpg",
          "test_349_9.jpg",
          "test_349_1.jpg",
          "test_349_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          8
        ],
        "winner_filenames": [
          "test_349_8.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            8
          ],
          "winner_filenames": [
            "test_349_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_349_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2230224609375,
            0.242919921875,
            0.2440185546875,
            0.20947265625,
            0.2493896484375,
            0.223388671875,
            0.2320556640625,
            0.2181396484375,
            0.27587890625,
            0.269287109375
          ],
          "order_indices": [
            8,
            9,
            4,
            2,
            1,
            6,
            5,
            0,
            7,
            3
          ],
          "order_filenames": [
            "test_349_8.jpg",
            "test_349_9.jpg",
            "test_349_4.jpg",
            "test_349_2.jpg",
            "test_349_1.jpg",
            "test_349_6.jpg",
            "test_349_5.jpg",
            "test_349_0.jpg",
            "test_349_7.jpg",
            "test_349_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.06666666666666667,
            "spearman_rho": 0.042424242424242475,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.75,
            31.640625,
            32.84375,
            29.265625,
            33.40625,
            33.1875,
            35.0,
            32.0,
            32.28125,
            32.0625
          ],
          "order_indices": [
            0,
            6,
            4,
            5,
            2,
            8,
            9,
            7,
            1,
            3
          ],
          "order_filenames": [
            "test_349_0.jpg",
            "test_349_6.jpg",
            "test_349_4.jpg",
            "test_349_5.jpg",
            "test_349_2.jpg",
            "test_349_8.jpg",
            "test_349_9.jpg",
            "test_349_7.jpg",
            "test_349_1.jpg",
            "test_349_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.24444444444444444,
            "spearman_rho": -0.34545454545454546,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.10085564851760864,
            -0.6563544273376465,
            -0.5009292364120483,
            -2.1003475189208984,
            -0.17621637880802155,
            -1.1951273679733276,
            -1.1198711395263672,
            -0.45304593443870544,
            -0.3904305100440979,
            0.5704150199890137
          ],
          "order_indices": [
            9,
            0,
            4,
            8,
            7,
            2,
            1,
            6,
            5,
            3
          ],
          "order_filenames": [
            "test_349_9.jpg",
            "test_349_0.jpg",
            "test_349_4.jpg",
            "test_349_8.jpg",
            "test_349_7.jpg",
            "test_349_2.jpg",
            "test_349_1.jpg",
            "test_349_6.jpg",
            "test_349_5.jpg",
            "test_349_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.23636363636363633,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 350,
      "prompt": "A baseball player pitching a baseball on a field.",
      "image_filenames": [
        "test_350_0.jpg",
        "test_350_1.jpg",
        "test_350_2.jpg",
        "test_350_3.jpg",
        "test_350_4.jpg",
        "test_350_5.jpg",
        "test_350_6.jpg",
        "test_350_7.jpg",
        "test_350_8.jpg",
        "test_350_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          7,
          6,
          8,
          3,
          5,
          9,
          2,
          4,
          0
        ],
        "order_filenames": [
          "test_350_1.jpg",
          "test_350_7.jpg",
          "test_350_6.jpg",
          "test_350_8.jpg",
          "test_350_3.jpg",
          "test_350_5.jpg",
          "test_350_9.jpg",
          "test_350_2.jpg",
          "test_350_4.jpg",
          "test_350_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_350_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_350_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_350_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.180908203125,
            0.224609375,
            0.2705078125,
            0.1986083984375,
            0.2139892578125,
            0.07232666015625,
            0.24267578125,
            0.169677734375,
            0.2218017578125,
            0.2283935546875
          ],
          "order_indices": [
            2,
            6,
            9,
            1,
            8,
            4,
            3,
            0,
            7,
            5
          ],
          "order_filenames": [
            "test_350_2.jpg",
            "test_350_6.jpg",
            "test_350_9.jpg",
            "test_350_1.jpg",
            "test_350_8.jpg",
            "test_350_4.jpg",
            "test_350_3.jpg",
            "test_350_0.jpg",
            "test_350_7.jpg",
            "test_350_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.06666666666666667,
            "spearman_rho": 0.042424242424242475,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            32.84375,
            36.4375,
            35.4375,
            26.65625,
            34.375,
            15.1015625,
            37.09375,
            26.40625,
            34.90625,
            32.90625
          ],
          "order_indices": [
            6,
            1,
            2,
            8,
            4,
            9,
            0,
            3,
            7,
            5
          ],
          "order_filenames": [
            "test_350_6.jpg",
            "test_350_1.jpg",
            "test_350_2.jpg",
            "test_350_8.jpg",
            "test_350_4.jpg",
            "test_350_9.jpg",
            "test_350_0.jpg",
            "test_350_3.jpg",
            "test_350_7.jpg",
            "test_350_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.15555555555555556,
            "spearman_rho": 0.21212121212121215,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.056185491383075714,
            -0.5103408098220825,
            0.1240139976143837,
            -2.180724859237671,
            0.0035729119554162025,
            -2.2479071617126465,
            -0.9197525978088379,
            -1.0093703269958496,
            0.22967775166034698,
            0.45419391989707947
          ],
          "order_indices": [
            9,
            8,
            2,
            4,
            0,
            1,
            6,
            7,
            3,
            5
          ],
          "order_filenames": [
            "test_350_9.jpg",
            "test_350_8.jpg",
            "test_350_2.jpg",
            "test_350_4.jpg",
            "test_350_0.jpg",
            "test_350_1.jpg",
            "test_350_6.jpg",
            "test_350_7.jpg",
            "test_350_3.jpg",
            "test_350_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.35757575757575766,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 351,
      "prompt": "Bikes sit parked under trees on a city street.",
      "image_filenames": [
        "test_351_0.jpg",
        "test_351_1.jpg",
        "test_351_2.jpg",
        "test_351_3.jpg",
        "test_351_4.jpg",
        "test_351_5.jpg",
        "test_351_6.jpg",
        "test_351_7.jpg",
        "test_351_8.jpg",
        "test_351_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          3,
          8,
          7,
          4,
          6,
          0,
          2,
          9,
          1
        ],
        "order_filenames": [
          "test_351_5.jpg",
          "test_351_3.jpg",
          "test_351_8.jpg",
          "test_351_7.jpg",
          "test_351_4.jpg",
          "test_351_6.jpg",
          "test_351_0.jpg",
          "test_351_2.jpg",
          "test_351_9.jpg",
          "test_351_1.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_351_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_351_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_351_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.20849609375,
            0.276611328125,
            0.29052734375,
            0.239990234375,
            0.2396240234375,
            0.233154296875,
            0.27734375,
            0.1722412109375,
            0.268798828125,
            0.27099609375
          ],
          "order_indices": [
            2,
            6,
            1,
            9,
            8,
            3,
            4,
            5,
            0,
            7
          ],
          "order_filenames": [
            "test_351_2.jpg",
            "test_351_6.jpg",
            "test_351_1.jpg",
            "test_351_9.jpg",
            "test_351_8.jpg",
            "test_351_3.jpg",
            "test_351_4.jpg",
            "test_351_5.jpg",
            "test_351_0.jpg",
            "test_351_7.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.37777777777777777,
            "spearman_rho": -0.5272727272727273,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            33.84375,
            33.5625,
            38.9375,
            30.71875,
            30.609375,
            34.03125,
            32.40625,
            24.71875,
            39.0625,
            37.78125
          ],
          "order_indices": [
            8,
            2,
            9,
            5,
            0,
            1,
            6,
            3,
            4,
            7
          ],
          "order_filenames": [
            "test_351_8.jpg",
            "test_351_2.jpg",
            "test_351_9.jpg",
            "test_351_5.jpg",
            "test_351_0.jpg",
            "test_351_1.jpg",
            "test_351_6.jpg",
            "test_351_3.jpg",
            "test_351_4.jpg",
            "test_351_7.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.15555555555555556,
            "spearman_rho": -0.17575757575757578,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.0191928148269653,
            -1.0759000778198242,
            1.5795036554336548,
            1.14723801612854,
            1.629939317703247,
            0.15107068419456482,
            0.3708678185939789,
            -2.0264272689819336,
            1.1504231691360474,
            1.3079888820648193
          ],
          "order_indices": [
            4,
            2,
            9,
            8,
            3,
            0,
            6,
            5,
            1,
            7
          ],
          "order_filenames": [
            "test_351_4.jpg",
            "test_351_2.jpg",
            "test_351_9.jpg",
            "test_351_8.jpg",
            "test_351_3.jpg",
            "test_351_0.jpg",
            "test_351_6.jpg",
            "test_351_5.jpg",
            "test_351_1.jpg",
            "test_351_7.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.1272727272727272,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 352,
      "prompt": "a young male holding a baseball bat in a baseball uniform",
      "image_filenames": [
        "test_352_0.jpg",
        "test_352_1.jpg",
        "test_352_2.jpg",
        "test_352_3.jpg",
        "test_352_4.jpg",
        "test_352_5.jpg",
        "test_352_6.jpg",
        "test_352_7.jpg",
        "test_352_8.jpg",
        "test_352_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          2,
          5,
          7,
          6,
          4,
          9,
          8,
          0,
          1
        ],
        "order_filenames": [
          "test_352_3.jpg",
          "test_352_2.jpg",
          "test_352_5.jpg",
          "test_352_7.jpg",
          "test_352_6.jpg",
          "test_352_4.jpg",
          "test_352_9.jpg",
          "test_352_8.jpg",
          "test_352_0.jpg",
          "test_352_1.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_352_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5,
            7
          ],
          "winner_filenames": [
            "test_352_5.jpg",
            "test_352_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_352_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1712646484375,
            0.1839599609375,
            0.2098388671875,
            0.1533203125,
            0.199951171875,
            0.091552734375,
            0.18212890625,
            0.1824951171875,
            0.302734375,
            0.263916015625
          ],
          "order_indices": [
            8,
            9,
            2,
            4,
            1,
            7,
            6,
            0,
            3,
            5
          ],
          "order_filenames": [
            "test_352_8.jpg",
            "test_352_9.jpg",
            "test_352_2.jpg",
            "test_352_4.jpg",
            "test_352_1.jpg",
            "test_352_7.jpg",
            "test_352_6.jpg",
            "test_352_0.jpg",
            "test_352_3.jpg",
            "test_352_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.28888888888888886,
            "spearman_rho": -0.36969696969696964,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.625,
            28.65625,
            36.65625,
            19.625,
            32.9375,
            12.3359375,
            36.1875,
            35.5625,
            39.59375,
            29.75
          ],
          "order_indices": [
            8,
            0,
            2,
            6,
            7,
            4,
            9,
            1,
            3,
            5
          ],
          "order_filenames": [
            "test_352_8.jpg",
            "test_352_0.jpg",
            "test_352_2.jpg",
            "test_352_6.jpg",
            "test_352_7.jpg",
            "test_352_4.jpg",
            "test_352_9.jpg",
            "test_352_1.jpg",
            "test_352_3.jpg",
            "test_352_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.15555555555555556,
            "spearman_rho": -0.3212121212121213,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.8135918974876404,
            -0.8905893564224243,
            0.15089626610279083,
            0.7701382637023926,
            0.49378275871276855,
            -2.259981393814087,
            -1.0502033233642578,
            -0.02992459386587143,
            1.8094242811203003,
            -0.14839906990528107
          ],
          "order_indices": [
            8,
            0,
            3,
            4,
            2,
            7,
            9,
            1,
            6,
            5
          ],
          "order_filenames": [
            "test_352_8.jpg",
            "test_352_0.jpg",
            "test_352_3.jpg",
            "test_352_4.jpg",
            "test_352_2.jpg",
            "test_352_7.jpg",
            "test_352_9.jpg",
            "test_352_1.jpg",
            "test_352_6.jpg",
            "test_352_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.06666666666666667,
            "spearman_rho": -0.1393939393939394,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 353,
      "prompt": "A clock tower with lighted clock faces, against a twilight sky.",
      "image_filenames": [
        "test_353_0.jpg",
        "test_353_1.jpg",
        "test_353_2.jpg",
        "test_353_3.jpg",
        "test_353_4.jpg",
        "test_353_5.jpg",
        "test_353_6.jpg",
        "test_353_7.jpg",
        "test_353_8.jpg",
        "test_353_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          8,
          6,
          7,
          9,
          3,
          5,
          4,
          2,
          1
        ],
        "order_filenames": [
          "test_353_0.jpg",
          "test_353_8.jpg",
          "test_353_6.jpg",
          "test_353_7.jpg",
          "test_353_9.jpg",
          "test_353_3.jpg",
          "test_353_5.jpg",
          "test_353_4.jpg",
          "test_353_2.jpg",
          "test_353_1.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_353_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_353_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_353_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2125244140625,
            0.271728515625,
            0.2822265625,
            0.189208984375,
            0.2188720703125,
            0.2459716796875,
            0.281982421875,
            0.2197265625,
            0.275634765625,
            0.252685546875
          ],
          "order_indices": [
            2,
            6,
            8,
            1,
            9,
            5,
            7,
            4,
            0,
            3
          ],
          "order_filenames": [
            "test_353_2.jpg",
            "test_353_6.jpg",
            "test_353_8.jpg",
            "test_353_1.jpg",
            "test_353_9.jpg",
            "test_353_5.jpg",
            "test_353_7.jpg",
            "test_353_4.jpg",
            "test_353_0.jpg",
            "test_353_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.16363636363636358,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.875,
            40.625,
            41.375,
            30.078125,
            33.5625,
            37.78125,
            39.1875,
            39.875,
            42.9375,
            36.28125
          ],
          "order_indices": [
            8,
            2,
            1,
            7,
            6,
            0,
            5,
            9,
            4,
            3
          ],
          "order_filenames": [
            "test_353_8.jpg",
            "test_353_2.jpg",
            "test_353_1.jpg",
            "test_353_7.jpg",
            "test_353_6.jpg",
            "test_353_0.jpg",
            "test_353_5.jpg",
            "test_353_9.jpg",
            "test_353_4.jpg",
            "test_353_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.06666666666666667,
            "spearman_rho": 0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.2344095706939697,
            0.953184962272644,
            1.1724051237106323,
            0.2682790160179138,
            0.5081489086151123,
            0.48758256435394287,
            1.1766916513442993,
            1.206786036491394,
            1.486117959022522,
            1.0921516418457031
          ],
          "order_indices": [
            8,
            0,
            7,
            6,
            2,
            9,
            1,
            4,
            5,
            3
          ],
          "order_filenames": [
            "test_353_8.jpg",
            "test_353_0.jpg",
            "test_353_7.jpg",
            "test_353_6.jpg",
            "test_353_2.jpg",
            "test_353_9.jpg",
            "test_353_1.jpg",
            "test_353_4.jpg",
            "test_353_5.jpg",
            "test_353_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.4666666666666667,
            "spearman_rho": 0.696969696969697,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 354,
      "prompt": "a girl a white bear a camera a tea pot and a cup",
      "image_filenames": [
        "test_354_0.jpg",
        "test_354_1.jpg",
        "test_354_2.jpg",
        "test_354_3.jpg",
        "test_354_4.jpg",
        "test_354_5.jpg",
        "test_354_6.jpg",
        "test_354_7.jpg",
        "test_354_8.jpg",
        "test_354_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          5,
          7,
          3,
          8,
          9,
          6,
          2,
          1,
          0
        ],
        "order_filenames": [
          "test_354_4.jpg",
          "test_354_5.jpg",
          "test_354_7.jpg",
          "test_354_3.jpg",
          "test_354_8.jpg",
          "test_354_9.jpg",
          "test_354_6.jpg",
          "test_354_2.jpg",
          "test_354_1.jpg",
          "test_354_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_354_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7,
            8
          ],
          "winner_filenames": [
            "test_354_7.jpg",
            "test_354_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4,
            7
          ],
          "winner_filenames": [
            "test_354_4.jpg",
            "test_354_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.162353515625,
            0.246826171875,
            0.247802734375,
            0.205078125,
            0.1876220703125,
            0.1741943359375,
            0.26025390625,
            0.23095703125,
            0.26318359375,
            0.260009765625
          ],
          "order_indices": [
            8,
            6,
            9,
            2,
            1,
            7,
            3,
            4,
            5,
            0
          ],
          "order_filenames": [
            "test_354_8.jpg",
            "test_354_6.jpg",
            "test_354_9.jpg",
            "test_354_2.jpg",
            "test_354_1.jpg",
            "test_354_7.jpg",
            "test_354_3.jpg",
            "test_354_4.jpg",
            "test_354_5.jpg",
            "test_354_0.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.19999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.46875,
            37.6875,
            35.4375,
            28.78125,
            29.28125,
            35.5625,
            32.90625,
            48.40625,
            43.71875,
            37.15625
          ],
          "order_indices": [
            7,
            8,
            1,
            9,
            5,
            0,
            2,
            6,
            4,
            3
          ],
          "order_filenames": [
            "test_354_7.jpg",
            "test_354_8.jpg",
            "test_354_1.jpg",
            "test_354_9.jpg",
            "test_354_5.jpg",
            "test_354_0.jpg",
            "test_354_2.jpg",
            "test_354_6.jpg",
            "test_354_4.jpg",
            "test_354_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.06666666666666667,
            "spearman_rho": -0.09090909090909083,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.2087949961423874,
            -0.649928867816925,
            -0.7259734272956848,
            -0.6844503879547119,
            -1.574464201927185,
            -1.664238691329956,
            -0.08311645686626434,
            1.4419918060302734,
            1.807752251625061,
            -0.7888768315315247
          ],
          "order_indices": [
            8,
            7,
            0,
            6,
            1,
            3,
            2,
            9,
            4,
            5
          ],
          "order_filenames": [
            "test_354_8.jpg",
            "test_354_7.jpg",
            "test_354_0.jpg",
            "test_354_6.jpg",
            "test_354_1.jpg",
            "test_354_3.jpg",
            "test_354_2.jpg",
            "test_354_9.jpg",
            "test_354_4.jpg",
            "test_354_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.28888888888888886,
            "spearman_rho": -0.38181818181818183,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 355,
      "prompt": "An athletic middle aged male skier courses downhill. ",
      "image_filenames": [
        "test_355_0.jpg",
        "test_355_1.jpg",
        "test_355_2.jpg",
        "test_355_3.jpg",
        "test_355_4.jpg",
        "test_355_5.jpg",
        "test_355_6.jpg",
        "test_355_7.jpg",
        "test_355_8.jpg",
        "test_355_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          5,
          7,
          3,
          4,
          9,
          0,
          8,
          1,
          2
        ],
        "order_filenames": [
          "test_355_6.jpg",
          "test_355_5.jpg",
          "test_355_7.jpg",
          "test_355_3.jpg",
          "test_355_4.jpg",
          "test_355_9.jpg",
          "test_355_0.jpg",
          "test_355_8.jpg",
          "test_355_1.jpg",
          "test_355_2.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_355_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_355_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_355_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2122802734375,
            0.21240234375,
            0.266357421875,
            0.2230224609375,
            0.218994140625,
            0.03179931640625,
            0.248779296875,
            0.1861572265625,
            0.267578125,
            0.2498779296875
          ],
          "order_indices": [
            8,
            2,
            9,
            6,
            3,
            4,
            1,
            0,
            7,
            5
          ],
          "order_filenames": [
            "test_355_8.jpg",
            "test_355_2.jpg",
            "test_355_9.jpg",
            "test_355_6.jpg",
            "test_355_3.jpg",
            "test_355_4.jpg",
            "test_355_1.jpg",
            "test_355_0.jpg",
            "test_355_7.jpg",
            "test_355_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.4424242424242424,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.28125,
            22.421875,
            31.71875,
            28.53125,
            29.421875,
            -8.1953125,
            32.09375,
            26.125,
            31.65625,
            31.828125
          ],
          "order_indices": [
            0,
            6,
            9,
            2,
            8,
            4,
            3,
            7,
            1,
            5
          ],
          "order_filenames": [
            "test_355_0.jpg",
            "test_355_6.jpg",
            "test_355_9.jpg",
            "test_355_2.jpg",
            "test_355_8.jpg",
            "test_355_4.jpg",
            "test_355_3.jpg",
            "test_355_7.jpg",
            "test_355_1.jpg",
            "test_355_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2,
            "spearman_rho": -0.1515151515151516,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.5075960159301758,
            -1.551688313484192,
            -0.20845212042331696,
            -0.20346511900424957,
            -0.09228330850601196,
            -2.280730724334717,
            0.37143781781196594,
            -0.9819310307502747,
            0.5967581868171692,
            0.44739481806755066
          ],
          "order_indices": [
            0,
            8,
            9,
            6,
            4,
            3,
            2,
            7,
            1,
            5
          ],
          "order_filenames": [
            "test_355_0.jpg",
            "test_355_8.jpg",
            "test_355_9.jpg",
            "test_355_6.jpg",
            "test_355_4.jpg",
            "test_355_3.jpg",
            "test_355_2.jpg",
            "test_355_7.jpg",
            "test_355_1.jpg",
            "test_355_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2,
            "spearman_rho": -0.16363636363636358,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 356,
      "prompt": "a public transit bus on a city street ",
      "image_filenames": [
        "test_356_0.jpg",
        "test_356_1.jpg",
        "test_356_2.jpg",
        "test_356_3.jpg",
        "test_356_4.jpg",
        "test_356_5.jpg",
        "test_356_6.jpg",
        "test_356_7.jpg",
        "test_356_8.jpg",
        "test_356_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          8,
          7,
          3,
          5,
          4,
          1,
          6,
          9,
          0
        ],
        "order_filenames": [
          "test_356_2.jpg",
          "test_356_8.jpg",
          "test_356_7.jpg",
          "test_356_3.jpg",
          "test_356_5.jpg",
          "test_356_4.jpg",
          "test_356_1.jpg",
          "test_356_6.jpg",
          "test_356_9.jpg",
          "test_356_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_356_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            8
          ],
          "winner_filenames": [
            "test_356_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2,
            8
          ],
          "winner_filenames": [
            "test_356_2.jpg",
            "test_356_8.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.222900390625,
            0.262939453125,
            0.277587890625,
            0.23193359375,
            0.2490234375,
            0.23486328125,
            0.2861328125,
            0.208984375,
            0.2371826171875,
            0.2685546875
          ],
          "order_indices": [
            6,
            2,
            9,
            1,
            4,
            8,
            5,
            3,
            0,
            7
          ],
          "order_filenames": [
            "test_356_6.jpg",
            "test_356_2.jpg",
            "test_356_9.jpg",
            "test_356_1.jpg",
            "test_356_4.jpg",
            "test_356_8.jpg",
            "test_356_5.jpg",
            "test_356_3.jpg",
            "test_356_0.jpg",
            "test_356_7.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.15555555555555556,
            "spearman_rho": -0.10303030303030303,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            30.703125,
            32.5,
            34.34375,
            29.625,
            30.53125,
            28.59375,
            31.765625,
            29.265625,
            34.78125,
            23.0625
          ],
          "order_indices": [
            8,
            2,
            1,
            6,
            0,
            4,
            3,
            7,
            5,
            9
          ],
          "order_filenames": [
            "test_356_8.jpg",
            "test_356_2.jpg",
            "test_356_1.jpg",
            "test_356_6.jpg",
            "test_356_0.jpg",
            "test_356_4.jpg",
            "test_356_3.jpg",
            "test_356_7.jpg",
            "test_356_5.jpg",
            "test_356_9.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2,
            "spearman_rho": 0.33333333333333337,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.4001232087612152,
            0.2236078381538391,
            0.36421287059783936,
            0.24600596725940704,
            0.6125376224517822,
            0.39709585905075073,
            0.6046838760375977,
            -0.6546124219894409,
            -0.3632168769836426,
            -0.1514883190393448
          ],
          "order_indices": [
            4,
            6,
            0,
            5,
            2,
            3,
            1,
            9,
            8,
            7
          ],
          "order_filenames": [
            "test_356_4.jpg",
            "test_356_6.jpg",
            "test_356_0.jpg",
            "test_356_5.jpg",
            "test_356_2.jpg",
            "test_356_3.jpg",
            "test_356_1.jpg",
            "test_356_9.jpg",
            "test_356_8.jpg",
            "test_356_7.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.24444444444444444,
            "spearman_rho": -0.39393939393939403,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 357,
      "prompt": "A tanker trunk is on it's side on the side of a road near a police car.",
      "image_filenames": [
        "test_357_0.jpg",
        "test_357_1.jpg",
        "test_357_2.jpg",
        "test_357_3.jpg",
        "test_357_4.jpg",
        "test_357_5.jpg",
        "test_357_6.jpg",
        "test_357_7.jpg",
        "test_357_8.jpg",
        "test_357_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          3,
          5,
          2,
          6,
          7,
          8,
          9,
          1,
          0
        ],
        "order_filenames": [
          "test_357_4.jpg",
          "test_357_3.jpg",
          "test_357_5.jpg",
          "test_357_2.jpg",
          "test_357_6.jpg",
          "test_357_7.jpg",
          "test_357_8.jpg",
          "test_357_9.jpg",
          "test_357_1.jpg",
          "test_357_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_357_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_357_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_357_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2066650390625,
            0.2047119140625,
            0.2056884765625,
            0.173095703125,
            0.1707763671875,
            0.176513671875,
            0.197509765625,
            0.192138671875,
            0.2080078125,
            0.241943359375
          ],
          "order_indices": [
            9,
            8,
            0,
            2,
            1,
            6,
            7,
            5,
            3,
            4
          ],
          "order_filenames": [
            "test_357_9.jpg",
            "test_357_8.jpg",
            "test_357_0.jpg",
            "test_357_2.jpg",
            "test_357_1.jpg",
            "test_357_6.jpg",
            "test_357_7.jpg",
            "test_357_5.jpg",
            "test_357_3.jpg",
            "test_357_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.6444444444444445,
            "spearman_rho": -0.793939393939394,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.03125,
            31.375,
            36.40625,
            28.125,
            26.90625,
            31.921875,
            35.28125,
            39.6875,
            37.15625,
            30.03125
          ],
          "order_indices": [
            7,
            0,
            8,
            2,
            6,
            5,
            1,
            9,
            3,
            4
          ],
          "order_filenames": [
            "test_357_7.jpg",
            "test_357_0.jpg",
            "test_357_8.jpg",
            "test_357_2.jpg",
            "test_357_6.jpg",
            "test_357_5.jpg",
            "test_357_1.jpg",
            "test_357_9.jpg",
            "test_357_3.jpg",
            "test_357_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4222222222222222,
            "spearman_rho": -0.5030303030303029,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.0175691843032837,
            0.2934856712818146,
            -0.0274286400526762,
            -0.4162243902683258,
            -1.319425344467163,
            -1.182979702949524,
            0.5847590565681458,
            0.42416730523109436,
            0.013658895157277584,
            0.3833509087562561
          ],
          "order_indices": [
            0,
            6,
            7,
            9,
            1,
            8,
            2,
            3,
            5,
            4
          ],
          "order_filenames": [
            "test_357_0.jpg",
            "test_357_6.jpg",
            "test_357_7.jpg",
            "test_357_9.jpg",
            "test_357_1.jpg",
            "test_357_8.jpg",
            "test_357_2.jpg",
            "test_357_3.jpg",
            "test_357_5.jpg",
            "test_357_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.6,
            "spearman_rho": -0.7818181818181817,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 358,
      "prompt": "A bathroom stall containing an empty toilet in it.",
      "image_filenames": [
        "test_358_0.jpg",
        "test_358_1.jpg",
        "test_358_2.jpg",
        "test_358_3.jpg",
        "test_358_4.jpg",
        "test_358_5.jpg",
        "test_358_6.jpg",
        "test_358_7.jpg",
        "test_358_8.jpg",
        "test_358_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          8,
          7,
          9,
          6,
          5,
          1,
          2,
          3,
          0,
          4
        ],
        "order_filenames": [
          "test_358_8.jpg",
          "test_358_7.jpg",
          "test_358_9.jpg",
          "test_358_6.jpg",
          "test_358_5.jpg",
          "test_358_1.jpg",
          "test_358_2.jpg",
          "test_358_3.jpg",
          "test_358_0.jpg",
          "test_358_4.jpg"
        ],
        "condorcet_winner": 7,
        "winner_indices": [
          8
        ],
        "winner_filenames": [
          "test_358_8.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_358_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_358_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1920166015625,
            0.17431640625,
            0.24072265625,
            0.220947265625,
            0.17138671875,
            0.1722412109375,
            0.2406005859375,
            0.1943359375,
            0.2437744140625,
            0.225341796875
          ],
          "order_indices": [
            8,
            2,
            6,
            9,
            3,
            7,
            0,
            1,
            5,
            4
          ],
          "order_filenames": [
            "test_358_8.jpg",
            "test_358_2.jpg",
            "test_358_6.jpg",
            "test_358_9.jpg",
            "test_358_3.jpg",
            "test_358_7.jpg",
            "test_358_0.jpg",
            "test_358_1.jpg",
            "test_358_5.jpg",
            "test_358_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.37777777777777777,
            "spearman_rho": 0.5393939393939393,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.15625,
            28.328125,
            34.1875,
            25.890625,
            35.09375,
            28.109375,
            38.5,
            34.25,
            30.296875,
            35.84375
          ],
          "order_indices": [
            6,
            9,
            4,
            7,
            2,
            0,
            8,
            1,
            5,
            3
          ],
          "order_filenames": [
            "test_358_6.jpg",
            "test_358_9.jpg",
            "test_358_4.jpg",
            "test_358_7.jpg",
            "test_358_2.jpg",
            "test_358_0.jpg",
            "test_358_8.jpg",
            "test_358_1.jpg",
            "test_358_5.jpg",
            "test_358_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.06666666666666667,
            "spearman_rho": 0.17575757575757578,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.18845804035663605,
            -1.56017005443573,
            -0.0192114245146513,
            -0.5478896498680115,
            -0.8507024645805359,
            -1.4419546127319336,
            0.3898541033267975,
            0.3281586468219757,
            -0.3826325535774231,
            0.13295097649097443
          ],
          "order_indices": [
            6,
            7,
            9,
            2,
            0,
            8,
            3,
            4,
            5,
            1
          ],
          "order_filenames": [
            "test_358_6.jpg",
            "test_358_7.jpg",
            "test_358_9.jpg",
            "test_358_2.jpg",
            "test_358_0.jpg",
            "test_358_8.jpg",
            "test_358_3.jpg",
            "test_358_4.jpg",
            "test_358_5.jpg",
            "test_358_1.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.28888888888888886,
            "spearman_rho": 0.4181818181818182,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 359,
      "prompt": "A flag flying with kites all around it.",
      "image_filenames": [
        "test_359_0.jpg",
        "test_359_1.jpg",
        "test_359_2.jpg",
        "test_359_3.jpg",
        "test_359_4.jpg",
        "test_359_5.jpg",
        "test_359_6.jpg",
        "test_359_7.jpg",
        "test_359_8.jpg",
        "test_359_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          6,
          3,
          7,
          4,
          2,
          1,
          8,
          0,
          9
        ],
        "order_filenames": [
          "test_359_5.jpg",
          "test_359_6.jpg",
          "test_359_3.jpg",
          "test_359_7.jpg",
          "test_359_4.jpg",
          "test_359_2.jpg",
          "test_359_1.jpg",
          "test_359_8.jpg",
          "test_359_0.jpg",
          "test_359_9.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_359_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            2,
            5,
            8
          ],
          "winner_filenames": [
            "test_359_2.jpg",
            "test_359_5.jpg",
            "test_359_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_359_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.20068359375,
            0.2315673828125,
            0.1494140625,
            0.2342529296875,
            0.1787109375,
            0.187255859375,
            0.23486328125,
            0.1951904296875,
            0.208984375,
            0.2396240234375
          ],
          "order_indices": [
            9,
            6,
            3,
            1,
            8,
            0,
            7,
            5,
            4,
            2
          ],
          "order_filenames": [
            "test_359_9.jpg",
            "test_359_6.jpg",
            "test_359_3.jpg",
            "test_359_1.jpg",
            "test_359_8.jpg",
            "test_359_0.jpg",
            "test_359_7.jpg",
            "test_359_5.jpg",
            "test_359_4.jpg",
            "test_359_2.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.06666666666666667,
            "spearman_rho": -0.19999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.9375,
            36.625,
            40.15625,
            36.8125,
            33.34375,
            29.625,
            39.34375,
            39.5,
            38.28125,
            30.71875
          ],
          "order_indices": [
            2,
            7,
            6,
            8,
            0,
            3,
            1,
            4,
            9,
            5
          ],
          "order_filenames": [
            "test_359_2.jpg",
            "test_359_7.jpg",
            "test_359_6.jpg",
            "test_359_8.jpg",
            "test_359_0.jpg",
            "test_359_3.jpg",
            "test_359_1.jpg",
            "test_359_4.jpg",
            "test_359_9.jpg",
            "test_359_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.022222222222222223,
            "spearman_rho": 0.018181818181818188,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.26124143600463867,
            -0.37479132413864136,
            -0.3472454249858856,
            0.15235555171966553,
            -0.8043209314346313,
            -1.0538334846496582,
            1.3601258993148804,
            -0.5603070259094238,
            -0.7378507256507874,
            1.5320093631744385
          ],
          "order_indices": [
            9,
            6,
            0,
            3,
            2,
            1,
            7,
            8,
            4,
            5
          ],
          "order_filenames": [
            "test_359_9.jpg",
            "test_359_6.jpg",
            "test_359_0.jpg",
            "test_359_3.jpg",
            "test_359_2.jpg",
            "test_359_1.jpg",
            "test_359_7.jpg",
            "test_359_8.jpg",
            "test_359_4.jpg",
            "test_359_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.24444444444444444,
            "spearman_rho": -0.36969696969696964,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 360,
      "prompt": "A train that is going by a building.",
      "image_filenames": [
        "test_360_0.jpg",
        "test_360_1.jpg",
        "test_360_2.jpg",
        "test_360_3.jpg",
        "test_360_4.jpg",
        "test_360_5.jpg",
        "test_360_6.jpg",
        "test_360_7.jpg",
        "test_360_8.jpg",
        "test_360_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          7,
          5,
          3,
          4,
          1,
          2,
          0,
          8,
          9
        ],
        "order_filenames": [
          "test_360_6.jpg",
          "test_360_7.jpg",
          "test_360_5.jpg",
          "test_360_3.jpg",
          "test_360_4.jpg",
          "test_360_1.jpg",
          "test_360_2.jpg",
          "test_360_0.jpg",
          "test_360_8.jpg",
          "test_360_9.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_360_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5,
            6,
            7
          ],
          "winner_filenames": [
            "test_360_5.jpg",
            "test_360_6.jpg",
            "test_360_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_360_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.21533203125,
            0.2626953125,
            0.28662109375,
            0.2286376953125,
            0.231689453125,
            0.187255859375,
            0.252197265625,
            0.2357177734375,
            0.200927734375,
            0.28173828125
          ],
          "order_indices": [
            2,
            9,
            1,
            6,
            7,
            4,
            3,
            0,
            8,
            5
          ],
          "order_filenames": [
            "test_360_2.jpg",
            "test_360_9.jpg",
            "test_360_1.jpg",
            "test_360_6.jpg",
            "test_360_7.jpg",
            "test_360_4.jpg",
            "test_360_3.jpg",
            "test_360_0.jpg",
            "test_360_8.jpg",
            "test_360_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.06666666666666667,
            "spearman_rho": -0.1272727272727272,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.625,
            25.25,
            31.671875,
            30.234375,
            31.46875,
            38.46875,
            30.46875,
            36.40625,
            40.03125,
            25.15625
          ],
          "order_indices": [
            8,
            5,
            0,
            7,
            2,
            4,
            6,
            3,
            1,
            9
          ],
          "order_filenames": [
            "test_360_8.jpg",
            "test_360_5.jpg",
            "test_360_0.jpg",
            "test_360_7.jpg",
            "test_360_2.jpg",
            "test_360_4.jpg",
            "test_360_6.jpg",
            "test_360_3.jpg",
            "test_360_1.jpg",
            "test_360_9.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.022222222222222223,
            "spearman_rho": 0.030303030303030276,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.4213186502456665,
            -1.0797063112258911,
            0.30476734042167664,
            -0.17062795162200928,
            0.11802159994840622,
            0.23070590198040009,
            -0.4515095055103302,
            -0.02059033140540123,
            0.5821136236190796,
            1.0899384021759033
          ],
          "order_indices": [
            9,
            8,
            0,
            2,
            5,
            4,
            7,
            3,
            6,
            1
          ],
          "order_filenames": [
            "test_360_9.jpg",
            "test_360_8.jpg",
            "test_360_0.jpg",
            "test_360_2.jpg",
            "test_360_5.jpg",
            "test_360_4.jpg",
            "test_360_7.jpg",
            "test_360_3.jpg",
            "test_360_6.jpg",
            "test_360_1.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.6444444444444445,
            "spearman_rho": -0.7575757575757576,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 361,
      "prompt": "The feet of Lacrosse players scramble for the ball.",
      "image_filenames": [
        "test_361_0.jpg",
        "test_361_1.jpg",
        "test_361_2.jpg",
        "test_361_3.jpg",
        "test_361_4.jpg",
        "test_361_5.jpg",
        "test_361_6.jpg",
        "test_361_7.jpg",
        "test_361_8.jpg",
        "test_361_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          1,
          3,
          5,
          2,
          6,
          4,
          7,
          9,
          8
        ],
        "order_filenames": [
          "test_361_0.jpg",
          "test_361_1.jpg",
          "test_361_3.jpg",
          "test_361_5.jpg",
          "test_361_2.jpg",
          "test_361_6.jpg",
          "test_361_4.jpg",
          "test_361_7.jpg",
          "test_361_9.jpg",
          "test_361_8.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_361_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3,
            5
          ],
          "winner_filenames": [
            "test_361_3.jpg",
            "test_361_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_361_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.22119140625,
            0.294189453125,
            0.3095703125,
            0.2110595703125,
            0.189208984375,
            0.1326904296875,
            0.283447265625,
            0.159423828125,
            0.188232421875,
            0.2451171875
          ],
          "order_indices": [
            2,
            1,
            6,
            9,
            0,
            3,
            4,
            8,
            7,
            5
          ],
          "order_filenames": [
            "test_361_2.jpg",
            "test_361_1.jpg",
            "test_361_6.jpg",
            "test_361_9.jpg",
            "test_361_0.jpg",
            "test_361_3.jpg",
            "test_361_4.jpg",
            "test_361_8.jpg",
            "test_361_7.jpg",
            "test_361_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.24444444444444444,
            "spearman_rho": 0.296969696969697,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.9375,
            33.25,
            33.0,
            29.265625,
            34.875,
            18.28125,
            31.671875,
            27.75,
            30.4375,
            35.5625
          ],
          "order_indices": [
            9,
            0,
            4,
            1,
            2,
            6,
            8,
            3,
            7,
            5
          ],
          "order_filenames": [
            "test_361_9.jpg",
            "test_361_0.jpg",
            "test_361_4.jpg",
            "test_361_1.jpg",
            "test_361_2.jpg",
            "test_361_6.jpg",
            "test_361_8.jpg",
            "test_361_3.jpg",
            "test_361_7.jpg",
            "test_361_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.06666666666666667,
            "spearman_rho": 0.054545454545454564,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.5474024415016174,
            0.7409383654594421,
            1.453478455543518,
            -0.08528319001197815,
            0.28798708319664,
            -1.3761173486709595,
            1.056232213973999,
            -0.188287153840065,
            -0.18162068724632263,
            0.3589189648628235
          ],
          "order_indices": [
            2,
            6,
            1,
            0,
            9,
            4,
            3,
            8,
            7,
            5
          ],
          "order_filenames": [
            "test_361_2.jpg",
            "test_361_6.jpg",
            "test_361_1.jpg",
            "test_361_0.jpg",
            "test_361_9.jpg",
            "test_361_4.jpg",
            "test_361_3.jpg",
            "test_361_8.jpg",
            "test_361_7.jpg",
            "test_361_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2,
            "spearman_rho": 0.296969696969697,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 362,
      "prompt": "A little kid riding a skateboard down a sidewalk.",
      "image_filenames": [
        "test_362_0.jpg",
        "test_362_1.jpg",
        "test_362_2.jpg",
        "test_362_3.jpg",
        "test_362_4.jpg",
        "test_362_5.jpg",
        "test_362_6.jpg",
        "test_362_7.jpg",
        "test_362_8.jpg",
        "test_362_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          6,
          7,
          8,
          0,
          5,
          9,
          3,
          4,
          2
        ],
        "order_filenames": [
          "test_362_1.jpg",
          "test_362_6.jpg",
          "test_362_7.jpg",
          "test_362_8.jpg",
          "test_362_0.jpg",
          "test_362_5.jpg",
          "test_362_9.jpg",
          "test_362_3.jpg",
          "test_362_4.jpg",
          "test_362_2.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_362_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_362_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_362_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1829833984375,
            0.260498046875,
            0.28466796875,
            0.18017578125,
            0.19189453125,
            0.1363525390625,
            0.21533203125,
            0.141845703125,
            0.253662109375,
            0.2177734375
          ],
          "order_indices": [
            2,
            1,
            8,
            9,
            6,
            4,
            0,
            3,
            7,
            5
          ],
          "order_filenames": [
            "test_362_2.jpg",
            "test_362_1.jpg",
            "test_362_8.jpg",
            "test_362_9.jpg",
            "test_362_6.jpg",
            "test_362_4.jpg",
            "test_362_0.jpg",
            "test_362_3.jpg",
            "test_362_7.jpg",
            "test_362_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.022222222222222223,
            "spearman_rho": -0.0060606060606061,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.78125,
            35.96875,
            38.3125,
            30.640625,
            36.71875,
            29.5625,
            35.4375,
            27.28125,
            37.40625,
            37.15625
          ],
          "order_indices": [
            2,
            8,
            9,
            0,
            4,
            1,
            6,
            3,
            5,
            7
          ],
          "order_filenames": [
            "test_362_2.jpg",
            "test_362_8.jpg",
            "test_362_9.jpg",
            "test_362_0.jpg",
            "test_362_4.jpg",
            "test_362_1.jpg",
            "test_362_6.jpg",
            "test_362_3.jpg",
            "test_362_5.jpg",
            "test_362_7.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.24444444444444444,
            "spearman_rho": -0.36969696969696964,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.1405675709247589,
            -0.05063869431614876,
            1.4559500217437744,
            -0.6570193767547607,
            0.572052001953125,
            -1.9503339529037476,
            0.992335855960846,
            -1.136776089668274,
            0.5181683301925659,
            0.9149050712585449
          ],
          "order_indices": [
            2,
            6,
            9,
            4,
            8,
            0,
            1,
            3,
            7,
            5
          ],
          "order_filenames": [
            "test_362_2.jpg",
            "test_362_6.jpg",
            "test_362_9.jpg",
            "test_362_4.jpg",
            "test_362_8.jpg",
            "test_362_0.jpg",
            "test_362_1.jpg",
            "test_362_3.jpg",
            "test_362_7.jpg",
            "test_362_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2,
            "spearman_rho": -0.2848484848484849,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 363,
      "prompt": "A man with his finger held up to his nose.",
      "image_filenames": [
        "test_363_0.jpg",
        "test_363_1.jpg",
        "test_363_2.jpg",
        "test_363_3.jpg",
        "test_363_4.jpg",
        "test_363_5.jpg",
        "test_363_6.jpg",
        "test_363_7.jpg",
        "test_363_8.jpg",
        "test_363_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          6,
          5,
          7,
          2,
          8,
          9,
          3,
          1,
          0
        ],
        "order_filenames": [
          "test_363_4.jpg",
          "test_363_6.jpg",
          "test_363_5.jpg",
          "test_363_7.jpg",
          "test_363_2.jpg",
          "test_363_8.jpg",
          "test_363_9.jpg",
          "test_363_3.jpg",
          "test_363_1.jpg",
          "test_363_0.jpg"
        ],
        "condorcet_winner": 4,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_363_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_363_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_363_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.169921875,
            0.2088623046875,
            0.25146484375,
            0.151611328125,
            0.15087890625,
            0.08026123046875,
            0.2451171875,
            0.2113037109375,
            0.2685546875,
            0.2646484375
          ],
          "order_indices": [
            8,
            9,
            2,
            6,
            7,
            1,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_363_8.jpg",
            "test_363_9.jpg",
            "test_363_2.jpg",
            "test_363_6.jpg",
            "test_363_7.jpg",
            "test_363_1.jpg",
            "test_363_0.jpg",
            "test_363_3.jpg",
            "test_363_4.jpg",
            "test_363_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.1515151515151516,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.46875,
            31.234375,
            30.671875,
            17.75,
            20.765625,
            17.46875,
            32.875,
            36.3125,
            38.96875,
            29.90625
          ],
          "order_indices": [
            8,
            7,
            0,
            6,
            1,
            2,
            9,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_363_8.jpg",
            "test_363_7.jpg",
            "test_363_0.jpg",
            "test_363_6.jpg",
            "test_363_1.jpg",
            "test_363_2.jpg",
            "test_363_9.jpg",
            "test_363_4.jpg",
            "test_363_3.jpg",
            "test_363_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.15555555555555556,
            "spearman_rho": -0.19999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.18497315049171448,
            -1.1584054231643677,
            0.8534449934959412,
            -2.2720224857330322,
            -0.44834521412849426,
            -2.282052516937256,
            1.7173324823379517,
            0.5900315046310425,
            1.6914876699447632,
            1.9247688055038452
          ],
          "order_indices": [
            9,
            6,
            8,
            2,
            7,
            0,
            4,
            1,
            3,
            5
          ],
          "order_filenames": [
            "test_363_9.jpg",
            "test_363_6.jpg",
            "test_363_8.jpg",
            "test_363_2.jpg",
            "test_363_7.jpg",
            "test_363_0.jpg",
            "test_363_4.jpg",
            "test_363_1.jpg",
            "test_363_3.jpg",
            "test_363_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.022222222222222223,
            "spearman_rho": 0.09090909090909094,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 364,
      "prompt": "A man placing a turkey in an oven with oven mitts.  ",
      "image_filenames": [
        "test_364_0.jpg",
        "test_364_1.jpg",
        "test_364_2.jpg",
        "test_364_3.jpg",
        "test_364_4.jpg",
        "test_364_5.jpg",
        "test_364_6.jpg",
        "test_364_7.jpg",
        "test_364_8.jpg",
        "test_364_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          8,
          6,
          4,
          7,
          3,
          2,
          9,
          1,
          0
        ],
        "order_filenames": [
          "test_364_5.jpg",
          "test_364_8.jpg",
          "test_364_6.jpg",
          "test_364_4.jpg",
          "test_364_7.jpg",
          "test_364_3.jpg",
          "test_364_2.jpg",
          "test_364_9.jpg",
          "test_364_1.jpg",
          "test_364_0.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_364_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6,
            7,
            8
          ],
          "winner_filenames": [
            "test_364_6.jpg",
            "test_364_7.jpg",
            "test_364_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_364_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.179443359375,
            0.2159423828125,
            0.2734375,
            0.176025390625,
            0.16650390625,
            0.132568359375,
            0.26416015625,
            0.1881103515625,
            0.257568359375,
            0.274658203125
          ],
          "order_indices": [
            9,
            2,
            6,
            8,
            1,
            7,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_364_9.jpg",
            "test_364_2.jpg",
            "test_364_6.jpg",
            "test_364_8.jpg",
            "test_364_1.jpg",
            "test_364_7.jpg",
            "test_364_0.jpg",
            "test_364_3.jpg",
            "test_364_4.jpg",
            "test_364_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.24444444444444444,
            "spearman_rho": -0.2969696969696969,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            39.03125,
            29.359375,
            39.8125,
            32.53125,
            29.359375,
            25.6875,
            38.09375,
            37.90625,
            40.875,
            38.3125
          ],
          "order_indices": [
            8,
            2,
            0,
            9,
            6,
            7,
            3,
            1,
            4,
            5
          ],
          "order_filenames": [
            "test_364_8.jpg",
            "test_364_2.jpg",
            "test_364_0.jpg",
            "test_364_9.jpg",
            "test_364_6.jpg",
            "test_364_7.jpg",
            "test_364_3.jpg",
            "test_364_1.jpg",
            "test_364_4.jpg",
            "test_364_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.15555555555555556,
            "spearman_rho": -0.23636363636363633,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.174499273300171,
            -1.5071907043457031,
            0.3007121980190277,
            -0.17505693435668945,
            -1.8100593090057373,
            -1.5459492206573486,
            0.7921469807624817,
            -0.09749476611614227,
            0.610675573348999,
            0.11138614267110825
          ],
          "order_indices": [
            6,
            8,
            2,
            9,
            7,
            3,
            0,
            1,
            5,
            4
          ],
          "order_filenames": [
            "test_364_6.jpg",
            "test_364_8.jpg",
            "test_364_2.jpg",
            "test_364_9.jpg",
            "test_364_7.jpg",
            "test_364_3.jpg",
            "test_364_0.jpg",
            "test_364_1.jpg",
            "test_364_5.jpg",
            "test_364_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.11515151515151512,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.3,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 365,
      "prompt": "freshly baked donuts priced to sell at 60cents each",
      "image_filenames": [
        "test_365_0.jpg",
        "test_365_1.jpg",
        "test_365_2.jpg",
        "test_365_3.jpg",
        "test_365_4.jpg",
        "test_365_5.jpg",
        "test_365_6.jpg",
        "test_365_7.jpg",
        "test_365_8.jpg",
        "test_365_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          7,
          5,
          0,
          6,
          2,
          8,
          4,
          3,
          9
        ],
        "order_filenames": [
          "test_365_1.jpg",
          "test_365_7.jpg",
          "test_365_5.jpg",
          "test_365_0.jpg",
          "test_365_6.jpg",
          "test_365_2.jpg",
          "test_365_8.jpg",
          "test_365_4.jpg",
          "test_365_3.jpg",
          "test_365_9.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_365_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_365_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_365_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1402587890625,
            0.251220703125,
            0.2408447265625,
            0.1929931640625,
            0.1790771484375,
            0.2010498046875,
            0.25634765625,
            0.173583984375,
            0.25341796875,
            0.2119140625
          ],
          "order_indices": [
            6,
            8,
            1,
            2,
            9,
            5,
            3,
            4,
            7,
            0
          ],
          "order_filenames": [
            "test_365_6.jpg",
            "test_365_8.jpg",
            "test_365_1.jpg",
            "test_365_2.jpg",
            "test_365_9.jpg",
            "test_365_5.jpg",
            "test_365_3.jpg",
            "test_365_4.jpg",
            "test_365_7.jpg",
            "test_365_0.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.022222222222222223,
            "spearman_rho": -0.042424242424242475,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            29.453125,
            31.328125,
            31.671875,
            26.359375,
            28.296875,
            30.703125,
            28.890625,
            33.78125,
            30.4375,
            33.5
          ],
          "order_indices": [
            7,
            9,
            2,
            1,
            5,
            8,
            0,
            6,
            4,
            3
          ],
          "order_filenames": [
            "test_365_7.jpg",
            "test_365_9.jpg",
            "test_365_2.jpg",
            "test_365_1.jpg",
            "test_365_5.jpg",
            "test_365_8.jpg",
            "test_365_0.jpg",
            "test_365_6.jpg",
            "test_365_4.jpg",
            "test_365_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.34545454545454546,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.8766772747039795,
            0.49021801352500916,
            0.7958930730819702,
            -0.6076565384864807,
            -0.6160290241241455,
            -0.39393672347068787,
            0.5298653244972229,
            -0.04537564888596535,
            0.41800543665885925,
            -0.8083191514015198
          ],
          "order_indices": [
            2,
            6,
            1,
            8,
            7,
            5,
            3,
            4,
            9,
            0
          ],
          "order_filenames": [
            "test_365_2.jpg",
            "test_365_6.jpg",
            "test_365_1.jpg",
            "test_365_8.jpg",
            "test_365_7.jpg",
            "test_365_5.jpg",
            "test_365_3.jpg",
            "test_365_4.jpg",
            "test_365_9.jpg",
            "test_365_0.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.28888888888888886,
            "spearman_rho": 0.35757575757575755,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 366,
      "prompt": "Some giraffes are walking around the zoo exhibit. ",
      "image_filenames": [
        "test_366_0.jpg",
        "test_366_1.jpg",
        "test_366_2.jpg",
        "test_366_3.jpg",
        "test_366_4.jpg",
        "test_366_5.jpg",
        "test_366_6.jpg",
        "test_366_7.jpg",
        "test_366_8.jpg",
        "test_366_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          8,
          7,
          9,
          2,
          6,
          0,
          3,
          4,
          5
        ],
        "order_filenames": [
          "test_366_1.jpg",
          "test_366_8.jpg",
          "test_366_7.jpg",
          "test_366_9.jpg",
          "test_366_2.jpg",
          "test_366_6.jpg",
          "test_366_0.jpg",
          "test_366_3.jpg",
          "test_366_4.jpg",
          "test_366_5.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_366_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            8
          ],
          "winner_filenames": [
            "test_366_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            8
          ],
          "winner_filenames": [
            "test_366_8.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1739501953125,
            0.257080078125,
            0.241455078125,
            0.19140625,
            0.1954345703125,
            0.2091064453125,
            0.2467041015625,
            0.1861572265625,
            0.2186279296875,
            0.220703125
          ],
          "order_indices": [
            1,
            6,
            2,
            9,
            8,
            5,
            4,
            3,
            7,
            0
          ],
          "order_filenames": [
            "test_366_1.jpg",
            "test_366_6.jpg",
            "test_366_2.jpg",
            "test_366_9.jpg",
            "test_366_8.jpg",
            "test_366_5.jpg",
            "test_366_4.jpg",
            "test_366_3.jpg",
            "test_366_7.jpg",
            "test_366_0.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2,
            "spearman_rho": 0.4303030303030303,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.53125,
            31.796875,
            32.21875,
            29.203125,
            30.53125,
            31.125,
            31.25,
            37.25,
            31.75,
            32.46875
          ],
          "order_indices": [
            7,
            0,
            9,
            2,
            1,
            8,
            6,
            5,
            4,
            3
          ],
          "order_filenames": [
            "test_366_7.jpg",
            "test_366_0.jpg",
            "test_366_9.jpg",
            "test_366_2.jpg",
            "test_366_1.jpg",
            "test_366_8.jpg",
            "test_366_6.jpg",
            "test_366_5.jpg",
            "test_366_4.jpg",
            "test_366_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.37777777777777777,
            "spearman_rho": 0.5636363636363637,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.17206193506717682,
            -0.4239369332790375,
            -0.07228592038154602,
            -1.3981735706329346,
            0.05048762634396553,
            -0.1353457272052765,
            -0.8962346911430359,
            0.3299843370914459,
            0.3219006657600403,
            0.21673862636089325
          ],
          "order_indices": [
            7,
            8,
            9,
            0,
            4,
            2,
            5,
            1,
            6,
            3
          ],
          "order_filenames": [
            "test_366_7.jpg",
            "test_366_8.jpg",
            "test_366_9.jpg",
            "test_366_0.jpg",
            "test_366_4.jpg",
            "test_366_2.jpg",
            "test_366_5.jpg",
            "test_366_1.jpg",
            "test_366_6.jpg",
            "test_366_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.38181818181818183,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 367,
      "prompt": "A pizza is displayed inside a pizza box.",
      "image_filenames": [
        "test_367_0.jpg",
        "test_367_1.jpg",
        "test_367_2.jpg",
        "test_367_3.jpg",
        "test_367_4.jpg",
        "test_367_5.jpg",
        "test_367_6.jpg",
        "test_367_7.jpg",
        "test_367_8.jpg",
        "test_367_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          4,
          1,
          0,
          7,
          6,
          2,
          3,
          8,
          9
        ],
        "order_filenames": [
          "test_367_5.jpg",
          "test_367_4.jpg",
          "test_367_1.jpg",
          "test_367_0.jpg",
          "test_367_7.jpg",
          "test_367_6.jpg",
          "test_367_2.jpg",
          "test_367_3.jpg",
          "test_367_8.jpg",
          "test_367_9.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_367_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_367_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_367_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1995849609375,
            0.2626953125,
            0.276123046875,
            0.2276611328125,
            0.2218017578125,
            0.205322265625,
            0.27880859375,
            0.187744140625,
            0.24609375,
            0.2666015625
          ],
          "order_indices": [
            6,
            2,
            9,
            1,
            8,
            3,
            4,
            5,
            0,
            7
          ],
          "order_filenames": [
            "test_367_6.jpg",
            "test_367_2.jpg",
            "test_367_9.jpg",
            "test_367_1.jpg",
            "test_367_8.jpg",
            "test_367_3.jpg",
            "test_367_4.jpg",
            "test_367_5.jpg",
            "test_367_0.jpg",
            "test_367_7.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.28888888888888886,
            "spearman_rho": -0.47878787878787876,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            32.34375,
            33.625,
            30.4375,
            24.84375,
            32.59375,
            30.4375,
            32.5625,
            31.640625,
            34.71875,
            32.15625
          ],
          "order_indices": [
            8,
            1,
            4,
            6,
            0,
            9,
            7,
            2,
            5,
            3
          ],
          "order_filenames": [
            "test_367_8.jpg",
            "test_367_1.jpg",
            "test_367_4.jpg",
            "test_367_6.jpg",
            "test_367_0.jpg",
            "test_367_9.jpg",
            "test_367_7.jpg",
            "test_367_2.jpg",
            "test_367_5.jpg",
            "test_367_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.06666666666666667,
            "spearman_rho": 0.030303030303030276,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.3494150638580322,
            -0.2989506125450134,
            0.7979797720909119,
            -1.1990965604782104,
            0.3195028305053711,
            -0.5986192226409912,
            0.3534635603427887,
            -0.6008840799331665,
            0.6814910173416138,
            0.8317490816116333
          ],
          "order_indices": [
            9,
            2,
            8,
            6,
            4,
            1,
            0,
            5,
            7,
            3
          ],
          "order_filenames": [
            "test_367_9.jpg",
            "test_367_2.jpg",
            "test_367_8.jpg",
            "test_367_6.jpg",
            "test_367_4.jpg",
            "test_367_1.jpg",
            "test_367_0.jpg",
            "test_367_5.jpg",
            "test_367_7.jpg",
            "test_367_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.46666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 368,
      "prompt": "a vintage photo of a man and a nurse ",
      "image_filenames": [
        "test_368_0.jpg",
        "test_368_1.jpg",
        "test_368_2.jpg",
        "test_368_3.jpg",
        "test_368_4.jpg",
        "test_368_5.jpg",
        "test_368_6.jpg",
        "test_368_7.jpg",
        "test_368_8.jpg",
        "test_368_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          6,
          3,
          4,
          8,
          5,
          7,
          9,
          1,
          0
        ],
        "order_filenames": [
          "test_368_2.jpg",
          "test_368_6.jpg",
          "test_368_3.jpg",
          "test_368_4.jpg",
          "test_368_8.jpg",
          "test_368_5.jpg",
          "test_368_7.jpg",
          "test_368_9.jpg",
          "test_368_1.jpg",
          "test_368_0.jpg"
        ],
        "condorcet_winner": 2,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_368_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5,
            6
          ],
          "winner_filenames": [
            "test_368_5.jpg",
            "test_368_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_368_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.205322265625,
            0.2308349609375,
            0.2130126953125,
            0.20556640625,
            0.1864013671875,
            0.1005859375,
            0.1953125,
            0.2244873046875,
            0.276611328125,
            0.2340087890625
          ],
          "order_indices": [
            8,
            9,
            1,
            7,
            2,
            3,
            0,
            6,
            4,
            5
          ],
          "order_filenames": [
            "test_368_8.jpg",
            "test_368_9.jpg",
            "test_368_1.jpg",
            "test_368_7.jpg",
            "test_368_2.jpg",
            "test_368_3.jpg",
            "test_368_0.jpg",
            "test_368_6.jpg",
            "test_368_4.jpg",
            "test_368_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.2606060606060605,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.09375,
            28.28125,
            37.75,
            30.171875,
            27.703125,
            10.8359375,
            30.734375,
            32.84375,
            42.0,
            35.5
          ],
          "order_indices": [
            8,
            2,
            0,
            9,
            7,
            6,
            3,
            1,
            4,
            5
          ],
          "order_filenames": [
            "test_368_8.jpg",
            "test_368_2.jpg",
            "test_368_0.jpg",
            "test_368_9.jpg",
            "test_368_7.jpg",
            "test_368_6.jpg",
            "test_368_3.jpg",
            "test_368_1.jpg",
            "test_368_4.jpg",
            "test_368_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.022222222222222223,
            "spearman_rho": 0.030303030303030276,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.07735641300678253,
            -0.06061457097530365,
            0.3325808644294739,
            -0.11455688625574112,
            -0.2660578489303589,
            -2.2807817459106445,
            0.07388857752084732,
            1.237439513206482,
            1.2671494483947754,
            0.38825535774230957
          ],
          "order_indices": [
            8,
            7,
            9,
            2,
            0,
            6,
            1,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_368_8.jpg",
            "test_368_7.jpg",
            "test_368_9.jpg",
            "test_368_2.jpg",
            "test_368_0.jpg",
            "test_368_6.jpg",
            "test_368_1.jpg",
            "test_368_3.jpg",
            "test_368_4.jpg",
            "test_368_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.022222222222222223,
            "spearman_rho": -0.1272727272727272,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 369,
      "prompt": "A blue airplane in a blue, cloudless sky",
      "image_filenames": [
        "test_369_0.jpg",
        "test_369_1.jpg",
        "test_369_2.jpg",
        "test_369_3.jpg",
        "test_369_4.jpg",
        "test_369_5.jpg",
        "test_369_6.jpg",
        "test_369_7.jpg",
        "test_369_8.jpg",
        "test_369_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          1,
          4,
          6,
          2,
          5,
          9,
          7,
          8,
          3
        ],
        "order_filenames": [
          "test_369_0.jpg",
          "test_369_1.jpg",
          "test_369_4.jpg",
          "test_369_6.jpg",
          "test_369_2.jpg",
          "test_369_5.jpg",
          "test_369_9.jpg",
          "test_369_7.jpg",
          "test_369_8.jpg",
          "test_369_3.jpg"
        ],
        "condorcet_winner": 0,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_369_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_369_0.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_369_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2388916015625,
            0.290283203125,
            0.28076171875,
            0.228515625,
            0.276123046875,
            0.1815185546875,
            0.25146484375,
            0.20166015625,
            0.2052001953125,
            0.273681640625
          ],
          "order_indices": [
            1,
            2,
            4,
            9,
            6,
            0,
            3,
            8,
            7,
            5
          ],
          "order_filenames": [
            "test_369_1.jpg",
            "test_369_2.jpg",
            "test_369_4.jpg",
            "test_369_9.jpg",
            "test_369_6.jpg",
            "test_369_0.jpg",
            "test_369_3.jpg",
            "test_369_8.jpg",
            "test_369_7.jpg",
            "test_369_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.5636363636363637,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.78125,
            34.4375,
            35.75,
            24.0625,
            32.84375,
            35.34375,
            34.1875,
            31.84375,
            34.90625,
            31.609375
          ],
          "order_indices": [
            0,
            2,
            5,
            8,
            1,
            6,
            4,
            7,
            9,
            3
          ],
          "order_filenames": [
            "test_369_0.jpg",
            "test_369_2.jpg",
            "test_369_5.jpg",
            "test_369_8.jpg",
            "test_369_1.jpg",
            "test_369_6.jpg",
            "test_369_4.jpg",
            "test_369_7.jpg",
            "test_369_9.jpg",
            "test_369_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.4222222222222222,
            "spearman_rho": 0.5393939393939393,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 1.0,
            "exact_position_match": 0.3,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.23446013033390045,
            0.24067923426628113,
            0.21532540023326874,
            -2.1105830669403076,
            0.5936703085899353,
            -1.9973108768463135,
            -0.27059656381607056,
            -1.237390160560608,
            -1.6438140869140625,
            -0.1543949395418167
          ],
          "order_indices": [
            4,
            1,
            0,
            2,
            9,
            6,
            7,
            8,
            5,
            3
          ],
          "order_filenames": [
            "test_369_4.jpg",
            "test_369_1.jpg",
            "test_369_0.jpg",
            "test_369_2.jpg",
            "test_369_9.jpg",
            "test_369_6.jpg",
            "test_369_7.jpg",
            "test_369_8.jpg",
            "test_369_5.jpg",
            "test_369_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.6444444444444445,
            "spearman_rho": 0.8303030303030303,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 370,
      "prompt": "A large dog laying on a couch in a room.",
      "image_filenames": [
        "test_370_0.jpg",
        "test_370_1.jpg",
        "test_370_2.jpg",
        "test_370_3.jpg",
        "test_370_4.jpg",
        "test_370_5.jpg",
        "test_370_6.jpg",
        "test_370_7.jpg",
        "test_370_8.jpg",
        "test_370_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          0,
          3,
          8,
          7,
          1,
          5,
          4,
          2,
          9
        ],
        "order_filenames": [
          "test_370_6.jpg",
          "test_370_0.jpg",
          "test_370_3.jpg",
          "test_370_8.jpg",
          "test_370_7.jpg",
          "test_370_1.jpg",
          "test_370_5.jpg",
          "test_370_4.jpg",
          "test_370_2.jpg",
          "test_370_9.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_370_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_370_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_370_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1553955078125,
            0.295166015625,
            0.2880859375,
            0.243896484375,
            0.1837158203125,
            0.192626953125,
            0.26953125,
            0.202392578125,
            0.267822265625,
            0.2744140625
          ],
          "order_indices": [
            1,
            2,
            9,
            6,
            8,
            3,
            7,
            5,
            4,
            0
          ],
          "order_filenames": [
            "test_370_1.jpg",
            "test_370_2.jpg",
            "test_370_9.jpg",
            "test_370_6.jpg",
            "test_370_8.jpg",
            "test_370_3.jpg",
            "test_370_7.jpg",
            "test_370_5.jpg",
            "test_370_4.jpg",
            "test_370_0.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.2848484848484849,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            32.0625,
            33.71875,
            36.78125,
            35.65625,
            35.75,
            32.65625,
            37.65625,
            36.34375,
            36.65625,
            31.15625
          ],
          "order_indices": [
            6,
            2,
            8,
            7,
            4,
            3,
            1,
            5,
            0,
            9
          ],
          "order_filenames": [
            "test_370_6.jpg",
            "test_370_2.jpg",
            "test_370_8.jpg",
            "test_370_7.jpg",
            "test_370_4.jpg",
            "test_370_3.jpg",
            "test_370_1.jpg",
            "test_370_5.jpg",
            "test_370_0.jpg",
            "test_370_9.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2,
            "spearman_rho": 0.2727272727272727,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.2204769402742386,
            0.03740166872739792,
            0.3052840530872345,
            -1.2413153648376465,
            -0.1787218451499939,
            -0.23987619578838348,
            -0.528853714466095,
            0.13147011399269104,
            -0.04036390408873558,
            -0.5777876377105713
          ],
          "order_indices": [
            2,
            7,
            1,
            8,
            4,
            0,
            5,
            6,
            9,
            3
          ],
          "order_filenames": [
            "test_370_2.jpg",
            "test_370_7.jpg",
            "test_370_1.jpg",
            "test_370_8.jpg",
            "test_370_4.jpg",
            "test_370_0.jpg",
            "test_370_5.jpg",
            "test_370_6.jpg",
            "test_370_9.jpg",
            "test_370_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2,
            "spearman_rho": -0.24848484848484853,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 371,
      "prompt": "A wooden trunk sitting outside with stickers on it.",
      "image_filenames": [
        "test_371_0.jpg",
        "test_371_1.jpg",
        "test_371_2.jpg",
        "test_371_3.jpg",
        "test_371_4.jpg",
        "test_371_5.jpg",
        "test_371_6.jpg",
        "test_371_7.jpg",
        "test_371_8.jpg",
        "test_371_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          3,
          2,
          4,
          5,
          6,
          7,
          8,
          1,
          9
        ],
        "order_filenames": [
          "test_371_0.jpg",
          "test_371_3.jpg",
          "test_371_2.jpg",
          "test_371_4.jpg",
          "test_371_5.jpg",
          "test_371_6.jpg",
          "test_371_7.jpg",
          "test_371_8.jpg",
          "test_371_1.jpg",
          "test_371_9.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_371_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_371_2.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_371_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.21044921875,
            0.2398681640625,
            0.27392578125,
            0.1561279296875,
            0.18310546875,
            0.185791015625,
            0.2296142578125,
            0.228271484375,
            0.18994140625,
            0.274658203125
          ],
          "order_indices": [
            9,
            2,
            1,
            6,
            7,
            0,
            8,
            5,
            4,
            3
          ],
          "order_filenames": [
            "test_371_9.jpg",
            "test_371_2.jpg",
            "test_371_1.jpg",
            "test_371_6.jpg",
            "test_371_7.jpg",
            "test_371_0.jpg",
            "test_371_8.jpg",
            "test_371_5.jpg",
            "test_371_4.jpg",
            "test_371_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4222222222222222,
            "spearman_rho": -0.5151515151515151,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.4375,
            34.15625,
            45.90625,
            28.671875,
            30.421875,
            20.859375,
            37.84375,
            41.8125,
            36.96875,
            31.21875
          ],
          "order_indices": [
            2,
            7,
            0,
            6,
            8,
            1,
            9,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_371_2.jpg",
            "test_371_7.jpg",
            "test_371_0.jpg",
            "test_371_6.jpg",
            "test_371_8.jpg",
            "test_371_1.jpg",
            "test_371_9.jpg",
            "test_371_4.jpg",
            "test_371_3.jpg",
            "test_371_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.8398969769477844,
            0.6410923600196838,
            1.7072904109954834,
            -2.078125238418579,
            -1.0842878818511963,
            -1.680094599723816,
            0.1154102087020874,
            1.3430722951889038,
            -0.06659038364887238,
            1.3533910512924194
          ],
          "order_indices": [
            2,
            9,
            7,
            0,
            1,
            6,
            8,
            4,
            5,
            3
          ],
          "order_filenames": [
            "test_371_2.jpg",
            "test_371_9.jpg",
            "test_371_7.jpg",
            "test_371_0.jpg",
            "test_371_1.jpg",
            "test_371_6.jpg",
            "test_371_8.jpg",
            "test_371_4.jpg",
            "test_371_5.jpg",
            "test_371_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.24444444444444444,
            "spearman_rho": -0.24848484848484853,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 372,
      "prompt": "A white Fed Ex sitting in front of a tall building.",
      "image_filenames": [
        "test_372_0.jpg",
        "test_372_1.jpg",
        "test_372_2.jpg",
        "test_372_3.jpg",
        "test_372_4.jpg",
        "test_372_5.jpg",
        "test_372_6.jpg",
        "test_372_7.jpg",
        "test_372_8.jpg",
        "test_372_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          1,
          4,
          7,
          0,
          6,
          8,
          5,
          2,
          9
        ],
        "order_filenames": [
          "test_372_3.jpg",
          "test_372_1.jpg",
          "test_372_4.jpg",
          "test_372_7.jpg",
          "test_372_0.jpg",
          "test_372_6.jpg",
          "test_372_8.jpg",
          "test_372_5.jpg",
          "test_372_2.jpg",
          "test_372_9.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3
        ],
        "winner_filenames": [
          "test_372_3.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_372_3.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_372_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.190673828125,
            0.1741943359375,
            0.263671875,
            0.2037353515625,
            0.1689453125,
            0.1895751953125,
            0.2069091796875,
            0.201171875,
            0.262939453125,
            0.1973876953125
          ],
          "order_indices": [
            2,
            8,
            6,
            3,
            7,
            9,
            0,
            5,
            1,
            4
          ],
          "order_filenames": [
            "test_372_2.jpg",
            "test_372_8.jpg",
            "test_372_6.jpg",
            "test_372_3.jpg",
            "test_372_7.jpg",
            "test_372_9.jpg",
            "test_372_0.jpg",
            "test_372_5.jpg",
            "test_372_1.jpg",
            "test_372_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.28888888888888886,
            "spearman_rho": -0.36969696969696964,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.8125,
            20.9375,
            38.28125,
            21.03125,
            21.578125,
            25.578125,
            26.28125,
            39.4375,
            36.28125,
            30.734375
          ],
          "order_indices": [
            0,
            7,
            2,
            8,
            9,
            6,
            5,
            4,
            3,
            1
          ],
          "order_filenames": [
            "test_372_0.jpg",
            "test_372_7.jpg",
            "test_372_2.jpg",
            "test_372_8.jpg",
            "test_372_9.jpg",
            "test_372_6.jpg",
            "test_372_5.jpg",
            "test_372_4.jpg",
            "test_372_3.jpg",
            "test_372_1.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.47878787878787876,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.2098705768585205,
            -2.0049636363983154,
            1.4186506271362305,
            -1.2788569927215576,
            -1.5398720502853394,
            -1.2229015827178955,
            -2.097784996032715,
            0.5569631457328796,
            1.250170350074768,
            -0.06751649081707001
          ],
          "order_indices": [
            2,
            8,
            0,
            7,
            9,
            5,
            3,
            4,
            1,
            6
          ],
          "order_filenames": [
            "test_372_2.jpg",
            "test_372_8.jpg",
            "test_372_0.jpg",
            "test_372_7.jpg",
            "test_372_9.jpg",
            "test_372_5.jpg",
            "test_372_3.jpg",
            "test_372_4.jpg",
            "test_372_1.jpg",
            "test_372_6.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.37777777777777777,
            "spearman_rho": -0.5030303030303029,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 373,
      "prompt": "there are three woman that are laying on the beach",
      "image_filenames": [
        "test_373_0.jpg",
        "test_373_1.jpg",
        "test_373_2.jpg",
        "test_373_3.jpg",
        "test_373_4.jpg",
        "test_373_5.jpg",
        "test_373_6.jpg",
        "test_373_7.jpg",
        "test_373_8.jpg",
        "test_373_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          3,
          5,
          7,
          9,
          2,
          4,
          1,
          8,
          0
        ],
        "order_filenames": [
          "test_373_6.jpg",
          "test_373_3.jpg",
          "test_373_5.jpg",
          "test_373_7.jpg",
          "test_373_9.jpg",
          "test_373_2.jpg",
          "test_373_4.jpg",
          "test_373_1.jpg",
          "test_373_8.jpg",
          "test_373_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_373_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_373_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_373_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2012939453125,
            0.2666015625,
            0.286376953125,
            0.1915283203125,
            0.192626953125,
            0.1431884765625,
            0.2666015625,
            0.1998291015625,
            0.300048828125,
            0.26953125
          ],
          "order_indices": [
            8,
            2,
            9,
            1,
            6,
            0,
            7,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_373_8.jpg",
            "test_373_2.jpg",
            "test_373_9.jpg",
            "test_373_1.jpg",
            "test_373_6.jpg",
            "test_373_0.jpg",
            "test_373_7.jpg",
            "test_373_4.jpg",
            "test_373_3.jpg",
            "test_373_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.4545454545454546,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.40625,
            34.71875,
            36.75,
            27.3125,
            29.265625,
            17.5625,
            38.0,
            34.6875,
            39.28125,
            24.25
          ],
          "order_indices": [
            8,
            0,
            6,
            2,
            1,
            7,
            4,
            3,
            9,
            5
          ],
          "order_filenames": [
            "test_373_8.jpg",
            "test_373_0.jpg",
            "test_373_6.jpg",
            "test_373_2.jpg",
            "test_373_1.jpg",
            "test_373_7.jpg",
            "test_373_4.jpg",
            "test_373_3.jpg",
            "test_373_9.jpg",
            "test_373_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.37777777777777777,
            "spearman_rho": -0.5151515151515151,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.1483738422393799,
            0.9427125453948975,
            0.6841437816619873,
            -1.8998074531555176,
            0.22569939494132996,
            -2.249382734298706,
            0.6750591993331909,
            0.33921125531196594,
            1.2116613388061523,
            -0.14518755674362183
          ],
          "order_indices": [
            8,
            1,
            2,
            6,
            7,
            4,
            9,
            0,
            3,
            5
          ],
          "order_filenames": [
            "test_373_8.jpg",
            "test_373_1.jpg",
            "test_373_2.jpg",
            "test_373_6.jpg",
            "test_373_7.jpg",
            "test_373_4.jpg",
            "test_373_9.jpg",
            "test_373_0.jpg",
            "test_373_3.jpg",
            "test_373_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.28888888888888886,
            "spearman_rho": -0.36969696969696964,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 374,
      "prompt": "Carrots bundled up for sale at an outside market",
      "image_filenames": [
        "test_374_0.jpg",
        "test_374_1.jpg",
        "test_374_2.jpg",
        "test_374_3.jpg",
        "test_374_4.jpg",
        "test_374_5.jpg",
        "test_374_6.jpg",
        "test_374_7.jpg",
        "test_374_8.jpg",
        "test_374_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          9,
          4,
          7,
          6,
          8,
          5,
          3,
          1,
          0
        ],
        "order_filenames": [
          "test_374_2.jpg",
          "test_374_9.jpg",
          "test_374_4.jpg",
          "test_374_7.jpg",
          "test_374_6.jpg",
          "test_374_8.jpg",
          "test_374_5.jpg",
          "test_374_3.jpg",
          "test_374_1.jpg",
          "test_374_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_374_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            9
          ],
          "winner_filenames": [
            "test_374_9.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_374_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1749267578125,
            0.277099609375,
            0.275634765625,
            0.212646484375,
            0.224365234375,
            0.2283935546875,
            0.269287109375,
            0.252685546875,
            0.2587890625,
            0.2425537109375
          ],
          "order_indices": [
            1,
            2,
            6,
            8,
            7,
            9,
            5,
            4,
            3,
            0
          ],
          "order_filenames": [
            "test_374_1.jpg",
            "test_374_2.jpg",
            "test_374_6.jpg",
            "test_374_8.jpg",
            "test_374_7.jpg",
            "test_374_9.jpg",
            "test_374_5.jpg",
            "test_374_4.jpg",
            "test_374_3.jpg",
            "test_374_0.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.24444444444444444,
            "spearman_rho": 0.296969696969697,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            42.9375,
            32.34375,
            34.0625,
            33.78125,
            36.6875,
            28.90625,
            31.0625,
            39.4375,
            34.40625,
            27.984375
          ],
          "order_indices": [
            0,
            7,
            4,
            8,
            2,
            3,
            1,
            6,
            5,
            9
          ],
          "order_filenames": [
            "test_374_0.jpg",
            "test_374_7.jpg",
            "test_374_4.jpg",
            "test_374_8.jpg",
            "test_374_2.jpg",
            "test_374_3.jpg",
            "test_374_1.jpg",
            "test_374_6.jpg",
            "test_374_5.jpg",
            "test_374_9.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.1515151515151516,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.4221397638320923,
            -0.11568979918956757,
            0.01933959312736988,
            -0.2020113617181778,
            0.1789218932390213,
            -1.206800103187561,
            -0.7792271971702576,
            0.09182219952344894,
            -0.33617281913757324,
            -1.4446008205413818
          ],
          "order_indices": [
            4,
            7,
            2,
            1,
            3,
            8,
            0,
            6,
            5,
            9
          ],
          "order_filenames": [
            "test_374_4.jpg",
            "test_374_7.jpg",
            "test_374_2.jpg",
            "test_374_1.jpg",
            "test_374_3.jpg",
            "test_374_8.jpg",
            "test_374_0.jpg",
            "test_374_6.jpg",
            "test_374_5.jpg",
            "test_374_9.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.1111111111111111,
            "spearman_rho": 0.19999999999999996,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 375,
      "prompt": "A nighstand topped with a white land-line phone, remote control, a metallic lamp, and two pens next to a black hardcover book.",
      "image_filenames": [
        "test_375_0.jpg",
        "test_375_1.jpg",
        "test_375_2.jpg",
        "test_375_3.jpg",
        "test_375_4.jpg",
        "test_375_5.jpg",
        "test_375_6.jpg",
        "test_375_7.jpg",
        "test_375_8.jpg",
        "test_375_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          3,
          4,
          6,
          2,
          8,
          1,
          7,
          9,
          0
        ],
        "order_filenames": [
          "test_375_5.jpg",
          "test_375_3.jpg",
          "test_375_4.jpg",
          "test_375_6.jpg",
          "test_375_2.jpg",
          "test_375_8.jpg",
          "test_375_1.jpg",
          "test_375_7.jpg",
          "test_375_9.jpg",
          "test_375_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_375_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5,
            6
          ],
          "winner_filenames": [
            "test_375_5.jpg",
            "test_375_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3,
            5
          ],
          "winner_filenames": [
            "test_375_3.jpg",
            "test_375_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.195068359375,
            0.1978759765625,
            0.2315673828125,
            0.135986328125,
            0.1688232421875,
            0.140380859375,
            0.1856689453125,
            0.2001953125,
            0.239013671875,
            0.2431640625
          ],
          "order_indices": [
            9,
            8,
            2,
            7,
            1,
            0,
            6,
            4,
            5,
            3
          ],
          "order_filenames": [
            "test_375_9.jpg",
            "test_375_8.jpg",
            "test_375_2.jpg",
            "test_375_7.jpg",
            "test_375_1.jpg",
            "test_375_0.jpg",
            "test_375_6.jpg",
            "test_375_4.jpg",
            "test_375_5.jpg",
            "test_375_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5555555555555556,
            "spearman_rho": -0.709090909090909,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.65625,
            31.8125,
            39.5,
            27.15625,
            24.875,
            27.640625,
            30.78125,
            35.5,
            39.5625,
            37.78125
          ],
          "order_indices": [
            8,
            2,
            9,
            0,
            7,
            1,
            6,
            5,
            3,
            4
          ],
          "order_filenames": [
            "test_375_8.jpg",
            "test_375_2.jpg",
            "test_375_9.jpg",
            "test_375_0.jpg",
            "test_375_7.jpg",
            "test_375_1.jpg",
            "test_375_6.jpg",
            "test_375_5.jpg",
            "test_375_3.jpg",
            "test_375_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4666666666666667,
            "spearman_rho": -0.6484848484848484,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.4777522087097168,
            -0.8917573094367981,
            -0.2278481423854828,
            -1.7775709629058838,
            -0.4658639132976532,
            -1.4890270233154297,
            -1.1146236658096313,
            0.5506206750869751,
            -0.018190259113907814,
            0.6168748736381531
          ],
          "order_indices": [
            9,
            7,
            8,
            2,
            4,
            0,
            1,
            6,
            5,
            3
          ],
          "order_filenames": [
            "test_375_9.jpg",
            "test_375_7.jpg",
            "test_375_8.jpg",
            "test_375_2.jpg",
            "test_375_4.jpg",
            "test_375_0.jpg",
            "test_375_1.jpg",
            "test_375_6.jpg",
            "test_375_5.jpg",
            "test_375_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5555555555555556,
            "spearman_rho": -0.6606060606060606,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 376,
      "prompt": "There is a man and woman posing together  in a restaurant",
      "image_filenames": [
        "test_376_0.jpg",
        "test_376_1.jpg",
        "test_376_2.jpg",
        "test_376_3.jpg",
        "test_376_4.jpg",
        "test_376_5.jpg",
        "test_376_6.jpg",
        "test_376_7.jpg",
        "test_376_8.jpg",
        "test_376_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          6,
          1,
          5,
          9,
          8,
          3,
          4,
          2,
          0
        ],
        "order_filenames": [
          "test_376_7.jpg",
          "test_376_6.jpg",
          "test_376_1.jpg",
          "test_376_5.jpg",
          "test_376_9.jpg",
          "test_376_8.jpg",
          "test_376_3.jpg",
          "test_376_4.jpg",
          "test_376_2.jpg",
          "test_376_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_376_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_376_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_376_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.16259765625,
            0.3056640625,
            0.283935546875,
            0.179443359375,
            0.189208984375,
            0.1331787109375,
            0.261474609375,
            0.1875,
            0.283447265625,
            0.282470703125
          ],
          "order_indices": [
            1,
            2,
            8,
            9,
            6,
            4,
            7,
            3,
            0,
            5
          ],
          "order_filenames": [
            "test_376_1.jpg",
            "test_376_2.jpg",
            "test_376_8.jpg",
            "test_376_9.jpg",
            "test_376_6.jpg",
            "test_376_4.jpg",
            "test_376_7.jpg",
            "test_376_3.jpg",
            "test_376_0.jpg",
            "test_376_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.022222222222222223,
            "spearman_rho": 0.09090909090909094,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            28.625,
            36.75,
            33.0625,
            26.265625,
            31.09375,
            15.5859375,
            32.40625,
            34.1875,
            33.28125,
            25.875
          ],
          "order_indices": [
            1,
            7,
            8,
            2,
            6,
            4,
            0,
            3,
            9,
            5
          ],
          "order_filenames": [
            "test_376_1.jpg",
            "test_376_7.jpg",
            "test_376_8.jpg",
            "test_376_2.jpg",
            "test_376_6.jpg",
            "test_376_4.jpg",
            "test_376_0.jpg",
            "test_376_3.jpg",
            "test_376_9.jpg",
            "test_376_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.15555555555555556,
            "spearman_rho": 0.3090909090909091,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -1.8029909133911133,
            0.10379086434841156,
            -0.2776872515678406,
            -1.4190670251846313,
            -0.5500995516777039,
            -2.0451300144195557,
            -0.28703856468200684,
            -0.48682600259780884,
            -1.2715238332748413,
            -0.6115410923957825
          ],
          "order_indices": [
            1,
            2,
            6,
            7,
            4,
            9,
            8,
            3,
            0,
            5
          ],
          "order_filenames": [
            "test_376_1.jpg",
            "test_376_2.jpg",
            "test_376_6.jpg",
            "test_376_7.jpg",
            "test_376_4.jpg",
            "test_376_9.jpg",
            "test_376_8.jpg",
            "test_376_3.jpg",
            "test_376_0.jpg",
            "test_376_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2,
            "spearman_rho": 0.32121212121212117,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 377,
      "prompt": "A tall giraffe in a zoo eating branches ",
      "image_filenames": [
        "test_377_0.jpg",
        "test_377_1.jpg",
        "test_377_2.jpg",
        "test_377_3.jpg",
        "test_377_4.jpg",
        "test_377_5.jpg",
        "test_377_6.jpg",
        "test_377_7.jpg",
        "test_377_8.jpg",
        "test_377_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          5,
          9,
          7,
          8,
          3,
          4,
          2,
          1,
          0
        ],
        "order_filenames": [
          "test_377_6.jpg",
          "test_377_5.jpg",
          "test_377_9.jpg",
          "test_377_7.jpg",
          "test_377_8.jpg",
          "test_377_3.jpg",
          "test_377_4.jpg",
          "test_377_2.jpg",
          "test_377_1.jpg",
          "test_377_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_377_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            9
          ],
          "winner_filenames": [
            "test_377_9.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_377_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.175048828125,
            0.2374267578125,
            0.24853515625,
            0.203369140625,
            0.2218017578125,
            0.2374267578125,
            0.259765625,
            0.2012939453125,
            0.279052734375,
            0.24853515625
          ],
          "order_indices": [
            8,
            6,
            2,
            9,
            1,
            5,
            4,
            3,
            7,
            0
          ],
          "order_filenames": [
            "test_377_8.jpg",
            "test_377_6.jpg",
            "test_377_2.jpg",
            "test_377_9.jpg",
            "test_377_1.jpg",
            "test_377_5.jpg",
            "test_377_4.jpg",
            "test_377_3.jpg",
            "test_377_7.jpg",
            "test_377_0.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.24444444444444444,
            "spearman_rho": 0.36969696969696975,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.84375,
            34.625,
            27.640625,
            22.734375,
            35.8125,
            33.75,
            35.0625,
            33.8125,
            37.46875,
            36.4375
          ],
          "order_indices": [
            8,
            9,
            4,
            6,
            0,
            1,
            7,
            5,
            2,
            3
          ],
          "order_filenames": [
            "test_377_8.jpg",
            "test_377_9.jpg",
            "test_377_4.jpg",
            "test_377_6.jpg",
            "test_377_0.jpg",
            "test_377_1.jpg",
            "test_377_7.jpg",
            "test_377_5.jpg",
            "test_377_2.jpg",
            "test_377_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.06666666666666667,
            "spearman_rho": 0.1636363636363637,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.3247227072715759,
            0.45465561747550964,
            -1.9400231838226318,
            -2.1637861728668213,
            -1.0926967859268188,
            -0.1303139179944992,
            -0.1337580531835556,
            -0.4636637270450592,
            0.4081212282180786,
            0.6442590951919556
          ],
          "order_indices": [
            9,
            1,
            8,
            5,
            6,
            0,
            7,
            4,
            2,
            3
          ],
          "order_filenames": [
            "test_377_9.jpg",
            "test_377_1.jpg",
            "test_377_8.jpg",
            "test_377_5.jpg",
            "test_377_6.jpg",
            "test_377_0.jpg",
            "test_377_7.jpg",
            "test_377_4.jpg",
            "test_377_2.jpg",
            "test_377_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.15555555555555556,
            "spearman_rho": 0.2727272727272727,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 378,
      "prompt": "A bear walks through a group of bushes with a plant in its mouth.",
      "image_filenames": [
        "test_378_0.jpg",
        "test_378_1.jpg",
        "test_378_2.jpg",
        "test_378_3.jpg",
        "test_378_4.jpg",
        "test_378_5.jpg",
        "test_378_6.jpg",
        "test_378_7.jpg",
        "test_378_8.jpg",
        "test_378_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          1,
          6,
          7,
          8,
          5,
          9,
          3,
          4,
          2
        ],
        "order_filenames": [
          "test_378_0.jpg",
          "test_378_1.jpg",
          "test_378_6.jpg",
          "test_378_7.jpg",
          "test_378_8.jpg",
          "test_378_5.jpg",
          "test_378_9.jpg",
          "test_378_3.jpg",
          "test_378_4.jpg",
          "test_378_2.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_378_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_378_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_378_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2294921875,
            0.294921875,
            0.30517578125,
            0.232421875,
            0.2222900390625,
            0.2119140625,
            0.258544921875,
            0.2064208984375,
            0.260498046875,
            0.2587890625
          ],
          "order_indices": [
            2,
            1,
            8,
            9,
            6,
            3,
            0,
            4,
            5,
            7
          ],
          "order_filenames": [
            "test_378_2.jpg",
            "test_378_1.jpg",
            "test_378_8.jpg",
            "test_378_9.jpg",
            "test_378_6.jpg",
            "test_378_3.jpg",
            "test_378_0.jpg",
            "test_378_4.jpg",
            "test_378_5.jpg",
            "test_378_7.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.06666666666666667,
            "spearman_rho": -0.11515151515151523,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.0625,
            30.828125,
            32.9375,
            29.4375,
            35.96875,
            38.5,
            27.171875,
            34.9375,
            32.625,
            30.03125
          ],
          "order_indices": [
            5,
            0,
            4,
            7,
            2,
            8,
            1,
            9,
            3,
            6
          ],
          "order_filenames": [
            "test_378_5.jpg",
            "test_378_0.jpg",
            "test_378_4.jpg",
            "test_378_7.jpg",
            "test_378_2.jpg",
            "test_378_8.jpg",
            "test_378_1.jpg",
            "test_378_9.jpg",
            "test_378_3.jpg",
            "test_378_6.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.022222222222222223,
            "spearman_rho": 0.0060606060606061,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.2726035416126251,
            1.811246395111084,
            1.7731506824493408,
            -1.4408046007156372,
            -1.7738227844238281,
            -0.2628774046897888,
            0.6106795072555542,
            -1.0049052238464355,
            0.5299356579780579,
            1.2912342548370361
          ],
          "order_indices": [
            1,
            2,
            9,
            6,
            8,
            5,
            0,
            7,
            3,
            4
          ],
          "order_filenames": [
            "test_378_1.jpg",
            "test_378_2.jpg",
            "test_378_9.jpg",
            "test_378_6.jpg",
            "test_378_8.jpg",
            "test_378_5.jpg",
            "test_378_0.jpg",
            "test_378_7.jpg",
            "test_378_3.jpg",
            "test_378_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.15555555555555556,
            "spearman_rho": 0.17575757575757578,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 379,
      "prompt": "A giraffe stands inside a enclosure with a group of people standing near by. ",
      "image_filenames": [
        "test_379_0.jpg",
        "test_379_1.jpg",
        "test_379_2.jpg",
        "test_379_3.jpg",
        "test_379_4.jpg",
        "test_379_5.jpg",
        "test_379_6.jpg",
        "test_379_7.jpg",
        "test_379_8.jpg",
        "test_379_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          1,
          8,
          4,
          5,
          6,
          3,
          9,
          0,
          7
        ],
        "order_filenames": [
          "test_379_2.jpg",
          "test_379_1.jpg",
          "test_379_8.jpg",
          "test_379_4.jpg",
          "test_379_5.jpg",
          "test_379_6.jpg",
          "test_379_3.jpg",
          "test_379_9.jpg",
          "test_379_0.jpg",
          "test_379_7.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_379_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            8
          ],
          "winner_filenames": [
            "test_379_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_379_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1976318359375,
            0.254638671875,
            0.2900390625,
            0.1593017578125,
            0.228271484375,
            0.1571044921875,
            0.2119140625,
            0.2188720703125,
            0.261474609375,
            0.256591796875
          ],
          "order_indices": [
            2,
            8,
            9,
            1,
            4,
            7,
            6,
            0,
            3,
            5
          ],
          "order_filenames": [
            "test_379_2.jpg",
            "test_379_8.jpg",
            "test_379_9.jpg",
            "test_379_1.jpg",
            "test_379_4.jpg",
            "test_379_7.jpg",
            "test_379_6.jpg",
            "test_379_0.jpg",
            "test_379_3.jpg",
            "test_379_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.37777777777777777,
            "spearman_rho": 0.5272727272727273,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.5,
            34.59375,
            40.71875,
            25.75,
            36.5,
            25.5625,
            29.59375,
            37.25,
            35.375,
            39.75
          ],
          "order_indices": [
            2,
            9,
            7,
            0,
            4,
            8,
            1,
            6,
            3,
            5
          ],
          "order_filenames": [
            "test_379_2.jpg",
            "test_379_9.jpg",
            "test_379_7.jpg",
            "test_379_0.jpg",
            "test_379_4.jpg",
            "test_379_8.jpg",
            "test_379_1.jpg",
            "test_379_6.jpg",
            "test_379_3.jpg",
            "test_379_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.06666666666666667,
            "spearman_rho": -0.07878787878787885,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.0607670322060585,
            0.781144380569458,
            1.5409812927246094,
            -1.9353268146514893,
            0.7127202749252319,
            -1.4883047342300415,
            -0.32508620619773865,
            0.17560210824012756,
            0.7835988402366638,
            0.7382990717887878
          ],
          "order_indices": [
            2,
            8,
            1,
            9,
            4,
            7,
            0,
            6,
            5,
            3
          ],
          "order_filenames": [
            "test_379_2.jpg",
            "test_379_8.jpg",
            "test_379_1.jpg",
            "test_379_9.jpg",
            "test_379_4.jpg",
            "test_379_7.jpg",
            "test_379_0.jpg",
            "test_379_6.jpg",
            "test_379_5.jpg",
            "test_379_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.4222222222222222,
            "spearman_rho": 0.5878787878787879,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 380,
      "prompt": "A pigeon sitting on top of a white table.",
      "image_filenames": [
        "test_380_0.jpg",
        "test_380_1.jpg",
        "test_380_2.jpg",
        "test_380_3.jpg",
        "test_380_4.jpg",
        "test_380_5.jpg",
        "test_380_6.jpg",
        "test_380_7.jpg",
        "test_380_8.jpg",
        "test_380_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          2,
          0,
          3,
          9,
          5,
          6,
          7,
          8,
          1
        ],
        "order_filenames": [
          "test_380_4.jpg",
          "test_380_2.jpg",
          "test_380_0.jpg",
          "test_380_3.jpg",
          "test_380_9.jpg",
          "test_380_5.jpg",
          "test_380_6.jpg",
          "test_380_7.jpg",
          "test_380_8.jpg",
          "test_380_1.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_380_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_380_2.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_380_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.23583984375,
            0.280029296875,
            0.286376953125,
            0.1781005859375,
            0.2235107421875,
            0.1953125,
            0.264404296875,
            0.1925048828125,
            0.283203125,
            0.2371826171875
          ],
          "order_indices": [
            2,
            8,
            1,
            6,
            9,
            0,
            4,
            5,
            7,
            3
          ],
          "order_filenames": [
            "test_380_2.jpg",
            "test_380_8.jpg",
            "test_380_1.jpg",
            "test_380_6.jpg",
            "test_380_9.jpg",
            "test_380_0.jpg",
            "test_380_4.jpg",
            "test_380_5.jpg",
            "test_380_7.jpg",
            "test_380_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.15555555555555556,
            "spearman_rho": -0.17575757575757578,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.90625,
            34.28125,
            43.375,
            17.953125,
            38.1875,
            28.671875,
            32.34375,
            39.8125,
            34.71875,
            33.875
          ],
          "order_indices": [
            2,
            7,
            4,
            0,
            8,
            1,
            9,
            6,
            5,
            3
          ],
          "order_filenames": [
            "test_380_2.jpg",
            "test_380_7.jpg",
            "test_380_4.jpg",
            "test_380_0.jpg",
            "test_380_8.jpg",
            "test_380_1.jpg",
            "test_380_9.jpg",
            "test_380_6.jpg",
            "test_380_5.jpg",
            "test_380_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.15555555555555556,
            "spearman_rho": 0.24848484848484853,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.14425452053546906,
            -2.084658145904541,
            1.2778781652450562,
            -2.0253961086273193,
            -1.6641210317611694,
            -1.4809224605560303,
            -1.5641236305236816,
            -0.5088595747947693,
            0.1496339589357376,
            0.6681472659111023
          ],
          "order_indices": [
            2,
            9,
            8,
            0,
            7,
            5,
            6,
            4,
            3,
            1
          ],
          "order_filenames": [
            "test_380_2.jpg",
            "test_380_9.jpg",
            "test_380_8.jpg",
            "test_380_0.jpg",
            "test_380_7.jpg",
            "test_380_5.jpg",
            "test_380_6.jpg",
            "test_380_4.jpg",
            "test_380_3.jpg",
            "test_380_1.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.15555555555555556,
            "spearman_rho": 0.21212121212121215,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 381,
      "prompt": "A group of people on a field playing with a frisbee.",
      "image_filenames": [
        "test_381_0.jpg",
        "test_381_1.jpg",
        "test_381_2.jpg",
        "test_381_3.jpg",
        "test_381_4.jpg",
        "test_381_5.jpg",
        "test_381_6.jpg",
        "test_381_7.jpg",
        "test_381_8.jpg",
        "test_381_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          6,
          7,
          4,
          3,
          1,
          9,
          8,
          2,
          0
        ],
        "order_filenames": [
          "test_381_5.jpg",
          "test_381_6.jpg",
          "test_381_7.jpg",
          "test_381_4.jpg",
          "test_381_3.jpg",
          "test_381_1.jpg",
          "test_381_9.jpg",
          "test_381_8.jpg",
          "test_381_2.jpg",
          "test_381_0.jpg"
        ],
        "condorcet_winner": 5,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_381_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_381_5.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_381_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.20751953125,
            0.26220703125,
            0.29248046875,
            0.19189453125,
            0.203125,
            0.137451171875,
            0.258056640625,
            0.215576171875,
            0.25244140625,
            0.277099609375
          ],
          "order_indices": [
            2,
            9,
            1,
            6,
            8,
            7,
            0,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_381_2.jpg",
            "test_381_9.jpg",
            "test_381_1.jpg",
            "test_381_6.jpg",
            "test_381_8.jpg",
            "test_381_7.jpg",
            "test_381_0.jpg",
            "test_381_4.jpg",
            "test_381_3.jpg",
            "test_381_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.46666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            40.625,
            37.84375,
            41.3125,
            32.46875,
            34.71875,
            23.609375,
            38.0625,
            36.90625,
            39.90625,
            34.125
          ],
          "order_indices": [
            2,
            0,
            8,
            6,
            1,
            7,
            4,
            9,
            3,
            5
          ],
          "order_filenames": [
            "test_381_2.jpg",
            "test_381_0.jpg",
            "test_381_8.jpg",
            "test_381_6.jpg",
            "test_381_1.jpg",
            "test_381_7.jpg",
            "test_381_4.jpg",
            "test_381_9.jpg",
            "test_381_3.jpg",
            "test_381_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4666666666666667,
            "spearman_rho": -0.6606060606060606,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.2510235011577606,
            -0.6727957725524902,
            0.7471712231636047,
            -1.2557449340820312,
            0.5343917608261108,
            -2.1090643405914307,
            0.44434991478919983,
            0.2750612497329712,
            0.34940391778945923,
            0.03399733081459999
          ],
          "order_indices": [
            2,
            4,
            6,
            8,
            7,
            0,
            9,
            1,
            3,
            5
          ],
          "order_filenames": [
            "test_381_2.jpg",
            "test_381_4.jpg",
            "test_381_6.jpg",
            "test_381_8.jpg",
            "test_381_7.jpg",
            "test_381_0.jpg",
            "test_381_9.jpg",
            "test_381_1.jpg",
            "test_381_3.jpg",
            "test_381_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.24444444444444444,
            "spearman_rho": -0.24848484848484853,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 382,
      "prompt": "A view of a red light at Tenth Avenue",
      "image_filenames": [
        "test_382_0.jpg",
        "test_382_1.jpg",
        "test_382_2.jpg",
        "test_382_3.jpg",
        "test_382_4.jpg",
        "test_382_5.jpg",
        "test_382_6.jpg",
        "test_382_7.jpg",
        "test_382_8.jpg",
        "test_382_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          2,
          1,
          4,
          5,
          6,
          3,
          7,
          8,
          9
        ],
        "order_filenames": [
          "test_382_0.jpg",
          "test_382_2.jpg",
          "test_382_1.jpg",
          "test_382_4.jpg",
          "test_382_5.jpg",
          "test_382_6.jpg",
          "test_382_3.jpg",
          "test_382_7.jpg",
          "test_382_8.jpg",
          "test_382_9.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_382_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_382_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0
          ],
          "winner_filenames": [
            "test_382_0.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2335205078125,
            0.256591796875,
            0.280029296875,
            0.23193359375,
            0.21337890625,
            0.1798095703125,
            0.2403564453125,
            0.264404296875,
            0.266845703125,
            0.255859375
          ],
          "order_indices": [
            2,
            8,
            7,
            1,
            9,
            6,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_382_2.jpg",
            "test_382_8.jpg",
            "test_382_7.jpg",
            "test_382_1.jpg",
            "test_382_9.jpg",
            "test_382_6.jpg",
            "test_382_0.jpg",
            "test_382_3.jpg",
            "test_382_4.jpg",
            "test_382_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.1393939393939394,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            34.625,
            31.453125,
            37.28125,
            30.328125,
            31.09375,
            28.140625,
            31.03125,
            39.25,
            33.0625,
            37.90625
          ],
          "order_indices": [
            7,
            9,
            2,
            0,
            8,
            1,
            4,
            6,
            3,
            5
          ],
          "order_filenames": [
            "test_382_7.jpg",
            "test_382_9.jpg",
            "test_382_2.jpg",
            "test_382_0.jpg",
            "test_382_8.jpg",
            "test_382_1.jpg",
            "test_382_4.jpg",
            "test_382_6.jpg",
            "test_382_3.jpg",
            "test_382_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.022222222222222223,
            "spearman_rho": -0.1515151515151516,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.6161141395568848,
            0.6640390753746033,
            0.6271440386772156,
            -0.10499376058578491,
            -0.35085365176200867,
            -1.378993034362793,
            0.8122573494911194,
            -0.2407856583595276,
            0.24571619927883148,
            -0.45347124338150024
          ],
          "order_indices": [
            6,
            1,
            2,
            8,
            3,
            7,
            4,
            9,
            0,
            5
          ],
          "order_filenames": [
            "test_382_6.jpg",
            "test_382_1.jpg",
            "test_382_2.jpg",
            "test_382_8.jpg",
            "test_382_3.jpg",
            "test_382_7.jpg",
            "test_382_4.jpg",
            "test_382_9.jpg",
            "test_382_0.jpg",
            "test_382_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.022222222222222223,
            "spearman_rho": 0.018181818181818188,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 383,
      "prompt": "A sculpture that is planted in rocks in front of the water.",
      "image_filenames": [
        "test_383_0.jpg",
        "test_383_1.jpg",
        "test_383_2.jpg",
        "test_383_3.jpg",
        "test_383_4.jpg",
        "test_383_5.jpg",
        "test_383_6.jpg",
        "test_383_7.jpg",
        "test_383_8.jpg",
        "test_383_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          5,
          3,
          7,
          6,
          1,
          4,
          8,
          9,
          0
        ],
        "order_filenames": [
          "test_383_2.jpg",
          "test_383_5.jpg",
          "test_383_3.jpg",
          "test_383_7.jpg",
          "test_383_6.jpg",
          "test_383_1.jpg",
          "test_383_4.jpg",
          "test_383_8.jpg",
          "test_383_9.jpg",
          "test_383_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_383_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            2,
            4,
            6,
            7
          ],
          "winner_filenames": [
            "test_383_2.jpg",
            "test_383_4.jpg",
            "test_383_6.jpg",
            "test_383_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_383_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2093505859375,
            0.2454833984375,
            0.2110595703125,
            0.2220458984375,
            0.164794921875,
            0.213623046875,
            0.227294921875,
            0.242431640625,
            0.24755859375,
            0.21728515625
          ],
          "order_indices": [
            8,
            1,
            7,
            6,
            3,
            9,
            5,
            2,
            0,
            4
          ],
          "order_filenames": [
            "test_383_8.jpg",
            "test_383_1.jpg",
            "test_383_7.jpg",
            "test_383_6.jpg",
            "test_383_3.jpg",
            "test_383_9.jpg",
            "test_383_5.jpg",
            "test_383_2.jpg",
            "test_383_0.jpg",
            "test_383_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": 0.0060606060606061,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.34375,
            36.1875,
            34.21875,
            37.34375,
            28.21875,
            35.0625,
            33.9375,
            40.6875,
            35.125,
            21.84375
          ],
          "order_indices": [
            7,
            3,
            1,
            0,
            8,
            5,
            2,
            6,
            4,
            9
          ],
          "order_filenames": [
            "test_383_7.jpg",
            "test_383_3.jpg",
            "test_383_1.jpg",
            "test_383_0.jpg",
            "test_383_8.jpg",
            "test_383_5.jpg",
            "test_383_2.jpg",
            "test_383_6.jpg",
            "test_383_4.jpg",
            "test_383_9.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.15555555555555556,
            "spearman_rho": 0.21212121212121215,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.28242170810699463,
            0.5604454278945923,
            -1.8176040649414062,
            0.5756848454475403,
            -1.22205650806427,
            -0.22277037799358368,
            -0.43487799167633057,
            0.43679162859916687,
            1.2011102437973022,
            0.7720622420310974
          ],
          "order_indices": [
            8,
            9,
            3,
            1,
            7,
            0,
            5,
            6,
            4,
            2
          ],
          "order_filenames": [
            "test_383_8.jpg",
            "test_383_9.jpg",
            "test_383_3.jpg",
            "test_383_1.jpg",
            "test_383_7.jpg",
            "test_383_0.jpg",
            "test_383_5.jpg",
            "test_383_6.jpg",
            "test_383_4.jpg",
            "test_383_2.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.28888888888888886,
            "spearman_rho": -0.4424242424242424,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 384,
      "prompt": "A bowl filled with apple slices and ice cream",
      "image_filenames": [
        "test_384_0.jpg",
        "test_384_1.jpg",
        "test_384_2.jpg",
        "test_384_3.jpg",
        "test_384_4.jpg",
        "test_384_5.jpg",
        "test_384_6.jpg",
        "test_384_7.jpg",
        "test_384_8.jpg",
        "test_384_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          8,
          4,
          5,
          0,
          7,
          3,
          6,
          9,
          2,
          1
        ],
        "order_filenames": [
          "test_384_8.jpg",
          "test_384_4.jpg",
          "test_384_5.jpg",
          "test_384_0.jpg",
          "test_384_7.jpg",
          "test_384_3.jpg",
          "test_384_6.jpg",
          "test_384_9.jpg",
          "test_384_2.jpg",
          "test_384_1.jpg"
        ],
        "condorcet_winner": 8,
        "winner_indices": [
          8
        ],
        "winner_filenames": [
          "test_384_8.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            8
          ],
          "winner_filenames": [
            "test_384_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            8
          ],
          "winner_filenames": [
            "test_384_8.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.18408203125,
            0.21142578125,
            0.28662109375,
            0.1932373046875,
            0.136962890625,
            0.184326171875,
            0.249755859375,
            0.1798095703125,
            0.27294921875,
            0.2509765625
          ],
          "order_indices": [
            2,
            8,
            9,
            6,
            1,
            3,
            5,
            0,
            7,
            4
          ],
          "order_filenames": [
            "test_384_2.jpg",
            "test_384_8.jpg",
            "test_384_9.jpg",
            "test_384_6.jpg",
            "test_384_1.jpg",
            "test_384_3.jpg",
            "test_384_5.jpg",
            "test_384_0.jpg",
            "test_384_7.jpg",
            "test_384_4.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.37777777777777777,
            "spearman_rho": -0.4303030303030304,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.03125,
            26.140625,
            40.4375,
            18.359375,
            28.03125,
            28.890625,
            35.53125,
            36.5,
            38.46875,
            37.90625
          ],
          "order_indices": [
            2,
            8,
            0,
            9,
            7,
            6,
            5,
            4,
            1,
            3
          ],
          "order_filenames": [
            "test_384_2.jpg",
            "test_384_8.jpg",
            "test_384_0.jpg",
            "test_384_9.jpg",
            "test_384_7.jpg",
            "test_384_6.jpg",
            "test_384_5.jpg",
            "test_384_4.jpg",
            "test_384_1.jpg",
            "test_384_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.022222222222222223,
            "spearman_rho": 0.07878787878787874,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.5488332509994507,
            0.15018582344055176,
            1.7657719850540161,
            -0.5659284591674805,
            -1.5141226053237915,
            0.6652207374572754,
            0.315635085105896,
            1.2618104219436646,
            1.870238184928894,
            1.8369545936584473
          ],
          "order_indices": [
            8,
            9,
            2,
            0,
            7,
            5,
            6,
            1,
            3,
            4
          ],
          "order_filenames": [
            "test_384_8.jpg",
            "test_384_9.jpg",
            "test_384_2.jpg",
            "test_384_0.jpg",
            "test_384_7.jpg",
            "test_384_5.jpg",
            "test_384_6.jpg",
            "test_384_1.jpg",
            "test_384_3.jpg",
            "test_384_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.022222222222222223,
            "spearman_rho": 0.042424242424242475,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 1.0,
            "exact_position_match": 0.4,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 385,
      "prompt": "people bicycling near the beach on a bicycle lane",
      "image_filenames": [
        "test_385_0.jpg",
        "test_385_1.jpg",
        "test_385_2.jpg",
        "test_385_3.jpg",
        "test_385_4.jpg",
        "test_385_5.jpg",
        "test_385_6.jpg",
        "test_385_7.jpg",
        "test_385_8.jpg",
        "test_385_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          5,
          3,
          2,
          7,
          1,
          9,
          4,
          8,
          0
        ],
        "order_filenames": [
          "test_385_6.jpg",
          "test_385_5.jpg",
          "test_385_3.jpg",
          "test_385_2.jpg",
          "test_385_7.jpg",
          "test_385_1.jpg",
          "test_385_9.jpg",
          "test_385_4.jpg",
          "test_385_8.jpg",
          "test_385_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_385_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            5,
            6
          ],
          "winner_filenames": [
            "test_385_5.jpg",
            "test_385_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_385_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2283935546875,
            0.22265625,
            0.2744140625,
            0.2110595703125,
            0.217529296875,
            0.165771484375,
            0.2685546875,
            0.19482421875,
            0.2254638671875,
            0.283447265625
          ],
          "order_indices": [
            9,
            2,
            6,
            0,
            8,
            1,
            4,
            3,
            7,
            5
          ],
          "order_filenames": [
            "test_385_9.jpg",
            "test_385_2.jpg",
            "test_385_6.jpg",
            "test_385_0.jpg",
            "test_385_8.jpg",
            "test_385_1.jpg",
            "test_385_4.jpg",
            "test_385_3.jpg",
            "test_385_7.jpg",
            "test_385_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.24444444444444444,
            "spearman_rho": -0.22424242424242413,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.8125,
            37.6875,
            36.1875,
            29.3125,
            31.640625,
            24.03125,
            35.65625,
            27.59375,
            35.09375,
            35.40625
          ],
          "order_indices": [
            1,
            2,
            0,
            6,
            9,
            8,
            4,
            3,
            7,
            5
          ],
          "order_filenames": [
            "test_385_1.jpg",
            "test_385_2.jpg",
            "test_385_0.jpg",
            "test_385_6.jpg",
            "test_385_9.jpg",
            "test_385_8.jpg",
            "test_385_4.jpg",
            "test_385_3.jpg",
            "test_385_7.jpg",
            "test_385_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2,
            "spearman_rho": -0.24848484848484853,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.8679660558700562,
            1.8696938753128052,
            1.936303734779358,
            1.0498484373092651,
            1.8021653890609741,
            -1.0650969743728638,
            1.9342769384384155,
            1.1358124017715454,
            1.7641087770462036,
            1.9178870916366577
          ],
          "order_indices": [
            2,
            6,
            9,
            1,
            0,
            4,
            8,
            7,
            3,
            5
          ],
          "order_filenames": [
            "test_385_2.jpg",
            "test_385_6.jpg",
            "test_385_9.jpg",
            "test_385_1.jpg",
            "test_385_0.jpg",
            "test_385_4.jpg",
            "test_385_8.jpg",
            "test_385_7.jpg",
            "test_385_3.jpg",
            "test_385_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.06666666666666667,
            "spearman_rho": -0.042424242424242475,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 386,
      "prompt": "A high shot of many people standing in an airport. ",
      "image_filenames": [
        "test_386_0.jpg",
        "test_386_1.jpg",
        "test_386_2.jpg",
        "test_386_3.jpg",
        "test_386_4.jpg",
        "test_386_5.jpg",
        "test_386_6.jpg",
        "test_386_7.jpg",
        "test_386_8.jpg",
        "test_386_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          4,
          7,
          2,
          1,
          5,
          3,
          9,
          6,
          8,
          0
        ],
        "order_filenames": [
          "test_386_4.jpg",
          "test_386_7.jpg",
          "test_386_2.jpg",
          "test_386_1.jpg",
          "test_386_5.jpg",
          "test_386_3.jpg",
          "test_386_9.jpg",
          "test_386_6.jpg",
          "test_386_8.jpg",
          "test_386_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          4
        ],
        "winner_filenames": [
          "test_386_4.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_386_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_386_4.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2147216796875,
            0.2685546875,
            0.26513671875,
            0.2366943359375,
            0.208740234375,
            0.1710205078125,
            0.276123046875,
            0.185791015625,
            0.2117919921875,
            0.236083984375
          ],
          "order_indices": [
            6,
            1,
            2,
            3,
            9,
            0,
            8,
            4,
            7,
            5
          ],
          "order_filenames": [
            "test_386_6.jpg",
            "test_386_1.jpg",
            "test_386_2.jpg",
            "test_386_3.jpg",
            "test_386_9.jpg",
            "test_386_0.jpg",
            "test_386_8.jpg",
            "test_386_4.jpg",
            "test_386_7.jpg",
            "test_386_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.23636363636363633,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.5,
            37.6875,
            34.6875,
            34.03125,
            29.6875,
            19.890625,
            36.15625,
            36.375,
            33.5,
            26.640625
          ],
          "order_indices": [
            1,
            0,
            7,
            6,
            2,
            3,
            8,
            4,
            9,
            5
          ],
          "order_filenames": [
            "test_386_1.jpg",
            "test_386_0.jpg",
            "test_386_7.jpg",
            "test_386_6.jpg",
            "test_386_2.jpg",
            "test_386_3.jpg",
            "test_386_8.jpg",
            "test_386_4.jpg",
            "test_386_9.jpg",
            "test_386_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.06666666666666667,
            "spearman_rho": -0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.3996873199939728,
            0.4968971014022827,
            1.451554536819458,
            0.9116648435592651,
            0.37988898158073425,
            -1.8688759803771973,
            1.386985421180725,
            0.598079264163971,
            0.34779635071754456,
            1.1389858722686768
          ],
          "order_indices": [
            2,
            6,
            9,
            3,
            7,
            1,
            0,
            4,
            8,
            5
          ],
          "order_filenames": [
            "test_386_2.jpg",
            "test_386_6.jpg",
            "test_386_9.jpg",
            "test_386_3.jpg",
            "test_386_7.jpg",
            "test_386_1.jpg",
            "test_386_0.jpg",
            "test_386_4.jpg",
            "test_386_8.jpg",
            "test_386_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.022222222222222223,
            "spearman_rho": 0.054545454545454564,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 387,
      "prompt": "A portrait of a dinner dish of a protein and greens.",
      "image_filenames": [
        "test_387_0.jpg",
        "test_387_1.jpg",
        "test_387_2.jpg",
        "test_387_3.jpg",
        "test_387_4.jpg",
        "test_387_5.jpg",
        "test_387_6.jpg",
        "test_387_7.jpg",
        "test_387_8.jpg",
        "test_387_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          9,
          6,
          1,
          4,
          7,
          5,
          8,
          2,
          3,
          0
        ],
        "order_filenames": [
          "test_387_9.jpg",
          "test_387_6.jpg",
          "test_387_1.jpg",
          "test_387_4.jpg",
          "test_387_7.jpg",
          "test_387_5.jpg",
          "test_387_8.jpg",
          "test_387_2.jpg",
          "test_387_3.jpg",
          "test_387_0.jpg"
        ],
        "condorcet_winner": 9,
        "winner_indices": [
          9
        ],
        "winner_filenames": [
          "test_387_9.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            9
          ],
          "winner_filenames": [
            "test_387_9.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            9
          ],
          "winner_filenames": [
            "test_387_9.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.20361328125,
            0.251220703125,
            0.2548828125,
            0.2269287109375,
            0.2265625,
            0.2060546875,
            0.240966796875,
            0.1983642578125,
            0.236572265625,
            0.202880859375
          ],
          "order_indices": [
            2,
            1,
            6,
            8,
            3,
            4,
            5,
            0,
            9,
            7
          ],
          "order_filenames": [
            "test_387_2.jpg",
            "test_387_1.jpg",
            "test_387_6.jpg",
            "test_387_8.jpg",
            "test_387_3.jpg",
            "test_387_4.jpg",
            "test_387_5.jpg",
            "test_387_0.jpg",
            "test_387_9.jpg",
            "test_387_7.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.022222222222222223,
            "spearman_rho": -0.05454545454545445,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            32.46875,
            34.09375,
            32.5,
            29.234375,
            27.90625,
            22.265625,
            29.671875,
            38.09375,
            28.671875,
            24.453125
          ],
          "order_indices": [
            7,
            1,
            2,
            0,
            6,
            3,
            8,
            4,
            9,
            5
          ],
          "order_filenames": [
            "test_387_7.jpg",
            "test_387_1.jpg",
            "test_387_2.jpg",
            "test_387_0.jpg",
            "test_387_6.jpg",
            "test_387_3.jpg",
            "test_387_8.jpg",
            "test_387_4.jpg",
            "test_387_9.jpg",
            "test_387_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.15555555555555556,
            "spearman_rho": -0.16363636363636358,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.4568937122821808,
            -0.30325213074684143,
            -0.29056012630462646,
            -0.26779064536094666,
            -0.9669155478477478,
            -1.296074628829956,
            0.05998143553733826,
            -1.0821456909179688,
            -0.6577340960502625,
            -0.508134126663208
          ],
          "order_indices": [
            6,
            3,
            2,
            1,
            0,
            9,
            8,
            4,
            7,
            5
          ],
          "order_filenames": [
            "test_387_6.jpg",
            "test_387_3.jpg",
            "test_387_2.jpg",
            "test_387_1.jpg",
            "test_387_0.jpg",
            "test_387_9.jpg",
            "test_387_8.jpg",
            "test_387_4.jpg",
            "test_387_7.jpg",
            "test_387_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.022222222222222223,
            "spearman_rho": -0.05454545454545445,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 388,
      "prompt": "A big metal bed frame with no mattress on it.",
      "image_filenames": [
        "test_388_0.jpg",
        "test_388_1.jpg",
        "test_388_2.jpg",
        "test_388_3.jpg",
        "test_388_4.jpg",
        "test_388_5.jpg",
        "test_388_6.jpg",
        "test_388_7.jpg",
        "test_388_8.jpg",
        "test_388_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          5,
          2,
          3,
          4,
          8,
          6,
          7,
          9,
          1,
          0
        ],
        "order_filenames": [
          "test_388_5.jpg",
          "test_388_2.jpg",
          "test_388_3.jpg",
          "test_388_4.jpg",
          "test_388_8.jpg",
          "test_388_6.jpg",
          "test_388_7.jpg",
          "test_388_9.jpg",
          "test_388_1.jpg",
          "test_388_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          5
        ],
        "winner_filenames": [
          "test_388_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_388_3.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2,
            3,
            4,
            5
          ],
          "winner_filenames": [
            "test_388_2.jpg",
            "test_388_3.jpg",
            "test_388_4.jpg",
            "test_388_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2137451171875,
            0.236083984375,
            0.2281494140625,
            0.1998291015625,
            0.1953125,
            0.132080078125,
            0.2479248046875,
            0.2247314453125,
            0.2232666015625,
            0.260009765625
          ],
          "order_indices": [
            9,
            6,
            1,
            2,
            7,
            8,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_388_9.jpg",
            "test_388_6.jpg",
            "test_388_1.jpg",
            "test_388_2.jpg",
            "test_388_7.jpg",
            "test_388_8.jpg",
            "test_388_0.jpg",
            "test_388_3.jpg",
            "test_388_4.jpg",
            "test_388_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.37777777777777777,
            "spearman_rho": -0.5151515151515151,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            33.125,
            31.203125,
            32.53125,
            30.453125,
            26.640625,
            19.15625,
            33.84375,
            31.84375,
            32.875,
            31.40625
          ],
          "order_indices": [
            6,
            0,
            8,
            2,
            7,
            9,
            1,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_388_6.jpg",
            "test_388_0.jpg",
            "test_388_8.jpg",
            "test_388_2.jpg",
            "test_388_7.jpg",
            "test_388_9.jpg",
            "test_388_1.jpg",
            "test_388_3.jpg",
            "test_388_4.jpg",
            "test_388_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.28888888888888886,
            "spearman_rho": -0.4545454545454546,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.2728623151779175,
            -0.2059120386838913,
            0.45226722955703735,
            -0.13140620291233063,
            -0.38280022144317627,
            -2.2746999263763428,
            0.34391841292381287,
            1.1554694175720215,
            0.3022702932357788,
            0.9347882270812988
          ],
          "order_indices": [
            7,
            9,
            2,
            6,
            8,
            0,
            3,
            1,
            4,
            5
          ],
          "order_filenames": [
            "test_388_7.jpg",
            "test_388_9.jpg",
            "test_388_2.jpg",
            "test_388_6.jpg",
            "test_388_8.jpg",
            "test_388_0.jpg",
            "test_388_3.jpg",
            "test_388_1.jpg",
            "test_388_4.jpg",
            "test_388_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.24444444444444444,
            "spearman_rho": -0.3090909090909091,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 389,
      "prompt": "Several different types of cell phones are shown here.",
      "image_filenames": [
        "test_389_0.jpg",
        "test_389_1.jpg",
        "test_389_2.jpg",
        "test_389_3.jpg",
        "test_389_4.jpg",
        "test_389_5.jpg",
        "test_389_6.jpg",
        "test_389_7.jpg",
        "test_389_8.jpg",
        "test_389_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          9,
          0,
          7,
          8,
          6,
          2,
          1,
          5,
          3,
          4
        ],
        "order_filenames": [
          "test_389_9.jpg",
          "test_389_0.jpg",
          "test_389_7.jpg",
          "test_389_8.jpg",
          "test_389_6.jpg",
          "test_389_2.jpg",
          "test_389_1.jpg",
          "test_389_5.jpg",
          "test_389_3.jpg",
          "test_389_4.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          9
        ],
        "winner_filenames": [
          "test_389_9.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            9
          ],
          "winner_filenames": [
            "test_389_9.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            9
          ],
          "winner_filenames": [
            "test_389_9.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1614990234375,
            0.243896484375,
            0.28271484375,
            0.198486328125,
            0.20068359375,
            0.1990966796875,
            0.259033203125,
            0.190673828125,
            0.2232666015625,
            0.260986328125
          ],
          "order_indices": [
            2,
            9,
            6,
            1,
            8,
            4,
            5,
            3,
            7,
            0
          ],
          "order_filenames": [
            "test_389_2.jpg",
            "test_389_9.jpg",
            "test_389_6.jpg",
            "test_389_1.jpg",
            "test_389_8.jpg",
            "test_389_4.jpg",
            "test_389_5.jpg",
            "test_389_3.jpg",
            "test_389_7.jpg",
            "test_389_0.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.022222222222222223,
            "spearman_rho": 0.042424242424242475,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            37.6875,
            30.453125,
            33.875,
            33.21875,
            33.875,
            36.375,
            32.0625,
            38.90625,
            37.59375,
            36.28125
          ],
          "order_indices": [
            7,
            0,
            8,
            5,
            9,
            2,
            4,
            3,
            6,
            1
          ],
          "order_filenames": [
            "test_389_7.jpg",
            "test_389_0.jpg",
            "test_389_8.jpg",
            "test_389_5.jpg",
            "test_389_9.jpg",
            "test_389_2.jpg",
            "test_389_4.jpg",
            "test_389_3.jpg",
            "test_389_6.jpg",
            "test_389_1.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.37777777777777777,
            "spearman_rho": 0.5636363636363637,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.4262295365333557,
            0.5293090343475342,
            0.41116058826446533,
            0.05170123279094696,
            0.563788115978241,
            0.5891388058662415,
            0.5311999917030334,
            0.4628998637199402,
            0.6915181875228882,
            0.7447468638420105
          ],
          "order_indices": [
            9,
            8,
            5,
            4,
            6,
            1,
            7,
            0,
            2,
            3
          ],
          "order_filenames": [
            "test_389_9.jpg",
            "test_389_8.jpg",
            "test_389_5.jpg",
            "test_389_4.jpg",
            "test_389_6.jpg",
            "test_389_1.jpg",
            "test_389_7.jpg",
            "test_389_0.jpg",
            "test_389_2.jpg",
            "test_389_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.15555555555555556,
            "spearman_rho": 0.22424242424242424,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 390,
      "prompt": "The umpire, catcher and batter during a baseball game",
      "image_filenames": [
        "test_390_0.jpg",
        "test_390_1.jpg",
        "test_390_2.jpg",
        "test_390_3.jpg",
        "test_390_4.jpg",
        "test_390_5.jpg",
        "test_390_6.jpg",
        "test_390_7.jpg",
        "test_390_8.jpg",
        "test_390_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          0,
          5,
          4,
          6,
          8,
          9,
          1,
          3,
          2
        ],
        "order_filenames": [
          "test_390_7.jpg",
          "test_390_0.jpg",
          "test_390_5.jpg",
          "test_390_4.jpg",
          "test_390_6.jpg",
          "test_390_8.jpg",
          "test_390_9.jpg",
          "test_390_1.jpg",
          "test_390_3.jpg",
          "test_390_2.jpg"
        ],
        "condorcet_winner": 7,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_390_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_390_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_390_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1993408203125,
            0.29931640625,
            0.2432861328125,
            0.234375,
            0.23095703125,
            0.0767822265625,
            0.226318359375,
            0.1695556640625,
            0.28857421875,
            0.279541015625
          ],
          "order_indices": [
            1,
            8,
            9,
            2,
            3,
            4,
            6,
            0,
            7,
            5
          ],
          "order_filenames": [
            "test_390_1.jpg",
            "test_390_8.jpg",
            "test_390_9.jpg",
            "test_390_2.jpg",
            "test_390_3.jpg",
            "test_390_4.jpg",
            "test_390_6.jpg",
            "test_390_0.jpg",
            "test_390_7.jpg",
            "test_390_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.5555555555555556,
            "spearman_rho": -0.7575757575757576,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            30.5,
            34.625,
            33.8125,
            31.3125,
            33.46875,
            7.546875,
            28.375,
            26.046875,
            33.34375,
            30.484375
          ],
          "order_indices": [
            1,
            2,
            4,
            8,
            3,
            0,
            9,
            6,
            7,
            5
          ],
          "order_filenames": [
            "test_390_1.jpg",
            "test_390_2.jpg",
            "test_390_4.jpg",
            "test_390_8.jpg",
            "test_390_3.jpg",
            "test_390_0.jpg",
            "test_390_9.jpg",
            "test_390_6.jpg",
            "test_390_7.jpg",
            "test_390_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.4666666666666667,
            "spearman_rho": -0.6484848484848484,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.41243845224380493,
            0.06375030428171158,
            0.16252893209457397,
            -0.2616981863975525,
            0.510858416557312,
            -2.2825756072998047,
            0.05221190303564072,
            -0.5738434195518494,
            -0.5679314136505127,
            0.5756028294563293
          ],
          "order_indices": [
            9,
            4,
            2,
            1,
            6,
            3,
            0,
            8,
            7,
            5
          ],
          "order_filenames": [
            "test_390_9.jpg",
            "test_390_4.jpg",
            "test_390_2.jpg",
            "test_390_1.jpg",
            "test_390_6.jpg",
            "test_390_3.jpg",
            "test_390_0.jpg",
            "test_390_8.jpg",
            "test_390_7.jpg",
            "test_390_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.37777777777777777,
            "spearman_rho": -0.5515151515151515,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 391,
      "prompt": "Kids are peering over a fence as a train rolls by.",
      "image_filenames": [
        "test_391_0.jpg",
        "test_391_1.jpg",
        "test_391_2.jpg",
        "test_391_3.jpg",
        "test_391_4.jpg",
        "test_391_5.jpg",
        "test_391_6.jpg",
        "test_391_7.jpg",
        "test_391_8.jpg",
        "test_391_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          6,
          7,
          5,
          2,
          8,
          3,
          4,
          9,
          0,
          1
        ],
        "order_filenames": [
          "test_391_6.jpg",
          "test_391_7.jpg",
          "test_391_5.jpg",
          "test_391_2.jpg",
          "test_391_8.jpg",
          "test_391_3.jpg",
          "test_391_4.jpg",
          "test_391_9.jpg",
          "test_391_0.jpg",
          "test_391_1.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          6
        ],
        "winner_filenames": [
          "test_391_6.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_391_6.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            6
          ],
          "winner_filenames": [
            "test_391_6.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2249755859375,
            0.248046875,
            0.255126953125,
            0.215087890625,
            0.1947021484375,
            0.150390625,
            0.251220703125,
            0.216552734375,
            0.269287109375,
            0.2890625
          ],
          "order_indices": [
            9,
            8,
            2,
            6,
            1,
            0,
            7,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_391_9.jpg",
            "test_391_8.jpg",
            "test_391_2.jpg",
            "test_391_6.jpg",
            "test_391_1.jpg",
            "test_391_0.jpg",
            "test_391_7.jpg",
            "test_391_3.jpg",
            "test_391_4.jpg",
            "test_391_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.11515151515151523,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            43.375,
            37.375,
            43.21875,
            30.59375,
            33.75,
            23.59375,
            38.4375,
            44.125,
            44.25,
            38.59375
          ],
          "order_indices": [
            8,
            7,
            0,
            2,
            9,
            6,
            1,
            4,
            3,
            5
          ],
          "order_filenames": [
            "test_391_8.jpg",
            "test_391_7.jpg",
            "test_391_0.jpg",
            "test_391_2.jpg",
            "test_391_9.jpg",
            "test_391_6.jpg",
            "test_391_1.jpg",
            "test_391_4.jpg",
            "test_391_3.jpg",
            "test_391_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.022222222222222223,
            "spearman_rho": 0.06666666666666665,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.4131196737289429,
            0.5098389983177185,
            1.7758573293685913,
            0.45930543541908264,
            -0.49882620573043823,
            -1.7481462955474854,
            0.5000149011611938,
            0.9343613982200623,
            1.4490914344787598,
            1.1945017576217651
          ],
          "order_indices": [
            2,
            8,
            0,
            9,
            7,
            1,
            6,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_391_2.jpg",
            "test_391_8.jpg",
            "test_391_0.jpg",
            "test_391_9.jpg",
            "test_391_7.jpg",
            "test_391_1.jpg",
            "test_391_6.jpg",
            "test_391_3.jpg",
            "test_391_4.jpg",
            "test_391_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.06666666666666667,
            "spearman_rho": -0.1393939393939394,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 392,
      "prompt": "Three cows eating in a field with sea in background.",
      "image_filenames": [
        "test_392_0.jpg",
        "test_392_1.jpg",
        "test_392_2.jpg",
        "test_392_3.jpg",
        "test_392_4.jpg",
        "test_392_5.jpg",
        "test_392_6.jpg",
        "test_392_7.jpg",
        "test_392_8.jpg",
        "test_392_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          2,
          3,
          5,
          7,
          6,
          4,
          8,
          9,
          0
        ],
        "order_filenames": [
          "test_392_1.jpg",
          "test_392_2.jpg",
          "test_392_3.jpg",
          "test_392_5.jpg",
          "test_392_7.jpg",
          "test_392_6.jpg",
          "test_392_4.jpg",
          "test_392_8.jpg",
          "test_392_9.jpg",
          "test_392_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_392_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            3,
            4,
            7,
            8
          ],
          "winner_filenames": [
            "test_392_3.jpg",
            "test_392_4.jpg",
            "test_392_7.jpg",
            "test_392_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            3
          ],
          "winner_filenames": [
            "test_392_3.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.1917724609375,
            0.26318359375,
            0.2734375,
            0.1934814453125,
            0.217041015625,
            0.19287109375,
            0.2183837890625,
            0.2215576171875,
            0.260009765625,
            0.237060546875
          ],
          "order_indices": [
            2,
            1,
            8,
            9,
            7,
            6,
            4,
            3,
            5,
            0
          ],
          "order_filenames": [
            "test_392_2.jpg",
            "test_392_1.jpg",
            "test_392_8.jpg",
            "test_392_9.jpg",
            "test_392_7.jpg",
            "test_392_6.jpg",
            "test_392_4.jpg",
            "test_392_3.jpg",
            "test_392_5.jpg",
            "test_392_0.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.24444444444444444,
            "spearman_rho": 0.38181818181818183,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.4,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.03125,
            37.78125,
            36.375,
            24.296875,
            38.0625,
            33.25,
            34.1875,
            37.65625,
            42.65625,
            31.0625
          ],
          "order_indices": [
            8,
            4,
            1,
            7,
            2,
            0,
            6,
            5,
            9,
            3
          ],
          "order_filenames": [
            "test_392_8.jpg",
            "test_392_4.jpg",
            "test_392_1.jpg",
            "test_392_7.jpg",
            "test_392_2.jpg",
            "test_392_0.jpg",
            "test_392_6.jpg",
            "test_392_5.jpg",
            "test_392_9.jpg",
            "test_392_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.06666666666666667,
            "spearman_rho": -0.030303030303030276,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.22748233377933502,
            0.9534227252006531,
            1.3655996322631836,
            -2.000046730041504,
            0.36600083112716675,
            -0.21472597122192383,
            -0.2974609136581421,
            0.6465182304382324,
            1.110951542854309,
            1.3720040321350098
          ],
          "order_indices": [
            9,
            2,
            8,
            1,
            7,
            4,
            0,
            5,
            6,
            3
          ],
          "order_filenames": [
            "test_392_9.jpg",
            "test_392_2.jpg",
            "test_392_8.jpg",
            "test_392_1.jpg",
            "test_392_7.jpg",
            "test_392_4.jpg",
            "test_392_0.jpg",
            "test_392_5.jpg",
            "test_392_6.jpg",
            "test_392_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.1111111111111111,
            "spearman_rho": -0.10303030303030303,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 393,
      "prompt": "A tall giraffe is eating out of a basket.",
      "image_filenames": [
        "test_393_0.jpg",
        "test_393_1.jpg",
        "test_393_2.jpg",
        "test_393_3.jpg",
        "test_393_4.jpg",
        "test_393_5.jpg",
        "test_393_6.jpg",
        "test_393_7.jpg",
        "test_393_8.jpg",
        "test_393_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          3,
          5,
          7,
          4,
          6,
          9,
          8,
          2,
          1,
          0
        ],
        "order_filenames": [
          "test_393_3.jpg",
          "test_393_5.jpg",
          "test_393_7.jpg",
          "test_393_4.jpg",
          "test_393_6.jpg",
          "test_393_9.jpg",
          "test_393_8.jpg",
          "test_393_2.jpg",
          "test_393_1.jpg",
          "test_393_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          3,
          5
        ],
        "winner_filenames": [
          "test_393_3.jpg",
          "test_393_5.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            2,
            5,
            7,
            8
          ],
          "winner_filenames": [
            "test_393_2.jpg",
            "test_393_5.jpg",
            "test_393_7.jpg",
            "test_393_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            5
          ],
          "winner_filenames": [
            "test_393_5.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2081298828125,
            0.262451171875,
            0.22705078125,
            0.1817626953125,
            0.1883544921875,
            0.212890625,
            0.2103271484375,
            0.201416015625,
            0.262451171875,
            0.3046875
          ],
          "order_indices": [
            9,
            1,
            8,
            2,
            5,
            6,
            0,
            7,
            4,
            3
          ],
          "order_filenames": [
            "test_393_9.jpg",
            "test_393_1.jpg",
            "test_393_8.jpg",
            "test_393_2.jpg",
            "test_393_5.jpg",
            "test_393_6.jpg",
            "test_393_0.jpg",
            "test_393_7.jpg",
            "test_393_4.jpg",
            "test_393_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.37777777777777777,
            "spearman_rho": -0.5515151515151515,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            38.59375,
            31.59375,
            25.78125,
            29.671875,
            29.203125,
            31.421875,
            25.671875,
            34.3125,
            34.3125,
            34.5
          ],
          "order_indices": [
            0,
            9,
            7,
            8,
            1,
            5,
            3,
            4,
            2,
            6
          ],
          "order_filenames": [
            "test_393_0.jpg",
            "test_393_9.jpg",
            "test_393_7.jpg",
            "test_393_8.jpg",
            "test_393_1.jpg",
            "test_393_5.jpg",
            "test_393_3.jpg",
            "test_393_4.jpg",
            "test_393_2.jpg",
            "test_393_6.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2,
            "spearman_rho": -0.3090909090909091,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.2704697847366333,
            0.0395183227956295,
            -2.0754284858703613,
            -2.1334354877471924,
            -1.2194459438323975,
            -0.6950139999389648,
            -1.4468921422958374,
            0.05675739794969559,
            -0.42201516032218933,
            0.7187761664390564
          ],
          "order_indices": [
            0,
            9,
            7,
            1,
            8,
            5,
            4,
            6,
            2,
            3
          ],
          "order_filenames": [
            "test_393_0.jpg",
            "test_393_9.jpg",
            "test_393_7.jpg",
            "test_393_1.jpg",
            "test_393_8.jpg",
            "test_393_5.jpg",
            "test_393_4.jpg",
            "test_393_6.jpg",
            "test_393_2.jpg",
            "test_393_3.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.3333333333333333,
            "spearman_rho": -0.46666666666666656,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 394,
      "prompt": "Group of birds sitting on top of a television antenna on a building. ",
      "image_filenames": [
        "test_394_0.jpg",
        "test_394_1.jpg",
        "test_394_2.jpg",
        "test_394_3.jpg",
        "test_394_4.jpg",
        "test_394_5.jpg",
        "test_394_6.jpg",
        "test_394_7.jpg",
        "test_394_8.jpg",
        "test_394_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          0,
          6,
          7,
          1,
          2,
          8,
          5,
          9,
          3,
          4
        ],
        "order_filenames": [
          "test_394_0.jpg",
          "test_394_6.jpg",
          "test_394_7.jpg",
          "test_394_1.jpg",
          "test_394_2.jpg",
          "test_394_8.jpg",
          "test_394_5.jpg",
          "test_394_9.jpg",
          "test_394_3.jpg",
          "test_394_4.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          0
        ],
        "winner_filenames": [
          "test_394_0.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_394_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            0,
            7
          ],
          "winner_filenames": [
            "test_394_0.jpg",
            "test_394_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.226806640625,
            0.297607421875,
            0.263427734375,
            0.2108154296875,
            0.19580078125,
            0.204833984375,
            0.2822265625,
            0.2318115234375,
            0.250732421875,
            0.2030029296875
          ],
          "order_indices": [
            1,
            6,
            2,
            8,
            7,
            0,
            3,
            5,
            9,
            4
          ],
          "order_filenames": [
            "test_394_1.jpg",
            "test_394_6.jpg",
            "test_394_2.jpg",
            "test_394_8.jpg",
            "test_394_7.jpg",
            "test_394_0.jpg",
            "test_394_3.jpg",
            "test_394_5.jpg",
            "test_394_9.jpg",
            "test_394_4.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.5111111111111111,
            "spearman_rho": 0.6848484848484848,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            42.5,
            37.46875,
            40.625,
            27.578125,
            30.0625,
            34.03125,
            37.59375,
            41.625,
            43.34375,
            31.984375
          ],
          "order_indices": [
            8,
            0,
            7,
            2,
            6,
            1,
            5,
            9,
            4,
            3
          ],
          "order_filenames": [
            "test_394_8.jpg",
            "test_394_0.jpg",
            "test_394_7.jpg",
            "test_394_2.jpg",
            "test_394_6.jpg",
            "test_394_1.jpg",
            "test_394_5.jpg",
            "test_394_9.jpg",
            "test_394_4.jpg",
            "test_394_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.6,
            "spearman_rho": 0.7454545454545455,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.2308335155248642,
            1.0484236478805542,
            0.6209303736686707,
            -1.7603095769882202,
            -0.6060351729393005,
            -0.23966926336288452,
            0.03685364872217178,
            0.10171360522508621,
            0.8688291311264038,
            -0.3323802649974823
          ],
          "order_indices": [
            1,
            8,
            2,
            0,
            7,
            6,
            5,
            9,
            4,
            3
          ],
          "order_filenames": [
            "test_394_1.jpg",
            "test_394_8.jpg",
            "test_394_2.jpg",
            "test_394_0.jpg",
            "test_394_7.jpg",
            "test_394_6.jpg",
            "test_394_5.jpg",
            "test_394_9.jpg",
            "test_394_4.jpg",
            "test_394_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.4666666666666667,
            "spearman_rho": 0.6363636363636364,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 395,
      "prompt": "a group of people wearing ski equipment on a snowy field",
      "image_filenames": [
        "test_395_0.jpg",
        "test_395_1.jpg",
        "test_395_2.jpg",
        "test_395_3.jpg",
        "test_395_4.jpg",
        "test_395_5.jpg",
        "test_395_6.jpg",
        "test_395_7.jpg",
        "test_395_8.jpg",
        "test_395_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          7,
          1,
          6,
          5,
          0,
          2,
          8,
          9,
          4,
          3
        ],
        "order_filenames": [
          "test_395_7.jpg",
          "test_395_1.jpg",
          "test_395_6.jpg",
          "test_395_5.jpg",
          "test_395_0.jpg",
          "test_395_2.jpg",
          "test_395_8.jpg",
          "test_395_9.jpg",
          "test_395_4.jpg",
          "test_395_3.jpg"
        ],
        "condorcet_winner": 7,
        "winner_indices": [
          7
        ],
        "winner_filenames": [
          "test_395_7.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_395_7.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            7
          ],
          "winner_filenames": [
            "test_395_7.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2310791015625,
            0.305419921875,
            0.320068359375,
            0.2568359375,
            0.25244140625,
            0.1455078125,
            0.29150390625,
            0.18408203125,
            0.2958984375,
            0.2783203125
          ],
          "order_indices": [
            2,
            1,
            8,
            6,
            9,
            3,
            4,
            0,
            7,
            5
          ],
          "order_filenames": [
            "test_395_2.jpg",
            "test_395_1.jpg",
            "test_395_8.jpg",
            "test_395_6.jpg",
            "test_395_9.jpg",
            "test_395_3.jpg",
            "test_395_4.jpg",
            "test_395_0.jpg",
            "test_395_7.jpg",
            "test_395_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.022222222222222223,
            "spearman_rho": -0.09090909090909083,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            35.28125,
            34.6875,
            33.125,
            33.0625,
            35.9375,
            25.0,
            33.625,
            30.9375,
            40.96875,
            34.40625
          ],
          "order_indices": [
            8,
            4,
            0,
            1,
            9,
            6,
            2,
            3,
            7,
            5
          ],
          "order_filenames": [
            "test_395_8.jpg",
            "test_395_4.jpg",
            "test_395_0.jpg",
            "test_395_1.jpg",
            "test_395_9.jpg",
            "test_395_6.jpg",
            "test_395_2.jpg",
            "test_395_3.jpg",
            "test_395_7.jpg",
            "test_395_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.2,
            "spearman_rho": -0.3090909090909091,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.0,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.518378496170044,
            0.8537490963935852,
            0.8274319767951965,
            0.2261601835489273,
            0.4919271171092987,
            -1.972222924232483,
            0.9092556238174438,
            -1.216445803642273,
            0.9487621784210205,
            0.41211140155792236
          ],
          "order_indices": [
            8,
            6,
            1,
            2,
            0,
            4,
            9,
            3,
            7,
            5
          ],
          "order_filenames": [
            "test_395_8.jpg",
            "test_395_6.jpg",
            "test_395_1.jpg",
            "test_395_2.jpg",
            "test_395_0.jpg",
            "test_395_4.jpg",
            "test_395_9.jpg",
            "test_395_3.jpg",
            "test_395_7.jpg",
            "test_395_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.06666666666666667,
            "spearman_rho": 0.054545454545454564,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 396,
      "prompt": "A stop sign with the phrase \"hammer time\" written on it. ",
      "image_filenames": [
        "test_396_0.jpg",
        "test_396_1.jpg",
        "test_396_2.jpg",
        "test_396_3.jpg",
        "test_396_4.jpg",
        "test_396_5.jpg",
        "test_396_6.jpg",
        "test_396_7.jpg",
        "test_396_8.jpg",
        "test_396_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          8,
          1,
          9,
          6,
          4,
          7,
          5,
          2,
          3,
          0
        ],
        "order_filenames": [
          "test_396_8.jpg",
          "test_396_1.jpg",
          "test_396_9.jpg",
          "test_396_6.jpg",
          "test_396_4.jpg",
          "test_396_7.jpg",
          "test_396_5.jpg",
          "test_396_2.jpg",
          "test_396_3.jpg",
          "test_396_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          8
        ],
        "winner_filenames": [
          "test_396_8.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            8
          ],
          "winner_filenames": [
            "test_396_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1,
            8
          ],
          "winner_filenames": [
            "test_396_1.jpg",
            "test_396_8.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2041015625,
            0.2083740234375,
            0.220703125,
            0.1827392578125,
            0.22265625,
            0.211181640625,
            0.216552734375,
            0.2138671875,
            0.2548828125,
            0.2578125
          ],
          "order_indices": [
            9,
            8,
            4,
            2,
            6,
            7,
            5,
            1,
            0,
            3
          ],
          "order_filenames": [
            "test_396_9.jpg",
            "test_396_8.jpg",
            "test_396_4.jpg",
            "test_396_2.jpg",
            "test_396_6.jpg",
            "test_396_7.jpg",
            "test_396_5.jpg",
            "test_396_1.jpg",
            "test_396_0.jpg",
            "test_396_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.4666666666666667,
            "spearman_rho": 0.6121212121212121,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            42.03125,
            31.390625,
            25.453125,
            25.234375,
            31.78125,
            29.5625,
            27.625,
            45.1875,
            37.625,
            42.46875
          ],
          "order_indices": [
            7,
            9,
            0,
            8,
            4,
            1,
            5,
            6,
            2,
            3
          ],
          "order_filenames": [
            "test_396_7.jpg",
            "test_396_9.jpg",
            "test_396_0.jpg",
            "test_396_8.jpg",
            "test_396_4.jpg",
            "test_396_1.jpg",
            "test_396_5.jpg",
            "test_396_6.jpg",
            "test_396_2.jpg",
            "test_396_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.24444444444444444,
            "spearman_rho": 0.2848484848484848,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            -0.09902127087116241,
            -0.5734061002731323,
            -1.084405541419983,
            -2.0934865474700928,
            -0.4818517565727234,
            -1.4746794700622559,
            -2.1138203144073486,
            0.021781081333756447,
            1.053953766822815,
            -0.1362481713294983
          ],
          "order_indices": [
            8,
            7,
            0,
            9,
            4,
            1,
            2,
            5,
            3,
            6
          ],
          "order_filenames": [
            "test_396_8.jpg",
            "test_396_7.jpg",
            "test_396_0.jpg",
            "test_396_9.jpg",
            "test_396_4.jpg",
            "test_396_1.jpg",
            "test_396_2.jpg",
            "test_396_5.jpg",
            "test_396_3.jpg",
            "test_396_6.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.2,
            "spearman_rho": 0.2727272727272727,
            "top1_match": 1.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3,
            "winner_agreement_borda": 1.0,
            "winner_agreement_plurality": 1.0,
            "winner_agreement_copeland": 1.0
          }
        }
      }
    },
    {
      "prompt_index": 397,
      "prompt": "Several bunches of unripened bananas growing from trees.",
      "image_filenames": [
        "test_397_0.jpg",
        "test_397_1.jpg",
        "test_397_2.jpg",
        "test_397_3.jpg",
        "test_397_4.jpg",
        "test_397_5.jpg",
        "test_397_6.jpg",
        "test_397_7.jpg",
        "test_397_8.jpg",
        "test_397_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          1,
          4,
          2,
          5,
          9,
          0,
          6,
          7,
          8,
          3
        ],
        "order_filenames": [
          "test_397_1.jpg",
          "test_397_4.jpg",
          "test_397_2.jpg",
          "test_397_5.jpg",
          "test_397_9.jpg",
          "test_397_0.jpg",
          "test_397_6.jpg",
          "test_397_7.jpg",
          "test_397_8.jpg",
          "test_397_3.jpg"
        ],
        "condorcet_winner": 1,
        "winner_indices": [
          1
        ],
        "winner_filenames": [
          "test_397_1.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_397_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            1
          ],
          "winner_filenames": [
            "test_397_1.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2242431640625,
            0.27783203125,
            0.3125,
            0.1639404296875,
            0.206787109375,
            0.182861328125,
            0.22265625,
            0.2705078125,
            0.22509765625,
            0.2391357421875
          ],
          "order_indices": [
            2,
            1,
            7,
            9,
            8,
            0,
            6,
            4,
            5,
            3
          ],
          "order_filenames": [
            "test_397_2.jpg",
            "test_397_1.jpg",
            "test_397_7.jpg",
            "test_397_9.jpg",
            "test_397_8.jpg",
            "test_397_0.jpg",
            "test_397_6.jpg",
            "test_397_4.jpg",
            "test_397_5.jpg",
            "test_397_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.24444444444444444,
            "spearman_rho": 0.34545454545454546,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.3,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.65625,
            32.96875,
            34.78125,
            18.234375,
            34.0625,
            31.28125,
            33.46875,
            34.90625,
            33.96875,
            33.78125
          ],
          "order_indices": [
            0,
            7,
            2,
            4,
            8,
            9,
            6,
            1,
            5,
            3
          ],
          "order_filenames": [
            "test_397_0.jpg",
            "test_397_7.jpg",
            "test_397_2.jpg",
            "test_397_4.jpg",
            "test_397_8.jpg",
            "test_397_9.jpg",
            "test_397_6.jpg",
            "test_397_1.jpg",
            "test_397_5.jpg",
            "test_397_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.022222222222222223,
            "spearman_rho": 0.054545454545454564,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.3,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.1726600080728531,
            0.2770853042602539,
            0.3516858220100403,
            -1.7508275508880615,
            0.07526715099811554,
            -0.6169737577438354,
            -1.4867666959762573,
            0.4200880825519562,
            0.0781991109251976,
            0.1361865997314453
          ],
          "order_indices": [
            7,
            2,
            1,
            0,
            9,
            8,
            4,
            5,
            6,
            3
          ],
          "order_filenames": [
            "test_397_7.jpg",
            "test_397_2.jpg",
            "test_397_1.jpg",
            "test_397_0.jpg",
            "test_397_9.jpg",
            "test_397_8.jpg",
            "test_397_4.jpg",
            "test_397_5.jpg",
            "test_397_6.jpg",
            "test_397_3.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.24444444444444444,
            "spearman_rho": 0.32121212121212117,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": 0.0,
            "exact_position_match": 0.2,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 398,
      "prompt": "a cellphone standing on a counter next to a small statue of buddy christ",
      "image_filenames": [
        "test_398_0.jpg",
        "test_398_1.jpg",
        "test_398_2.jpg",
        "test_398_3.jpg",
        "test_398_4.jpg",
        "test_398_5.jpg",
        "test_398_6.jpg",
        "test_398_7.jpg",
        "test_398_8.jpg",
        "test_398_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          8,
          2,
          7,
          1,
          9,
          5,
          0,
          6,
          4,
          3
        ],
        "order_filenames": [
          "test_398_8.jpg",
          "test_398_2.jpg",
          "test_398_7.jpg",
          "test_398_1.jpg",
          "test_398_9.jpg",
          "test_398_5.jpg",
          "test_398_0.jpg",
          "test_398_6.jpg",
          "test_398_4.jpg",
          "test_398_3.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          8
        ],
        "winner_filenames": [
          "test_398_8.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            8
          ],
          "winner_filenames": [
            "test_398_8.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2,
            8
          ],
          "winner_filenames": [
            "test_398_2.jpg",
            "test_398_8.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.15966796875,
            0.273681640625,
            0.26513671875,
            0.1593017578125,
            0.1341552734375,
            0.130615234375,
            0.252197265625,
            0.1824951171875,
            0.2122802734375,
            0.2408447265625
          ],
          "order_indices": [
            1,
            2,
            6,
            9,
            8,
            7,
            0,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_398_1.jpg",
            "test_398_2.jpg",
            "test_398_6.jpg",
            "test_398_9.jpg",
            "test_398_8.jpg",
            "test_398_7.jpg",
            "test_398_0.jpg",
            "test_398_3.jpg",
            "test_398_4.jpg",
            "test_398_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.5151515151515151,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.3,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            41.78125,
            45.25,
            48.53125,
            25.0625,
            21.6875,
            24.09375,
            34.3125,
            35.15625,
            43.125,
            21.671875
          ],
          "order_indices": [
            2,
            1,
            8,
            0,
            7,
            6,
            3,
            5,
            4,
            9
          ],
          "order_filenames": [
            "test_398_2.jpg",
            "test_398_1.jpg",
            "test_398_8.jpg",
            "test_398_0.jpg",
            "test_398_7.jpg",
            "test_398_6.jpg",
            "test_398_3.jpg",
            "test_398_5.jpg",
            "test_398_4.jpg",
            "test_398_9.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.4222222222222222,
            "spearman_rho": 0.6121212121212121,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 1.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            1.195031762123108,
            1.3044402599334717,
            1.6210987567901611,
            -1.672196626663208,
            -1.8657134771347046,
            -2.0632286071777344,
            0.6220300197601318,
            1.3090834617614746,
            0.9642441272735596,
            1.7725242376327515
          ],
          "order_indices": [
            9,
            2,
            7,
            1,
            0,
            8,
            6,
            3,
            4,
            5
          ],
          "order_filenames": [
            "test_398_9.jpg",
            "test_398_2.jpg",
            "test_398_7.jpg",
            "test_398_1.jpg",
            "test_398_0.jpg",
            "test_398_8.jpg",
            "test_398_6.jpg",
            "test_398_3.jpg",
            "test_398_4.jpg",
            "test_398_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.4222222222222222,
            "spearman_rho": 0.6,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.4,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    },
    {
      "prompt_index": 399,
      "prompt": "a train on a track with a car near by",
      "image_filenames": [
        "test_399_0.jpg",
        "test_399_1.jpg",
        "test_399_2.jpg",
        "test_399_3.jpg",
        "test_399_4.jpg",
        "test_399_5.jpg",
        "test_399_6.jpg",
        "test_399_7.jpg",
        "test_399_8.jpg",
        "test_399_9.jpg"
      ],
      "human_consensus": {
        "order_indices": [
          2,
          3,
          4,
          5,
          6,
          7,
          9,
          1,
          8,
          0
        ],
        "order_filenames": [
          "test_399_2.jpg",
          "test_399_3.jpg",
          "test_399_4.jpg",
          "test_399_5.jpg",
          "test_399_6.jpg",
          "test_399_7.jpg",
          "test_399_9.jpg",
          "test_399_1.jpg",
          "test_399_8.jpg",
          "test_399_0.jpg"
        ],
        "condorcet_winner": null,
        "winner_indices": [
          2
        ],
        "winner_filenames": [
          "test_399_2.jpg"
        ]
      },
      "voting_rules": {
        "plurality": {
          "winner_indices": [
            4
          ],
          "winner_filenames": [
            "test_399_4.jpg"
          ]
        },
        "copeland": {
          "winner_indices": [
            2
          ],
          "winner_filenames": [
            "test_399_2.jpg"
          ]
        }
      },
      "models": {
        "hpsv2::v2.1": {
          "scores": [
            0.2216796875,
            0.22802734375,
            0.26220703125,
            0.24072265625,
            0.2301025390625,
            0.1495361328125,
            0.262451171875,
            0.212646484375,
            0.15966796875,
            0.259033203125
          ],
          "order_indices": [
            6,
            2,
            9,
            3,
            4,
            1,
            0,
            7,
            8,
            5
          ],
          "order_filenames": [
            "test_399_6.jpg",
            "test_399_2.jpg",
            "test_399_9.jpg",
            "test_399_3.jpg",
            "test_399_4.jpg",
            "test_399_1.jpg",
            "test_399_0.jpg",
            "test_399_7.jpg",
            "test_399_8.jpg",
            "test_399_5.jpg"
          ],
          "metrics": {
            "kendall_tau": 0.3333333333333333,
            "spearman_rho": 0.4303030303030303,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "open_clip::ViT-H-14::laion2b_s32b_b79k": {
          "scores": [
            36.5,
            30.046875,
            26.921875,
            31.28125,
            31.765625,
            26.359375,
            38.8125,
            35.6875,
            30.71875,
            35.21875
          ],
          "order_indices": [
            6,
            0,
            7,
            9,
            4,
            3,
            8,
            1,
            2,
            5
          ],
          "order_filenames": [
            "test_399_6.jpg",
            "test_399_0.jpg",
            "test_399_7.jpg",
            "test_399_9.jpg",
            "test_399_4.jpg",
            "test_399_3.jpg",
            "test_399_8.jpg",
            "test_399_1.jpg",
            "test_399_2.jpg",
            "test_399_5.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.24444444444444444,
            "spearman_rho": -0.34545454545454546,
            "top1_match": 0.0,
            "top3_overlap": 0.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        },
        "image_reward::ImageReward-v1.0": {
          "scores": [
            0.11995283514261246,
            -0.18004071712493896,
            -0.9821475744247437,
            0.42519867420196533,
            -0.19785764813423157,
            -0.7406102418899536,
            1.754464864730835,
            0.11391617357730865,
            -0.9365590214729309,
            1.8143911361694336
          ],
          "order_indices": [
            9,
            6,
            3,
            0,
            7,
            1,
            4,
            5,
            8,
            2
          ],
          "order_filenames": [
            "test_399_9.jpg",
            "test_399_6.jpg",
            "test_399_3.jpg",
            "test_399_0.jpg",
            "test_399_7.jpg",
            "test_399_1.jpg",
            "test_399_4.jpg",
            "test_399_5.jpg",
            "test_399_8.jpg",
            "test_399_2.jpg"
          ],
          "metrics": {
            "kendall_tau": -0.15555555555555556,
            "spearman_rho": -0.21212121212121215,
            "top1_match": 0.0,
            "top3_overlap": 1.0,
            "condorcet_top1": null,
            "exact_position_match": 0.1,
            "winner_agreement_borda": 0.0,
            "winner_agreement_plurality": 0.0,
            "winner_agreement_copeland": 0.0
          }
        }
      }
    }
  ],
  "summary": {
    "hpsv2::v2.1": {
      "kendall_tau": -0.07791666666666666,
      "spearman_rho": -0.10655681818181818,
      "top1_match": 0.0825,
      "top3_overlap": 0.685,
      "condorcet_top1": 0.05161290322580645,
      "exact_position_match": 0.09152777777777778,
      "winner_agreement_borda": 0.09,
      "winner_agreement_plurality": 0.06,
      "winner_agreement_copeland": 0.095,
      "prompts_evaluated": 400
    },
    "open_clip::ViT-H-14::laion2b_s32b_b79k": {
      "kendall_tau": -0.09602777777777778,
      "spearman_rho": -0.13295075757575758,
      "top1_match": 0.0725,
      "top3_overlap": 0.65,
      "condorcet_top1": 0.06451612903225806,
      "exact_position_match": 0.08727777777777777,
      "winner_agreement_borda": 0.0825,
      "winner_agreement_plurality": 0.11,
      "winner_agreement_copeland": 0.0825,
      "prompts_evaluated": 400
    },
    "image_reward::ImageReward-v1.0": {
      "kendall_tau": -0.08402777777777777,
      "spearman_rho": -0.11461363636363636,
      "top1_match": 0.0725,
      "top3_overlap": 0.67,
      "condorcet_top1": 0.05806451612903226,
      "exact_position_match": 0.09347222222222222,
      "winner_agreement_borda": 0.075,
      "winner_agreement_plurality": 0.0875,
      "winner_agreement_copeland": 0.0975,
      "prompts_evaluated": 400
    }
  }
}